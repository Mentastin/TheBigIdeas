\chapter{What is logic?}
In this part some useful concepts from logic will be discussed.

The word ``logic'' comes from the ancient greek word \textgreek{λόγος} that originally meant ``word'', but came to mean ``thought'' and ``reason'' as well. Most historical surveys of logic start with the ancient Greeks. The big name in this context is Aristotle (384–322 BC). He introduced many core concepts of logic, such as terms, predicates, propositions and syllogisms. Stoic logic was also very influential.

During the medieval period, scholasticism was the dominant method of critical thought. The scholastics were mainly interested in reconciling Christian theology with classical philosophy. For modern logic William of Ockham (1287 – 1347) is of particular note.

The next big innovation (if fact in many ways the first big innovation since Aristotle) is the development of symbolic logic. This development was started in 1854 by George Boole who introduced the principles of what is now called Boolean algebra. In 1879 Gottlob Frege pushes this concept further with the publishing of his \textit{Begriffsschrift}. His aim was to construct a ``formula language of pure thought'', such that it would be possible to prove all truths of arithmetic deductively from a limited number of logical axioms.

The theory that all mathematics can ultimately be deduced from purely formal logical axioms is called logicism. This programme was championed by Bertrand Russell and Alfred Whitehead who published \textit{Principia Mathematica} together in three volumes (1910, 1912 and 1913). 

Around this time mathematics was suffering its foundational crisis. This is a fascinating topic, both from a technical and historical perspective, but not one I wish to get into here. It suffices to say that from then on logic was of utmost importance to both philosophy and mathematics. When computers started appearing, computer scientist realised that Boolean algebra was a very useful basis on which to build much of theoretical (and less theoretical) computer science and also wanted a piece of the pie. Logic is now taught and studied at three different faculties; consequently there is a lot of competing notation when it comes to logic.

\section{Platonism, formalism and intuitionism}
TODO

\section{Logical formal systems}
\subsection{Syntactic elements}
\subsection{Semantics}
A formal system is essentially only a particular way to write symbols on paper (i.e. a \textit{text}). In theory these symbols do not actually need to mean anything, although in practice we will not consider any formal systems that do not have a useful interpretation. In fact in subsequent chapters the interpretation will guide the construction of the formal systems and suggest inference rules. If a formal system has a particular interpretation, we say it is a \udef{model} for that interpretation.

The \udef{semantics} of a formal system essentially tells us what it means for a formula to be written in a text.

\begin{example}
In logic, the meaning of a formula having been written in a proof is typically that it is true (assuming the premises are true).

In a calculation the meaning is typically that it has the same value as the premise.
\end{example}

Once that meaning (i.e. the interpretation) has been fixed, it may be possible to \textit{empirically} see that some formulae must be conclusions. These so-called semantic conclusions are written using $\models$ instead of $\vdash$.

If a formal model accurately models its interpretation then $\models$ and $\vdash$ are interchangeable.

\begin{example}
In a logical system that models arithmetic, $5$ should be a conclusion of $2+3$, because empirically if you take two things and then three, you get five things. Luckily the rules of arithmetic allow us to calculate $5$ from $2+3$, so in this case the model is accurate.
\end{example}


\chapter{Propositional logic}
TODO: rewrite.
When symbolic logic was first introduced, it was in a form similar to this. The basic building blocks of propositional logic are propositions. They are essentially assertions that may be true or false, for example
\begin{itemize}
\item Socrates is bald;
\item It is raining;
\item Circle $A$ is bigger than circle $B$;
\item \ldots
\end{itemize}

Such assertions are assigned letters (traditionally the letters $p,q,r,s, \ldots$) are used. Propositional logic cannot say anything about elements smaller than a proposition - for example it would not be possible to say that for any circle $A$ there is a circle bigger than $A$ - only whether a proposition is true or false.

Where propositional logic is useful on the other hand, is in stringing multiple propositions together. This can be done using several different connectives. Thus, for example, from the propositions ``Socrates is bald'' and ``Socrates is wearing a hat'' we may infer ``Socrates is bald \textbf{and} is wearing a hat''.

\section{Syntax}
In propositional logic the alphabet consists of three sorts of symbols: letters for primitive propositions, symbols for the logical connectives (like he \textbf{and} above) and parentheses for resolving ambiguities:
\begin{enumerate}
\item Primitive propositions, denoted $p,q,r,s, \ldots$;
\item \udef{Connectives}:
\begin{enumerate}
\item $\neg$ which represents a negation,
\item $\lor$ which represents the disjunction \textbf{or}
\item $\land$ which represents the conjunction \textbf{and},
\item $\implies$ which represents the implication \textbf{if $\ldots$ then} and
\item $\iff$ which represents the equivalence \textbf{if and only if};
\end{enumerate}
\item Parentheses: $($ and $)$.
\end{enumerate}
We can then define wffs recursively in the following manner:
\begin{enumerate}
\item The characters $p,q,r,s, \ldots$ are wffs;
\item If $A$ is a wff, then $\neg A$ is a wff;
\item If $A$ and $B$ are wffs, then
\begin{enumerate}
\item $A \lor B$,
\item $A \land B$,
\item $A \implies B$ and
\item $A \iff B$
\end{enumerate}
are wffs;
\item Nothing else is a wff.
\end{enumerate}

The connectives $\land, \lor, \implies$ and $\iff$ are called \udef{binary} because they ``connect'' two wffs. The connective $\neg$ is called \udef{unitary}.

Based on this we can rewrite many logical assertions in the language of propositional logic.
\begin{example}
If we call ``Socrates is bald'' $p$ and ``Socrates is wearing a hat'' $q$, we can write ``Socrates is bald \textbf{and} is \textbf{not} wearing a hat'' as 
\[p \land \neg q\]
\end{example}

\section{Inference rules}
So far we have not achieved very much; we have a way to partially rewrite some English sentences using obscure symbols. The advantage of the symbolic notation is that it allows us to isolate the logical structure of sentences. 

\begin{example}
The English sentences ``Socrates is bald \textbf{and} is \textbf{not} wearing a hat'', ``Socrates is bald \textbf{and} has \textbf{not} got a hat on'' and ``Socrates has \textbf{no} hair \textbf{and} Socrates is \textbf{not} wearing a hat'' all mean the same, but are written differently. In English it is no trivial matter to work out in general which sentences mean the same thing.
\end{example}

In propositional logic we have a way to determine if two sentences mean the same thing, using inference rules. We can also use these rules to derive new truths from things we already know. 
\begin{example}
One of the inference rules we will see is that if we know both $p$ and $q$ to be correct, then we can derive $p \land q$.

Using this, we can formally derive ``Socrates is bald \textbf{and} is wearing a hat'' from the propositions ``Socrates is bald'' and ``Socrates is wearing a hat''.
\end{example}

In what follows, a number of inference rules will be listed. In general we will be able to infer new inference rules from old ones, so the list of possible rules is endless. For theoretical purposes it is useful to have a list of inference rules from which all others can be derived, preferably as small as possible. One such list will be given. TODO reconstruction

\subsection{A minimal list of inference rules}
The rules in this list have been chosen because they in some way contain the essence of each connective and thus can define them. Other, equivalent, choices can be made.
\begin{itemize}
\item \textbf{Implication}
\begin{itemize}
\item \textit{Modus ponens} \[ A \implies B, \  A \quad\vdash\quad B \]
\item \textit{Conditional proof.} This introduces the implication $\implies$. In a proof we may always state a wff as a hypothesis. We then enter a subproof and may then use the inference rules as usual assuming the hypothesis is correct. In order to break out of the subproof, we write $A \implies B$ where $A$ is the hypothesis and $B$ is the result of the subproof. Any wff that has been established in the main proof may be reiterated in the subproof.
\end{itemize}
\item \textbf{Conjunction}
\begin{itemize}
\item \textit{Conjunction introduction}\[ A, \; B \quad\vdash\quad A \land B \]
\item \textit{Conjunction elimination}
\begin{align*}
A \land B \quad&\vdash\quad A \\
A \land B \quad&\vdash\quad B
\end{align*}
\end{itemize}
\item \textbf{Disjunction}
\begin{itemize}
\item \textit{Disjunction introduction}
\begin{align*}
A \quad&\vdash\quad A\lor B \\
B \quad&\vdash\quad A \lor B
\end{align*}
\item \textit{Disjunction elimination}
\[ A \lor B, \  A \implies C, \  B \implies C \quad\vdash\quad C \]
\end{itemize}
\item \textbf{Equivalence}
\begin{itemize}
\item \textit{Biconditional introduction}
\[ A \implies B, \  B\implies A \quad\vdash\quad A \iff B \]
\item \textit{Biconditional elimination}
\begin{align*}
A \iff B \quad&\vdash\quad A \implies B \\
A \iff B \quad&\vdash\quad B \implies A
\end{align*}
\end{itemize}
\item \textbf{Negation}
\begin{itemize}
\item \textit{Double negation}
\[ \neg \neg A \quad\vdash\quad A \]
\item \textit{Reductio ad absurdum}
\[ A\implies B, \  A\implies \neg B \quad\vdash\quad \neg A \]
\end{itemize}
\end{itemize}

At this point a couple of observations can be made.
\begin{itemize}
\item Some results can be derived without any premises. These are called \udef{tautologies} (TODO: remove def). The most famous (and controversial) one is probably the law of excluded middle
\[ \vdash \quad p \lor \neg p. \]
\begin{example}
A derivation of the law of excluded middle may be given as follows:
\begin{enumerate}
\item Start a conditional proof with the hypothesis $\neg(p\lor \neg p)$
\begin{enumerate}
\item Start a conditional proof with the hypothesis $p$
\begin{enumerate}
\item Disjunction introduction with the hypothesis (a) yields $p \lor \neg p$
\end{enumerate}
\item The conclusion of the subproof yields $p \implies (p \lor \neg p)$
\item Start a conditional proof with the hypothesis $p$
\begin{enumerate}
\item The wff 1. may be reiterated in the subproof: $\neg(p\lor \neg p)$
\end{enumerate}
\item The conclusion of the subproof yields $p \implies \neg(p \lor \neg p)$
\item Reductio ad absurdum of (b) and (d) yields $\neg p$
\end{enumerate}
\item The conclusion of the subproof yields $\neg(p\lor \neg p) \implies \neg p$
\item Start a conditional proof with the hypothesis $\neg(p\lor \neg p)$
\begin{enumerate}
\item Start a conditional proof with the hypothesis $\neg p$
\begin{enumerate}
\item Disjunction introduction with the hypothesis (a) yields $p \lor \neg p$
\end{enumerate}
\item The conclusion of the subproof yields $\neg p \implies (p \lor \neg p)$
\item Start a conditional proof with the hypothesis $\neg p$
\begin{enumerate}
\item The wff 1. may be reiterated in the subproof: $\neg(p\lor \neg p)$
\end{enumerate}
\item The conclusion of the subproof yields $\neg p \implies \neg(p \lor \neg p)$
\item Reductio ad absurdum of (b) and (d) yields $\neg (\neg p)$
\item Double negation in (e) yields $p$
\end{enumerate}
\item The conclusion of the subproof yields $\neg(p\lor \neg p) \implies p$
\item Reductio ad absurdum of 2. and 4. yields $\neg\neg(p\lor \neg p)$
\item Double negation in 5. yields $p\lor \neg p$
\end{enumerate}
This concludes the proof.
\end{example}
\item Obviously proofs using just these inference rules tend to be very long, repetitive and not very illuminating. The proof above can be shortened quite considerably with some of the inference rules we will see later.
\item In these inference rules the implication $\implies$ has been given a special place. It is the only connective that appears outside the rules that define it. From this we may wonder if it is possible to define the other connectives in terms of implication. This will be discussed in more detail in the next section.
\item All valid deductions may be rephrased as implications. If we have a valid deduction
\[ A, B ,\ldots \quad\vdash\quad C \]
then we may use this deduction to deduce
\[ \vdash\quad A \land B \land\ldots \implies C. \]
\begin{note}
\begin{enumerate}
\item Start a conditional proof with the hypothesis $A \land B \land\ldots$
\begin{enumerate}
\item Conjunction elimination of 1. yields A, B ,\ldots
\item Use the valid deduction $A, B ,\ldots \quad\vdash\quad C$ to deduce $C$
\end{enumerate}
\item The conclusion of the subproof yields $A \land B \land\ldots \implies C$
\end{enumerate}
This concludes the proof.
\end{note}
Conversely, if we have the premises $A, B ,\ldots$, the tautology $A \land B \land\ldots \implies C$ allows the deduction of $C$.
\begin{note}
\begin{enumerate}
\item Start with the premises $A, B ,\ldots$
\item Conjunction introduction of 1. yields $A \land B \land\ldots$
\item Because it is a tautology, the wff $A \land B \land\ldots \implies C$ can be deduced here.
\item Modus ponens of 2. and 3. yields $C$
\end{enumerate}
This concludes the proof.
\end{note}
We have now shown two statements that look like implications:
\begin{itemize}
\item \textbf{If} we have a deduction $A, B \ldots \;\vdash\; C$,
\textbf{then} we may deduce $\vdash\; A \land B \land\ldots \implies C$.
\item \textbf{If} we have a tautology $\vdash\; A \land B \land\ldots \implies C$,
\textbf{then} we may deduce $A, B ,\ldots \;\vdash\; C$.
\end{itemize}
We may now use the inference rule \textit{biconditional introduction} to infer their equivalence. TODO: deduction theorem.
\item The previous point is proves a result from the meta-theory: the theory about the theory. It also shows a first practical application of the theory. TODO integrate with formal system theory.
\end{itemize}

\subsection{More inference rules}
For ease of use we split this section up into two parts:
\begin{itemize}
\item Rules of inference proper and
\item Rules of replacement: these are symbolic expressions that are equivalent and may always be substituted one for the other.
\end{itemize}
All of these rules can be deduced from the previous rules.
\subsubsection{Rules of inference}
\begin{enumerate}
\item \textit{Modus tollens}\[ A\implies B, \neg B \quad\vdash\quad \neg A \]
\item \textit{Modus ponendo tollens}\[ \neg(A\land B), A \quad\vdash\quad \neg B \]
\item \textit{Disjunctive syllogism} \[ A\lor B, \neg A \quad\vdash\quad B \]
\item \textit{Hypothetical syllogism} or \textit{transitivity of the implication}
\[ A \implies B, B \implies C \quad\vdash\quad A \implies C \]
\item \textit{Dilemma} \[ A\lor B, A \implies C \quad\vdash\quad C\lor B \]
\item \textit{Absorption} \[ A\implies B \quad\vdash\quad A \implies A\land B \]
\item \textit{Negation of equivalence}
\begin{align*}
\neg (A\iff B) \quad&\vdash\quad A\lor B \\
\neg (A\iff B) \quad&\vdash\quad \neg A\lor \neg B
\end{align*}
\item \textit{Reductio ad absurdum of a hypothesis}. If, in a conditional proof that that start with the hypothesis $A$, both the wff $B$ and $\neg B$ appear as valid, one may conclude $\neg A$ in the main proof. This concludes the subproof.
\end{enumerate}
\subsubsection{Rules of replacement}
\begin{enumerate}
\item \textbf{Double negation}. This rules is repeated here because it can in general be thought of as a rules of replacement.
\[ \neg \neg A \iff A \]
\item \textbf{Commutativity}
\begin{enumerate}
\item \textit{Of equivalence} \[ (A\iff B) \iff (B\iff A) \]
\item \textit{Of conjunction} \[ (A\land B) \iff (B\land A) \]
\item \textit{Of disjunction} \[ (A\lor B) \iff (B\lor A) \]
\end{enumerate}
\item \textbf{Associativity}
\begin{enumerate}
\item \textit{Of conjunction} \[ ((A\land B)\land C) \iff (A \land(B\land C)) \]
\item \textit{Of disjunction} \[ ((A\lor B)\lor C) \iff (A \lor(B\lor C)) \]
\end{enumerate}
\item \textbf{Distributivity}
\begin{align*}
A \land (B\lor C) &\iff (A\land B)\lor(A\land C) \\
A \lor (B\land C) &\iff (A\lor B)\land(A\lor C)
\end{align*}
\item \textbf{Negation}
\begin{enumerate}
\item \textit{Of conjunction} also known as one \udef{De Morgan's laws} \[ \neg(A\land B) \iff \neg A \lor \neg B \]
\item \textit{Of disjunction} also known as one \udef{De Morgan's laws} \[ \neg(A\lor B) \iff \neg A \land \neg B \]
\item \textit{Of implication} \[ \neg(A\implies B) \iff A \land \neg B \]
\end{enumerate}
\item \textbf{Transposition} \[ (A \implies B) \iff (\neg B \implies \neg A) \]
\item \textbf{Material implication} \[ (A\implies B) \iff (\neg A \lor B) \]
\item \textbf{Tautology}
\begin{align*}
A &\iff (A\lor A) \\
A &\iff (A\land A)
\end{align*}
\end{enumerate}

\section{Other formulations of predicate logic}
In this section three other, equivalent formulations of predicate logic are given. Many interesting technical details could be given, but this can easily get quite complicated and a text on physics is not really the place. (Read: I haven't a clue what I'm talking about). This section can easily be skipped.
\subsection{With axiom schemata}
This formulation uses \udef{axiom schemata} instead of inference rules. These give families of tautologies. Specific tautologies can be obtained by filling in the upper case letters with specific wffs. Only one inference rule is kept: \textbf{modus ponens}.

Deductions are made by writing down tautologies and applying modus ponens.

The axiom schemata (AS) which are posited to be tautologies are:
\[\begin{array}{l l}
AS1 & A \implies (B\implies A) \\
AS2 & (A \implies (B \implies C))\implies((A\implies B)\implies(A\implies C)) \\
AS3 & ((A\implies B)\implies A)\implies A \\
AS4 & (A\land B) \implies A \\
AS5 & (A\land B) \implies B \\
AS6 & A\implies(B\implies(A\land B)) \\
AS7 & A \implies (A\lor B) \\
AS8 & B \implies (A\lor B) \\
AS9 & (A\implies C)\implies ((B\implies C)\implies ((A\lor B)\implies C)) \\
AS10 & (A\iff B)\implies (A\implies B) \\
AS11 & (A\iff B) \implies (B\implies A) \\
AS12 & (A\implies B)\implies ((B\implies A)\implies (A\iff B)) \\
AS13 & \neg \neg A \implies A \\
AS14 & (A\implies B)\implies ((A\implies \neg B)\implies \neg A)
\end{array}\]
\subsection{With definitions}
In our first formulation some of the inference rules acted like definitions. In the list axiom schemata clearly some of them fulfill the same rôle. Thus the list can be drastically shortened by explicitly introducing definitions, which we denote with the symbol $\equiv$.

This formulation of predicate logic consists of
\begin{itemize}
\item Definitions:
\begin{align*}
A \lor B &\quad\equiv\quad \neg A \implies B \\
A \land B &\quad\equiv\quad \neg(\neg A\lor \neg B) \\
A \iff B &\quad\equiv\quad (A\implies B)\land(B\implies A)
\end{align*}
\item Axiom schemata: AS1 - AS3, AS13 and AS14
\item Inference rule: modus ponens
\end{itemize}

\subsubsection{Some relevant technicalities for definitions}
This last formulation of predicate logic used \udef{explicit definitions}. It was, however, equivalent to previous formulations. In a way this means the connectives were also ``defined'' in the previous formulations, albeit implicitly. An \udef{implicit definition} fixes the meaning of a connective (or symbol or object in general) by saying which inferences containing said connective are valid.

\paragraph{Giving explicit definitions of connectives.}
It may be striking in this formulation of predicate logic with definitions that only three connectives are given explicit definitions. Clearly giving all connectives explicit definitions would be impossible as an explicit definition is defined in terms of something else and then there would be nothing else in terms of which to define things. The choice of which connectives to give explicit and which to give implicit definitions is to some degree arbitrary. Here everything was defined in terms of $\neg$ and $\implies$, but we could just as easily have defined $\implies$ as
\[ A \implies B \quad\equiv\quad \neg A \lor B \]
in which case everything would have been defined in terms of $\neg$ and $\lor$.

If it is possible to give an explicit definition for a connective, then every formula containing that connective can be written using its definition. It is, in effect, redundant. Such a ``redundant'' symbol is properly called \udef{eliminable}. Thus it is only possible to give an explicit definition of a symbol if it is eliminable. Additionally it may not be possible to give an explicit definition if too many other explicit definitions have already been given. For example, $\land, \lor, \implies$ and $\iff$ are all eliminable, but not all at the same time.

Not all symbols are eliminable. For example $\neg$ is not.\footnote{This can be easily seen by attempting to define $\neg A$ using the other connectives. Such a definition may only contain the other connectives and $A$. There are a limited number of ways we can combine these building blocks. The expressions $A \land A$ and $A \lor A$ are both equivalent to $A$, so using those is quite useless. The expressions $A \implies A$ and $A \iff A$ are both tautologies. Combining a tautology, a connective and $A$ can only every yield $A$ or another tautology, as the reader can readily verify. Repeating this process will not yield anything new, especially not $\neg A$. Thus $\neg$ is not eliminable.} So far we have managed to eliminate all connectives but two, one unitary and one binary. It is however possible to formulate predicate logic with only one connective, if we introduce new connectives.

\paragraph{Giving explicit definitions of new connectives.}
So far we have not actually given a proper, formal definition of ``explicit definitions'', only some examples. It turns out that giving a good definition is not easy. Not every sentence containing a ``$\equiv$'' is a good definition. Take for example the definition
\[ \flat A \quad\equiv\quad A \implies B \]
for any wff $B$. This definition cannot be added to the system of propositional logic we have developed so far without substantially altering it.
\begin{example}
Naively extending propositional logic to include the connective $\flat$, means that any proposition can imply anything. That is, for any $A$ and $B$, $A \implies B$ is tautologically true. The derivation of this fact is as follows:
\begin{enumerate}
\item Start with AS1: $A \implies (C\implies A)$.
\item Using the definition, 1. yields $\flat A$.
\item Substituting in the definition now yields $A \implies B$.
\end{enumerate}
\end{example}
Obviously this definition creates many new tautologies. For this reason it is called a \udef{creative} definition (or a \udef{non-conservative} definition). In fact this system is especially bad: all wffs are now tautological, rendering the system completely trivial.

So now we want a way to construct an explicit definition such that
\begin{enumerate}
\item the symbol being defined is eliminable in the new system that contains it;
\item the definition is not creative.
\end{enumerate}
An explicit definition with the following structure has these properties:
\[ \text{definiendum} \qquad \equiv \qquad \text{definiens} \]
where
\begin{itemize}
\item the definiendum is an expression containing only the new symbol to be defined once, variables, and potentially brackets;
\item the definiens contains no variables that are not also present in the definiendum.
\end{itemize}
The definition of $\flat A$ fails on the second point. This is a reasonable definition of an explicit definition. However it is actually too strict. There are some perfectly good explicit definitions that do not fit this mold (TODO which?). Unfortunately finding the perfect definition is still an open problem.

\paragraph{Some new connectives.}
We can now give some examples of good explicit definitions:
\begin{itemize}
\item The \udef{Sheffer stroke}, written as $\uparrow$ or $|$, also known as NAND in computer science and engineering, can be defined as
\[ A \uparrow B \quad\equiv\quad \neg(A\land B). \]
\item The \udef{Pierce arrow} $\downarrow$, also known as the \udef{Quine dagger} $\dagger$, also known as NOR in computer science and engineering, can be defined as
\[ A \downarrow B \quad\equiv\quad \neg (A \lor B). \]
\item The \udef{exclusive disjunction} $\veebar$, also known as the ``exclusive or'' or XOR, can be defined as
\[ A \veebar B \quad\equiv\quad (A \lor B) \land \neg (A \land B). \]
\end{itemize}
Once either that the Sheffer stroke or Pierce arrow have been introduced, all other connectives can be simultaneously eliminated, including $\neg$.

\subsection{With axioms}
The concept of an axiom schema can be replaced with a new inference rules: \textit{uniform substitution} (TODO slash notation). This rule states that in any tautology we may replace a letter denoting a primitive proposition with an arbitrary wff.

The final formulation of predicate logic consists of the following:
\begin{itemize}
\item Axioms:
\[ \begin{array}{l l}
A1 & p\implies (q \implies p) \\
A2 & (p\implies (q \implies r))\implies((p\implies q)\implies (p\implies r)) \\
A3 & ((p\implies q)\implies p)\implies p \\
A4 & \neg \neg p \implies p \\
A5 & (p\implies q)\implies ((p\implies \neg q)\implies \neg p)
\end{array} \]
\item Definitions:
\begin{align*}
A \lor B &\quad\equiv\quad \neg A \implies B \\
A \land B &\quad\equiv\quad \neg(\neg A\lor \neg B) \\
A \iff B &\quad\equiv\quad (A\implies B)\land(B\implies A)
\end{align*}
\item Inference rule: modus ponens and uniform substitution.
\end{itemize}

\section{Semantics}
\subsection{Model-theoretic semantics}
\subsection{Proof-theoretic semantics}

standard and nonstandard models

TODO valuation function

\subsection{A note on constructivism}

\subsection{Truth tables}
\subsection{Semantic tableaux}
\subsection{A couple of paradoxes}

\chapter{Critiques and extensions of propositional logic}
\section{Some problems with propositional logic}
\subsection{Interpreting the implication}
\subsection{Relevant derivation}
\subsection{Ex falso quodlibet}
\section{Multi-valued logic}
\section{Intuitionistic logic}
\section{Modal logic}
\section{Relevant logic}
\section{Paraconsistent logic}
\section{Non-monotonic logic}

\chapter{First-order predicate logic}
problem of multiple generality
\section{Syntactic extensions}
terms and formulae

polish notation

quantifiers

bound variables, scope and heuristics

\section{Higher-order logic}

\chapter{What constitutes a proof?}
\section{Proofs as convincing texts}
not symbols. convince
\subsection{Use of the word ``arbitrary''}
\section{Types of proof}
existence and uniqueness

two inclusions