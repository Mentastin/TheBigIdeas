\chapter{Circuit model}
\section{Qubits}
\begin{definition}
A \udef{qubit} is an element of $\C P^2$.
\end{definition}

\subsection{$\suAlg(2)$ and the Pauli matrices}
The qubit Hamiltonians are elements of $\uAlg(2)$. Getting rid of the arbitrary global phase gives us elements of $\suAlg(2)$.

\begin{lemma} \label{su2Eigenvalues}
For all $\sigma\in \suAlg(2)$, the eigenvalues $\lambda_1, \lambda_2$ are real and $\lambda_1 = -\lambda_2$.
\end{lemma}
\begin{proof}
For all $\sigma\in \suAlg(2)$, $\sigma$ is self-adjoint and $\Tr[\sigma] = \lambda_1 + \lambda_2 = 0$. 
\end{proof}
\begin{corollary}
For all $\sigma\in \suAlg(2)$, we have $\norm{\sigma}_{2} = \sqrt{2}\norm{\sigma}$, where $\norm{\cdot}_2$ is the Hilbert-Schmidt norm.
\end{corollary}
\begin{proof}
We have $\norm{\sigma}_{2} = \sqrt{\lambda_1^2 + \lambda_2^2} = \sqrt{2}|\lambda_1| = \sqrt{2}\norm{\sigma}$.
\end{proof}
\begin{corollary}
The inner product
\[ \inner{\cdot,\cdot}: (\sigma_1,\sigma_2) \mapsto \frac{1}{2}\Tr[\sigma_1\sigma_2] \]
on $\suAlg(2)$ yields the operator norm as the norm associated with this inner product.
\end{corollary}
\begin{corollary} \label{eigenvaluesUnitVectorsu2}
Let $\sigma$ be a unit vector in $\suAlg(2)$. Then $\sigma$ has eigenvalues $\pm 1$. This means $\sigma$ is unitary.
\end{corollary}
\begin{corollary} \label{BlochBijection}
There is a bijection between the unit vectors in $\suAlg(2)$ and the rank-1 projections on $\C^2$ given by $\suAlg(2)/\R \to \sigma\mapsto E^\sigma_{1}$, where $E^\sigma_{1}$ is the eigenspace of $\sigma$ associated with eigenvalue $+1$.
\end{corollary}
\begin{proof}
We construct an inverse of the map. Let $P_1$ be the orthogonal projector on $E^\sigma_{1}$. Then $\sigma = 2P_1 - \id$.
\end{proof}


\begin{proposition}
Let $\sigma\in\suAlg(2)$. Then $\sigma^2 = \norm{\sigma}^2\;\vec{1}$.
\end{proposition}
\begin{proof}
We have 
\[ \sigma^2 = \norm{\sigma}^2 \left(\frac{\sigma}{\norm{\sigma}}\right)^2 = \norm{\sigma}^2 \frac{\sigma}{\norm{\sigma}}\left(\frac{\sigma}{\norm{\sigma}}\right)^* = \norm{\sigma}^2\;\vec{1}, \]
where we have used that $\frac{\sigma}{\norm{\sigma}}$ is unitary by \ref{eigenvaluesUnitVectorsu2}.
\end{proof}
\begin{corollary}
The real algebra generated by $\suAlg(2)$ is the Clifford algebra $\Cl_{3,0}$. The unit pseudoscalar is $i\vec{1}$.
\end{corollary}
Note that $\suAlg(2)$ is a Lie algebra and thus closed under the Lie bracket, but not an algebra under operator composition. Thus the algebra generated by $\suAlg(2)$ is larger than $\suAlg(2)$ (indeed $\sigma^2 = \norm{\sigma}^2\;\vec{1}\notin \suAlg(2)$).

\subsubsection{Pauli matrices}
\begin{proposition}[Pauli matrices]
The Clifford algebra $\suAlg(2)$ has an orthonormal basis
\[ \sigma_x = \begin{pmatrix}
0 & 1 \\ 1 & 0
\end{pmatrix}, \qquad \sigma_y = \begin{pmatrix}
0 & -i \\ i & 0
\end{pmatrix} \qquad \text{and}\qquad \sigma_z = \begin{pmatrix}
1 & 0 \\ 0 & -1
\end{pmatrix}. \]
\end{proposition}

\begin{proposition}
The Pauli matrices obey
\begin{enumerate}
\item $[\sigma_i, \sigma_j] = 2i\leviCivita_{i,j,k}\sigma_k$;
\item $\{\sigma_i, \sigma_j\} = 2\delta_{i,j}\mathbb{1}_2$;
\item $\sigma_i\sigma_j = \delta_{i,j}\mathbb{1}_2 + i\leviCivita_{i,j,k}\sigma_{k}$
\end{enumerate}
\end{proposition}

\begin{corollary}
TODO $\sigma_i\sigma_j\sigma_i = $.
\end{corollary}
eg $\sigma_x\sigma_y\sigma_x = -\sigma_y$.

\subsubsection{Qubit bases}
\begin{definition}
We call
\begin{itemize}
\item the eigenbasis of $\sigma_z$ the \udef{$Z$-basis} or \udef{computational basis} and write the elements
\[ \ket{0} = \begin{pmatrix}
1 \\ 0
\end{pmatrix} \qquad \ket{1} = \begin{pmatrix}
0 \\ 1
\end{pmatrix}; \]
\item the eigenbasis of $\sigma_x$ the \udef{$X$-basis} or \udef{coherence basis} and write the elements
\[ \ket{+} = \frac{1}{\sqrt{2}}\begin{pmatrix}
1 \\ 1
\end{pmatrix} = \frac{\ket{0} + \ket{1}}{\sqrt{2}} \qquad \ket{-} = \frac{1}{\sqrt{2}}\begin{pmatrix}
1 \\ -1
\end{pmatrix} = \frac{\ket{0} - \ket{1}}{\sqrt{2}}. \]
\end{itemize}
\end{definition}

\subsection{The Bloch sphere}
Because $\suAlg(2)$ is the Clifford algebra $\Cl_{3,0}$, we can use the unit sphere in $\R^3$ to represent the unit vectors in $\suAlg(2)$. By \ref{BlochBijection} we can also use it to represent the rank-1 projections on $\C^2$. The unit sphere with as $x,y,z$ axes the Pauli matrices $\sigma_x,\sigma_y, \sigma_z$ is called the \udef{Bloch sphere}.

TODO image of Bloch sphere.

TODO spherical coordinates: $\cos\theta / 2\ket{0} + e^{i\phi}\sin\theta/2 \ket{1}$
\begin{lemma}
\[ e^{\phi/2 i\sigma}e^{\theta/2 i\sigma^\perp}\ket{1} = \cos\theta / 2\ket{0} + e^{i\phi}\sin\theta/2 \ket{1} \]
\end{lemma}

\section{Gates}
\subsection{One-qubit gates}
\subsubsection{Hadamard gate}
\begin{definition}
The \udef{Hadamard gate} or \udef{Walsh-Hadamard gate} $W$ is the linear operation determined by the following matrix:
\[ W = \frac{1}{\sqrt{2}}\begin{pmatrix}
1 & 1 \\ 1 & -1
\end{pmatrix}. \]
\end{definition}
We have the following mappings
\begin{align*}
W\ket{0} &= \ket{+} & W\ket{+} &= \ket{0} \\
W\ket{1} &= \ket{-} & W\ket{-} &= \ket{1}
\end{align*}

\begin{lemma}
The Hadamard gate is its own inverse: $W^2 = \mathbb{1}$.
\end{lemma}

\subsubsection{Pauli gates}
\begin{definition}
Each of the Pauli matrices determines an operation on $\C^2$. In this context we often write $X,Y$ and $Z$ for $\sigma_x, \sigma_y$ and $\sigma_z$.
\end{definition}

\begin{lemma}
The Pauli gates are their own inverses: $X^2 = Y^2 = Z^2 = \mathbb{1}$.
\end{lemma}

\subsection{Controlled gates}
\begin{definition}
Let $H_1, H_2$ be two Hilbert spaces. Let $P$ be a projector on $H_1$ and $L$ an operator on $H_2$. The operation of $L$ \udef{controlled by} $P$ is the operation $P\otimes L + (\id_{H_1} - P)\otimes \id_{H_2}$ in $H_1\otimes H_2 \to H_1\otimes H_2$. 
\end{definition}

\subsection{Two-qubit gates}
\subsubsection{Swap}

\begin{definition}
\[ \begin{quantikz}
&\swap{1}& \\ &\targX{}&
\end{quantikz} \defeq \begin{quantikz}
&\permute{2,1} & \\
& & 
\end{quantikz} \]

$\begin{pmatrix}1&0&0&0\\0&0&1&0\\0&1&0&0\\0&0&0&1\end{pmatrix}$
\end{definition}

\begin{proposition} \label{swapFromCNOT}
\[ \begin{quantikz}
&\swap{1}& \\ &\targX{}&
\end{quantikz} = \begin{quantikz}
&\ctrl{1} & \targ{} & \ctrl{1}& \\
&\targ{} & \ctrl{-1} & \targ{}&
\end{quantikz} \]
\end{proposition}


\chapter{Eigenpath traversal}
\section{Quantum Zeno effect}
\begin{proposition}
Consider a path of states $\ket{\psi(s)}$ where $s\in[0,1]$. Assume that, for fixed $d$ and all $\delta$,
\[ |\braket{\psi(s)}{\psi(s+\delta}|^2 \geq 1-d^2\delta^2. \]
Then 
\end{proposition}

\section{Adiabatic quantum computation}
\section{Evolution through measurement}
\subsection{Phase randomisation}
$\ket{\psi_0} = \ket{E_0(0)} = \sum_i\alpha_i\ket{E_i(s_1)}$
\begin{align*}
\rho(s_1) &= \frac{1}{T}\int_0^T e^{-iH(s_1)t}\ketbra{\psi_0}{\psi_0} e^{iH(s_1)t} \diff{t} \\
&= \sum_{i,j}\alpha_i\alpha_j^* \frac{1}{T}\left(\int_0^T e^{-i(E_i-E_j)t}\diff{t}\right)\ketbra{E_i}{E_j} \\
&= \sum_{i,j}\alpha_i\alpha_j^* \left(\frac{i(e^{-i(E_i-E_j)T}-1)}{T(E_i-E_j)}\right)\ketbra{E_i}{E_j}
\end{align*}

\begin{theorem}[Randomised dephasing]
Let $\ket{\psi(s)}$ be a nondegenerate eigenstate of $H(s)$ and $\{\omega_j\}$ the energy differences to the other eigenstates $\ket{\psi_j(s)}$. Let $T$ be a random variable. Then, for all states $\rho$, we have
\[ \norm{(M_l - e^{-iH(s)T}\rho e^{-iH(s)T}}_\text{tr} \leq \epsilon = \sup_{\omega_j}|\Phi(\omega_j)| \]
\end{theorem}

\chapter{Variational quantum algorithms}

\chapter{Algorithms}
\section{Some building blocks}
\subsection{Preparing states}
\subsubsection{Uniform superposition}
\begin{lemma}
Consider the Hilbert space $\hilbert_{\F_2^k}$. We can generate a uniform superposition of computational basis states by applying a Hadamard gate to each register, initialised to zero:
\[ \frac{1}{2^k}\sum_{b\in \F_2^k}\ket{b} = W^{\otimes k}\ket{0}^{\otimes k}. \]
\end{lemma}

Projection on the $n$-dimensional uniform superposition is given by $\frac{1}{n}\mathbb{J}_{n\times n}$.
\subsection{Quantum Fourier transform}
Set $R_k \defeq \begin{pmatrix}
1 & 0 \\ 0 & e^{2\pi i / 2^k}
\end{pmatrix}$.

TODO: produces swapped result!

Requires $n$ Hadamard gates and $\frac{n(n-1)}{2}$ controlled $R$-gates. At most $n/2$ swaps. Each with three CNOTs (\ref{swapFromCNOT}).

\subsection{Quantum phase estimation}
Needs large number of ancillas.

\begin{proposition}
Let $U$ be a unitary operator and $\ket{\psi}$ an eigenvector of $U$. acting on an $m$-qubit register and . 
\end{proposition}

\subsection{Quantum singular value transformation}

\section{Quantum oracle querying}
\subsection{Oracle set-up}
\begin{definition}
For any finite set $A$, we define a mapping
\[ O: (A\to \F_2) \to \End(\hilbert_{A}\otimes \hilbert_{\F_2}): f\mapsto O_f \]
where
\[ O_f(\ket{k}\otimes \ket{q}) \defeq \ket{k}\otimes \ket{f(k) + q}.  \]
We call $O_f$ the \udef{quantum oracle} of $f$.
\end{definition}

\begin{lemma} \label{phaseUnitaryFromOracle}
We can convert an oracle $O_f$ to a unitary operator $U_f: \hilbert_A\to\hilbert_A: \ket{k}\mapsto (-1)^{f(k)}\ket{k}$ using only a constant number of Hadamard and NOT gates:
\[\begin{quantikz}
\lstick{$\ket{k}$} \qw &  \qw & \qw & \gate[wires=2]{O_f} & \qw & \qw & \qw & \qw \rstick{$U_f \ket{k}$} \\
\lstick{$\ket{0}$} & \gate{X} & \gate{W} & {} & \gate{W} & \gate{X} & \trash{\ket{0}} 
\end{quantikz} \]
If $A$ is finite, then $U_f = \id - 2 \sum_{k\in f^{\preimf}(1)}\ketbra{k}{k}$, which is a Householder matrix.
\end{lemma}
\begin{proof}
We show that the circuit transforms $\ket{k}$ into $(-1)^{f(k)}\ket{k}$.

Given input $\ket{k}$, the oracle acts on $\ket{k}\otimes\ket{-} = \ket{k}\otimes\left(\frac{\ket{0}-\ket{1}}{\sqrt{2}}\right) = \frac{\ket{k}\otimes\ket{0}}{\sqrt{2}} - \frac{\ket{k}\otimes\ket{1}}{\sqrt{2}}$ and produces
\begin{align*}
\frac{\ket{k}\otimes\ket{f(k)}}{\sqrt{2}} - \frac{\ket{k}\otimes\ket{f(k)+1}}{\sqrt{2}} &= \begin{cases}
\ket{k}\otimes\ket{-} & (f(k) = 0) \\
-\ket{k}\otimes\ket{-} & (f(k) = 1) \\
\end{cases} \\
&= (-1)^{f(k)}\ket{k}\otimes\ket{-}.
\end{align*}
Given that $XW$ is the inverse of $WX$, the output $U_f\ket{k}$ is equal to $(-1)^{f(k)}\ket{k}$. The second register is left in the state $\ket{0}$, thus we can either measure of just discard it.

Finally, assume $A$ finite. Then
\begin{align*}
U_f &= U_f\id = U_f\sum_{k\in A}\ketbra{k}{k} = \sum_{k\in f^{\preimf}(0)}U_f\ketbra{k}{k} + \sum_{k\in f^{\preimf}(1)}U_f\ketbra{k}{k} \\
&= \sum_{k\in f^{\preimf}(0)}\ketbra{k}{k} - \sum_{k\in f^{\preimf}(1)}\ketbra{k}{k} \\
&= \sum_{k\in f^{\preimf}(0)}\ketbra{k}{k} - \sum_{k\in f^{\preimf}(1)}\ketbra{k}{k} + \sum_{k\in f^{\preimf}(1)}\ketbra{k}{k} - \sum_{k\in f^{\preimf}(1)}\ketbra{k}{k} \\
&= \left(\sum_{k\in f^{\preimf}(0)}\ketbra{k}{k} + \sum_{k\in f^{\preimf}(1)}\ketbra{k}{k}\right) - 2\sum_{k\in f^{\preimf}(1)}\ketbra{k}{k} \\
&= \id - 2\sum_{k\in f^{\preimf}(1)}\ketbra{k}{k}
\end{align*}
\end{proof}

\subsection{Deutsch's problem}
\begin{problem}
Suppose we have a 1-bit to 1-bit function $f: \{0,1\} \to \{0,1\}: x\mapsto f(x)$.

Determine whether $f$ is
\begin{itemize}
    \item \emph{constant}, i.e.\ $f(0) = f(1)$; or
    \item \emph{balanced}, i.e.\ $f(0) \neq f(1)$.
\end{itemize}
\end{problem}

\begin{proposition}
The classical query complexity of Deutch's problem is 2. The quantum query complexity is 1.
\end{proposition}
\begin{proof}
The classical case is clear.

In the quantum case, we have access to the unitary $U_f: \hilbert_{\F_2}\to \hilbert_{\F_2}$ from \ref{phaseUnitaryFromOracle}. The state $WU_fW\ket{0}$ is as follows:
\begin{align*}
WU_fW\ket{0} &= WU_f\ket{+} = WU_f\left(\frac{\ket{0}+\ket{1}}{\sqrt{2}}\right) \\
&= W\left(\frac{(-1)^{f(0)}\ket{0}+(-1)^{f(1)}\ket{1}}{\sqrt{2}}\right) \\
&= W\begin{cases}
(-1)^{f(0)}\frac{\ket{0} + \ket{1}}{\sqrt{2}} = (-1)^{f(0)}\ket{+} & (f(0) = f(1)) \\
(-1)^{f(0)}\frac{\ket{0} - \ket{1}}{\sqrt{2}} = (-1)^{f(0)}\ket{-} & (f(0) \neq f(1))
\end{cases} \\
&= \begin{cases}
(-1)^{f(0)}\ket{0} & (f(0) = f(1)) \\
(-1)^{f(0)}\ket{1} & (f(0) \neq f(1))
\end{cases}
\end{align*} 
If we measure this state, then we will certainly measure $0$ is $f$ is constant and $1$ if $f$ is balanced.
\end{proof}



\subsection{Grover's search algorithm}
\begin{problem}
Suppose we have a set $\mathcal{N}$ of $N$ items, some of which are marked. WLOG we can take $\mathcal{N}$ to be the set of bit strings of length $\nu$. The marked items form a subset $\mathcal{M}$ of size $M$. Suppose we have an oracle that tells us whether an object is marked or not:
\[ f:\mathcal{N} \to \{0,1\}: x\mapsto \begin{cases}
0 & (x\in \mathcal{M}) \\
1 & (x\notin \mathcal{M})
\end{cases} \]
The problem is to find any marked item.
\end{problem}

Classically we need to check $\Theta(N/M)$ items on average. Grover's algorithm has a query complexity of $O(\sqrt{N/M})$.

\subsubsection{The algorithm}
Define the states
\[ \ket{\mathcal{N}} \defeq \frac{1}{\sqrt{N}}\sum_{n\in\mathcal{N}}\ket{n}, \qquad\text{and}\qquad \ket{\mathcal{M}} \defeq \frac{1}{\sqrt{M}}\sum_{m\in\mathcal{M}}\ket{m}. \]

Using \ref{phaseUnitaryFromOracle}, construct the unitary $U_f = \id_{\mathcal{H}_N} - 2\sum_{m\in\mathcal{M}}\ketbra{m}{m}$. Also construct the Householder matrix
\[ U = W^{\otimes\nu}(\id - 2\ketbra{0}{0})W^{\otimes\nu} = \id - \mathbb{J}_{2\times 2}^{\otimes\nu} = \id - \mathbb{J}_{2\nu\times 2\nu} = \id - 2\ketbra{\mathcal{N}}{\mathcal{N}}. \]
(TODO Householder circuit).

Now consider the subspace $S \defeq \Span\{\ket{\mathcal{M}}, \ket{\mathcal{N}}\}$. We take an orthonormal basis $\{\ket{\mathcal{M}}, \ket{\mathcal{M}'}\}$ of $S$ where
\[ \ket{\mathcal{M}'} \defeq \sqrt{\frac{N}{N-M}}\ket{\mathcal{N}} - \sqrt{\frac{M}{N-M}}\ket{\mathcal{M}} = \frac{1}{\sqrt{N-M}}\sum_{k\in \mathcal{N}\setminus\mathcal{M}}\ket{k}. \]
Then we can write
\[ \ket{\mathcal{N}} = \sqrt{\frac{N-M}{N}}\ket{\mathcal{M}'}+ \sqrt{\frac{M}{N}}\ket{\mathcal{M}} \]
and (using $\id = \ketbra{\mathcal{M}}{\mathcal{M}} + \ketbra{\mathcal{M}'}{\mathcal{M}'}$)
\begin{align*}
U_f &= \id - 2 \ketbra{\mathcal{M}}{\mathcal{M}} = - \ketbra{\mathcal{M}}{\mathcal{M}} + \ketbra{\mathcal{M}'}{\mathcal{M}'} \\
U &= \id - 2\left(\sqrt{\frac{N-M}{N}}\ket{\mathcal{M}'}+ \sqrt{\frac{M}{N}}\ket{\mathcal{M}}\right)\left(\sqrt{\frac{N-M}{N}}\bra{\mathcal{M}'}+ \sqrt{\frac{M}{N}}\bra{\mathcal{M}}\right) \\
&= \frac{N-2M}{N}\ketbra{\mathcal{M}}{\mathcal{M}} + \frac{2M-N}{N}\ketbra{\mathcal{M}'}{\mathcal{M}'} - 2\left(\frac{\sqrt{M}\sqrt{N-M}}{N}\right)\big(\ketbra{\mathcal{M}}{\mathcal{M}'} +  \ketbra{\mathcal{M}'}{\mathcal{M}}\big)
\end{align*}
So $S$ is invariant under both $U$ and $U_f$ and we can write the matrix $G$ of $-UU_f$ in this basis:
\[ G = \begin{pmatrix}
1 - \frac{2M}{N} & -2 \frac{\sqrt{M}\sqrt{N-M}}{N} \\
2 \frac{\sqrt{M}\sqrt{N-M}}{N} & 1 - \frac{2M}{N}
\end{pmatrix}. \]
We note that $1 - \frac{2M}{N}$ is some number between $-1$ and $1$, so we can write it as $\cos\alpha$. Then
\[ \sin\alpha = \sqrt{1- \cos^2\alpha} = \sqrt{1 - \left(1-2 \frac{M}{N}\right)^2} = \sqrt{4 \frac{M}{N} - 4 \frac{M^2}{N^2}} = 2\sqrt{\frac{M}{N}}\sqrt{1- \frac{M}{N}} = 2 \frac{\sqrt{M}\sqrt{N-M}}{N}. \]
Thus
\[ G = \begin{pmatrix}
\cos\alpha & -\sin\alpha \\
\sin\alpha & \cos\alpha
\end{pmatrix} = R_\alpha. \]
We now want to apply $G$ a certain number of times, say $k$, such that
\[ G^k\ket{\mathcal{N}} = G^k \begin{pmatrix}
\sqrt{M/N} \\ \sqrt{1 - M/N}
\end{pmatrix} = R_{k\alpha}R_{\tan^{-1}(\sqrt{N/M - 1})} \begin{pmatrix}
1 \\ 0
\end{pmatrix} \approx \begin{pmatrix}
1 \\ 0
\end{pmatrix} = \ket{\mathcal{M}}. \]

TODO:
\[ \sqrt{\frac{N}{M}} \approx T_k(\cos\alpha) - \sqrt{\frac{N}{M} - 1}U_{k-1}(\cos\alpha) \]
or
\[ 0 \approx \sqrt{\frac{N}{M}-1}T_k(\cos\alpha) + U_{k-1}(\cos\alpha)\sin\alpha \]
and
\[ (\cos\alpha + \sin\alpha)^k = T_k(\cos\alpha) + \sin\alpha U_{k-1}(\cos\alpha). \]

We also have $\cos\alpha + \sin\alpha = \frac{(\sqrt{N-M}-\sqrt{M})^2+2M}{N}$.

\subsubsection{Analogue Grover}
Consider the Hamiltonian $H = \ketbra{\mathcal{M}}{\mathcal{M}} + \ketbra{\mathcal{N}}{\mathcal{N}}$, which we can rewrite in terms of $\ket{\mathcal{M}}$ and $\ket{\mathcal{M}'}$:
\[ H = \left(1 + \frac{M}{N}\right)\ketbra{\mathcal{M}}{\mathcal{M}} + \left(1 - \frac{M}{N}\right)\ketbra{\mathcal{M}'}{\mathcal{M}'} + \frac{\sqrt{M}\sqrt{N-M}}{M}\Big(\ketbra{\mathcal{M}}{\mathcal{M}'}+\ketbra{\mathcal{M}'}{\mathcal{M}}\Big), \]
This operator is self-adjoint and leaves the subspace $S$ invariant, so $S$ has a basis of eigenvectors for it.

By \zref{m-eigenvectorsGenerator}, all elements of $e^{-iHt}\ket{\mathcal{N}}$ lie in $S$. W.r.t.\ the basis $\{\ket{\mathcal{M}}, \ket{\mathcal{M}'}\}$, we have
\[ e^{-iHt}\ket{\mathcal{N}} = \begin{pmatrix}
\sqrt{M/N}\cos(\sqrt{M/N}t) - i\sin(\sqrt{M/N}t) \\ \sqrt{1- M/N}\cos(\sqrt{M/N}t)
\end{pmatrix}. \]
Thus $\braket[e^{-iHt}]{\mathcal{M}}{\mathcal{N}} = \frac{M}{N}\cos^2(\sqrt{M/N}t) + \sin^2(\sqrt{M/N}t)$. This is equal to 1 when $t = \frac{\pi}{2}\sqrt{\frac{N}{M}}$.

Thus we can produce $\ket{\mathcal{M}}$ in $O(\sqrt{N/M})$ time.

TODO: optimality.

\subsubsection{Adiabatic Grover}
\[ H_0 = \vec{1} - \ketbra{\mathcal{N}}{\mathcal{N}} = \mathbb{1}-\mathbb{J}/N \]
\[ H_f = \vec{1} - \sum_{m\in\mathcal{M}}\ketbra{m}{m} = \begin{pmatrix}
0 & 0 \\ 0 & \mathbb{1}_{N-M}
\end{pmatrix}.\]

Then
\[ H(s) = (1-s)H_0 + sH_f = \begin{pmatrix}
(1-s)\mathbb{1} +\frac{s-1}{N}\mathbb{J} & \frac{s-1}{N}\mathbb{J} \\
\frac{s-1}{N}\mathbb{J} & \mathbb{1} + \frac{s-1}{N}\mathbb{J}
\end{pmatrix} = \begin{pmatrix}
(1-s)\mathbb{1}_M & 0 \\ 0 & \mathbb{1}_{N-M}
\end{pmatrix} + \frac{s-1}{N}\mathbb{J}. \]
Then, setting $A = \begin{pmatrix}
(1-s-\lambda)\mathbb{1}_M & 0 \\ 0 & (1-\lambda)\mathbb{1}_{N-M}
\end{pmatrix}$
\begin{align*}
\det(H(s)-\lambda) &= \det \left(A + \frac{s-1}{N}\mathbb{J}^{n\times 1}\mathbb{J}^{1\times n}\right) \\
&= \det(A)\det \left(\mathbb{1}_N + \frac{s-1}{N}A^{-1}\mathbb{J}^{n\times 1}\mathbb{J}^{1\times n}\right) \\
&= \det(A)\det \left(1 + \frac{s-1}{N}\mathbb{J}^{1\times n}A^{-1}\mathbb{J}^{n\times 1}\right) \\
&= (1-s-\lambda)^{M}(1-\lambda)^{N-M}\left(1 + \frac{M(s-1)}{(1-s-\lambda)N} + \frac{(N-M)(s-1)}{(1-\lambda)N}\right) \\
&= (1-s-\lambda)^{M-1}(1-\lambda)^{N-M-1}\left(\lambda^2 - \lambda + s(1-s)\frac{N-M}{N}\right),
\end{align*}
where we have used the matrix determinant lemma to simplify the calculation.

We see that there are four distinct eigenvalues:
\begin{align*}
\lambda_{0,1} &= \frac{1}{2}\left(1\pm \sqrt{1-4(1- \frac{M}{N})s(1-s)}\right) &\text{with multiplicity $1$} \\
&= \frac{1}{2}\left(1\pm \sqrt{\frac{M}{N}+4(1- \frac{M}{N})(s-\frac{1}{2})^2}\right) \\
\lambda_{2} &= 1-s &\text{with multiplicity $M-1$}\\
\lambda_{3} &= 1 &\text{with multiplicity $N-M-1$.}
\end{align*}

Define $\Delta \defeq \lambda_1-\lambda_0 = \sqrt{1-4(1- \frac{M}{N})s(1-s)}$.
TODO: we can ignore $\lambda_{2,3}$! (Why?)

\begin{lemma}
\[ \int_0^1 \frac{1}{\Delta}\diff{s} = \sqrt{\frac{\frac{N}{M}}{4\big(\frac{N}{M}-4\big)}}\log\Bigg(\frac{\sqrt{\frac{N}{M}\big(\frac{N}{M}-1\big)}+ \big(\frac{N}{M}-1\big)}{\sqrt{\frac{N}{M}\big(\frac{N}{M}-1\big)}- \big(\frac{N}{M}-1\big)}\Bigg) \sim \log\Big(\frac{N}{M}\Big). \]
\end{lemma}

Next we are interested in the eigen vectors associated to $\lambda_{0,1}$. Let $Q_1$ be a unitary transformation that maps $\mathbb{J}^{M\times 1}$ to $\begin{pmatrix}
\sqrt{M} \\ 0 \\ 0 \\ \vdots
\end{pmatrix} \in \C^M$. Similarly let $Q_2$ be a unitary transformation that maps $\mathbb{J}^{(N-M)\times 1}$ to $\begin{pmatrix}
\sqrt{N-M} \\ 0 \\ 0 \\ \vdots
\end{pmatrix} \in \C^{(N-M)}$ and define $Q = \begin{pmatrix}
Q_1 & 0 \\ 0 & Q_2
\end{pmatrix}$, which is also unitary. Then we have
\begin{align*}
    QH(s)Q^{-1} &= \begin{pmatrix}
        (1-s)\mathbb{1}_M & 0 \\ 0 & \mathbb{1}_{N-M}
        \end{pmatrix} + \frac{s-1}{N}Q\mathbb{J}^{N\times 1}(\mathbb{J}^{N\times 1})^*Q^* \\
    &= \begin{pmatrix}
        (1-s)\mathbb{1}_M & 0 \\ 0 & \mathbb{1}_{N-M}
        \end{pmatrix} + \frac{s-1}{N} \begin{pmatrix}\sqrt{M} \\ 0 \\ \vdots \\ 0 \\ \sqrt{N-M} \\ 0 \\ \vdots \end{pmatrix}\begin{pmatrix}\sqrt{M} \\ 0 \\ \vdots \\ 0 \\ \sqrt{N-M} \\ 0 \\ \vdots \end{pmatrix}^*.
\end{align*}

All but two of the eigenvectors are just elements of $\mathcal{N}$. To study the other two we can simplify by ``removing the zeros''. Now the eigenvalue problem becomes
\[ \left(\begin{pmatrix}
1-s-\lambda_{0,1} & 0 \\ 0 & 1 -\lambda_{0,1}
\end{pmatrix} + \frac{s-1}{N}\begin{pmatrix}
\sqrt{M} \\ \sqrt{N-M}
\end{pmatrix}\begin{pmatrix}
\sqrt{M} \\ \sqrt{N-M}
\end{pmatrix}^*\right)\vec{v} = 0. \]
Setting $\vec{v} = \begin{pmatrix}
x_1 \\ x_2
\end{pmatrix}$ gives us the equations
\begin{align*}
0 &= (1-s-\lambda_{0,1})x_1 + \frac{s-1}{N}(Mx_1 + \sqrt{M}\sqrt{N-M}x_2) \\
0 &= (1-\lambda_{0,1})x_2 + \frac{s-1}{N}(\sqrt{M}\sqrt{N-M}x_1 + (N-M)x_2)
\end{align*}
reshuffling and dividing these equations gives
\[ \frac{(1-s-\lambda_{0,1})x_1}{(1-s-\lambda_{0,1})x_2} = \frac{-\frac{s-1}{N}(Mx_1 + \sqrt{M}\sqrt{N-M}x_2)}{-\frac{s-1}{N}(\sqrt{M}\sqrt{N-M}x_1 + (N-M)x_2)} = \frac{\sqrt{M}(\sqrt{M}x_1 + \sqrt{N-M}x_2)}{\sqrt{N-M}(\sqrt{M}x_1 + \sqrt{N-M}x_2)} = \frac{\sqrt{M}}{\sqrt{N-M}}. \]
So we have eigenvectors $\vec{v}_{0,1} = (\sqrt{M}(1-\lambda_{0,1}), \sqrt{N-M}(1-s-\lambda_{0,1}))^\transp$ of $QH(s)Q^{-1}$. The corresponding eigenvectors of $H(s)$ are then given by
\[ Q^*\vec{v}_{0,1} = \begin{pmatrix}
(1-\lambda_{0,1})\mathbb{J}^{M\times 1} \\ (1-s-\lambda_{0,1})\mathbb{J}^{(N-M)\times 1}
\end{pmatrix}. \]

For computational ease we will keep on working with the eigenvectors $\vec{v}_{0,1}$ of $QH(s)Q^{-1}$. We denote by $\ket{0}$ and $\ket{1}$ the normalisation of $\vec{v}_{0,1}$.


\subsubsection{Poisson projective measurement}
The dynamics of the system is governed by the differential equation
\[ \od{\rho}{s} = \Lambda(\ketbra{0}{0}\rho \ketbra{0}{0} + \ketbra{1}{1} \rho \ketbra{1}{1} - \rho). \]
Now we can rewrite $\od{\rho}{t}$ in the basis $ \ket{0}, \ket{1}$: let $i,j,k,l=0,1 \mod 2$ with implicit summation
\begin{align*}
\od{\rho}{s} &= \od{}{s}\left(\ketbra{i}{i}\rho\ketbra{j}{j}\right) \\
&= \od{}{s}(\braket[\rho]{i}{j})\ketbra{i}{j} + \braket[\rho]{i}{j}\od{}{s}(\ketbra{i}{j}) \\
&= \od{}{s}(\braket[\rho]{i}{j})\ketbra{i}{j} + \braket[\rho]{i}{j}\ketbra{k}{k}\od{}{s}\ketbra{i}{j} - \braket[\rho]{i}{j}\ketbra{i}{j}\od{}{s}\ketbra{l}{l} \\
&= \od{}{s}(\braket[\rho]{i}{j})\ketbra{i}{j} + \braket[\rho]{i}{j}\ketbra{i+1}{i+1}\od{}{s}\ketbra{i}{j} - \braket[\rho]{i}{j}\ketbra{i}{j}\od{}{s}\ketbra{j+1}{j+1} \\
&= \left(\od{}{s}(\braket[\rho]{i}{j}) + \braket[\rho]{i+1}{j}\braket[\od{}{s}]{i}{i+1}  - \braket[\rho]{i}{j+1}\braket[\od{}{s}]{j+1}{j}\right)\ketbra{i}{j}. \\
\end{align*}
For each $\ketbra{i}{j}$ we get an equation, four in total. One of these is redundant by the zero trace requirement. Writing $y_{i,j}\defeq \braket[\rho]{i}{j})$ and $\omega_{ij} \defeq \braket[\od{}{s}]{i}{j}$ the three remaining equations are
\begin{align*}
\od{\rho_{00}}{s} &= -\rho_{10}\omega_{01} + \rho_{01}\omega_{10} \\
\od{\rho_{01}}{s} &= -\Lambda \rho_{01} - (1-\rho_{00})\omega_{01} + \rho_{00}\omega_{01} \\
\od{\rho_{10}}{s} &= -\Lambda \rho_{10} - \rho_{00}\omega_{10} + (1-\rho_{00})\omega_{10}
\end{align*}
Setting $\omega = \omega_{10} = - \omega_{01}$ and $y = \rho_{00} - 1/2$we obtain the equation
\[ \od[2]{y}{s} = \left(\frac{\od{\omega}{s}}{\omega}-\Lambda\right)\od{y}{s} - 4\omega^2y. \]


Setting $\vec{y} = \begin{pmatrix}
y \\ y'
\end{pmatrix}$ this second order differential equation is equivalent to the first order system
\[ \begin{pmatrix}
y \\ y'
\end{pmatrix}' = \begin{pmatrix}
0 & 1 \\ -4 & -\Lambda/\omega
\end{pmatrix}, \]
which is in the form $\vec{y}' = A \vec{y}$. Now $A$ is similar to $\begin{pmatrix}
    \omega/\Lambda & 0 \\ -4 & -\Lambda/\omega
\end{pmatrix}$, so it is bounded if both $\Lambda$ and $\Lambda^{-1}$ are bounded functions.

Then by the Picard-Lindelöf theorem the initial value problem has a unique solution on $[0,1]$. In addition let $y_1$ be the solution obtained using $\Lambda_1$ and $y_2$ using $\Lambda_2$. Then
\[ \Lambda_1 \leq \Lambda_2 \implies y_1 \leq y_2. \]
To see this, we may first remark that
\[ \setbuilder{t\in[0,1]}{y_1(t)\leq y_2(t) \land y'_1(t)\leq y'_2(t)} = (y_2-y_1)^{-1}[\;[0,+\infty[\;] \cap (y'_2-y'_1)^{-1}[\;[0,+\infty[\;] \]
is a closed and bounded set that contains $0$. Let $t_1$ be its supremum. This means that $y_1(t_1)\leq y_2(t_1)$ and $y'_1(t_1)\leq y'_2(t_1)$, but $y_1(t) > y_2(t)$ or $y'_1(t) > y'_2(t)$ on some open set $]t_1, t_1+\delta [$.







