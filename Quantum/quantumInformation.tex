\chapter{Circuit model}
\section{Qubits}
\begin{definition}
A \udef{qubit} is an element of $\C P^2$.
\end{definition}

\subsection{$\suAlg(2)$ and the Pauli matrices}
The qubit Hamiltonians are elements of $\suAlg(2)$. Getting rid of the arbitrary global phase gives us elements of $\suAlg(2)$.

\begin{lemma}
For all $\sigma\in \suAlg(2)$, the eigenvalues $\lambda_1, \lambda_2$ are real and $\lambda_1 = -\lambda_2$.
\end{lemma}
\begin{proof}
For all $\sigma\in \suAlg(2)$, $\sigma$ is self-adjoint and $\Tr[\sigma] = \lambda_1 + \lambda_2 = 0$. 
\end{proof}
\begin{corollary}
For all $\sigma\in \suAlg(2)$, we have $\norm{\sigma}_{2} = \sqrt{2}\norm{\sigma}$, where $\norm{\cdot}_2$ is the Hilbert-Schmidt norm.
\end{corollary}
\begin{proof}
We have $\norm{\sigma}_{2} = \sqrt{\lambda_1^2 + \lambda_2^2} = \sqrt{2}|\lambda_1| = \sqrt{2}\norm{\sigma}$.
\end{proof}
\begin{corollary}
The inner product
\[ \inner{\cdot,\cdot}: (\sigma_1,\sigma_2) \mapsto \frac{1}{2}\Tr[\sigma_1\sigma_2] \]
on $\suAlg(2)$ yields the operator norm as the norm associated with this inner product.
\end{corollary}
\begin{corollary} \label{eigenvaluesUnitVectorsu2}
Let $\sigma$ be a unit vector in $\suAlg(2)$. Then $\sigma$ has eigenvalues $\pm 1$. This means $\sigma$ is unitary.
\end{corollary}
\begin{corollary} \label{BlochBijection}
There is a bijection between the unit vectors in $\suAlg(2)$ and the rank-1 projections on $\C^2$ given by $\suAlg(2)/\R \to \sigma\mapsto E^\sigma_{1}$, where $E^\sigma_{1}$ is the eigenspace of $\sigma$ associated with eigenvalue $+1$.
\end{corollary}
\begin{proof}
We construct an inverse of the map. Let $P_1$ be the orthogonal projector on $E^\sigma_{1}$. Then $\sigma = 2P_1 - \id$.
\end{proof}


\begin{proposition}
Let $\sigma\in\suAlg(2)$. Then $\sigma^2 = \norm{\sigma}^2\;\vec{1}$.
\end{proposition}
\begin{proof}
We have 
\[ \sigma^2 = \norm{\sigma}^2 \left(\frac{\sigma}{\norm{\sigma}}\right)^2 = \norm{\sigma}^2 \frac{\sigma}{\norm{\sigma}}\left(\frac{\sigma}{\norm{\sigma}}\right)^* = \norm{\sigma}^2\;\vec{1}, \]
where we have used that $\frac{\sigma}{\norm{\sigma}}$ is unitary by \ref{eigenvaluesUnitVectorsu2}.
\end{proof}
\begin{corollary}
The real algebra generated by $\suAlg(2)$ is the Clifford algebra $\Cl_{3,0}$. The unit pseudoscalar is $i\vec{1}$.
\end{corollary}
Note that $\suAlg(2)$ is a Lie algebra and thus closed under the Lie bracket, but not an algebra under operator composition. Thus the algebra generated by $\suAlg(2)$ is larger than $\suAlg(2)$ (indeed $\sigma^2 = \norm{\sigma}^2\;\vec{1}\notin \suAlg(2)$).

\begin{proposition}[Pauli matrices]
The Clifford algebra $\suAlg(2)$ has an orthonormal basis
\[ \sigma_x = \begin{pmatrix}
0 & 1 \\ 1 & 0
\end{pmatrix}, \qquad \sigma_y = \begin{pmatrix}
0 & -i \\ i & 0
\end{pmatrix} \qquad \text{and}\qquad \sigma_z = \begin{pmatrix}
1 & 0 \\ 0 & -1
\end{pmatrix}. \]
\end{proposition}

\subsection{The Bloch sphere}
Because $\suAlg(2)$ is the Clifford algebra $\Cl_{3,0}$, we can use the unit sphere in $\R^3$ to represent the unit vectors in $\suAlg(2)$. By \ref{BlochBijection} we can also use it to represent the rank-1 projections on $\C^2$. The unit sphere with as $x,y,z$ axes the Pauli matrices $\sigma_x,\sigma_y, \sigma_z$ is called the \udef{Bloch sphere}.

TODO image of Bloch sphere.

TODO spherical coordinates: $\cos\theta / 2\ket{0} + e^{i\phi}\sin\theta/2 \ket{1}$
\begin{lemma}
\[ e^{\phi/2 i\sigma}e^{\theta/2 i\sigma^\perp}\ket{1} = \cos\theta / 2\ket{0} + e^{i\phi}\sin\theta/2 \ket{1} \]
\end{lemma}

\section{Gates}

\subsection{Controlled gates}
\begin{definition}
Let $H_1, H_2$ be two Hilbert spaces. Let $P$ be a projector on $H_1$ and $L$ an operator on $H_2$. The operation of $L$ \udef{controlled by} $P$ is the operation $P\otimes L + (\id_{H_1} - P)\otimes \id_{H_2}$ in $H_1\otimes H_2 \to H_1\otimes H_2$. 
\end{definition}

\chapter{Eigenpath traversal}
\section{Quantum Zeno effect}
\begin{proposition}
Consider a path of states $\ket{\psi(s)}$ where $s\in[0,1]$. Assume that, for fixed $d$ and all $\delta$,
\[ |\braket{\psi(s)}{\psi(s+\delta}|^2 \geq 1-d^2\delta^2. \]
Then 
\end{proposition}

\section{Adiabatic quantum computation}
\section{Evolution through measurement}
\subsection{Phase randomisation}
$\ket{\psi_0} = \ket{E_0(0)} = \sum_i\alpha_i\ket{E_i(s_1)}$
\begin{align*}
\rho(s_1) &= \frac{1}{T}\int_0^T e^{-iH(s_1)t}\ketbra{\psi_0}{\psi_0} e^{iH(s_1)t} \diff{t} \\
&= \sum_{i,j}\alpha_i\alpha_j^* \frac{1}{T}\left(\int_0^T e^{-i(E_i-E_j)t}\diff{t}\right)\ketbra{E_i}{E_j} \\
&= \sum_{i,j}\alpha_i\alpha_j^* \left(\frac{i(e^{-i(E_i-E_j)T}-1)}{T(E_i-E_j)}\right)\ketbra{E_i}{E_j}
\end{align*}

\begin{theorem}[Randomised dephasing]
Let $\ket{\psi(s)}$ be a nondegenerate eigenstate of $H(s)$ and $\{\omega_j\}$ the energy differences to the other eigenstates $\ket{\psi_j(s)}$. Let $T$ be a random variable. Then, for all states $\rho$, we have
\[ \norm{(M_l - e^{-iH(s)T}\rho e^{-iH(s)T}}_\text{tr} \leq \epsilon = \sup_{\omega_j}|\Phi(\omega_j)| \]
\end{theorem}

\chapter{Variational quantum algorithms}

\chapter{Algorithms}
\section{Deutsch's problem}

\section{Grover's search algorithm}
Suppose we have a set $\mathcal{N}$ of $N$ items, some of which are marked. WLOG we can take $\mathcal{N}$ to be the set of bit strings of length $\nu$. The marked items form a subset $\mathcal{M}$ of size $M$. Suppose we have an oracle that tells us whether an object is marked or not:
\[ f:\mathcal{N} \to \{0,1\}: x\mapsto \begin{cases}
0 & (x\in \mathcal{M}) \\
1 & (x\notin \mathcal{M})
\end{cases} \]
Now we want to find a marked item. Classically we need to check $\Theta(N/M)$ items on average.

\subsection{Circuit model}
Let $\setbuilder{\ket{n}}{n\in\mathcal{N}}$ be a basis of a Hilbert space $\mathcal{H}_N$ and let $\mathcal{H}_2$ be a qubit space.

\subsubsection{The oracle}
We would like to use the operator
\[ U_f: \mathcal{H}_N\to \mathcal{H}_N: \ket{n}\mapsto (-1)^{f(n)}\ket{n}. \]

This can be constructed from the oracle
\[ O_f: \mathcal{H}_N\otimes \mathcal{H}_2 \to \mathcal{H}_N\otimes \mathcal{H}_2: \ket{n}\otimes \ket{q}\mapsto \ket{n}\otimes\ket{f(n)\oplus q}, \]
where $\oplus$ is addition modulo $2$, by preparing the qubit in the superposition $\frac{1}{\sqrt{2}}(\ket{0}-\ket{1})$. Then
\begin{align*}
O_f\left(\ket{n}\otimes \frac{1}{\sqrt{2}}(\ket{0}-\ket{1})\right)
&= \ket{n}\otimes \frac{1}{\sqrt{2}}(\ket{f(n)}-\ket{f(n)\oplus 1}) \\
&= (-1)^{f(n)}\ket{n}\otimes \frac{1}{\sqrt{2}}(\ket{0}-\ket{1}).
\end{align*}

The operator $U_f$ can also be written
\[ U_f = \id_{\mathcal{H}_N} - 2\sum_{m\in\mathcal{M}}\ketbra{m}{m}. \]

\subsubsection{The algorithm}
We construct the an initial state which is a superposition of all possible solutions
\[ \ket{\mathcal{N}} = \frac{1}{\sqrt{N}}\sum_{n\in\mathcal{N}}\ket{n}. \]
This can be prepared by applying a Hadamard gate $W$ to each qubit in the register.

We also define the state
\[ \ket{\mathcal{M}} = \frac{1}{\sqrt{M}}\sum_{m\in\mathcal{M}}\ket{m}. \]

We define the operation
\[ U_0 = W^{\otimes\nu}(\id - 2\ketbra{0}{0})W^{\otimes\nu}= \id - 2\ketbra{\mathcal{N}}{\mathcal{N}}. \]

Now both $U_0$ and $U_f$ leave $\Span\{\}$

\subsection{Analogue Grover}
Why does analogue Grover work?


\subsection{Adiabatic Grover}
\[ H_0 = \vec{1} - \ketbra{\mathcal{N}}{\mathcal{N}} = \mathbb{1}-\mathbb{J}/N \]
\[ H_f = \vec{1} - \sum_{m\in\mathcal{M}}\ketbra{m}{m} = \begin{pmatrix}
0 & 0 \\ 0 & \mathbb{1}_{N-M}
\end{pmatrix}.\]

Then
\[ H(s) = (1-s)H_0 + sH_f = \begin{pmatrix}
(1-s)\mathbb{1} +\frac{s-1}{N}\mathbb{J} & \frac{s-1}{N}\mathbb{J} \\
\frac{s-1}{N}\mathbb{J} & \mathbb{1} + \frac{s-1}{N}\mathbb{J}
\end{pmatrix} = \begin{pmatrix}
(1-s)\mathbb{1}_M & 0 \\ 0 & \mathbb{1}_{N-M}
\end{pmatrix} + \frac{s-1}{N}\mathbb{J}. \]
Then, setting $A = \begin{pmatrix}
(1-s-\lambda)\mathbb{1}_M & 0 \\ 0 & (1-\lambda)\mathbb{1}_{N-M}
\end{pmatrix}$
\begin{align*}
\det(H(s)-\lambda) &= \det \left(A + \frac{s-1}{N}\mathbb{J}^{n\times 1}\mathbb{J}^{1\times n}\right) \\
&= \det(A)\det \left(\mathbb{1}_N + \frac{s-1}{N}A^{-1}\mathbb{J}^{n\times 1}\mathbb{J}^{1\times n}\right) \\
&= \det(A)\det \left(1 + \frac{s-1}{N}\mathbb{J}^{1\times n}A^{-1}\mathbb{J}^{n\times 1}\right) \\
&= (1-s-\lambda)^{M}(1-\lambda)^{N-M}\left(1 + \frac{M(s-1)}{(1-s-\lambda)N} + \frac{(N-M)(s-1)}{(1-\lambda)N}\right) \\
&= (1-s-\lambda)^{M-1}(1-\lambda)^{N-M-1}\left(\lambda^2 - \lambda + s(1-s)\frac{N-M}{N}\right),
\end{align*}
where we have used the matrix determinant lemma to simplify the calculation.

We see that there are four distinct eigenvalues:
\begin{align*}
\lambda_{0,1} &= \frac{1}{2}\left(1\pm \frac{\sqrt{N+4(Ns^2-Ns-Ms^2+Ms)}}{\sqrt{N}}\right) &\text{with multiplicity $1$}\\
\lambda_{2} &= 1-s &\text{with multiplicity $M-1$}\\
\lambda_{3} &= 1 &\text{with multiplicity $N-M-1$.}
\end{align*}

Next we are interested in the eigen vectors associated to $\lambda_{0,1}$. Let $Q_1$ be a unitary transformation that maps $\mathbb{J}^{M\times 1}$ to $\begin{pmatrix}
\sqrt{M} \\ 0 \\ 0 \\ \vdots
\end{pmatrix} \in \C^M$. Similarly let $Q_2$ be a unitary transformation that maps $\mathbb{J}^{(N-M)\times 1}$ to $\begin{pmatrix}
\sqrt{N-M} \\ 0 \\ 0 \\ \vdots
\end{pmatrix} \in \C^{(N-M)}$ and define $Q = \begin{pmatrix}
Q_1 & 0 \\ 0 & Q_2
\end{pmatrix}$, which is also unitary. Then we have
\begin{align*}
    QH(s)Q^{-1} &= \begin{pmatrix}
        (1-s)\mathbb{1}_M & 0 \\ 0 & \mathbb{1}_{N-M}
        \end{pmatrix} + \frac{s-1}{N}Q\mathbb{J}^{N\times 1}(\mathbb{J}^{N\times 1})^*Q^* \\
    &= \begin{pmatrix}
        (1-s)\mathbb{1}_M & 0 \\ 0 & \mathbb{1}_{N-M}
        \end{pmatrix} + \frac{s-1}{N} \begin{pmatrix}\sqrt{M} \\ 0 \\ \vdots \\ 0 \\ \sqrt{N-M} \\ 0 \\ \vdots \end{pmatrix}\begin{pmatrix}\sqrt{M} \\ 0 \\ \vdots \\ 0 \\ \sqrt{N-M} \\ 0 \\ \vdots \end{pmatrix}^*.
\end{align*}

All but two of the eigenvectors are just elements of $\mathcal{N}$. To study the other two we can simplify by ``removing the zeros''. Now the eigenvalue problem becomes
\[ \left(\begin{pmatrix}
1-s-\lambda_{0,1} & 0 \\ 0 & 1 -\lambda_{0,1}
\end{pmatrix} + \frac{s-1}{N}\begin{pmatrix}
\sqrt{M} \\ \sqrt{N-M}
\end{pmatrix}\begin{pmatrix}
\sqrt{M} \\ \sqrt{N-M}
\end{pmatrix}^*\right)\vec{v} = 0. \]
Setting $\vec{v} = \begin{pmatrix}
x_1 \\ x_2
\end{pmatrix}$ gives us the equations
\begin{align*}
0 &= (1-s-\lambda_{0,1})x_1 + \frac{s-1}{N}(Mx_1 + \sqrt{M}\sqrt{N-M}x_2) \\
0 &= (1-\lambda_{0,1})x_2 + \frac{s-1}{N}(\sqrt{M}\sqrt{N-M}x_1 + (N-M)x_2)
\end{align*}
reshuffling and dividing these equations gives
\[ \frac{(1-s-\lambda_{0,1})x_1}{(1-s-\lambda_{0,1})x_2} = \frac{-\frac{s-1}{N}(Mx_1 + \sqrt{M}\sqrt{N-M}x_2)}{-\frac{s-1}{N}(\sqrt{M}\sqrt{N-M}x_1 + (N-M)x_2)} = \frac{\sqrt{M}(\sqrt{M}x_1 + \sqrt{N-M}x_2)}{\sqrt{N-M}(\sqrt{M}x_1 + \sqrt{N-M}x_2)} = \frac{\sqrt{M}}{\sqrt{N-M}}. \]
So we have eigenvectors $\vec{v}_{0,1} = (\sqrt{M}(1-\lambda_{0,1}), \sqrt{N-M}(1-s-\lambda_{0,1}))^\transp$ of $QH(s)Q^{-1}$. The corresponding eigenvectors of $H(s)$ are then given by
\[ Q^*\vec{v}_{0,1} = \begin{pmatrix}
(1-\lambda_{0,1})\mathbb{J}^{M\times 1} \\ (1-s-\lambda_{0,1})\mathbb{J}^{(N-M)\times 1}
\end{pmatrix}. \]

For computational ease we will keep on working with the eigenvectors $\vec{v}_{0,1}$ of $QH(s)Q^{-1}$. We denote by $\ket{0}$ and $\ket{1}$ the normalisation of $\vec{v}_{0,1}$.


\subsubsection{Poisson projective measurement}
The dynamics of the system is governed by the differential equation
\[ \od{\rho}{s} = \Lambda(\ketbra{0}{0}\rho \ketbra{0}{0} + \ketbra{1}{1} \rho \ketbra{1}{1} - \rho). \]
Now we can rewrite $\od{\rho}{t}$ in the basis $ \ket{0}, \ket{1}$: let $i,j,k,l=0,1 \mod 2$ with implicit summation
\begin{align*}
\od{\rho}{s} &= \od{}{s}\left(\ketbra{i}{i}\rho\ketbra{j}{j}\right) \\
&= \od{}{s}(\braket[\rho]{i}{j})\ketbra{i}{j} + \braket[\rho]{i}{j}\od{}{s}(\ketbra{i}{j}) \\
&= \od{}{s}(\braket[\rho]{i}{j})\ketbra{i}{j} + \braket[\rho]{i}{j}\ketbra{k}{k}\od{}{s}\ketbra{i}{j} - \braket[\rho]{i}{j}\ketbra{i}{j}\od{}{s}\ketbra{l}{l} \\
&= \od{}{s}(\braket[\rho]{i}{j})\ketbra{i}{j} + \braket[\rho]{i}{j}\ketbra{i+1}{i+1}\od{}{s}\ketbra{i}{j} - \braket[\rho]{i}{j}\ketbra{i}{j}\od{}{s}\ketbra{j+1}{j+1} \\
&= \left(\od{}{s}(\braket[\rho]{i}{j}) + \braket[\rho]{i+1}{j}\braket[\od{}{s}]{i}{i+1}  - \braket[\rho]{i}{j+1}\braket[\od{}{s}]{j+1}{j}\right)\ketbra{i}{j}. \\
\end{align*}
For each $\ketbra{i}{j}$ we get an equation, four in total. One of these is redundant by the zero trace requirement. Writing $y_{i,j}\defeq \braket[\rho]{i}{j})$ and $\omega_{ij} \defeq \braket[\od{}{s}]{i}{j}$ the three remaining equations are
\begin{align*}
\od{\rho_{00}}{s} &= -\rho_{10}\omega_{01} + \rho_{01}\omega_{10} \\
\od{\rho_{01}}{s} &= -\Lambda \rho_{01} - (1-\rho_{00})\omega_{01} + \rho_{00}\omega_{01} \\
\od{\rho_{10}}{s} &= -\Lambda \rho_{10} - \rho_{00}\omega_{10} + (1-\rho_{00})\omega_{10}
\end{align*}
Setting $\omega = \omega_{10} = - \omega_{01}$ and $y = \rho_{00} - 1/2$we obtain the equation
\[ \od[2]{y}{s} = \left(\frac{\od{\omega}{s}}{\omega}-\Lambda\right)\od{y}{s} - 4\omega^2y. \]


Setting $\vec{y} = \begin{pmatrix}
y \\ y'
\end{pmatrix}$ this second order differential equation is equivalent to the first order system
\[ \begin{pmatrix}
y \\ y'
\end{pmatrix}' = \begin{pmatrix}
0 & 1 \\ -4 & -\Lambda/\omega
\end{pmatrix}, \]
which is in the form $\vec{y}' = A \vec{y}$. Now $A$ is similar to $\begin{pmatrix}
    \omega/\Lambda & 0 \\ -4 & -\Lambda/\omega
\end{pmatrix}$, so it is bounded if both $\Lambda$ and $\Lambda^{-1}$ are bounded functions.

Then by the Picard-LindelÃ¶f theorem the initial value problem has a unique solution on $[0,1]$. In addition let $y_1$ be the solution obtained using $\Lambda_1$ and $y_2$ using $\Lambda_2$. Then
\[ \Lambda_1 \leq \Lambda_2 \implies y_1 \leq y_2. \]
To see this, we may first remark that
\[ \setbuilder{t\in[0,1]}{y_1(t)\leq y_2(t) \land y'_1(t)\leq y'_2(t)} = (y_2-y_1)^{-1}[\;[0,+\infty[\;] \cap (y'_2-y'_1)^{-1}[\;[0,+\infty[\;] \]
is a closed and bounded set that contains $0$. Let $t_1$ be its supremum. This means that $y_1(t_1)\leq y_2(t_1)$ and $y'_1(t_1)\leq y'_2(t_1)$, but $y_1(t) > y_2(t)$ or $y'_1(t) > y'_2(t)$ on some open set $]t_1, t_1+\delta [$.







