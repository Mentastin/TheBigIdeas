\chapter{Semigroups and evolution operators}
\section{Semigroups of linear operators}
\begin{definition}
Let $X$ be a Banach space and $\sSet{I, +, 0, \leq}$ a partially ordered normed group with positive cone $I^+$. We call a function $T: I^+ \to \Lin(X)$ a \udef{semigroup of linear operators} (or just \udef{semigroup}) if
\begin{itemize}
\item $T(0) = \id_X$;
\item $T(s+t) = T(s)T(t)$ for all $s,t \in I^+$.
\end{itemize}
A function $T: I \to \Lin(X)$ satisfying the same conditions is called a \udef{group of linear operators}.

A semigroup is called \udef{strongly continuous} if it is continuous when $I$ is equipped with the order convergence and $X$ with the strong operator topology.

We call $T$ \udef{bounded} if $T(t)$ is bounded for all $t\in I^+$.
\end{definition}

\begin{lemma}
A semigroup of linear operators $T:I^+\to \Lin(X)$ is bounded \textup{if and only if} $T[S]$ is a set of bounded operators for some $S\subseteq I+$ that generates $I^+$ as a monoid.
\end{lemma}

\begin{proposition}
Let $T:I^+\to \Lin(X)$ be a semigroup of operators on a Banach space. Then the following are equivalent:
\begin{enumerate}
\item $T$ is strongly continuous;
\item $T$ is strongly continuous at $0$;
\item $T(t)$ is uniformly bounded on some neighbourhood of $0$ and there exists a dense subset $D\subseteq X$ such that $\lim_{t\to 0} T(t)x = x$ for all $x\in D$.
\end{enumerate}
\end{proposition}
\begin{proof}
$(1) \Rightarrow (2)$ If a semigroup is strongly continuous, then it is obviously strongly continuous at $0$.

$(2) \Rightarrow (3)$ Because $T(0) = \id_X$, strong continuity at $0$ means that $\lim_{t\to 0} T(t)x = x$ for all $x\in X$. Thus this also holds for all $x$ in any (dense) subset of $X$.

For the uniform bound we use the uniform boundedness principle \ref{uniformBoundednessPrinciple}. It is then enough to show that there exists a neighbourhood $U$ of $0$ such that $\sup\setbuilder{\norm{T(t)x}}{t\in U} <\infty$ for all $x\in X$.

TODO

$(3) \Rightarrow (1)$

Conversely, assume a semigroup $T: I^+\to \Lin(X)$ is continuous at $0$. Take $t_0\in I^+$. By \ref{leftRightConvergence} it is enough to check that $T$ is left and right continuous at $t_0$.

First let $F$ be a filter in $\powerfilters(\upset t_0)$ that converges to $t_0$. Then $F - t_0 \in \powerfilters(I^+)$ and $F-t_0 \to 0$. Thus $T[F] = T[F-t_0 + t_0] = T[F-t_0]T[t_0] \to T[0]T[t_0] = T[t_0]$, meaning that $T$ is right continuous.

TODO left continuity.
\end{proof}
TODO cfr SOT.

\subsection{Growth bounds}
\begin{proposition}
Let $T: I^+ \to \Lin(X)$ be a strongly continuous semigroup of bounded linear operators. Then there exist contstants $w\in \R$ and $M\geq 1$ such that
\[ \forall t\in I^+:\quad \norm{T(t)} \leq Me^{w\norm{t}}. \]
\end{proposition}
\begin{proof}
Choose $M$ such that for all $0\leq s\leq 1$, $\norm{T(s)}\leq M$.
\end{proof}

\begin{definition}

\end{definition}

\subsection{Differentiability}
\begin{definition}
Let $T: I^+ \to \Lin(X)$ be a semigroup of linear operators. We say $T$ is \udef{differentiable} at $t\in I$ if the limit
\[  \]
\end{definition}

\subsection{$C_0$-semigroups}
\begin{definition}
A $C_0$-semigroup
\end{definition}

\section{One-parameter semigroups on Banach spaces}
In this section we will study functions $T: \R^+\to \Bounded(X)$ that are strongly continuous semigroups on a Banach spaces $X$. We will shorten this description to \udef{operator semigroup}.

\subsection{Orbit maps}
\begin{lemma}
Let $T: \R^+\to \Bounded(X)$ be an operator semigroup. Consider the orbit map $\xi_x: \R^+ \to X: t\mapsto T(t)x$ for some $x\in X$. The following are equivalent:
\begin{enumerate}
\item $\xi_x$ is differentiable;
\item $\xi_x$ is differentiable at $0$.
\end{enumerate}
\end{lemma}
\begin{proof}
Clearly $(1)$ implies $(2)$. Now assume $(2)$, we show $\xi_x$ is left and right differentiable at all points $t\in\R^+$ (TODO cfr. \ref{leftRightConvergence}). For right differentiability we can calculate
\begin{align*}
\lim_{h\downarrow 0} h^{-1}(\xi_x(t+h) - \xi_x(t)) &= \lim_{h\downarrow 0} h^{-1}(T(t+h)x - T(t)x) \\
&= T(t)\lim_{h\downarrow 0} h^{-1}(T(h)x - T(0)x) \\
&= T(t)\lim_{h\downarrow 0} h^{-1}(\xi_x(h) - \xi_x(0)) = \xi_x'(0).
\end{align*}
TODO
\end{proof}

\begin{lemma} \label{integrabilityOrbitMaps}
Let $T: \R^+\to \Bounded(X)$ be an operator semigroup. For all $x\in X$, the orbit map $\xi_x$ is integrable on any compact $K\subseteq [0,\infty]$.
\end{lemma}
\begin{proof}
By \ref{BochnerIntegrabilityCondition} we just need to show $\int_K\norm{\xi_x(s)}\diff{s} < \infty$. We have $\int_K\norm{\xi_x(s)}\diff{s} \leq \sup_{s\in K}\norm{\xi_x(s)}\lambda(K)$. Now $\lambda(K)$ is finite by \ref{HaarConsequences} and $\sup_{s\in K}\norm{\xi_x(s)}$ is finite by (TODO ref: extreme value theorem), as $\R \to \R: t\mapsto \norm{\xi_x(t)}$ is a continuous function.
\end{proof}

\subsection{The generator}
\begin{definition}
Let $T: \R^+\to \Bounded(X)$ be an operator semigroup. The \udef{generator} of $T$ is the operator $A: X\not\to X$ defined by
\[ Ax \defeq \xi_x'(0) = \lim_{h\downarrow 0}\frac{1}{h}\big(T(h)x - x\big) \]
with domain
\[ \dom(A) = \setbuilder{x\in X}{\text{$\xi_x$ is differentiable}}. \]
\end{definition}
Notice that the generator is indeed a linear operator.

\begin{lemma} \label{differentialOperatorSemigroupGenerator}
Let $T: \R^+\to \Bounded(X)$ be an operator semigroup with generator $A$. If $x\in\dom(A)$, then $T(t)x\in\dom(A)$ and
\[ \od{}{t}T(t)x = T(t)Ax = AT(t)x \]
for all $t\in [0,\infty]$.
\end{lemma}

\begin{proposition} \label{integralOperatorSemigroupGenerator}
Let $T: \R^+\to \Bounded(X)$ be an operator semigroup with generator $A$. For all $x\in X$, then $\int_0^t T(s)x\diff{s}\in\dom(A)$ and, for all $t\in [0,\infty]$,
\begin{align*}
T(t)x - x &= A\int_0^t T(s)x\diff{s} \qquad\text{for all $x\in X$} \\
&= \int_0^t T(s)Ax\diff{s} \qquad\text{if $x\in\dom(A)$}.
\end{align*}
\end{proposition}
This is an integrated version of \ref{differentialOperatorSemigroupGenerator}, except it holds for all $x\in X$.
\begin{proof}
Firstly $\int_0^t T(s)x\diff{s}$ exists and is finite by \ref{integrabilityOrbitMaps}.

To show $A\int_0^t T(s)x\diff{s}$ is well-defined, we calculate
\begin{align*}
A\int_0^t T(s)x\diff{s} &= \left.\dod{}{h}\right|_{h=0}T(h)\int_0^t T(s)x\diff{s} \\
&= \left.\dod{}{h}\right|_{h=0}\int_0^t T(h)T(s)x\diff{s} \\
&= \left.\dod{}{h}\right|_{h=0}\int_0^t T(s+h)x\diff{s} \\
&= \left.\dod{}{h}\right|_{h=0}\int_h^{t+h} T(s)x\diff{s} \\
&= \left.\dod{}{h}\right|_{h=0}\left(\int_0^{t+h} T(s)x\diff{s}-\int_0^{h} T(s)x\diff{s}\right) \\
&= \left.\dod{}{h}\right|_{h=t}\int_0^{h} T(s)x\diff{s}-\left.\dod{}{h}\right|_{h=0}\int_0^{h} T(s)x\diff{s} \\
&= T(t)x - x,
\end{align*}
where we have used \ref{boundedOperatorUnderIntegral} and (TODO ref: fundamental theorem calculus for Bochner integral+continuity to deal with equality a.e.).

Finally $\int_0^t T(s)Ax\diff{s}$ exists and is finite by \ref{integrabilityOrbitMaps} applied to $Ax$. We conclude using \ref{differentialOperatorSemigroupGenerator} and (TODO ref: second fundamental theorem of calculus).
\end{proof}

TODO Taylor theorem!

\begin{proposition} \label{generatorClosedDenselyDefined}
The generator of an operator semigroup is closed and densely defined.
\end{proposition}
\begin{proof}
Let $T: \R^+\to \Bounded(X)$ be an operator semigroup with generator $A$. To show $A$ is closed, consider $\seq{x_n}\subseteq \dom(A)$ such that $x_n\to x$ and $Ax_n \to y$. From \ref{integralOperatorSemigroupGenerator} we have $T(t)x_n - x_n = \int_0^tT(s)Ax_n\diff{s}$. Thus
\[ T(t)x-x = \lim_{n\to\infty} T(t)x_n - x_n = \lim_{n\to\infty} \int_0^tT(s)Ax_n\diff{s}. \]
Now $Ax_n \to y$ means the sequence $\seq{Ax_n}$ is bounded by some constant $M$. Then $\norm{T(s)Ax_n} \leq M\cdot\sup_{0\leq s \leq t}\norm{T(s)}$, meaning we can apply the dominated convergence theorem (TODO ref). So $T(t)x-x = \int_0^tT(s)y\diff{s}$ and thus
\[ Ax = \lim_{t\downarrow 0}\frac{1}{t}(T(t)x-x) = \lim_{t\downarrow 0}\frac{1}{t}\int_0^tT(s)y\diff{s} = \left.\dod{}{t}\right|_{t=0}\int_0^tT(s)y\diff{s} = T(0)y = y, \]
by the fundamental theorem of calculus (TODO ref).

For any $x\in X$ we can find a sequence $\seq{x_n}$ in $\dom(A)$ that converges to $x$, namely
\[ \frac{1}{t_n}\int^{t_n}_0T(s)x\diff{s} \qquad \text{for any sequence $\seq{t_n}$ in $[0,\infty[$ converging to $0$.}  \]
This is a sequence in $\dom(A)$ by \ref{integralOperatorSemigroupGenerator} and converges to $x$ by TODO ref. Thus $\dom(A)$ is dense in $X$ by TODO ref.
\end{proof}

\begin{proposition}
An operator is the generator of at most one operator semigroup.
\end{proposition}
\begin{proof}
Let $T: \R^+\to \Bounded(X)$ and $S: \R^+\to \Bounded(X)$ be two operator semigroups with the same generator $A$. Then for any $t\in [0,\infty[$ and $x\in \dom(A)$,
\begin{align*}
\dod{}{s} \left(T(t-s)S(s)x\right) &= T(t-s)S'(s)x - T'(t-s)S(s)x \\
&= T(t-s)As(s)x - T(t-s)As(s)x \\
&= 0
\end{align*}
by (TODO ref!!!). TODO rest.
\end{proof}

\begin{proposition} \label{boundedGenerator}
Let $T: \R^+\to \Bounded(X)$ be an operator semigroup with generator $A$. Then the following are equivalent:
\begin{enumerate}
\item $A$ is bounded;
\item $A$ is defined everywhere;
\item $T$ is uniformly continuous;
\item $T(t) = e^{tA}$ for all $t\in\R ^+$.
\end{enumerate}
\end{proposition}
\begin{proof}
$(1) \Rightarrow (2)$ Because $A$ is closed, $\dom(A)$ is closed by the closed graph theorem \ref{closedGraphTheorem}. As $\dom(A)$ is dense in $X$, this means $\dom(A) = X$.

$(2) \Rightarrow (1)$ TODO also closed graph.

$(3)$ TODO

$(4)$ $e^{tA}$ is a semigroup with generator $A$. TODO
\end{proof}

\subsubsection{Cores of the generator}
TODO move:
\begin{lemma} \label{uniformContinuityAverage}
Let $\seq{f_n: [a,b]\to X}$ be a sequence of functions from $[a,b]\subseteq \R$ to a Banach space $X$ that converges uniformly to $f: X\to Y$. Then
\[ [a,b]\to X: t\mapsto \frac{1}{t}\int_{0}^tf_n(s)\diff{s} \quad\longrightarrow\quad [a,b]\to X: t\mapsto \frac{1}{t}\int_{0}^tf(s)\diff{s} \qquad \text{uniformly.} \]
\end{lemma}
\begin{proof}
We have
\begin{align*}
\sup_{t\in[a,b]}\frac{1}{t}\int_0^t \norm{f_n(s) - f(s)}\diff{s} &\leq \sup_{t\in[a,b]}\frac{1}{t}\int_0^t \diff{s}\sup_{s\in [a,b]} \norm{f_n(s) - f(s)} \\
&= \sup_{s\in [a,b]} \norm{f_n(s) - f(s)} \to 0.
\end{align*}
\end{proof}

\begin{lemma} \label{uniformContinuityOrbitMapsConvergentSequence}
Let $T: \R^+\to \Bounded(X)$ be an operator semigroup and $\seq{x_n} \to x$ a convergent sequence in $X$. Then $f_n: [0,1]\to X: t\mapsto T(t)x_n$ converges uniformly to $f: [0,1]\to X: t\mapsto T(t)x$.
\end{lemma}
\begin{proof}
The image of $[0,1]$ under $t\mapsto \norm{T(t)}$ is compact and thus bounded, with bound $M$. Then
\begin{align*}
\sup_{t\in [0,1]}\norm{f_n(t) - f(t)} &= \sup_{t\in [0,1]}\norm{T(t)x_n - T(t)x} \\
&= \sup_{t\in [0,1]}\norm{T(t)(x_n - x)} \\
&\leq M\norm{(x_n - x)} \to 0.
\end{align*}
\end{proof}

\begin{proposition} \label{coreGeneratorCriterion}
Let $T: \R^+\to \Bounded(X)$ be an operator semigroup with generator $A$ and $D$ a subspace of $\dom(A)$. If $D$ is norm dense in $X$ and invariant under $T(t)$ for all $t\in [0,+\infty]$, then $D$ is a core for $A$.
\end{proposition}
Note norm density in $X$ is the same as norm density in $\dom(A)$, because $A$ is densely defined.
\begin{proof}
We use \ref{operatorCoreCriterion}. Take $x\in \dom(A)$; we need to show that $x\in\closure_{\norm{\cdot}_A}(D)$.

Because $D$ is norm dense in $X$, we can find a sequence $\seq{x_n}$ in $D$ that norm converges to $x$. We claim it also converges in the graph norm. To show that, it is enough to show that $\seq{Ax_n} \to Ax$ in norm.

Combining \ref{uniformContinuityOrbitMapsConvergentSequence} and \ref{uniformContinuityAverage} gives that
\[ [0,1] \to X: t\mapsto \frac{1}{t}\int_0^t T(s)x_n\diff{s} \]
converges uniformly in $n$. Thus by \ref{integralOperatorSemigroupGenerator} and Moore-Osgood (TODO ref) we have
\begin{align*}
\lim_{n\to \infty} Ax_n &= \lim_{n\to \infty} \lim_{t\downarrow 0}\frac{1}{t}\int_0^t T(s)Ax_n \diff{s} \\
&= \lim_{n\to \infty} \lim_{t\downarrow 0}\frac{1}{t}(T(t)x_n - x_n) \\
&= \lim_{t\downarrow 0}\frac{1}{t}\lim_{n\to \infty}(T(t)x_n - x_n) \\
&= \lim_{t\downarrow 0}\frac{1}{t}(T(t)x - x) = Ax.
\end{align*}

TODO

Take a sequence $\seq{t_n}\to 0$ in $\R$. Then we claim
\[ \seq{x'_n} = \seq{\frac{1}{t_n}\int_0^{t_n}T(s)x_n\diff{s}} \]
is a sequence in $D$ that converges to $x$ in the graph norm. It is definitely a sequence in $D$ by the invariance of $D$ under $T(t)$. It is now enough to show $\seq{x'_n}$ norm converges to $x$ and $\seq{Ax'_n}$ norm converges to $Ax$.
\end{proof}

\begin{proposition}
Let $T: \R^+\to \Bounded(X)$ be an operator semigroup with generator $A$. Then $\bigcap_{n\in\N}\dom(A^n)$ is a core for $A$.
\end{proposition}
\begin{proof}
The space $\bigcap_{n\in\N}\dom(A^n)$ is invariant under $T$ by \ref{differentialOperatorSemigroupGenerator}. In order to use \ref{coreGeneratorCriterion}, we need to verify that $\bigcap_{n\in\N}\dom(A^n)$ is norm dense in $\dom (A)$. TODO
\end{proof}

\subsubsection{Algebra of semigroups and generators}
\begin{proposition}
Let $T: \R^+\to \Bounded(X)$ be a strongly continuous operator semigroup with generator $A$, $\mu\in\C$ and $\alpha >0$. Then $e^{\mu t}T(\alpha t)$ is a strongly continuous operator semigroup with generator $\alpha A + \mu\id_X$.
\end{proposition}

\begin{proposition} \label{productSemigroup}
Let $T: \R^+\to \Bounded(X)$ and $S: \R^+\to \Bounded(X)$ be strongly continuous operator semigroups with generators $A$ and $B$, resp., such that $T(t)$ and $S(t)$ commute for all $t\in \R^+$. Then
\begin{enumerate}
\item $S(t)T(t)$ is a strongly continuous operator semigroup with generator $C$;
\item $\dom(A)\cap \dom(B)$ is a core of $C$;
\item $Cx = Ax + Bx$ for all $x\in \dom(A)\cap \dom(B)$.
\end{enumerate}
\end{proposition}
\begin{proof}
(1) The norm continuity of the operator multiplication implies strong continuity of the multiplication and thus of $S(t)T(t)$. The semigroup property is immediate, using commutativity.

(2) We use \ref{coreGeneratorCriterion}.TODO

(3) TODO
\end{proof}

\subsubsection{Spectral properties of resolvents}

\begin{lemma} \label{expScaledSemigroupLemma}
Let $T: \R^+\to \Bounded(X)$ be an operator semigroup with generator $A$. Take $\lambda\in \C$ and $t> 0$. Then
\begin{align*}
e^{-\lambda t}T(t)x - x &= (A- \lambda\id)\int_0^t e^{-\lambda s}T(s)x\diff{s} \qquad\text{for all $x\in X$} \\
&= \int_0^t e^{-\lambda s}T(s)(A-\lambda\id)x\diff{s} \qquad\text{if $x\in\dom(A)$}.
\end{align*}
\end{lemma}
\begin{proof}
Consider the operator semigroup $t\mapsto e^{-\lambda t}T(t)$. Its generator is $A-\lambda\id$ with domain equal to $\dom(A)$, TODO ref. The lemma is then a straightforward application of \ref{integralOperatorSemigroupGenerator}.
\end{proof}
\begin{corollary} \label{limitInftyExpScaledSemigroup}
Let $T: \R^+\to \Bounded(X)$ be an operator semigroup. If both
\[ \int_0^\infty e^{-\lambda s}T(s)x\diff{s} \qquad\text{and}\qquad \int_0^{\infty}e^{-\lambda s}T(s)(A-\lambda\id)x\diff{s} \]
exist, then $\lim_{t\to\infty}e^{-\lambda t}T(t)x = 0$.
\end{corollary}
\begin{proof}
First we show that if $\lim_{t\to\infty}e^{-\lambda t}T(t)x$ converges, it must converge to $0$. Indeed assume it converges to $y \neq 0$, then there exists $t_0 > 0$ such that for all $t\geq t_0$, $\norm{e^{-\lambda t}T(t)x} \geq \norm{y}/2$. Thus
\begin{align*}
\int_0^\infty \norm{e^{-\lambda s}T(s)x}\diff{s} &= \int_0^{t_0}\norm{e^{-\lambda s}T(s)x}\diff{s} + \int_{t_0}^{\infty}\norm{e^{-\lambda s}T(s)x}\diff{s} \\
&\geq \int_0^{t_0}\norm{e^{-\lambda s}T(s)x}\diff{s} + \int_{t_0}^{\infty}\norm{y}/2\diff{s} \\
&= \infty,
\end{align*}
meaning $\int_0^\infty e^{-\lambda s}T(s)x\diff{s}$ does not exists by \ref{BochnerIntegrabilityCondition}.

Then $x + \int_0^{\infty}e^{-\lambda t}T(t)x(A-\lambda\id)x\diff{s}$ exists by assumption and
\begin{align*}
x + \int_0^{\infty}e^{-\lambda t}T(t)x(A-\lambda\id)x\diff{s} &= x+\lim_{t\to\infty}\int_0^{t}e^{-\lambda s}T(s)x(A-\lambda\id)x\diff{s} \\
&= \lim_{t\to\infty}x+\int_0^{t}e^{-\lambda s}T(s)x(A-\lambda\id)x\diff{s} \\
&= \lim_{t\to\infty} e^{-\lambda t}T(t)x.
\end{align*}
\end{proof}


\begin{proposition}
Let $T: \R^+\to \Bounded(X)$ be an operator semigroup with generator $A$. If $\int_0^\infty e^{-\lambda s}T(s)x\diff{s}$ exists for all $x\in X$, then
\begin{enumerate}
\item $\lambda\in\res(A)$;
\item $R_A(\lambda) = \int_0^\infty e^{-\lambda s}T(s)\diff{s}$.
\end{enumerate}
\end{proposition}
\begin{proof}
(1) By \ref{closedOperatorBanachSpaceSpectrumCriterion} it is enough to show that $\lambda\id - A$ is bijective in this case. 

We verify injectivity: take $x,y\in \dom(A)$ such that $(\lambda\id - A)x = (\lambda\id - A)y$. We use \ref{expScaledSemigroupLemma} and \ref{limitInftyExpScaledSemigroup} to calculate
\begin{align*}
x-y &= x-y + \int_0^\infty e^{-\lambda s}T(s)(\lambda\id - A)(x-y)\diff{s} \\
&= \lim_{t\to \infty}x-y + \int_0^t e^{-\lambda s}T(s)(\lambda\id - A)(x-y)\diff{s} \\
&= \lim_{t\to \infty}e^{-\lambda t}T(t)(x-y) \\
&= 0.
\end{align*}

We verify surjectivity: consider \ref{expScaledSemigroupLemma} and \ref{limitInftyExpScaledSemigroup}. Note that for all $x\in X$ both $\lim_{t\to \infty}\int_0^t e^{-\lambda s}T(s)x\diff{s}$ and
\[ \lim_{t\to \infty}(\lambda\id-A)\int_0^t e^{-\lambda s}T(s)x\diff{s} = \lim_{t\to \infty}x - e^{-\lambda t}T(t)x = x \]
converge. So, because $\lambda \id - A$ is closed,
\begin{align}
    x &= \lim_{t\to \infty}(\lambda\id-A)\int_0^t e^{-\lambda s}T(s)x\diff{s} \nonumber \\
    &= (\lambda\id-A)\lim_{t\to \infty}\int_0^t e^{-\lambda s}T(s)x\diff{s} \nonumber \\
    &= (\lambda\id-A)\int_0^\infty e^{-\lambda s}T(s)x\diff{s}. \label{eq:resolventGenerator}
\end{align}
Thus each $x\in X$ is in $\im(\lambda\id-A)$.

(2) From \eqref{eq:resolventGenerator} we see that $R_A(\lambda)x = \int_0^\infty e^{-\lambda s}T(s)x\diff{s}$. TODO: show that $R$ is integrable!!!

Then we conclude with \ref{integralBoundedOperator}.
\end{proof}
\begin{corollary} \label{resolventGeneratorEstimate}
Let $T: \R^+\to \Bounded(X)$ be an operator semigroup with growth bound $\norm{T(t)}\leq Me^{wt}$. Then
\begin{enumerate}
\item $\Re \lambda > w$ implies $\lambda \in\res(A)$;
\item $\norm{R_A(\lambda)} \leq \frac{M}{\Re \lambda - w}$ for all $\lambda$ such that $\Re \lambda > w$.
\end{enumerate}
\end{corollary}
\begin{proof}
We estimate
\[ \norm{R_A(\lambda)} \leq \int_0^\infty\norm{e^{-\lambda s}T(s)x\diff{s}} \leq M\int_0^\infty e^{(w-\Re\lambda)s}\diff{s}\norm{x} = \frac{M}{\Re\lambda - w}\norm{x} \]
if $\Re \lambda > w$. 
\end{proof}
\begin{corollary} \label{resolventGeneratorPowerEstimate}
Let $T: \R^+\to \Bounded(X)$ be an operator semigroup with growth bound $\norm{T(t)}\leq Me^{wt}$. Then for all $n\in \N$
\begin{enumerate}
\item $R_A(\lambda)^n x = \frac{1}{(n-1)!}\int_0^\infty s^{n-1}e^{-\lambda s}T(s)x\diff{s}$;
\item $\norm{R_A(\lambda)^n} \leq \frac{M}{(\Re \lambda - w)^n}$ for all $\lambda$ such that $\Re \lambda > w$.
\end{enumerate}
\end{corollary}
\begin{proof}
TODO
\end{proof}

\subsubsection{Hille-Yosida generation theorems}
\begin{lemma} \label{resolventLimitLemma}
Let $A$ be an operator on a Banach space $X$. Suppose
\begin{itemize}
\item there exists $w\in \R$ such that $[w,\infty[ \subseteq \res(A)$;
\item there exists $M>0$ such that $\norm{r R_A(r)}\leq M$ for all $r \geq w$.
\end{itemize}
Then $\lim_{r\to \infty} r R_A(r)x = x$ for all $x\in \overline{\dom(A)}$.
\end{lemma}
\begin{proof}
Take $y\in \dom(A)$. Then $R_A(r)(r\id - A)y = y$ implies $r R_A(r)y = R_A(r)Ay + y$. The right-hand side converges to $y$ as $r\to\infty$ because $\norm{R_A(r)Ay} \leq \frac{M}{r}\norm{Ay} \to 0$.

Now we need to extend this result to $\overline{\dom(A)}$. Take $x\in \overline{\dom(A)}$, then we can find a sequence $\seq{x_n}$ in $\dom(A)$ that converges to $x$. By assumption $r \to r R_A(r)$ is uniformly bounded and thus uniformly continuous (TODO ref), meaning we can use the Moore-Osgood theorem (TODO ref):
\begin{align*}
\lim_{r\to \infty} r R_A(r)x &= \lim_{r\to \infty} r R_A(r)\left(\lim_{n\to\infty}x_n\right) \\
&= \lim_{n\to\infty}\lim_{r\to \infty} r R_A(r)x_n \\
&= \lim_{n\to\infty}x_n = x.
\end{align*}
\end{proof}
\begin{corollary} \label{YosidaApproximantsLemma}
If $A$ is closed in addition to the other requirements, then
\[ \lim_{r\to \infty} r AR_A(r)x = Ax \qquad \text{for all $x\in \dom(A)$.} \]
\end{corollary}
\begin{proof}
Because $A$ and $R_A(r)$ commute, we have $\lim_{r\to \infty} r AR_A(r)x = \lim_{r\to \infty} r R_A(r)Ax =Ax$.
\end{proof}

\begin{theorem}[Hille-Yosida theorem] \label{HilleYosidaContraction}
Let $A$ be an operator on a Banach space $X$. The following are equivalent:
\begin{enumerate}
\item $A$ generates a strongly continuous contraction semigroup;
\item $A$ is closed, densely defined, $\R^{>0}\subseteq \res(A)$ and for all $r > 0$, $\norm{rR_A(r)} \leq 1$.
\end{enumerate}
\end{theorem}
\begin{proof}
$(1)\Rightarrow (2)$ Follows from \ref{generatorClosedDenselyDefined} and \ref{resolventGeneratorEstimate}, setting $M = 1$ and $w = 0$.

$(2)\Rightarrow (1)$ Consider, for each $n\in \N$, the bounded operator
\[ A_n \defeq nAR_A(n) = n^2R_A(n) - n\id_X. \]
By \ref{YosidaApproximantsLemma} this sequence converges points pointwise to $A$. By \ref{boundedGenerator} each $A_n$ generates a semigroup $e^{tA_n}$. Let $T$ be the pointwise limit of these semigroups, which exists by \ref{continuityExp}. We need to show that $T$ is a strongly continuous contraction semigroup and that $A$ is the generator of $T$.


\end{proof}
\begin{corollary}
Let $A$ be an operator on a Banach space $X$. The following are equivalent:
\begin{enumerate}
\item $A$ generates a strongly continuous semigroup $T: \R^+\to \Bounded(X)$ satisfying $\norm{T(t)}\leq e^{wt}$ for some $w\in \R$ and all $t\in\R^+$;
\item $A$ is closed, densely defined, and $\lambda\in  \res(A)$, $\norm{(r-w)R_A(r)} \leq 1$ for all $r>w$.
\end{enumerate}
\end{corollary}
\begin{proof}
Applying the Hille-Yosida theorem to $A-w\id$ yields a semigroup $S(t)$. The rescaled semigroup $T(t) = e^{wt}S(t)$ has generator $A$.
\end{proof}
Semigroups satisfying $\norm{T(t)} \leq e^{wt}$ are called \udef{quasi-contractive}.

\begin{lemma} \label{dissipativeYosidaOperators}
Let $A$ be an operator on a Banach space $X$. The following are equivalent:
\begin{enumerate}
\item $A$ is dissipative;
\item $R_A(r)$ exists and $\norm{rR_A(r)}\leq 1$ for all $r>0$.
\end{enumerate}
\end{lemma}
\begin{proof}
Direct application of \ref{dissipativeResolventBound}.
\end{proof}

\begin{theorem}[Lumer-Phillips theorem]
Let $A$ be an operator on a Banach space $X$. The following are equivalent:
\begin{enumerate}
\item $\overline{A}$ generates a strongly continuous contraction semigroup;
\item $A$ is densely defined, dissipative and $\im(\lambda\id-A)$ is dense in $X$ for some $\lambda > 0$.
\end{enumerate}
\end{theorem}
\begin{proof}
$(1) \Rightarrow (2)$  This is a combination of \ref{dissipativeYosidaOperators} and the Hille-Yosida theorem \ref{HilleYosidaContraction}. The surjectivity of $\lambda\id-\overline{A}$ for all $\lambda > 0$ implies the density of $\im(\lambda\id-A)$ by \ref{dissipativeOperatorClosable}.

$(2) \Rightarrow (1)$ Because $A$ is densely defined and dissipative, it is closable by \ref{dissipativeOperatorClosable}.
Also by \ref{dissipativeOperatorClosable}, $\lambda\id-\overline{A}$ is surjective. Thus by \ref{dissipativeYosidaOperators}, we have $r\in \res(A)$. Then $]0,+\infty[\,\subseteq \res(A)$ by \ref{spectrumDissipativeOperator}.
For all $r>0$, the resolvent $R_A(r)$ exists and is bounded by \ref{dissipativeResolventBound}. It is surjective by\ref{rangeDisjunctionDissipativeOperator}.

We have verified all the conditions of the Hille-Yosida theorem \ref{HilleYosidaContraction}.
\end{proof}
\begin{corollary}
Let $A$ be a densely defined operator on a Banach space $X$. If both $A$ and $A^t$ are dissipative, then $\overline{A}$ generates a contraction semigroup on $X$.
\end{corollary}
\begin{proof}
It is enough to prove that $\im(\id - A)$ is dense in $X$.

Assume, towards a contradiction, that $\overline{\im(\id - A)} \neq X$. Then by \ref{functionalZeroOnClosedSubSpace} we can find a non-zero bounded functional $f$ that is zero on $\overline{\im(\id - A)}$. Thus for all $x\in \dom(A)$:
\[ 0 = f((\id- A)x) = (\id-A)^t(f)(x). \]
Because $\dom(A)$ is dense in $X$, we conclude that $(\id-A)^t(f) = 0$ and thus that $(\id-A)^t = \id - A^t$ is not dissipative.
\end{proof}

\begin{proposition}
Let $A$ be a dissipative operator on a Banach space $X$. If $\lambda\id - A$ is surjective for some $\lambda > 0$, then $A|^{\overline{\dom(A)}}: \overline{\dom(A)}\not\to \overline{\dom(A)}$ generates a contraction semigroup on $\overline{\dom(A)}$.
\end{proposition}
\begin{proof}
First note that $A|^{\overline{\dom(A)}}$ is still dissipative. 

The surjectivity of $\lambda\id - A$ implies the surjectivity of $(\lambda\id_X - A)|^{\overline{\dom(A)}} = \lambda\id_{\overline{\dom(A)}} - A|^{\overline{\dom(A)}}$.

Using \ref{dissipativeYosidaOperators} and \ref{spectrumDissipativeOperator}, we get that $]0,+\infty[\,\subseteq \res(A|^{\overline{\dom(A)}})$.
Also $A|^{\overline{\dom(A)}}$ is closed by \ref{closureDissipativeOperator}.

In order to conclude with \ref{dissipativeYosidaOperators} and the Hille-Yosida theorem \ref{HilleYosidaContraction}, we need to show that $A|^{\overline{\dom(A)}}$ is densely defined.
To that end take an $x\in \overline{\dom(A)}$ and consider $\seq{nR_A(n)x}$. By \ref{dissipativeYosidaOperators} and \ref{resolventLimitLemma}, we have $nR_A(n)x \to x$.

We just need to verify that $nR_A(n)x\in \dom\Big(A|^{\overline{\dom(A)}}\Big)$. Indeed $nR_A(n)x\in\dom(A)$ by construction and
\[ A(nR_A(n)x) = n^2R_A(n)x - nx \in \overline{\dom(A)}. \]
\end{proof}
\begin{corollary}
Let $A$ be a dissipative operator on a reflexive Banach space $X$. If $\lambda\id - A$ is surjective for some $\lambda > 0$, then $A$ generates a contraction semigroup on $\overline{\dom(A)}$.
\end{corollary}
In particular note that $A$ is densely defined.
\begin{proof}
It is enough to show the density of $\dom(A)$. Take $x\in X$. As before, we consider the sequence $\seq{nR_A(n)x}$, which is bounded by $\norm{nR_A(n)x} \leq \norm{nR_A(n)}\,\norm{x} \leq \norm{x}$. By reflexivity (TODO ref!) this sequence has a weakly convergent subsequence $\seq{n_kR_A(n_k)x}_k$ with limit $x'$. 

It remains to be shown that $x=x'$. Indeed, using \ref{resolventLimitLemma} and the fact that $R_A(1)y\in \dom(A)$ for all $y\in X$,
\[ R_A(1)x' = R_A(1)\lim^w_{k\to \infty}n_kR_A(n_k)x = \lim^w_{k\to \infty}n_kR_A(n_k)R_A(1)x = \lim_{k\to \infty}n_kR_A(n_k)R_A(1)x = R_A(1)x, \]
by the weak continuity of $R_A(1)$, TODO ref(\url{https://math.stackexchange.com/questions/3834847/weakly-continuous-vs-weakly-sequentially-continuous-operator}).

So $x'= (\id - A)R_A(1)x' = (\id - A)R_A(1)x = x$.
\end{proof}


\begin{theorem}[Feller-Miyadera-Phillips theorem]
Let $A$ be an operator on a Banach space $X$. The following are equivalent:
\begin{enumerate}
\item $A$ generates a strongly continuous semigroup $T: \R^+\to \Bounded(X)$ satisfying $\norm{T(t)}\leq Me^{wt}$ for some $w\in \R$, $M\geq 1$ and all $t\in\R^+$;
\item $A$ is closed, densely defined, and $r\in \res(A)$, $\norm{(r-w)^nR_A(r)^n} \leq M$ for all $r>w$ and $n\in \N$.
\end{enumerate}
\end{theorem}
This theorem is the general case of the Hille-Yosida theorem \ref{HilleYosidaContraction} and sometimes goes by the same name.
\begin{proof}
$(1)\Rightarrow (2)$ Follows from \ref{generatorClosedDenselyDefined} and \ref{resolventGeneratorPowerEstimate}.

$(2) \Rightarrow (1)$ We define an equivalent norm on $X$ in two steps that makes $T$ a contraction semigroup. We can then use the Hille-Yosida theorem \ref{HilleYosidaContraction}.

First define a norm on $X$ for all $r>0$ by
\[ \norm{x}_{r} = \sup_{n\in\N}\norm{(r-w)^nR_A(r)^nx} \]
it is easy to see that all $\norm{\cdot}_{r}$ are norms and
\[ \norm{x} \leq \norm{x}_r \leq M\norm{x}. \]
So $\norm{\cdot}_{r}$ is equivalent to $\norm{\cdot}$ for all $r>0$. Also $\norm{(r-w)^nR_A(r)^nx}_r$
\end{proof}
\begin{corollary}
Let $A$ be an operator on a Banach space $X$ such that $r\in \res(A)$, $\norm{(r-w)^nR_A(r)^n} \leq M$ for all $r>w$ and $n\in \N$. Then
\begin{enumerate}
\item $A|^{\overline{\dom(A)}}$ generates a strongly continuous semigroup $T: \R^+\to \Bounded(X)$ satisfying $\norm{T(t)}\leq Me^{wt}$ for all $t\in\R^+$;
\item if $X$ is reflexive, then $\overline{\dom(A)} = X$.
\end{enumerate}
\end{corollary}
\begin{proof}
TODO
\end{proof}

\subsubsection{Generation theorems for groups}
\begin{lemma} \label{generatorInverseStronglyContinuousGroup}
Let $T: \R\to \Bounded(X)$ be a strongly continuous group on a Banach space $X$ generated by $A$. Then the strongly continuous group $T(-t)$ is generated by $-A$.
\end{lemma}
\begin{proof}
By direct calculation
\[ \lim_{h\to 0} \frac{T(-h) - x}{h} = \lim_{h\to 0} \frac{T(h)x - x}{-h} = -\lim_{h\to 0} \frac{T(h) - x}{h} = -A. \]
\end{proof}

\begin{proposition}
Let $A$ be an operator on a Banach space $X$. The following are equivalent:
\begin{enumerate}
\item $A$ generates a strongly continuous group $T: \R\to \Bounded(X)$;
\item $A$ and $-A$ both generate strongly continuous semigroups, $T_+: \R^+\to \Bounded(X)$ and $T_-: \R^+\to \Bounded(X)$.
\end{enumerate}
In this case $T(t) = \begin{cases}
T_+(t) & t \geq 0 \\ T_-(-t) & t<0
\end{cases}$.
\end{proposition}
\begin{proof}
$(1) \Rightarrow (2)$ By \ref{generatorInverseStronglyContinuousGroup}, both $A$ and $-A$ generate strongly continuous groups, and thus also semigroups.

$(2) \Rightarrow (1)$ The function $T$ defined using $T_+$ and $T_-$ is definitely strongly continuous, because $T(0) = \id_X = T_+(0) = T_-(0)$. We just need to show it satisfies the group property.
\end{proof}

\begin{theorem}[Stone's theorem]
Let $A$ be a densely defined operator on a Hilbert space $H$. Then $iA$ generates a unitary group $T: \R \to \Unitaries(H)$ \textup{if and only if} $A$ is self-adjoint.
\end{theorem}
\begin{proof}
Assume $A$ generates a unitary group $T: \R \to \Unitaries(H)$. Then $T(t)^* = T(t)^{-1} = T(-t)$ for all $t\in \R$. TODO

Conversely both $iA$ and $-iA$ are closed.
\end{proof}

\subsection{Contraction semigroups}

\begin{proposition}[Landau-Kallman-Rota inequality]
Let $A$ be the generator of a contraction semigroup on a Banach space $X$, then
\[ \norm{Ax}^2 \leq 4 \norm{A^2x}\cdot\norm{x} \]
for all $x\in\dom(A^2)$.
\end{proposition}
The constant can be improved to 2 for groups of isometries. (TODO)
\begin{proof}
From Taylor's formula (TODO ref)
\[ T(t)x = x + tAx + \int_0^t(t-s)T(s)A^2x \diff{s} \]
we get
\begin{align*}
\norm{Ax} &\leq \frac{\norm{T(t)x}}{t} + \frac{\norm{x}}{t} + \frac{1}{t}\int_0^t(t-s)\norm{T(s)}\cdot\norm{A^2x}\diff{s} \\
&\leq 2\frac{\norm{x}}{t} + \frac{1}{t}\int_0^t(t-s)\diff{s}\norm{A^2x} \\
&= 2\frac{\norm{x}}{t} + \frac{1}{t}\left(t^2 - \frac{t^2}{2}\right)\norm{A^2x} \\
&= 2\frac{\norm{x}}{t} + \frac{t}{2}\norm{A^2x}.
\end{align*}
This holds for all $t$. In particular this holds if $t = 2\sqrt{\frac{\norm{x}}{\norm{A^x}}}$ (this is in fact the minimum). Then we get
\begin{align*}
\norm{Ax}^2 &\leq \left(\sqrt{\norm{x}\cdot\norm{A^2x}} + \sqrt{\norm{x}\cdot\norm{A^2x}}\right)^2 \\
&= 4\norm{x}\cdot\norm{A^2x}.
\end{align*}
\end{proof}

\subsection{Analytic semigroups}


\chapter{Operator equations}
Linear Operator Equations: Approximation and Regularization
\section{Terminology}
\begin{definition}
Let $T: X\not\to Y$ be a (non-)linear operator between normed spaces. An \udef{operator equation} is an equation of the form
\[ T(u) = f \qquad f\in Y\; \text{$u$ unknown.} \]
A \udef{solution} to is operator equation is a vector $a\in X$ such that $T(a) = f$.
\end{definition}
\subsection{Well- and ill-posed problems}
Some natural questions associated to such problems are:
\begin{enumerate}
\item Whether a solution exists for a given $f\in Y$.
\item Whether this solution is unique.
\item Whether this solution depends continuously on $f$, i.e.\ whether the solution is stable under perturbation.
\end{enumerate}
The later questions depend on the affirmative answers of the former. A problem is called \udef{well-posed} if the answer to all three questions is positive and \udef{ill-posed} if not. The terminology is due to Jacques Hadamard (TODO ref Hadamard, Jacques (1902). Sur les problèmes aux dérivées partielles et leur signification physique. Princeton University Bulletin. pp. 49–52.)

\begin{proposition}
Let $ T(u) = f$ be an operator equation where $T$ is a linear operator. Then the problem of solving this operator equation is well-posed for all $f\in\im(T)$ \textup{if and only if} $T$ is bounded below.
\end{proposition}
\begin{proof}
By \ref{boundedBelow}.
\end{proof}

\begin{proposition}
Let $T$ be a linear operator and $\lambda \in \C$. Consider the operator equation
\[  Tu = \lambda u + f. \]
This problem is well-posed if and only if $\lambda\in \rho(T)$.

In particular, 
\begin{enumerate}
\item if $\lambda\in\sigma_\text{p}(T)$, then uniqueness fails.
\item if $\lambda\in\sigma_\text{r}(T)$, then existence fails for some $f$,
\item if $\lambda\in\sigma_\text{c}(T)$, then the solution does not depend continuously on $f$. TODO: verify with (re)definition of continuous spectrum.
\end{enumerate}
\end{proposition}

\subsection{Equations of the first and second kind}
\begin{definition}
\begin{itemize}
\item An operator equation of the form $T(u) = f$ is said to be of the \udef{first kind}
\item An operator equation of the form $\lambda u - T(u) = f$ for some non-zero scalar $\lambda$ is said to be of the \udef{second kind}.
\end{itemize}
\end{definition}

\section{Equations on function spaces}
\subsection{Relevant spaces}

\subsection{Solutions}
classical, weak, distributional.

\subsubsection{Green's functions}


\subsection{Boundary conditions}
It is often useful to identify a subset of functions using boundary conditions.
\begin{definition}
Let $X$ be a topological space and $\Omega$ a closed subset. A \udef{boundary condition} is an operator equation of the form
\[ \big[Tu\big]_{\partial\Omega} = f \]
where $f$ is a function on $\partial\Omega$. The operator $B\defeq u\mapsto \big[Tu\big]_{\partial\Omega}$ is called a \udef{boundary operator}.

The boundary condition is called
\begin{itemize}
\item \udef{Dirichlet} or \udef{first-type} if $T = \id$;
\item \udef{Neumann} or \udef{second-type} if $\Omega$ is a Riemannian manifold and $T = \partial_{\vec{n}}$ where $\vec{n}$ is the vector normal to $\Omega$; (TODO: correct setting??)
\item \udef{Robin} or \udef{third-type} if $T = \id + \alpha \partial_{\vec{n}}$ for some non-zero constant $\alpha$.
\end{itemize}
The boundary condition is called \udef{homogenous} if $f\equiv 0$.

If the boundary condition is specified on a subset of $\partial\Omega$, then we have a \udef{partial boundary condition}.
\begin{itemize}
\item If $\partial\Omega$ is partitioned with a partial boundary condition specified on each partition, we call this a \udef{mixed boundary condition}.
\item A \udef{Cauchy boundary condition} consists of both a partial Dirichlet and a partial Neumann boundary condition.
\end{itemize}
\end{definition}
TODO: An Introduction to the Finite Element Method - Reddy + TODO generalised functions?

\begin{lemma}
A boundary condition is of the first, second or third type \textup{if and only if} it is of the general form
\[ \Big[(\alpha\id + \beta\partial_{\vec{n}})u\Big]_{\partial\Omega} = f \]
where $\alpha, \beta$ are constants that are not both zero.

In particular, the boundary condition is
\begin{enumerate}
\item Dirichlet if $\beta = 0$;
\item Neumann if $\alpha = 0$;
\item Robin if $\alpha \neq 0 \neq \beta$.
\end{enumerate}
\end{lemma}

\begin{lemma}
Functions obeying a homogeneous boundary condition with linear boundary operator form a subspace.
\end{lemma}
\begin{proof}
These functions are exactly the functions in the kernel of the boundary operator.
\end{proof}

\subsection{Periodic boundary conditions}
TODO

\section{Linear dynamical systems}



\section{Approximating well-posed problems}
\section{Regularising ill-posed problems}
\section{Regularised approximation methods}


\chapter{Ordinary differential equations}
\url{https://www.mat.univie.ac.at/~gerald/ftp/book-ode/ode.pdf}
\url{file:///C:/Users/user/Downloads/978-3-030-47849-0.pdf}
\url{file:///C:/Users/user/Downloads/Polyanin%20A.,%20D.,%20Zaitsev%20V.%20F.,%20Handbook%20of%20exact%20solutions%20for%20ordinary%20differential%20equations.pdf}

\section{Classification}
\begin{definition}
An \udef{$n^\text{th}$ order (ordinary) differential equation} (or ODE) is an equation of the form
\[ F(t, u, u', u^{\prime\prime}, \ldots, u^{(n)}) \equiv 0. \]
We call a real function $u: [a,b] \to \R$ a \udef{solution} of this differential equation on $[a,b]$
if it has at least $n$ continuous derivatives such that $F(t, u(t), u'(t), u^{\prime\prime}(t), \ldots, u^{(n)}(t))$ is zero for all $t\in [a,b]$. The set of all solutions is called the \udef{general solution}.

We call the differential equation
\begin{enumerate}
\item \udef{linear} if $\md{F}{2}{u^{(i)}}{}{u^{(j)}}{} \equiv 0$ for all $i,j\in [0,n]$;
\item \udef{homogenous} if $F(t, 0,\ldots, 0) = 0$.
\end{enumerate}
Unless explicitly stated, we will always assume that $F$ can be solved for the highest derivative, such that the ODE can be written as
\[ u^{(n)} \equiv f(t,u,u',\ldots, u^{(n-1)}). \]
\end{definition}

A linear $n^\text{th}$ order differential equation can be written in the form
\[ \sum_{i=0}^n a_{i}(t)u^{(i)}(t) - g(t) = 0 \]
where $a_i, g \in (]a,b[\to\R)$.

\begin{definition}
Let $\sum_{i=0}^n a_{i}(t)u^{(i)}(t) \equiv g(t)$ be a linear differential equation. We call the functions $a_i$ the \udef{coefficients} and we say the ODE has \udef{constant coefficients} if all the $a_i$ are constants.
\end{definition}

In the linear case we can introduce the linear operator
\[ L \defeq \sum_{i=0}^n a_{i} \left(\dod{}{t}\right). \]
Then the differential equation can be written as $Lu = g$.

The differential equation is homogenous if and only if $g = 0$.

\subsection{Differential problems}
\subsubsection{Initial value problems}
\begin{definition}
An \udef{initial value problem} (IVP) is an $n^{\text{th}}$ order ODE together with \udef{initial conditions}
\[ u^{(i)}(t_0) = c_i \qquad i \in 0:n-1 \]
where $t_0$ and the $c_i$ are real numbers.
\end{definition}

TODO: replace derivatives with Lipschitz continuity.
\begin{theorem}
Let $u^{(n)} \equiv f(t,u,u',\ldots, u^{(n-1)})$ be an $n^{\text{th}}$ order ODE with initial conditions
\[ u^{(i)}(t_0) = c_i \qquad i \in 0:n-1. \]
Assume
\[ f, \pd{f}{t}, \pd{f}{u}, \pd{f}{u'}, \ldots, \pd{f}{u^{(n-1)}} \]
are defined and continuous on a neighbourhood of $(t_0, c_0, \ldots, c_{n-1})\in \R^{n+1}$.

Then there exists $\epsilon > 0$ such that the IVP has a unique solution on the interval $]t_0-\epsilon, t_0+\epsilon[$.
\end{theorem}
\begin{proof}
TODO
\end{proof}

It is possible for a solution $u$ to be defined outside the interval $]t_0-\epsilon, t_0+\epsilon[$, but not be a solution to the IVP.
\begin{example}
Consider the IVP
\[ u' = u^2 \qquad u(0) = c. \]
The function
\[ u: \R\setminus\{1/c\} \to \R: t\mapsto \frac{c}{1-ct} \]
is the solution only for $t < 1/c$.
\end{example}

\subsubsection{Boundary value problems}
\begin{definition}
A \udef{boundary value problem} (BVP) is an $n^{\text{th}}$ order ODE together with boundary conditions.
\end{definition}

The questions of existence and uniqueness are less clear than for IVPs.
\begin{example}
Consider the ODE
\[ u''(t) + u(t) = 0 \qquad 0<t<\pi. \]
The general solution is $u(t) = c_1\sin t + c_2 \cos t$. All solutions have $u(0) = u(\pi)$.
So the BVP with boundary conditions
\[ u(0) = 0 \qquad u(\pi) = 1 \]
has no solution and the BVP with boundary conditions
\[ u(0) = 0 \qquad u(\pi) = 0 \]
has infinitely many solutions.
\end{example}


\subsection{Systems of differential equations}

\section{Existence and uniqueness}
\subsection{Existence}
Generally solutions to IVPs exist if $f$ (TODO ref) is continuous. Such existence results are generally only local.

\begin{example}
Consider $u' = u^2$ with condition $u(1) = -1$. A solution is given by $u(t) = -t^{-1}$. This solution does not exist at $0$, even though $u\mapsto u^2$ is continuous.
\end{example}

\subsubsection{Picard-Lindelöf theorem}
\begin{theorem}[Picard-Lindelöf]
Consider $f: \R\times \R^d \to \R^d$ and the differential problem of finding $y:\R\to \R^d$ such that
\[ y' = f(t,y) \qquad y(t_0) = y_0 \qquad (t_0\in \R, y_0\in\R^d). \]
Let $R$ be the rectangle $[t_0,t_0+a]\times B(y_0, b)$ for some $a,b\in \R$.
If $f$ is continuous on $R$  and uniformly Lipschitz continuous w.r.t. $y$, then the differential problem has a unique solution $y(t)$ on $[t_0,t_0+\alpha]$, where $\alpha = \min(a,b/M)$ and $M$ is a bound for $|f(t,y)|$ on the rectangle $R$.
\end{theorem}
Any norm on $\R^d$ can be used to define $B(y_0, b)$, as they are all equivalent.
\begin{proof}
For any potential solution $y(t)$, the function $t\mapsto f(t,y(t))$ is integrable (TODO ref). So the solution must satisfy \[ y(t) = y_0 + \int_{t_0}^tf(s, y(s))\diff{s}. \]
We use this the construct a sequence of approximate solutions. Set $y_0: t\mapsto y_0$ and
\[ y_{n+1}: [t_0, t_0+a] \to \R^d: t\mapsto y_0 + \int_{t_0}^t f(s,y_n(s))\diff{s}. \]
These integrals can be taken because the graph of each $y_n$ lies in the rectangle $R$:
\[ |y_n(t) - y_0| \leq \int_{t_0}^t|f(s,y_{n-1}(s))|\diff{s} \leq M\alpha \leq b. \]

TODO
\end{proof}

\subsubsection{Peano's existence theorem}
\begin{theorem}[Peano's existence theorem]
Consider $f: \R\times \R^d \to \R^d$ and the differential problem of finding $y:\R\to \R^d$ such that
\[ y' = f(t,y) \qquad y(t_0) = y_0 \qquad (t_0\in \R, y_0\in\R^d). \]
Let $R$ be the rectangle $[t_0,t_0+a]\times B(y_0, b)$ for some $a,b\in \R$.

If $f$ is continuous on $R$ and $|f(t,y)|$ is bounded on $R$ with bound $M$, then the differential problem has at least one solution $y(t)$ on $[t_0,t_0+\alpha]$.
\end{theorem}
Any norm on $\R^d$ can be used to define $B(y_0, b)$, as they are all equivalent.
\begin{proof}
TODO
\end{proof}

\subsection{Differential inequalities}
\subsection{Dependence on initial conditions and parameters}

\section{First order differential equations}
\subsection{Existence and uniqueness}
\subsection{Qualitative properties of solutions}
\subsection{A miscellany of solutions for different types of equations}
\subsubsection{Separable equations}
\paragraph{The logistic equation.}
\subsubsection{Exact equations}
\subsubsection{Linear first order differential equations}
\subsubsection{Homogeneous equations}
\subsubsection{Bernoulli equations}

\section{Systems of equations and higher order equations}
\subsection{Problem statement and notation}
Equivalence systems and higher order
\subsection{Existence and uniqueness}
\subsection{Second order equations}
\subsection{Higher order linear equations}
\subsection{Systems of first order equations}

\section{Qualitative analysis}

\section{Solutions by infinite series and Bessel functions}

\section{Second order differential equations}
\subsection{Solutions with Green's functions}
\begin{proposition}
Consider a second order linear differential equation on an interval $[a,b]$, which is of the general form
\[ Lu = a_2u^{\prime\prime} + a_1u' + a_0u = f \]
where $a_2,a_1, a_0, f\in \cont([a,b])$.
Consider mixed homogenous boundary conditions of first, second or third type, i.e.\ of the form
\begin{align*}
B_au = c_1 u(a) + c_2 u'(a) &= 0 \\
B_bu = c_3 u(b) + c_4 u'(b) &= 0
\end{align*}
where at least one of $c_1,c_2$ and $c_3,c_4$ is non-zero.

Assume that $a_2(x) \neq 0$ for all $x\in [a,b]$, $f\in L^2([a,b])$ and the kernel of $L$ is trivial.

Then there exists a unique solution of the form
\[ u(x) = \int_{a}^b G(x,y)f(y)\diff{y} \]
where $G$ is a bounded function in $([a,b]\times [a,b] \to \C)$.
\end{proposition}
\begin{proof}
We want to find a kernel $G$ such that
\[ L(G(\cdot, y)) = \delta_y \]
as distributions for all fixed $y\in [a,b]$ and
\[ B_aG(\cdot, y) = 0 = B_bG(\cdot, y). \]
TODO
\end{proof}

\subsection{Sturm-Liouville theory}
\subsubsection{Strum-Liouville problems and operators}
\begin{definition}
A \udef{Sturm-Liouville equation} is a real second-order ODE of the form
\[ -(pu')' + qu = \lambda \omega u \]
where $\lambda\in\R$ and $p,p',q,\omega\in \cont([a,b])$ for some $a,b\in \R$. Also $p$ is assumed strictly positive on $]a,b[$ and $\omega$ strictly positive on $[a,b]$.

A \udef{Sturm-Liouville operator} is a linear operator on the Sobolev space $W^{2,2}([a,b])$ of the form
\[ L: u\mapsto \frac{1}{\omega}\Big(-(pu')' + qu\Big) \]
where $p,q, \omega$ are as above.

A \udef{Sturm-Liouville problem} is a Sturm-Liouville equation with mixed homogenous boundary conditions of first, second or third type, i.e.\ of the form
\[ c_1 u(t_b) + c_2 u'(t_b) = 0 \]
where $t_b$ is $a$ or $b$ and at least one of $c_1,c_2$ is non-zero.

We call the Sturm-Liouville problem
\begin{itemize}
\item \udef{regular} if $p$ is strictly positive on $[a,b]$ and boundary conditions are specified at $a$ and $b$;
\item \udef{singular} if any of the following hold:
\begin{itemize}
\item $p(a) = 0$ and there is no boundary condition at $a$;
\item $p(b) = 0$ and there is no boundary condition at $a$;
\item $p(a) = 0 = p(b)$ and there are no boundary conditions; or
\item $[a,b]$ is infinite.
\end{itemize}
\end{itemize}
\end{definition}
For finite $[a,b]$, all $u\in\cont([a,b])$ are square integrable: $u$ is necessarily bounded by \ref{imageCompactIsClosedBounded} and the integral is bounded by this bound times $|b-a|$. If $[a,b]$ is infinite we still require solutions to be square integrable.

We may consider $\cont([a,b]) \subset (\R\to\C)$, in which case the Sturm-Liouville operator maps real functions to real functions.

\begin{proposition}
Consider a Sturm-Liouville problem. Take the Sobolev space $W^{2,2}([a,b], \omega(x)\diff{x})$ and let $\mathcal{H}$ be the subspace of functions that obey the boundary conditions. Then the Sturm-Liouville operator $L$ restricted to $\mathcal{H}$ is self-adjoint.
\end{proposition}
We take $Lu$ to be defined if $Lu\in\cont([a,b])$. If $[a,b]$ is infinite, we 
\begin{proof}

\end{proof}

\chapter{Partial differential equations}
Transport equation, Laplace's equation, Heat equation, Wave equation
\section{Classification}
\begin{definition}
An \udef{$n^\text{th}$ order partial differential equation} (or PDE) is an equation of the form
\[ F(x, \{D^\alpha u\}_{|\alpha|\leq m}) \equiv 0. \]
We call a  function $u: \Omega \subset \R^N \to \R$ a \udef{solution} of this differential equation on $\Omega$ if $D^\alpha u$ exists and is continuous for $|\alpha|\leq m$ and $F(x, \{D^\alpha u(x)\}_{|\alpha|\leq m})$ is zero for all $x\in \Omega$.

The set of all solutions is called the \udef{general solution}.

We call the differential equation
\begin{enumerate}
\item \udef{linear} if $\md{F}{2}{(D^\alpha u)}{}{(D^\beta u)}{} \equiv 0$ for $|\alpha|,|\beta|\leq m$;
\item \udef{homogenous} if $F(x, 0,\ldots, 0) = 0$.
\end{enumerate}
\end{definition}

\begin{lemma}
A PDE is linear \textup{if and only if} it can be written in the form
\[ Lu(x) = \sum_{|\alpha|\leq m}a_\alpha(x)D^\alpha u(x) = g(x). \]
A linear PDE is homogeneous \textup{if and only if} $g = 0$.
\end{lemma}

\subsection{Elliptic, Hyperbolic and Parabolic PDEs}