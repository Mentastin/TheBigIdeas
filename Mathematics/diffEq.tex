\chapter{Semigroups and evolution operators}
\section{Semigroups of linear operators}
\begin{definition}
Let $X$ be a Banach space and $\sSet{I, +, 0, \leq}$ a partially ordered normed group with positive cone $I^+$. We call a function $T: I^+ \to \Lin(X)$ a \udef{semigroup of linear operators} (or just \udef{semigroup}) if
\begin{itemize}
\item $T(0) = \id_X$;
\item $T(s+t) = T(s)T(t)$ for all $s,t \in I^+$.
\end{itemize}
A function $T: I \to \Lin(X)$ satisfying the same conditions is called a \udef{group of linear operators}.

A semigroup is called \udef{strongly continuous} if it is continuous when $I$ is equipped with the order convergence and $X$ with the strong operator topology.

We call $T$ \udef{bounded} if $T(t)$ is bounded for all $t\in I^+$.
\end{definition}

\begin{lemma}
A semigroup of linear operators $T:I^+\to \Lin(X)$ is bounded \textup{if and only if} $T[S]$ is a set of bounded operators for some $S\subseteq I+$ that generates $I^+$ as a monoid.
\end{lemma}

\begin{proposition}
Let $T:I^+\to \Lin(X)$ be a semigroup of operators on a Banach space. Then the following are equivalent:
\begin{enumerate}
\item $T$ is strongly continuous;
\item $T$ is strongly continuous at $0$;
\item $T(t)$ is uniformly bounded on some neighbourhood of $0$ and there exists a dense subset $D\subseteq X$ such that $\lim_{t\to 0} T(t)x = x$ for all $x\in D$.
\end{enumerate}
\end{proposition}
\begin{proof}
$(1) \Rightarrow (2)$ If a semigroup is strongly continuous, then it is obviously strongly continuous at $0$.

$(2) \Rightarrow (3)$ Because $T(0) = \id_X$, strong continuity at $0$ means that $\lim_{t\to 0} T(t)x = x$ for all $x\in X$. Thus this also holds for all $x$ in any (dense) subset of $X$.

For the uniform bound we use the uniform boundedness principle \ref{uniformBoundednessPrinciple}. It is then enough to show that there exists a neighbourhood $U$ of $0$ such that $\sup\setbuilder{\norm{T(t)x}}{t\in U} <\infty$ for all $x\in X$.

TODO

$(3) \Rightarrow (1)$

Conversely, assume a semigroup $T: I^+\to \Lin(X)$ is continuous at $0$. Take $t_0\in I^+$. By \ref{leftRightConvergence} it is enough to check that $T$ is left and right continuous at $t_0$.

First let $F$ be a filter in $\powerfilters(\upset t_0)$ that converges to $t_0$. Then $F - t_0 \in \powerfilters(I^+)$ and $F-t_0 \to 0$. Thus $T[F] = T[F-t_0 + t_0] = T[F-t_0]T[t_0] \to T[0]T[t_0] = T[t_0]$, meaning that $T$ is right continuous.

TODO left continuity.
\end{proof}
TODO cfr SOT.

\subsection{Growth bounds}
\begin{proposition}
Let $T: I^+ \to \Lin(X)$ be a strongly continuous semigroup of bounded linear operators. Then there exist contstants $w\in \R$ and $M\geq 1$ such that
\[ \forall t\in I^+:\quad \norm{T(t)} \leq Me^{w\norm{t}}. \]
\end{proposition}
\begin{proof}
Choose $M$ such that for all $0\leq s\leq 1$, $\norm{T(s)}\leq M$.
\end{proof}

\begin{definition}

\end{definition}

\subsection{Differentiability}
\begin{definition}
Let $T: I^+ \to \Lin(X)$ be a semigroup of linear operators. We say $T$ is \udef{differentiable} at $t\in I$ if the limit
\[  \]
\end{definition}

\subsection{$C_0$-semigroups}
\begin{definition}
A $C_0$-semigroup
\end{definition}

\section{One-parameter semigroups on Banach spaces}
In this section we will study functions $T: \R^+\to \Bounded(X)$ that are strongly continuous semigroups on a Banach spaces $X$. We will shorten this description to \udef{operator semigroup}.

\subsection{Orbit maps}
\begin{lemma}
Let $T: \R^+\to \Bounded(X)$ be an operator semigroup. Consider the orbit map $\xi_x: \R^+ \to X: t\mapsto T(t)x$ for some $x\in X$. The following are equivalent:
\begin{enumerate}
\item $\xi_x$ is differentiable;
\item $\xi_x$ is differentiable at $0$.
\end{enumerate}
\end{lemma}
\begin{proof}
Clearly $(1)$ implies $(2)$. Now assume $(2)$, we show $\xi_x$ is left and right differentiable at all points $t\in\R^+$ (TODO cfr. \ref{leftRightConvergence}). For right differentiability we can calculate
\begin{align*}
\lim_{h\downarrow 0} h^{-1}(\xi_x(t+h) - \xi_x(t)) &= \lim_{h\downarrow 0} h^{-1}(T(t+h)x - T(t)x) \\
&= T(t)\lim_{h\downarrow 0} h^{-1}(T(h)x - T(0)x) \\
&= T(t)\lim_{h\downarrow 0} h^{-1}(\xi_x(h) - \xi_x(0)) = \xi_x'(0).
\end{align*}
TODO
\end{proof}

\begin{lemma} \label{integrabilityOrbitMaps}
Let $T: \R^+\to \Bounded(X)$ be an operator semigroup. For all $x\in X$, the orbit map $\xi_x$ is integrable on any compact $K\subseteq [0,\infty]$.
\end{lemma}
\begin{proof}
By \ref{BochnerIntegrabilityCondition} we just need to show $\int_K\norm{\xi_x(s)}\diff{s} < \infty$. We have $\int_K\norm{\xi_x(s)}\diff{s} \leq \sup_{s\in K}\norm{\xi_x(s)}\lambda(K)$. Now $\lambda(K)$ is finite by \ref{HaarConsequences} and $\sup_{s\in K}\norm{\xi_x(s)}$ is finite by (TODO ref: extreme value theorem), as $\R \to \R: t\mapsto \norm{\xi_x(t)}$ is a continuous function.
\end{proof}

\subsection{The generator}
\begin{definition}
Let $T: \R^+\to \Bounded(X)$ be an operator semigroup. The \udef{generator} of $T$ is the operator $A: X\not\to X$ defined by
\[ Ax \defeq \xi_x'(0) = \lim_{h\downarrow 0}\frac{1}{h}\big(T(h)x - x\big) \]
with domain
\[ \dom(A) = \setbuilder{x\in X}{\text{$\xi_x$ is differentiable}}. \]
\end{definition}
Notice that the generator is indeed a linear operator.

\begin{lemma} \label{differentialOperatorSemigroupGenerator}
Let $T: \R^+\to \Bounded(X)$ be an operator semigroup with generator $A$. If $x\in\dom(A)$, then $T(t)x\in\dom(A)$ and
\[ \od{}{t}T(t)x = T(t)Ax = AT(t)x \]
for all $t\in [0,\infty]$.
\end{lemma}

\begin{proposition} \label{integralOperatorSemigroupGenerator}
Let $T: \R^+\to \Bounded(X)$ be an operator semigroup with generator $A$. For all $x\in X$, then $\int_0^t T(s)x\diff{s}\in\dom(A)$ and
\begin{align*}
T(t)x - x &= A\int_0^t T(s)x\diff{s}
\end{align*}
for all $t\in [0,\infty]$. Also
\begin{align*}
T(t)x - x &= \int_0^t T(s)Ax\diff{s}
\end{align*}
for all $x\in\dom(A)$ and $t\in [0,\infty]$.
\end{proposition}
This is an integrated version of \ref{differentialOperatorSemigroupGenerator}, except it holds for all $x\in X$.
\begin{proof}
Firstly $\int_0^t T(s)x\diff{s}$ exists and is finite by \ref{integrabilityOrbitMaps}.

To show $A\int_0^t T(s)x\diff{s}$ is well-defined, we calculate
\begin{align*}
A\int_0^t T(s)x\diff{s} &= \left.\dod{}{h}\right|_{h=0}T(h)\int_0^t T(s)x\diff{s} \\
&= \left.\dod{}{h}\right|_{h=0}\int_0^t T(h)T(s)x\diff{s} \\
&= \left.\dod{}{h}\right|_{h=0}\int_0^t T(s+h)x\diff{s} \\
&= \left.\dod{}{h}\right|_{h=0}\int_h^{t+h} T(s)x\diff{s} \\
&= \left.\dod{}{h}\right|_{h=0}\left(\int_0^{t+h} T(s)x\diff{s}-\int_0^{h} T(s)x\diff{s}\right) \\
&= \left.\dod{}{h}\right|_{h=t}\int_0^{h} T(s)x\diff{s}-\left.\dod{}{h}\right|_{h=0}\int_0^{h} T(s)x\diff{s} \\
&= T(t)x - x,
\end{align*}
where we have used \ref{boundedOperatorUnderIntegral} and (TODO ref: fundamental theorem calculus for Bochner integral+continuity to deal with equality a.e.).

Finally $\int_0^t T(s)Ax\diff{s}$ exists and is finite by \ref{integrabilityOrbitMaps} applied to $Ax$. We conclude using \ref{differentialOperatorSemigroupGenerator} and (TODO ref: second fundamental theorem of calculus).
\end{proof}

\begin{proposition}
The generator of an operator semigroup is closed and densely defined.
\end{proposition}
\begin{proof}
Let $T: \R^+\to \Bounded(X)$ be an operator semigroup with generator $A$. To show $A$ is closed, consider $\seq{x_n}\subseteq \dom(A)$ such that $x_n\to x$ and $Ax_n \to y$. From \ref{integralOperatorSemigroupGenerator} we have $T(t)x_n - x_n = \int_0^tT(s)Ax_n\diff{s}$. Thus
\[ T(t)x-x = \lim_{n\to\infty} T(t)x_n - x_n = \lim_{n\to\infty} \int_0^tT(s)Ax_n\diff{s}. \]
Now $Ax_n \to y$ means the sequence $\seq{Ax_n}$ is bounded by some constant $M$. Then $\norm{T(s)Ax_n} \leq M\cdot\sup_{0\leq s \leq t}\norm{T(s)}$, meaning we can apply the dominated convergence theorem (TODO ref). So $T(t)x-x = \int_0^tT(s)y\diff{s}$ and thus
\[ Ax = \lim_{t\downarrow 0}\frac{1}{t}(T(t)x-x) = \lim_{t\downarrow 0}\frac{1}{t}\int_0^tT(s)y\diff{s} = \left.\dod{}{t}\right|_{t=0}\int_0^tT(s)y\diff{s} = T(0)y = y, \]
by the fundamental theorem of calculus (TODO ref).

For any $x\in X$ we can find a sequence $\seq{x_n}$ in $\dom(A)$ that converges to $x$, namely
\[ \frac{1}{t_n}\int^{t_n}_0T(s)x\diff{s} \qquad \text{for any sequence $\seq{t_n}$ in $[0,\infty[$ converging to $0$.}  \]
This is a sequence in $\dom(A)$ by \ref{integralOperatorSemigroupGenerator} and converges to $x$ by TODO ref. Thus $\dom(A)$ is dense in $X$ by TODO ref.
\end{proof}

\begin{proposition}
An operator is the generator of at most one operator semigroup.
\end{proposition}
\begin{proof}
Let $T: \R^+\to \Bounded(X)$ and $S: \R^+\to \Bounded(X)$ be two operator semigroups with the same generator $A$. Then for any $t\in [0,\infty[$ and $x\in \dom(A)$,
\begin{align*}
\dod{}{s} \left(T(t-s)S(s)x\right) &= T(t-s)S'(s)x - T'(t-s)S(s)x \\
&= T(t-s)As(s)x - T(t-s)As(s)x \\
&= 0
\end{align*}
by (TODO ref!!!). TODO rest.
\end{proof}

\begin{proposition}
Let $T: \R^+\to \Bounded(X)$ be an operator semigroup with generator $A$. Then the following are equivalent:
\begin{enumerate}
\item $A$ is bounded;
\item $A$ is defined everywhere;
\item $T$ is uniformly continuous.
\end{enumerate}
In each case $T(t) = e^{tA}$.
\end{proposition}
\begin{proof}
$(1) \Rightarrow (2)$ Because $A$ is closed, $\dom(A)$ is closed by the closed graph theorem \ref{closedGraphTheorem}. As $\dom(A)$ is dense in $X$, this means $\dom(A) = X$.

$(2) \Rightarrow (1)$ TODO also closed graph.

$(3)$ TODO
\end{proof}

\subsubsection{Cores of the generator}
TODO move:
\begin{lemma} \label{uniformContinuityAverage}
Let $\seq{f_n: [a,b]\to X}$ be a sequence of functions from $[a,b]\subseteq \R$ to a Banach space $X$ that converges uniformly to $f: X\to Y$. Then
\[ [a,b]\to X: t\mapsto \frac{1}{t}\int_{0}^tf_n(s)\diff{s} \quad\longrightarrow\quad [a,b]\to X: t\mapsto \frac{1}{t}\int_{0}^tf(s)\diff{s} \qquad \text{uniformly.} \]
\end{lemma}
\begin{proof}
We have
\begin{align*}
\sup_{t\in[a,b]}\frac{1}{t}\int_0^t \norm{f_n(s) - f(s)}\diff{s} &\leq \sup_{t\in[a,b]}\frac{1}{t}\int_0^t \diff{s}\sup_{s\in [a,b]} \norm{f_n(s) - f(s)} \\
&= \sup_{s\in [a,b]} \norm{f_n(s) - f(s)} \to 0.
\end{align*}
\end{proof}

\begin{lemma} \label{uniformContinuityOrbitMapsConvergentSequence}
Let $T: \R^+\to \Bounded(X)$ be an operator semigroup and $\seq{x_n} \to x$ a convergent sequence in $X$. Then $f_n: [0,1]\to X: t\mapsto T(t)x_n$ converges uniformly to $f: [0,1]\to X: t\mapsto T(t)x$.
\end{lemma}
\begin{proof}
The image of $[0,1]$ under $t\mapsto \norm{T(t)}$ is compact and thus bounded, with bound $M$. Then
\begin{align*}
\sup_{t\in [0,1]}\norm{f_n(t) - f(t)} &= \sup_{t\in [0,1]}\norm{T(t)x_n - T(t)x} \\
&= \sup_{t\in [0,1]}\norm{T(t)(x_n - x)} \\
&\leq M\norm{(x_n - x)} \to 0.
\end{align*}
\end{proof}

\begin{proposition} \label{coreGeneratorCriterion}
Let $T: \R^+\to \Bounded(X)$ be an operator semigroup with generator $A$ and $D$ a subspace of $\dom(A)$. If $D$ is norm dense in $X$ and invariant under $T(t)$ for all $t\in [0,+\infty]$, then $D$ is a core for $A$.
\end{proposition}
Note norm density in $X$ is the same as norm density in $\dom(A)$, because $A$ is densely defined.
\begin{proof}
We use \ref{operatorCoreCriterion}. Take $x\in \dom(A)$; we need to show that $x\in\closure_{\norm{\cdot}_A}(D)$.

Because $D$ is norm dense in $X$, we can find a sequence $\seq{x_n}$ in $D$ that norm converges to $x$. We claim it also converges in the graph norm. To show that, it is enough to show that $\seq{Ax_n} \to Ax$ in norm.

Combining \ref{uniformContinuityOrbitMapsConvergentSequence} and \ref{uniformContinuityAverage} gives that
\[ [0,1] \to X: t\mapsto \frac{1}{t}\int_0^t T(s)x_n\diff{s} \]
converges uniformly in $n$. Thus by \ref{integralOperatorSemigroupGenerator} and Moore-Osgood (TODO ref) we have
\begin{align*}
\lim_{n\to \infty} Ax_n &= \lim_{n\to \infty} \lim_{t\downarrow 0}\frac{1}{t}\int_0^t T(s)Ax_n \diff{s} \\
&= \lim_{n\to \infty} \lim_{t\downarrow 0}\frac{1}{t}(T(t)x_n - x_n) \\
&= \lim_{t\downarrow 0}\frac{1}{t}\lim_{n\to \infty}(T(t)x_n - x_n) \\
&= \lim_{t\downarrow 0}\frac{1}{t}(T(t)x - x) = Ax.
\end{align*}

TODO

Take a sequence $\seq{t_n}\to 0$ in $\R$. Then we claim
\[ \seq{x'_n} = \seq{\frac{1}{t_n}\int_0^{t_n}T(s)x_n\diff{s}} \]
is a sequence in $D$ that converges to $x$ in the graph norm. It is definitely a sequence in $D$ by the invariance of $D$ under $T(t)$. It is now enough to show $\seq{x'_n}$ norm converges to $x$ and $\seq{Ax'_n}$ norm converges to $Ax$.
\end{proof}

\begin{proposition}
Let $T: \R^+\to \Bounded(X)$ be an operator semigroup with generator $A$. Then $\bigcap_{n\in\N}\dom(A^n)$ is a core for $A$.
\end{proposition}
\begin{proof}
The space $\bigcap_{n\in\N}\dom(A^n)$ is invariant under $T$ by \ref{differentialOperatorSemigroupGenerator}. In order to use \ref{coreGeneratorCriterion}, we need to verify that $\bigcap_{n\in\N}\dom(A^n)$ is norm dense in $\dom (A)$. TODO
\end{proof}

\subsubsection{Spectral properties of resolvents}
\begin{proposition}
Let $T: \R^+\to \Bounded(X)$ be an operator semigroup with generator $A$ and growth bound $\norm{T(t)}\leq Me^{wt}$. If $\int_0^\infty e^{-\lambda s}T(s)x\diff{s}$ exists for all $x\in X$, then $\lambda\in\res(A)$ and
\[ R_A(\lambda)x = \int_0^\infty e^{-\lambda s}T(s)x\diff{s} \]
for all $x\in X$.
\end{proposition}
\begin{proof}
We use \ref{elementResolventSetNormedSpace}.
\end{proof}
\begin{corollary}
et $T: \R^+\to \Bounded(X)$ be an operator semigroup with growth bound $\norm{T(t)}\leq Me^{wt}$. Then
\begin{enumerate}
\item $\Re \lambda > w$ implies $\lambda \in\res(A)$;
\item $\norm{R_A(\lambda)} \leq \frac{M}{\Re \lambda - w}$ for all $\lambda$ such that $\Re \lambda > w$.
\end{enumerate}
\end{corollary}
\begin{proof}
We estimate
\[ \norm{\int_0^t e^{-\lambda s}T(s)x\diff{s}} \leq M\int_0^t e^{(w-\Re\lambda)s}\diff{s}\norm{x} \]
\end{proof}


\chapter{Operator equations}
Linear Operator Equations: Approximation and Regularization
\section{Terminology}
\begin{definition}
Let $T: X\not\to Y$ be a (non-)linear operator between normed spaces. An \udef{operator equation} is an equation of the form
\[ T(u) = f \qquad f\in Y\; \text{$u$ unknown.} \]
A \udef{solution} to is operator equation is a vector $a\in X$ such that $T(a) = f$.
\end{definition}
\subsection{Well- and ill-posed problems}
Some natural questions associated to such problems are:
\begin{enumerate}
\item Whether a solution exists for a given $f\in Y$.
\item Whether this solution is unique.
\item Whether this solution depends continuously on $f$, i.e.\ whether the solution is stable under perturbation.
\end{enumerate}
The later questions depend on the affirmative answers of the former. A problem is called \udef{well-posed} if the answer to all three questions is positive and \udef{ill-posed} if not. The terminology is due to Jacques Hadamard (TODO ref Hadamard, Jacques (1902). Sur les problèmes aux dérivées partielles et leur signification physique. Princeton University Bulletin. pp. 49–52.)

\begin{proposition}
Let $ T(u) = f$ be an operator equation where $T$ is a linear operator. Then the problem of solving this operator equation is well-posed for all $f\in\im(T)$ \textup{if and only if} $T$ is bounded below.
\end{proposition}
\begin{proof}
By \ref{boundedBelow}.
\end{proof}

\begin{proposition}
Let $T$ be a linear operator and $\lambda \in \C$. Consider the operator equation
\[  Tu = \lambda u + f. \]
This problem is well-posed if and only if $\lambda\in \rho(T)$.

In particular, 
\begin{enumerate}
\item if $\lambda\in\sigma_\text{p}(T)$, then uniqueness fails.
\item if $\lambda\in\sigma_\text{r}(T)$, then existence fails for some $f$,
\item if $\lambda\in\sigma_\text{c}(T)$, then the solution does not depend continuously on $f$. TODO: verify with (re)definition of continuous spectrum.
\end{enumerate}
\end{proposition}

\subsection{Equations of the first and second kind}
\begin{definition}
\begin{itemize}
\item An operator equation of the form $T(u) = f$ is said to be of the \udef{first kind}
\item An operator equation of the form $\lambda u - T(u) = f$ for some non-zero scalar $\lambda$ is said to be of the \udef{second kind}.
\end{itemize}
\end{definition}

\section{Equations on function spaces}
\subsection{Relevant spaces}

\subsection{Solutions}
classical, weak, distributional.

\subsubsection{Green's functions}


\subsection{Boundary conditions}
It is often useful to identify a subset of functions using boundary conditions.
\begin{definition}
Let $X$ be a topological space and $\Omega$ a closed subset. A \udef{boundary condition} is an operator equation of the form
\[ \big[Tu\big]_{\partial\Omega} = f \]
where $f$ is a function on $\partial\Omega$. The operator $B\defeq u\mapsto \big[Tu\big]_{\partial\Omega}$ is called a \udef{boundary operator}.

The boundary condition is called
\begin{itemize}
\item \udef{Dirichlet} or \udef{first-type} if $T = \id$;
\item \udef{Neumann} or \udef{second-type} if $\Omega$ is a Riemannian manifold and $T = \partial_{\vec{n}}$ where $\vec{n}$ is the vector normal to $\Omega$; (TODO: correct setting??)
\item \udef{Robin} or \udef{third-type} if $T = \id + \alpha \partial_{\vec{n}}$ for some non-zero constant $\alpha$.
\end{itemize}
The boundary condition is called \udef{homogenous} if $f\equiv 0$.

If the boundary condition is specified on a subset of $\partial\Omega$, then we have a \udef{partial boundary condition}.
\begin{itemize}
\item If $\partial\Omega$ is partitioned with a partial boundary condition specified on each partition, we call this a \udef{mixed boundary condition}.
\item A \udef{Cauchy boundary condition} consists of both a partial Dirichlet and a partial Neumann boundary condition.
\end{itemize}
\end{definition}
TODO: An Introduction to the Finite Element Method - Reddy + TODO generalised functions?

\begin{lemma}
A boundary condition is of the first, second or third type \textup{if and only if} it is of the general form
\[ \Big[(\alpha\id + \beta\partial_{\vec{n}})u\Big]_{\partial\Omega} = f \]
where $\alpha, \beta$ are constants that are not both zero.

In particular, the boundary condition is
\begin{enumerate}
\item Dirichlet if $\beta = 0$;
\item Neumann if $\alpha = 0$;
\item Robin if $\alpha \neq 0 \neq \beta$.
\end{enumerate}
\end{lemma}

\begin{lemma}
Functions obeying a homogeneous boundary condition with linear boundary operator form a subspace.
\end{lemma}
\begin{proof}
These functions are exactly the functions in the kernel of the boundary operator.
\end{proof}

\subsection{Periodic boundary conditions}
TODO

\section{Linear dynamical systems}



\section{Approximating well-posed problems}
\section{Regularising ill-posed problems}
\section{Regularised approximation methods}


\chapter{Ordinary differential equations}
\url{https://www.mat.univie.ac.at/~gerald/ftp/book-ode/ode.pdf}
\url{file:///C:/Users/user/Downloads/978-3-030-47849-0.pdf}
\url{file:///C:/Users/user/Downloads/Polyanin%20A.,%20D.,%20Zaitsev%20V.%20F.,%20Handbook%20of%20exact%20solutions%20for%20ordinary%20differential%20equations.pdf}

\section{Classification}
\begin{definition}
An \udef{$n^\text{th}$ order (ordinary) differential equation} (or ODE) is an equation of the form
\[ F(t, u, u', u^{\prime\prime}, \ldots, u^{(n)}) \equiv 0. \]
We call a real function $u: [a,b] \to \R$ a \udef{solution} of this differential equation on $[a,b]$
if it has at least $n$ continuous derivatives such that $F(t, u(t), u'(t), u^{\prime\prime}(t), \ldots, u^{(n)}(t))$ is zero for all $t\in [a,b]$. The set of all solutions is called the \udef{general solution}.

We call the differential equation
\begin{enumerate}
\item \udef{linear} if $\md{F}{2}{u^{(i)}}{}{u^{(j)}}{} \equiv 0$ for all $i,j\in [0,n]$;
\item \udef{homogenous} if $F(t, 0,\ldots, 0) = 0$.
\end{enumerate}
Unless explicitly stated, we will always assume that $F$ can be solved for the highest derivative, such that the ODE can be written as
\[ u^{(n)} \equiv f(t,u,u',\ldots, u^{(n-1)}). \]
\end{definition}

A linear $n^\text{th}$ order differential equation can be written in the form
\[ \sum_{i=0}^n a_{i}(t)u^{(i)}(t) - g(t) = 0 \]
where $a_i, g \in (]a,b[\to\R)$.

\begin{definition}
Let $\sum_{i=0}^n a_{i}(t)u^{(i)}(t) \equiv g(t)$ be a linear differential equation. We call the functions $a_i$ the \udef{coefficients} and we say the ODE has \udef{constant coefficients} if all the $a_i$ are constants.
\end{definition}

In the linear case we can introduce the linear operator
\[ L \defeq \sum_{i=0}^n a_{i} \left(\dod{}{t}\right). \]
Then the differential equation can be written as $Lu = g$.

The differential equation is homogenous if and only if $g = 0$.

\subsection{Differential problems}
\subsubsection{Initial value problems}
\begin{definition}
An \udef{initial value problem} (IVP) is an $n^{\text{th}}$ order ODE together with \udef{initial conditions}
\[ u^{(i)}(t_0) = c_i \qquad i \in 0:n-1 \]
where $t_0$ and the $c_i$ are real numbers.
\end{definition}

TODO: replace derivatives with Lipschitz continuity.
\begin{theorem}
Let $u^{(n)} \equiv f(t,u,u',\ldots, u^{(n-1)})$ be an $n^{\text{th}}$ order ODE with initial conditions
\[ u^{(i)}(t_0) = c_i \qquad i \in 0:n-1. \]
Assume
\[ f, \pd{f}{t}, \pd{f}{u}, \pd{f}{u'}, \ldots, \pd{f}{u^{(n-1)}} \]
are defined and continuous on a neighbourhood of $(t_0, c_0, \ldots, c_{n-1})\in \R^{n+1}$.

Then there exists $\epsilon > 0$ such that the IVP has a unique solution on the interval $]t_0-\epsilon, t_0+\epsilon[$.
\end{theorem}
\begin{proof}
TODO
\end{proof}

It is possible for a solution $u$ to be defined outside the interval $]t_0-\epsilon, t_0+\epsilon[$, but not be a solution to the IVP.
\begin{example}
Consider the IVP
\[ u' = u^2 \qquad u(0) = c. \]
The function
\[ u: \R\setminus\{1/c\} \to \R: t\mapsto \frac{c}{1-ct} \]
is the solution only for $t < 1/c$.
\end{example}

\subsubsection{Boundary value problems}
\begin{definition}
A \udef{boundary value problem} (BVP) is an $n^{\text{th}}$ order ODE together with boundary conditions.
\end{definition}

The questions of existence and uniqueness are less clear than for IVPs.
\begin{example}
Consider the ODE
\[ u''(t) + u(t) = 0 \qquad 0<t<\pi. \]
The general solution is $u(t) = c_1\sin t + c_2 \cos t$. All solutions have $u(0) = u(\pi)$.
So the BVP with boundary conditions
\[ u(0) = 0 \qquad u(\pi) = 1 \]
has no solution and the BVP with boundary conditions
\[ u(0) = 0 \qquad u(\pi) = 0 \]
has infinitely many solutions.
\end{example}


\subsection{Systems of differential equations}

\section{Existence and uniqueness}
\subsection{Existence}
Generally solutions to IVPs exist if $f$ (TODO ref) is continuous. Such existence results are generally only local.

\begin{example}
Consider $u' = u^2$ with condition $u(1) = -1$. A solution is given by $u(t) = -t^{-1}$. This solution does not exist at $0$, even though $u\mapsto u^2$ is continuous.
\end{example}

\subsubsection{Picard-Lindelöf theorem}
\begin{theorem}[Picard-Lindelöf]
Consider $f: \R\times \R^d \to \R^d$ and the differential problem of finding $y:\R\to \R^d$ such that
\[ y' = f(t,y) \qquad y(t_0) = y_0 \qquad (t_0\in \R, y_0\in\R^d). \]
Let $R$ be the rectangle $[t_0,t_0+a]\times B(y_0, b)$ for some $a,b\in \R$.
If $f$ is continuous on $R$  and uniformly Lipschitz continuous w.r.t. $y$, then the differential problem has a unique solution $y(t)$ on $[t_0,t_0+\alpha]$, where $\alpha = \min(a,b/M)$ and $M$ is a bound for $|f(t,y)|$ on the rectangle $R$.
\end{theorem}
Any norm on $\R^d$ can be used to define $B(y_0, b)$, as they are all equivalent.
\begin{proof}
For any potential solution $y(t)$, the function $t\mapsto f(t,y(t))$ is integrable (TODO ref). So the solution must satisfy \[ y(t) = y_0 + \int_{t_0}^tf(s, y(s))\diff{s}. \]
We use this the construct a sequence of approximate solutions. Set $y_0: t\mapsto y_0$ and
\[ y_{n+1}: [t_0, t_0+a] \to \R^d: t\mapsto y_0 + \int_{t_0}^t f(s,y_n(s))\diff{s}. \]
These integrals can be taken because the graph of each $y_n$ lies in the rectangle $R$:
\[ |y_n(t) - y_0| \leq \int_{t_0}^t|f(s,y_{n-1}(s))|\diff{s} \leq M\alpha \leq b. \]

TODO
\end{proof}

\subsubsection{Peano's existence theorem}
\begin{theorem}[Peano's existence theorem]
Consider $f: \R\times \R^d \to \R^d$ and the differential problem of finding $y:\R\to \R^d$ such that
\[ y' = f(t,y) \qquad y(t_0) = y_0 \qquad (t_0\in \R, y_0\in\R^d). \]
Let $R$ be the rectangle $[t_0,t_0+a]\times B(y_0, b)$ for some $a,b\in \R$.

If $f$ is continuous on $R$ and $|f(t,y)|$ is bounded on $R$ with bound $M$, then the differential problem has at least one solution $y(t)$ on $[t_0,t_0+\alpha]$.
\end{theorem}
Any norm on $\R^d$ can be used to define $B(y_0, b)$, as they are all equivalent.
\begin{proof}
TODO
\end{proof}

\subsection{Differential inequalities}
\subsection{Dependence on initial conditions and parameters}

\section{First order differential equations}
\subsection{Existence and uniqueness}
\subsection{Qualitative properties of solutions}
\subsection{A miscellany of solutions for different types of equations}
\subsubsection{Separable equations}
\paragraph{The logistic equation.}
\subsubsection{Exact equations}
\subsubsection{Linear first order differential equations}
\subsubsection{Homogeneous equations}
\subsubsection{Bernoulli equations}

\section{Systems of equations and higher order equations}
\subsection{Problem statement and notation}
Equivalence systems and higher order
\subsection{Existence and uniqueness}
\subsection{Second order equations}
\subsection{Higher order linear equations}
\subsection{Systems of first order equations}

\section{Qualitative analysis}

\section{Solutions by infinite series and Bessel functions}

\section{Second order differential equations}
\subsection{Solutions with Green's functions}
\begin{proposition}
Consider a second order linear differential equation on an interval $[a,b]$, which is of the general form
\[ Lu = a_2u^{\prime\prime} + a_1u' + a_0u = f \]
where $a_2,a_1, a_0, f\in \cont([a,b])$.
Consider mixed homogenous boundary conditions of first, second or third type, i.e.\ of the form
\begin{align*}
B_au = c_1 u(a) + c_2 u'(a) &= 0 \\
B_bu = c_3 u(b) + c_4 u'(b) &= 0
\end{align*}
where at least one of $c_1,c_2$ and $c_3,c_4$ is non-zero.

Assume that $a_2(x) \neq 0$ for all $x\in [a,b]$, $f\in L^2([a,b])$ and the kernel of $L$ is trivial.

Then there exists a unique solution of the form
\[ u(x) = \int_{a}^b G(x,y)f(y)\diff{y} \]
where $G$ is a bounded function in $([a,b]\times [a,b] \to \C)$.
\end{proposition}
\begin{proof}
We want to find a kernel $G$ such that
\[ L(G(\cdot, y)) = \delta_y \]
as distributions for all fixed $y\in [a,b]$ and
\[ B_aG(\cdot, y) = 0 = B_bG(\cdot, y). \]
TODO
\end{proof}

\subsection{Sturm-Liouville theory}
\subsubsection{Strum-Liouville problems and operators}
\begin{definition}
A \udef{Sturm-Liouville equation} is a real second-order ODE of the form
\[ -(pu')' + qu = \lambda \omega u \]
where $\lambda\in\R$ and $p,p',q,\omega\in \cont([a,b])$ for some $a,b\in \R$. Also $p$ is assumed strictly positive on $]a,b[$ and $\omega$ strictly positive on $[a,b]$.

A \udef{Sturm-Liouville operator} is a linear operator on the Sobolev space $W^{2,2}([a,b])$ of the form
\[ L: u\mapsto \frac{1}{\omega}\Big(-(pu')' + qu\Big) \]
where $p,q, \omega$ are as above.

A \udef{Sturm-Liouville problem} is a Sturm-Liouville equation with mixed homogenous boundary conditions of first, second or third type, i.e.\ of the form
\[ c_1 u(t_b) + c_2 u'(t_b) = 0 \]
where $t_b$ is $a$ or $b$ and at least one of $c_1,c_2$ is non-zero.

We call the Sturm-Liouville problem
\begin{itemize}
\item \udef{regular} if $p$ is strictly positive on $[a,b]$ and boundary conditions are specified at $a$ and $b$;
\item \udef{singular} if any of the following hold:
\begin{itemize}
\item $p(a) = 0$ and there is no boundary condition at $a$;
\item $p(b) = 0$ and there is no boundary condition at $a$;
\item $p(a) = 0 = p(b)$ and there are no boundary conditions; or
\item $[a,b]$ is infinite.
\end{itemize}
\end{itemize}
\end{definition}
For finite $[a,b]$, all $u\in\cont([a,b])$ are square integrable: $u$ is necessarily bounded by \ref{imageCompactIsClosedBounded} and the integral is bounded by this bound times $|b-a|$. If $[a,b]$ is infinite we still require solutions to be square integrable.

We may consider $\cont([a,b]) \subset (\R\to\C)$, in which case the Sturm-Liouville operator maps real functions to real functions.

\begin{proposition}
Consider a Sturm-Liouville problem. Take the Sobolev space $W^{2,2}([a,b], \omega(x)\diff{x})$ and let $\mathcal{H}$ be the subspace of functions that obey the boundary conditions. Then the Sturm-Liouville operator $L$ restricted to $\mathcal{H}$ is self-adjoint.
\end{proposition}
We take $Lu$ to be defined if $Lu\in\cont([a,b])$. If $[a,b]$ is infinite, we 
\begin{proof}

\end{proof}

\chapter{Partial differential equations}
Transport equation, Laplace's equation, Heat equation, Wave equation
\section{Classification}
\begin{definition}
An \udef{$n^\text{th}$ order partial differential equation} (or PDE) is an equation of the form
\[ F(x, \{D^\alpha u\}_{|\alpha|\leq m}) \equiv 0. \]
We call a  function $u: \Omega \subset \R^N \to \R$ a \udef{solution} of this differential equation on $\Omega$ if $D^\alpha u$ exists and is continuous for $|\alpha|\leq m$ and $F(x, \{D^\alpha u(x)\}_{|\alpha|\leq m})$ is zero for all $x\in \Omega$.

The set of all solutions is called the \udef{general solution}.

We call the differential equation
\begin{enumerate}
\item \udef{linear} if $\md{F}{2}{(D^\alpha u)}{}{(D^\beta u)}{} \equiv 0$ for $|\alpha|,|\beta|\leq m$;
\item \udef{homogenous} if $F(x, 0,\ldots, 0) = 0$.
\end{enumerate}
\end{definition}

\begin{lemma}
A PDE is linear \textup{if and only if} it can be written in the form
\[ Lu(x) = \sum_{|\alpha|\leq m}a_\alpha(x)D^\alpha u(x) = g(x). \]
A linear PDE is homogeneous \textup{if and only if} $g = 0$.
\end{lemma}

\subsection{Elliptic, Hyperbolic and Parabolic PDEs}