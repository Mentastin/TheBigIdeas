\chapter{Abstract rewriting systems}
\section{Syntactic structures}
\subsection{Lists and trees}
\begin{definition}
Let $V$ be a \emph{collection} of tokens.
\begin{itemize}
\item The collection $L_V$ of $V$-lists is defined by $L_V \defeq \big[\seq{} | L_V | (L_V,L_V)\big]$.
\item The collection $T_V$ of $V$-trees is defined by $T_V \defeq V - L_{T_V}$.
\end{itemize}
\end{definition}
TODO collection not set, tree definition mutually recursive. TODO $\seq{}$ should be interpreted as the empty string.

\subsection{Lists of strings}
\subsubsection{Transitive closure}
Transitive closure = list of intermediate steps.

\subsubsection{From trees to lists}
Extra column with justification. Prove equivalence with tree.

\subsubsection{Context}
Turnstile
\subsubsection{Hypothesis introduction}



\subsection{Diagrams}
\subsubsection{Diagrams for rewriting systems}
TODO place here.


\section{Definitions}
\begin{definition}
An \udef{(abstract) rewriting system} is a pair $\sSet{X, R}$ where
\begin{itemize}
\item $X$ is a set;
\item $R$ is a binary relation on $X$. The elements of $R$ are called \udef{(rewriting) rules}.
\end{itemize}
Let $x,y\in X$. Then we call
\begin{itemize}
\item $y$ a \udef{successor} of $x$ if $xR^+y$;
\item $y$ a \udef{direct successor} of $x$ if $xRy$.
\end{itemize}
We say
\begin{itemize}
\item $x$ is \udef{reducible} if there exists $y$ such that $x\mathrel{R}y$;
\item $x$ is \udef{irreducible} or \udef{in normal form} if $x$ is not reducible;
\item $y$ is a \udef{normal form of} $x$ if $xR^*y$ and $y$ is in normal form.
\end{itemize}
We say
\begin{itemize}
\item $x$ is \udef{weakly normalising} if it has a normal form;
\item $x$ is \udef{strongly normalising} if $\upset\{x\} \subseteq T_R$ is terminating.
\end{itemize}
We say
\begin{itemize}
\item $x$ and $y$ are \udef{joinable} if $x\big(R^*;(R^\transp)^*\big)y$. We write $x \joins y$.
\end{itemize}
\end{definition}


\subsection{Properties of rewriting systems}
\begin{definition}
Let $\sSet{X, R}$ be a rewriting system. This system is called
\begin{itemize}
\item \udef{terminating} (or \udef{strongly normalising}) if $T_R$ is terminating;
\item \udef{(weakly) normalising} if every element has a normal form;
\end{itemize}
it is said to
\begin{itemize}
\item have the \udef{Church-Rosser} property if $\forall x,y\in X: \; x\mathrel{\equiv_R}y \implies x \joins y$;
\item be \udef{confluent} if $\forall x,y_1, y_2\in X: \; \big(x\mathrel{R^*}y_1\big) \land \big(x\mathrel{R^*}y_2\big) \implies y_1 \joins y_2$;
\item be \udef{semi-confluent} if $\forall x,y_1, y_2\in X: \; \big(x\mathrel{R}y_1\big) \land \big(x\mathrel{R^*}y_2\big) \implies y_1 \joins y_2$.
\end{itemize}
The system is called
\begin{itemize}
\item \udef{convergent} if it is both confluent and terminating.
\end{itemize}
\end{definition}
Note that the Church-Rosser property is equivalent to
\[ \forall x,y\in X: \; x\mathrel{\equiv_R}y \iff x \joins y. \]
In other words, two elements are equivalent if and only if they are joinable.

A rewriting system $\sSet{X, R}$ is normalising if and only if the associated tree $\sSet{T_R, \sqsubseteq}$ is coatomic. The normal forms are the coatoms.

\begin{lemma} \label{successionNormalForm}
Let $\sSet{X,R}$ be a rewriting system and $x\in X$ in normal form. If $y\in X$ is such that $xR^*y$, then $y=x$. 
\end{lemma}

\begin{proposition}
Any terminating relation is normalising, but the converse is not true.
\end{proposition}
This result assumes DC.
\begin{proof}
Let $\sSet{X, R}$ be a non-normalising rewriting system. Then we can find $u\in T_R$ such that $u{\sqsubseteq}$ does not contains a terminal node. Thus ${\sqsubseteq}u \cup u{\sqsubseteq}$ is a pruned tree. By \ref{ZornEquivalentsDC} it contains an infinite branch. Thus $T_R$ contains an infinite branch and $R$ is not terminating.

The following example shows that the converse is not true.
\end{proof}

\begin{example}
Confluent, normalising and asymmetric, but not terminating.
\[ \begin{tikzcd}
\bullet \rar \dar & \bullet \rar \ar[dl] & \bullet \rar \ar[dll] & \hdots \\
\bullet
\end{tikzcd} \]
\end{example}


\subsubsection{Diagrams for rewriting systems}
\begin{definition}
Let $\sSet{X,R}$ be a rewriting system. An \udef{RS-diagram} is a diagram with nodes and arrows between the nodes.
\begin{itemize}
\item Each node is labeled either by a variable (in which case we call it a variable node) or a constant (in which case we call it a constant node).
\item A constant node is drawn in a box.
\item An unlabeled node is implicitly a variable node.
\end{itemize}
Each arrow represents a proposition (with two unbounded variables):
\begin{itemize}
\item $x\to y$ represents $xRy$;
\item $x\leftrightarrow y$ represents $x(R\cup R^\transp)y$;
\item $x\overset{?}{\to}y$ represents $x(R\cup \id_X)y$;
\item $x\overset{+}{\to}y$ represents $xR^+y$;
\item $x\overset{*}{\to}y$ represents $xR^*y$;
\item $x\overset{n}{\to}y$ for some $n\in \N$ represents $xR^ny$;
\item $x\overset{-1}{\to}y$ represents $xR^\transp y$;
\item $x\overset{?}{\leftrightarrow}y$ represents $x(R\cup R^\transp \cup \id_X)y$;
\item $x\overset{+}{\leftrightarrow}y$ represents $x(R\cup R^\transp)^+y$;
\item $x\overset{*}{\leftrightarrow}y$ represents $x(R\cup R^\transp)^*y$;
\item $x\overset{n}{\leftrightarrow}y$ for some $n\in \N$ represents $x(R\cup R^\transp)^ny$.
\end{itemize}
Each arrow may be solid or dashed. Let
\begin{itemize}
\item $x_0, \ldots x_n$ be the variables that label variable nodes connected by at least one solid arrow;
\item $y_0,\ldots y_n$ the other variables in the diagram;
\item $A_0, \ldots, A_k$ the propositions represented by the solid arrows;
\item $B_0, \ldots, B_l$ the propositions represented by the dashed arrows.
\end{itemize}
Then the diagram represents the proposition
\[ \forall x_0, \ldots x_n \in X: \Big(A_0\land \ldots\land A_k \land\textbf{TRUE} \; \implies\; \exists y_0,\ldots y_n: (B_0\land \ldots \land B_l) \lor\textbf{FALSE} \Big). \]
\end{definition}

The addition of the constants TRUE and FALSE is for when a diagram contains either no solid or no dashed arrows.

\begin{itemize}
\item If the diagram contains no dashed arrows, then it is trivially true.
\item If the diagram contains no solid arrows, then its proposition is equivalent to
\[ \exists y_0,\ldots y_n: \; B_0\land \ldots \land B_l. \]
\end{itemize}

We note the following rules for manipulating \emph{true} diagrams:
\begin{itemize}
\item If we have two diagrams such that we can match the dashed arrows of one to the solid arrows of the other (such that the dashed arrow types imply the solid arrow types), then we can simply add the dashed lines of the second diagram to the first.
\item We can always remove dashed arrows and add solid arrows.
\end{itemize}

\begin{example}
Let $\sSet{X,R}$ be a rewriting system and $a,b\in X$.
\begin{itemize}
\item The joinability of $a$ and $b$ (i.e.\ $a\joins b$) is expressed by
\[ \begin{tikzcd}
a \arrow[r, dashed, "{*}"] & {} & b \arrow[l, dashed, swap, "{*}"]
\end{tikzcd}. \]
\item In any rewriting system, we have the diagram
\[ \begin{tikzcd}
x \arrow[rr, dashed, leftrightarrow, "{*}"] \arrow[dr, swap, "{*}"] & {} & y \arrow[dl, "{*}"] \\
{} & {} & {}
\end{tikzcd} \]
\item The Church-Rosser property is expressed by the diagram
\[ \begin{tikzcd}
x \arrow[rr, leftrightarrow, "{*}"] \arrow[dr, swap, dashed, "{*}"] & {} & y \arrow[dl, dashed, "{*}"] \\
{} & {} & {}
\end{tikzcd} \]
\item Confluence is expressed by the diagram
\[ \begin{tikzcd}
x \arrow[r, "{*}"] \arrow[d, swap, "{*}"] & y_1 \arrow[d, dashed, "{*}"] \\
y_2 \arrow[r, dashed, swap, "{*}"] & {}
\end{tikzcd} \]
\item Semi-confluence is expressed by the diagram
\[ \begin{tikzcd}
x \arrow[r] \arrow[d, swap, "{*}"] & y_1 \arrow[d, dashed, "{*}"] \\
y_2 \arrow[r, dashed, swap, "{*}"] & {}
\end{tikzcd} \]
\end{itemize}
\end{example}

\begin{proposition}[Induction on RS-diagrams] \label{inductionRSdiagrams}
Let $\sSet{X,R}$ be a rewriting system and $D_1, D_2$ two RS-diagrams such that $D_1$ implies $D_2$ and $D_1$ is a subdiagram of $D_2$.

If $D_1$ holds, then any diagram that we can obtain from $D_1$ by substituting in $D_2$ also holds.
\end{proposition}

TODO: general form of repeated application of a rule.

\begin{lemma} \label{triangelRSdiagrams}
Let $\sSet{X,R}$ be a rewriting system. Then the diagram
\[ \begin{tikzcd}
{} & \arrow[dl, dashed, swap, "{?}"] z \arrow[dr, dashed, "{?}"] & {} \\
x \arrow[rr, leftrightarrow] & {} & y
\end{tikzcd} \qquad\text{holds.} \]
\end{lemma}
\begin{proof}
If $xRy$, then we may set $z = x$. If $yRx$, then we may set $z = y$.
\end{proof}

\begin{lemma} \label{transitiveClosureRSdiagram}
Let $\sSet{X,R}$ be a rewriting system. Then the diagram
\[ \begin{tikzcd}
{} & z \arrow[dr] & {} \\
x \arrow[ur, "{*}"] \arrow[rr, dashed, "{*}"] & {} & y
\end{tikzcd} \qquad\text{holds.} \]
\end{lemma}
\begin{proof}
We have $R^*;R \subseteq R^*$.
\end{proof}


TODO
\[ \begin{tikzcd}
{} & \arrow[dl, swap, "{*}"] z \arrow[dr, "{*}"] & {} \\
x \arrow[rr, dashed, leftrightarrow, "{*}"] & {} & y
\end{tikzcd} \qquad\text{holds.} \]


\begin{lemma} \label{confluenceInduction}
Let $\sSet{X,R}$ be a confluent rewriting system. Then any diagram of the form
\[ \begin{tikzcd}[column sep=1.8em]
{} & x_1 \arrow[dl, swap, "{*}"] \arrow[dr, "{*}"] & {} & \arrow[dl, swap, "{*}"]\arrow[dr, "{*}"] \hdots & {} & x_n \arrow[dl, swap, "{*}"] \arrow[dr, "{*}"] & {} \\
y_0 \arrow[dr, dashed, "{*}"] & {} & \arrow[dl, swap, dashed, "{*}"] y_1 & \hdots & \arrow[ddll, swap, dashed, "{*}"] y_n  & {} & \arrow[dddlll, swap, dashed, "{*}"] y_{n+1} \\
{} & {} \arrow[dr, dashed, "{*}"] & {} &  {}  & {} &  {} & {} \\
{} & {} & {} \arrow[dr, dashed, "{*}"] & {} & {} & {} & {} \\
{} & {} & {} & {} & {} & {} & {} \\
\end{tikzcd} \qquad \text{holds.} \]
\end{lemma}
\begin{proof}
We prove this by induction \ref{inductionRSdiagrams} because we have the implications

\begin{align*}
\begin{tikzcd}[column sep=1.5em, row sep=1.5em, ampersand replacement=\&]
{} \& \arrow[dl, swap, "{*}"] x \arrow[dr, "{*}"] \& {} \\
y \arrow[dr, dashed, "{*}"] \& {} \& \arrow[dl, dashed, swap, "{*}"] y' \\
{} \& {} \& {}
\end{tikzcd} \qquad&\implies\qquad \begin{tikzcd}[column sep=1.5em, row sep=1.5em, ampersand replacement=\&]
{} \& \arrow[dl, swap, "{*}"] x \arrow[dr, "{*}"] \& {} \& \arrow[dl, swap, "{*}"] x' \arrow[dr, "{*}"] \& {} \\
y \arrow[dr, dashed, "{*}"] \& {} \& \arrow[dl, dashed, swap, "{*}"] y' \& {} \& y^{\prime\prime} \\
{} \& {} \& {}
\end{tikzcd} \\
&\implies\qquad \begin{tikzcd}[column sep=1.5em, row sep=1.5em, ampersand replacement=\&]
{} \& \arrow[dl, swap, "{*}"] x \arrow[dr, "{*}"] \& {} \& \arrow[dl, swap, "{*}"] x \arrow[dr, "{*}"] \arrow[ddll, dashed, bend left, "{*}"] \& {} \\
y \arrow[dr, dashed, "{*}"] \& {} \& \arrow[dl, dashed, swap, "{*}"] y' \& {} \& y^{\prime\prime} \\
{} \& {} \& {}
\end{tikzcd} \\
&\implies\qquad \begin{tikzcd}[column sep=1.5em, row sep=1.5em, ampersand replacement=\&]
{} \& \arrow[dl, swap, "{*}"] x \arrow[dr, "{*}"] \& {} \& \arrow[dl, swap, "{*}"] x' \arrow[dr, "{*}"] \& {} \\
y \arrow[dr, dashed, "{*}"] \& {} \& \arrow[dl, dashed, swap, "{*}"] y' \& {} \& y^{\prime\prime} \arrow[ddll, dashed, swap, "{*}"] \\
{} \& {} \arrow[dr, dashed, "{*}"] \& {} \\
{} \& {} \& {}
\end{tikzcd}
\end{align*}
The second implication uses \ref{transitiveClosureRSdiagram} and the third uses confluence. The base case is just confluence.
\end{proof}

\begin{proposition} \label{confluenceEquivalents}
Let $\sSet{X, R}$ be a rewriting system. The following are equivalent:
\begin{enumerate}
\item $R$ has the Church-Rosser property;
\item $R$ is confluent;
\item $R$ is semi-confluent.
\end{enumerate}
\end{proposition}
\begin{proof}
$(1) \Rightarrow (2)$ Take $x,y_1, y_2\in X$ and assume $\big(x\mathrel{R^*}y_1\big) \land \big(x\mathrel{R^*}y_2\big)$. Then $y_1 \equiv_R y_2$ and so $y_1\joins y_2$ by the Church-Rosser property.


$(2) \Rightarrow (1)$ Take $x,y\in X$ such that $x\equiv_R y$. Then there exists a finite sequence $\seq{x,x_0,\ldots, x_n, y}$ such that each pair of adjacent terms in the sequence is an element of $R\cup R^\transp$. I.e.\ we have
\[ \begin{tikzcd}
x \ar[r, leftrightarrow] & x_0 \ar[r, leftrightarrow] & \hdots \ar[r, leftrightarrow] & x_n \ar[r, leftrightarrow] & y
\end{tikzcd} \]
By \ref{triangelRSdiagrams}, this implies
\[ \begin{tikzcd}[column sep=1.5em, row sep=1.5em]
{}& \arrow[dl, dashed, swap, "{?}"]{}\arrow[dr, dashed, "{?}"] & &\arrow[dl, dashed, swap, "{?}"]{}\arrow[dr, dashed, "{?}"]&{}&\arrow[dl, dashed, swap, "{?}"]{}\arrow[dr, dashed, "{?}"]&{}&\arrow[dl, dashed, swap, "{?}"]{}\arrow[dr, dashed, "{?}"]&{} \\
x \ar[rr, leftrightarrow] &{}& x_0 \ar[rr, leftrightarrow] &{}& \hdots \ar[rr, leftrightarrow] &{}& x_n \ar[rr, leftrightarrow] &{}& y
\end{tikzcd} \]
By \ref{confluenceInduction}, this implies (as $\overset{?}{\to}$ implies $\overset{*}{\to}$)
\[ \begin{tikzcd}[column sep=1.5em, row sep=1.5em]
{}& \arrow[dl, dashed, swap, "{?}"]{}\arrow[dr, dashed, "{?}"] & &\arrow[dl, dashed, swap, "{?}"]{}\arrow[dr, dashed, "{?}"]&{}&\arrow[dl, dashed, swap, "{?}"]{}\arrow[dr, dashed, "{?}"]&{}&\arrow[dl, dashed, swap, "{?}"]{}\arrow[dr, dashed, "{?}"]&{} \\
x \ar[rr, leftrightarrow]\arrow[dr, dashed, "{*}"] \arrow[ddddrrrr, dashed, bend right, "{*}"] &{}& x_0 \ar[rr, leftrightarrow]\arrow[dl, swap, dashed, "{*}"] &{}& \arrow[ddll, swap, dashed, "{*}"] \hdots \ar[rr, leftrightarrow] &{}& x_n \arrow[dddlll, swap, dashed, "{*}"] \ar[rr, leftrightarrow] &{}& y \arrow[ddddllll, swap, dashed, "{*}"] \\
{}&{}\arrow[dr, dashed, "{*}"]&{}&{}&{}&{}&{}&{}&{} \\
{}&{}&{}\arrow[dr, dashed, "{*}"]&{}&{}&{}&{}&{}&{} \\
{}&{}&{}&{}\arrow[dr, dashed, "{*}"]&{}&{}&{}&{}&{} \\
{}&{}&{}&{}&{}&{}&{}&{}&{} \\
\end{tikzcd} \]
Removing extraneous arrows gives $\begin{tikzcd}
x \arrow[rr, leftrightarrow, "{*}"] \arrow[dr, dashed, "{*}"] &{}& y \arrow[dl, dashed, swap, "{*}"] \\
{} & {} & {}
\end{tikzcd}$, which is the Church-Rosser property.

$(2) \Rightarrow (3)$ Immediate.

$(3) \Rightarrow (1)$ Assume semi-confluence. We prove this by diagrammatic induction. We take two base cases:
\[ \begin{tikzcd}
{} & {} \arrow[dl, swap, "{*}"] \\
{} \arrow[dr, dashed, "{*}"] & {} \\
{}&{}
\end{tikzcd} \qquad\text{and}\qquad \begin{tikzcd}[column sep=1.5em, row sep=1.5em]
{} & {} \arrow[dl, swap, "{*}"] \arrow[dr] & {} \\
{} \arrow[dr, dashed, "{*}"] & {} & {} \arrow[dl, swap, dashed, "{*}"] \\
{}&{}&{} 
\end{tikzcd} \qquad \text{hold.} \]
Because of semi-confluence, we have the implication
\begin{align*}
\begin{tikzcd}[column sep=1.5em, row sep=1.5em, ampersand replacement=\&]
{} \& \arrow[dl, swap, "{*}"] {} \arrow[dr] \& {} \\
{} \arrow[dr, dashed, "{*}"] \& {} \& \arrow[dl, dashed, swap, "{*}"] {} \\
{} \& {} \& {}
\end{tikzcd} \qquad&\implies\qquad \begin{tikzcd}[column sep=1.5em, row sep=1.5em, ampersand replacement=\&]
{} \& \arrow[dl, swap, "{*}"] {} \arrow[dr] \& {} \& {} \\
{} \arrow[dr, dashed, "{*}"] \& {} \& \arrow[dl, dashed, swap, "{*}"] \arrow[dr] {} \& {} \\
{} \& {} \& {} \& {} \\
{} \& {} \& {} \& {}
\end{tikzcd} \\
\qquad&\implies\qquad \begin{tikzcd}[column sep=1.5em, row sep=1.5em, ampersand replacement=\&]
{} \& \arrow[dl, swap, "{*}"] {} \arrow[dr] \& {} \& {} \\
{} \arrow[dr, dashed, "{*}"] \& {} \& \arrow[dl, dashed, swap, "{*}"] \arrow[dr] {} \& {} \\
{} \& {} \arrow[dr, dashed, "{*}"] \& {} \& {} \arrow[dl, dashed, swap, "{*}"] \\
{} \& {} \& {} \& {}
\end{tikzcd}
\end{align*}
\end{proof}
\begin{corollary} \label{confluenceUniquenessNormalForm}
Let $\sSet{X,R}$ be a confluent rewriting system. Then
\begin{enumerate}
\item if $x\equiv_R y$ and $y$ is in normal form, then $xR^*y$;
\item if $x\equiv_R y$ and $x, y$ are both in normal form, then $x = y$;
\item every element has at most one normal form.
\end{enumerate}
\end{corollary}
\begin{proof}
(1) As $\sSet{X,R}$ is Church-Rosser, we have $\begin{tikzcd}[column sep=small, row sep=small]
\boxed{x} \arrow[rr, leftrightarrow, "{*}"] \arrow[dr, dashed, "{*}"] &{}& \boxed{y} \arrow[dl, dashed, swap, "{*}"] \\
{} & {z} & {}
\end{tikzcd}$. As $y$ is in normal form, we have $z = y$ (by \ref{successionNormalForm}). Thus $xR^*y$.

(2) By \ref{successionNormalForm}.

(3) Let $y_1, y_2$ both be normal forms of $x$. Then $y_1 (R^\transp)^* x R^* y_2$, so $y_1 \equiv_R y_2$ and $y_1 = y_2$ by (2).
\end{proof}

\begin{proposition}
Let $\sSet{X,R}$ be a rewriting system. Then the rewriting system is confluent and normalising \textup{if and only if} every element has a unique normal form.
\end{proposition}
\begin{proof}
$\boxed{\Rightarrow}$ Normalising implies existence (by definition) and confluence implies unicity by \ref{confluenceUniquenessNormalForm}.

$\boxed{\Leftarrow}$ The rewriting system is normalising by definition. For confluence, assume $x R^* y_1$ and $xR^*y_2$. Let $y_1',y_2'$ be the normal forms of $y_1$ and $y_2$, respectively.

Then $xR^*y_1 R^*y_1'$, so $xR^*y_1'$. Also $xR^*y_2'$. Thus both $y_1'$ and $y_2'$ are normal forms of $x$. By unicity $y_1' = y_2' = y'$, so $y_1 R^* y' (R^\transp)^* y_2$, which means that $y_1 \joins y_2$ and thus that the rewriting system is confluent.
\end{proof}

\begin{definition}
Let $\sSet{X,R}$ be a confluent and normalising rewriting system. The unique normal form of $x\in X$ is denoted $\normalform{x}$.
\end{definition}

\begin{proposition}
Let $\sSet{X,R}$ be a confluent and normalising rewriting system and $x,y\in X$. Then $x \equiv_R y$ \textup{if and only if} $\normalform{x} = \normalform{y}$.
\end{proposition}
\begin{proof}
$\boxed{\Rightarrow}$ From $x \equiv_R y$, we have $\normalform{x} \equiv_R \normalform{y}$ and thus $\normalform{x} = \normalform{y}$ by \ref{confluenceUniquenessNormalForm}.

$\boxed{\Leftarrow}$ Set $z = \normalform{x} = \normalform{y}$. Then $x R^* z (R^\transp)^* y$, so $x \equiv_R y$.
\end{proof}

\section{Termination}

\begin{lemma}
Let $\sSet{X,R}$ be a rewriting system. Then $R$ is terminating \textup{if and only if} $R^+$ is terminating.
\end{lemma}

\begin{lemma}
If $\sSet{X, R}$ is a terminating rewriting system. Then $R$ is asymmetric.
\end{lemma}
\begin{proof}
Assume $R$ not asymmetric. Then there exists $(x,y)\in R\cap R^\transp$. The initial segments of the sequence $n\mapsto \begin{cases}
x & (\text{$n$ is even}) \\
y & (\text{$n$ is odd})
\end{cases}$ form a monotonic sequence and thus determine an infinite branch of $T_R$ by \ref{monotoneSequenceBranch}.
\end{proof}

\begin{proposition}
A $\sSet{X,R}$ rewriting system is terminating \textup{if and only if} $\sSet{A,R^+}$ is terminating.
\end{proposition}
\begin{proof}
TODO
\end{proof}

\subsection{Chain conditions}
\begin{definition}
Let $\sSet{X, R}$ be a relational structure. Then $\sSet{X, R}$ is said to
\begin{itemize}
\item satisfy the \udef{ascending chain condition} (ACC) if $\sSet{X, R}$ terminates.
\item satisfies the \udef{descending chain condition} (DCC) if $\sSet{X, R^\transp}$.
\end{itemize}
\end{definition}

\subsection{Induction on terminating rewriting systems}
Assuming the axiom of dependent choice, a terminating rewriting system $\sSet{X,R}$ is strictly converse well-founded by \ref{welfoundedACC}. This implies the following version of induction: let $P\subseteq X$
\[ \text{if}\quad  \forall x\in X: \Big(\big(xR\subseteq P\big)\implies x\in P\Big), \quad \text{then}\quad P=U. \]


\subsection{Progress functions}
\begin{proposition} \label{rewritingSystemProgressFunction}
Let $\sSet{X, R}$ be a rewriting system and $\sSet{Y,S}$ a terminating rewriting system.

If there exists a monotone function $f: X \to Y$, then $X$ is also terminating.
\end{proposition}
\begin{proof}
We have that $(\lambda_f)^\imf(T_R)$ is a subtree of $T_S$ by \ref{monotoneFunctionSubAssociatedTree}.

We prove the contrapositive: Assume $X$ is not terminating. Then we can find an infinite branch $S\in [T_R]$ and $(\lambda_f)^\imf(S)$ is an infinite branch in $(\lambda_f)^\imf(T_R) \subseteq T_S$, so $Y$ is not terminating.
\end{proof}

\begin{lemma}
A finitely branching rewriting system $\sSet{X,R}$ terminates \textup{if and only if} there exists a monotone function $f: \sSet{X,R} \to \sSet{\N,>}$.
\end{lemma}
\begin{proof}
$\boxed{\Rightarrow}$ Let $\sSet{X,R}$ be a finitely branching rewriting system. Take $x\in X$. Then $xR^+$ is finite by KÅ‘nig's lemma (TODO ref!). So we can define $\varphi: \sSet{X, R^+}\to \sSet{\N, >}: x\mapsto \#(xR^+)$. This is clearly monotone because $xR;R^+ \subseteq xR^+$.

$\boxed{\Leftarrow}$ Follows from \ref{rewritingSystemProgressFunction}.
\end{proof}

\section{Confluence}
TODO put Church-Rosser equivalence here? And combine definition of local confluence above?

\begin{lemma} \label{confluenceTransitiveReflexiveClosure}
Let $\sSet{X,R}$ be a rewriting system. Then $R$ is confluent \textup{if and only if} $R^*$ is confluent.
\end{lemma}

\subsection{Confluence-related properties}
\begin{definition}
Let $\sSet{X,R}$ be a rewriting system. The system is said
\begin{itemize}
\item to be \udef{locally confluent} if 
$\forall x,y_1, y_2\in X: \; \big(x\mathrel{R}y_1\big) \land \big(x\mathrel{R}y_2\big) \implies y_1 \joins y_2$;
\item to be \udef{strongly confluent} if $\forall x,y_1, y_2\in X: \; \big(x\mathrel{R}y_1\big) \land \big(x\mathrel{R}y_2\big) \implies \exists z:  \big(y_1 \mathrel{R^*}x\big) \land \big(y_2\mathrel{R^?}x\big)$;
\item to have the \udef{diamond property} if $\forall x,y_1, y_2\in X: \; \big(x\mathrel{R}y_1\big) \land \big(x\mathrel{R}y_2\big) \implies \exists z: \big(y_1 \mathrel{R}x\big) \land \big(y_2\mathrel{R}x\big)$.
\end{itemize}
\end{definition}

\begin{example}
Let $\sSet{X,R}$ be a rewriting system.
\begin{itemize}
\item Local confluence is expressed by the diagram
\[ \begin{tikzcd}
x \arrow[r, "{}"] \arrow[d, swap, "{}"] & y_1 \arrow[d, dashed, "{*}"] \\
y_2 \arrow[r, dashed, swap, "{*}"] & {}
\end{tikzcd} \]
\item Strong confluence is expressed by the diagram
\[ \begin{tikzcd}
x \arrow[r] \arrow[d, swap, "{}"] & y_1 \arrow[d, dashed, "{?}"] \\
y_2 \arrow[r, dashed, swap, "{*}"] & {}
\end{tikzcd} \]
\item The diamond property is expressed by the diagram
\[ \begin{tikzcd}
x \arrow[r] \arrow[d, swap, "{}"] & y_1 \arrow[d, dashed, "{}"] \\
y_2 \arrow[r, dashed, swap, "{}"] & {}
\end{tikzcd} \]
\end{itemize}
\end{example}

\begin{lemma} \label{confluenceImplications}
Let $\sSet{X,R}$ be a rewriting system. Then each of the following properties implies the next:
\begin{enumerate}
\item diamond property;
\item strong confluence;
\item confluence;
\item local confluence.
\end{enumerate}
\end{lemma}
\begin{proof}
$(1) \Rightarrow (2)$ Immediate as $R \subseteq R^?$ and $R\subseteq R^*$.

$(2) \Rightarrow (3)$ By \ref{confluenceEquivalents} it is enough to prove semi-confluence. First we observe the lemma
\begin{lemma*} The following diagrams are equivalent:
\[ \begin{tikzcd}
x \arrow[r] \arrow[d, "{}"] & y_1 \arrow[d, dashed, swap, "{?}"] \\
y_2 \arrow[r, dashed, swap, "{*}"] & {z}
\end{tikzcd} \qquad\iff\qquad \begin{tikzcd}
x \arrow[r] \arrow[d, "{?}"] & y_1 \arrow[d, dashed, "{?}"] \\
y_2 \arrow[r, dashed, swap, "{*}"] & {z}
\end{tikzcd}. \]
\end{lemma*}
\begin{proof}[Proof of sublemma] \renewcommand{\qedsymbol}{$\dashv$}
The direction $\Leftarrow$ is immediate because $R\subseteq R^?$. For the other direction, take $x,y_1,y_2 \in X$ such that $xRy_1$ and $xR^?y_2$. If $xRy_2$, then the implication is immediate. If not, then $x=y_2$ and we can take $z = y_1$ and we have $y_2Rz$.
\end{proof}
By induction on RS-diagrams, we conclude from
\[ \begin{tikzcd}[ampersand replacement=\&]
{} \arrow[r] \arrow[d, swap, "{?}"] \& {} \arrow[d, dashed, "{?}"] \\
{} \arrow[r, swap, dashed, "{*}"] \& {}
\end{tikzcd} \quad\iff\quad \begin{tikzcd}[ampersand replacement=\&]
{} \arrow[r] \arrow[d] \& {} \arrow[d, dashed, "{?}"] \\
{} \arrow[r, swap, dashed, "{*}"] \& {}
\end{tikzcd} \quad\implies\quad \begin{tikzcd}[ampersand replacement=\&]
{} \arrow[r] \arrow[d] \& {} \arrow[d, dashed, "{?}"] \arrow[r] \& {}  \\
{} \arrow[r, swap, dashed, "{*}"] \& {} \& {}
\end{tikzcd} \quad\implies\quad \begin{tikzcd}[ampersand replacement=\&]
{} \arrow[r] \arrow[d] \& {} \arrow[d, dashed, "{?}"] \arrow[r] \& {} \arrow[d, dashed, "{?}"] \\
{} \arrow[r, swap, dashed, "{*}"] \& {} \arrow[r, swap, dashed, "{*}"] \& {}
\end{tikzcd} \]
that $\begin{tikzcd}
{} \arrow[r, "{*}"] \arrow[d] & {} \arrow[d, dashed, "{?}"] \\
{} \arrow[r, swap, dashed, "{*}"] & {}
\end{tikzcd}$. This implies $\begin{tikzcd}
{} \arrow[r, "{*}"] \arrow[d] & {} \arrow[d, dashed, "{*}"] \\
{} \arrow[r, swap, dashed, "{*}"] & {}
\end{tikzcd}$, i.e.\ semi-confluence.

$(3) \Rightarrow (4)$ Immediate because $R\subseteq R^*$.
\end{proof}

\begin{proposition}[Newman's lemma]
Let $\sSet{X,R}$ be a terminating rewriting system. Then $X$ is confluent \textup{if and only if} $X$ is locally confluent.
\end{proposition}
This assumes DC.
\begin{proof}
One direction is given by \ref{confluenceImplications}.

For the other direction, consider the set
\[ P  = \setbuilder{x\in X}{\forall y_1,y_2 \big(xR^*y_1\big)\land\big(xR^*y_2\big) \implies y_1\joins y_2}. \]
We need to show that $P = X$, which we do with well-founded induction on $\sSet{X,(R^\transp)^*}$ . Take $x\in X$ and assume the induction hypothesis.

We need to prove
\[ \begin{tikzcd}
\boxed{x} \arrow[r, "{*}"] \arrow[d, swap, "{*}"] & y_1 \arrow[d, dashed, "{*}"] \\
y_2 \arrow[r, swap, dashed, "{*}"] & {z}
\end{tikzcd}, \]
which we split into four cases:
\[ \begin{tikzcd}
\boxed{x} \arrow[r, equal] \arrow[d, swap, equal] & y_1 \arrow[d, dashed, "{*}"] \\
y_2 \arrow[r, swap, dashed, "{*}"] & {z}
\end{tikzcd}, \qquad \begin{tikzcd}
\boxed{x} \arrow[r, equal] \arrow[d, swap, "{+}"] & y_1 \arrow[d, dashed, "{*}"] \\
y_2 \arrow[r, swap, dashed, "{*}"] & {z}
\end{tikzcd}, \qquad \begin{tikzcd}
\boxed{x} \arrow[r, "{+}"] \arrow[d, equal] & y_1 \arrow[d, dashed, "{*}"] \\
y_2 \arrow[r, swap, dashed, "{*}"] & {z}
\end{tikzcd}, \quad\text{and}\quad \begin{tikzcd}
\boxed{x} \arrow[r, "{+}"] \arrow[d, swap, "{+}"] & y_1 \arrow[d, dashed, "{*}"] \\
y_2 \arrow[r, swap, dashed, "{*}"] & {z}
\end{tikzcd}. \]
The first three cases are immediate (by taking $z$ equal to $x, y_2$ and $y_1$, respectively). For the third case, we have
\[ \begin{tikzcd}
\boxed{x} \rar \dar & u_1 \arrow[d, dashed, "{*}"] \\
u_2 \arrow[r, dashed, "{*}"] & v
\end{tikzcd} \quad\implies\quad \begin{tikzcd}
\boxed{x} \rar \dar & u_1 \arrow[d, dashed, "{*}"] \\
u_2 \arrow[d, swap, "{*}"] \arrow[r, dashed, "{*}"] & v \arrow[d, dashed, "{*}"] \\
y_2 \arrow[r, swap, dashed, "{*}"] & w
\end{tikzcd} \quad\implies\quad \begin{tikzcd}
\boxed{x} \rar \dar & u_1 \arrow[r, "{*}"] \arrow[d, dashed, "{*}"] & y_1 \arrow[dd, dashed, "{*}"] \\
u_2 \arrow[d, swap, "{*}"] \arrow[r, dashed, "{*}"] & v \arrow[d, dashed, "{*}"] & {} \\
y_2 \arrow[r, swap, dashed, "{*}"] & w \arrow[r, swap, dashed, "{*}"] & z
\end{tikzcd}. \]
These implications follow because $u_2$ and $u_1$ are elements of $P$ by the induction hypothesis. The antecedent of the implication is local confluence, which holds. We conclude the consequent and thus that $x\in P$.

By induction $P=X$.
\end{proof}

\subsection{Commutation}
\begin{definition}
Let $R,S$ be two relations on a class $X$. We say
\begin{itemize}
\item $R$ and $S$ \udef{commute} if $\forall x,y_1,y_2\in X:\; \big(xR^*y_1\big)\land\big(xS^*y_2\big)\implies \exists z\in X: \big(y_1S^*z\big)\land\big(y_2R^*z\big)$;
\item $R$ \udef{strongly commutes} with $S$ if $\forall x,y_1,y_2\in X:\; \big(xRy_1\big)\land\big(xSy_2\big)\implies \exists z\in X: \big(y_1S^?z\big)\land\big(y_2R^*z\big)$;
\item $R$ and $S$ have the \udef{commuting diamond property} if $\forall x,y_1,y_2\in X:\; \big(xRy_1\big)\land\big(xSy_2\big)\implies \exists z\in X: \big(y_1Sz\big)\land\big(y_2Rz\big)$.
\end{itemize}
\end{definition}

\begin{example}
Let $R,S$ be two relations on a class $X$.
\begin{itemize}
\item Commutation of $R$ and $S$ is expressed by the diagram
\[ \begin{tikzcd}
x \arrow[r, "{R^*}"] \arrow[d, swap, "{S^*}"] & y_1 \arrow[d, dashed, "{S^*}"] \\
y_2 \arrow[r, dashed, swap, "{R^*}"] & {}
\end{tikzcd} \]
\item Strong commutation of $R$ and $S$ is expressed by the diagram
\[ \begin{tikzcd}
x \arrow[r, "{R}"] \arrow[d, swap, "{S}"] & y_1 \arrow[d, dashed, "{S^?}"] \\
y_2 \arrow[r, dashed, swap, "{R^*}"] & {}
\end{tikzcd} \]
\item The commuting diamond property of $R$ and $S$ is expressed by the diagram
\[ \begin{tikzcd}
x \arrow[r, "{R}"] \arrow[d, swap, "{S}"] & y_1 \arrow[d, dashed, "{S}"] \\
y_2 \arrow[r, dashed, swap, "{R}"] & {}
\end{tikzcd} \]
\end{itemize}
\end{example}

The property of confluence and the commuting diamond property are symmetric in $R$ and $S$.
\begin{example}
The property of strong confluence is asymmetric in $R$ and $S$.

Consider the set $\N$ and
\begin{itemize}
\item $mRn$ if $m + 1 = n$; so $mR^*n$ iff $m\leq n$;
\item $mSn$ if $2\cdot m = n$; so $mS^*n$ iff $n/m = 2^k$ for some $k\geq 0$.
\end{itemize}
Then $R$ strongly commutes with $S$. Indeed if $xRy_1$, then $y_1 = x+1$ and if $xSy_2$, then $y_2 = 2x$. Now we can take $z=x+1$ because $(x+1)S^?\big(2(x+1)\big)$ and $2x \leq 2x+2 = 2(x+1)$ so $2xR^*(2x+2)$.

But $S$ does not strongly commute with $R$. For a counterexample, take $x= 2$ Indeed in this case $y_1 = 2x = 4$ and $y_2 = x+1 = 3$. Then $y_1R^?z$ iff $z=2x= 4$ or $z=2x+1 = 5$. In the first case $z/y_2 = 4/3$, in the second case $z/y_2 = 5/3$. In neither case is $z/y_2 = 2^k$, so we cannot have $y_2S^*z$.
\end{example}

\begin{lemma}
Let $\sSet{X,R}$ be a rewriting system. Then $R$ is confluent if $R$ commutes with itself.
\end{lemma}

\begin{lemma}
Let $R,S$ be two relations on a class $X$. Then each of the following properties implies
the next:
\begin{enumerate}
\item the commuting diamond property of $R$ and $S$;
\item strong commutation of $R$ and $S$;
\item commutation of $R$ and $S$.
\end{enumerate}
\end{lemma}
\begin{proof}
$(1) \Rightarrow (2)$ Immediate because $R\subseteq R^*$ and $S\subseteq S^?$.

$(2) \Rightarrow (3)$ See \ref{confluenceImplications} TODO.
\end{proof}

\begin{proposition}
Let $R,S$ be two relations on a class $X$. If $R$ and $S$ are both confluent and commute, then $R\cup S$ is confluent.
\end{proposition}
\begin{proof}
Using confluence of $R, S$ and commutation, we have the diagram
\[ \begin{tikzcd}[]
{\hspace{1pt}} \arrow[r, "{R^*}"] \arrow[d, "{R^*}"] & {} \arrow[r, "{S^*}"] \arrow[d,  dashed, "{R^*}"] & {} \arrow[d, dashed, "{R^*}"] \\
{\hspace{1pt}} \arrow[r, dashed, "{R^*}"] \arrow[d, "{S^*}"] & {} \arrow[r, dashed, "{S^*}"] \arrow[d, dashed, "{S^*}"] & {} \arrow[d, dashed, "{S^*}"] \\
{\hspace{1pt}} \arrow[r, dashed, "{R^*}"]  & {} \arrow[r, dashed, "{S^*}"] & {} 
\end{tikzcd}. \]
This shows that $R^*;S^*$ satisfies the diamond property and thus $R^*;S^*$ is confluent. Also
\[ R\cup S \subseteq R^*;S^* \subseteq (R\cup S)^*, \]
so $(R^*;S^*)^* = (R\cup S)^*$. Thus $(R\cup S)^*$ is confluent and so $R\cup S$ is confluent by \ref{confluenceTransitiveReflexiveClosure}. 
\end{proof}

\section{Term rewriting}
\begin{definition}
A \udef{string rewriting system} or \udef{semi-Thue system} is a pair $\sSet{\Sigma, R}$ where
\begin{itemize}
\item $\Sigma$ is a set (the \udef{alphabet});
\item $R$ is a binary relation on $\Sigma^*$. The elements of $R$ are called \udef{(rewriting) rules}.
\end{itemize}
\end{definition}

\chapter{Languages}
\begin{definition}
A \udef{language} is a set of strings.
\end{definition}

\begin{definition}
Let $L$ be a language in an alphabet $A$. Then we define the \udef{Kleene closure} of the language $L$ as
\[ L^* \defeq \Closure_\concat(L) \cup \{\seq{}\}. \]
\end{definition}
Note that $A^* = \setbuilder{\seq{a}}{a\in A}^*$.

\section{Grammars}
\begin{definition}
A \udef{(formal) grammar} is a tuple $G = \sSet{\Sigma, N, R, S}$ where
\begin{itemize}
\item $\Sigma$ is a finite set, called the \udef{alphabet} or set of \udef{terminal symbols};
\item $N$ a finite set, disjoint from $\Sigma$, of \udef{nonterminal symbols};
\item $R$ is relation on $(\Sigma \uplus V)^*$ that is a finite set; it is also called the set of \udef{production rules};
\item $S\in N$.
\end{itemize}
\end{definition}

\subsection{Chomsky+ hierarchy}
\subsubsection{Regular or type-3}
\subsubsection{Context-free or type-2}
\subsubsection{Context-sensitive or type-1}
\subsubsection{Recursive}

\subsubsection{Recursively enumerable or type-0}

\begin{example}
Let
\end{example}

\section{Automata}
\begin{definition}
An \udef{automaton} is a $5$-tuple $M = \sSet{\Sigma, Q, \delta, q_0, F}$, where
\begin{itemize}
\item $\Sigma$ is a finite set, called the \udef{input alphabet} of the automaton,
\item $Q$ is a set of \udef{states},
\item $\delta: Q\times \Sigma\to Q$ is a function, called the \udef{transition function},
\item $q\in Q$ is the \udef{start state}, and
\item $F\subseteq Q$ is the set of \udef{accept states} or \udef{final states}.
\end{itemize}
We call the automaton \udef{finite} if $Q$ is finite.

The automaton $M$ defines a function $e_M: \Sigma^* \to Q^*$ recursively by
\[ \begin{cases}
e_M(\seq{}) = \seq{q_0}, \\
e_M(u\concat \seq{x}) = e_M(u)\concat \delta(e(u)_{-1}, x) & (u\in \Sigma^*, x\in \Sigma).
\end{cases} \]

We say $M$ \udef{accepts} a string $u\in \Sigma^*$ if $e_M(u)_{-1} \in F$.

The set of all strings in $\Sigma^*$ that are accepted by the automaton is the language \udef{recognised} by $M$, or just the \udef{language of $M$}:
\[ L_M \defeq \setbuilder{u\in\Sigma^*}{e_M(u)_{-1} \in F}. \]
\end{definition}

\begin{lemma} \label{automatonExecutionLength}
Let $M = \sSet{\Sigma, Q, \delta, q_0, F}$ be an automaton and $u\in \Sigma^*$. Then $\len(e_M(u)) = \len(u)+1$.
\end{lemma}

\begin{proposition}
Let $M_1 = \sSet{\Sigma, Q_1, \delta_1, q_{0,1}, F_1}$ and $M_2 = \sSet{\Sigma, Q_2, \delta_2, q_{0,2}, F_2}$ be automata that accept the languages $L_{M_1}$ and $L_{M_2}$ in the same alphabet $\Sigma$. Define
\[ \delta = \curry_2^{-1}\Big(a\mapsto (\delta_1(-, a), \delta_2(-, a))\Big). \]
Then
\begin{enumerate}
\item $M_{\cup} = \sSet{\Sigma, Q_1\times Q_2, \delta, (q_{0,1}, q_{0,2}), (F_1\times Q_1) \cup (F_2\times Q_2)}$ is an automaton that recognises $L_{M_1}\cup L_{M_2}$;
\item $M_{\cap} = \sSet{\Sigma, Q_1\times Q_2, \delta, (q_{0,1}, q_{0,2}), F_1 \times F_2}$ is an automaton that recognises $L_{M_1}\cap L_{M_2}$.
\end{enumerate}
\end{proposition}

\subsection{State diagrams}
TODO. Double circle for accept states.

\subsection{Constructions}
\subsubsection{Changing initial state}
\begin{definition}
Let $M = \sSet{\Sigma, Q, \delta, q_{0}, F}$ be an automaton and $q\in Q$. Then $M|_{q}$ is the automaton $\sSet{\Sigma, Q, \delta, q, F}$, i.e.\ the same automaton except the initial state has been replaced by $q$.
\end{definition}

\begin{lemma} \label{automatonRunFactorisation}
Let $M = \sSet{\Sigma, Q, \delta, q_{0}, F}$ be an automaton and $x,y\in \Sigma^*$. Then
\[ e_M(x \concat y) = e_M(x)\concat \big(e_{M|_{q_x}}(y)[1:]\big), \]
where $q_x = e_M(x)_{-1}$.
\end{lemma}
\begin{proof}
Consider the functions $y\mapsto e_M(x \concat y)$ and $y\mapsto e_M(x)\concat e_{M|_{q_x}}(y)$. They satisfy the same recursion relation and thus are the same by \ref{stringRecursion}.
\end{proof}

\subsection{Non-deterministic automata}
\begin{definition}
A \udef{non-deterministic automaton} is a $5$-tuple $M = \sSet{\Sigma, Q, \delta, Q_0, F}$, where
\begin{itemize}
\item $\Sigma$ is a finite set of symbols, called the \udef{input alphabet} of the automaton,
\item $Q$ is a set of \udef{states},
\item $\delta: Q\times \Sigma \to \powerset(Q)$ is a function, called the \udef{transition function},
\item $Q_0\subseteq Q$ is the \udef{start state}, and
\item $F\subseteq Q$ is the set of \udef{accept states} or \udef{final states}.
\end{itemize}
We call the non-deterministic automaton \udef{finite} if $Q$ is finite.

The automaton $M$ defines a function $e_M: \Sigma^* \to \powerset(Q^*)$ recursively by
\[ \begin{cases}
e(\seq{}) = \setbuilder{\seq{q_0}}{q_0\in Q_0}, \\
e(u\concat \seq{x}) = \setbuilder{v\concat q}{v\in e(u), q\in \delta(v_{-1}, x)} & (u\in \Sigma^*, x\in \Sigma).
\end{cases} \]

We say $M$ \udef{accepts} a string $u\in \Sigma^*$ if $\exists r\in e_M(u): r_{-1} \in F$.

The set of all strings in $\Sigma^*$ that are accepted by the automaton is the language \udef{recognised} by $M$, or just the \udef{language of $M$}:
\[ L_M \defeq \setbuilder{u\in\Sigma^*}{\exists r\in e_M(u): r_{-1} \in F}. \]
\end{definition}

\begin{lemma} \label{automatonAsNDAutomaton}
Let $M = \sSet{\Sigma, Q, \delta, q_0, F}$ be an automaton. Consider the non-deterministic automaton $M' = \sSet{\Sigma, Q, \delta', Q_0', F}$, where
\begin{itemize}
\item $Q_0' = \{q_0\}$; and
\item $\delta' = \{\delta(-)\}$.
\end{itemize}
Then
\begin{enumerate}
\item $e_{M} = \{e_{M'}(-)\}$;
\item $M$ and $M'$ accept the same language.
\end{enumerate}
\end{lemma}
\begin{proof}
Point (2) follows straight from point (1) and point (1) is easy to prove by induction on input string length.
\end{proof}

\begin{proposition}
Let $M_1 = \sSet{\Sigma, Q_1, \delta_1, Q_{0,1}, F_1}$ and $M_2 = \sSet{\Sigma, Q_2, \delta_2, Q_{0,2}, F_2}$ be non-deterministic automata that accept the languages $L_{M_1}$ and $L_{M_2}$ in the same alphabet $\Sigma$.
Then
\begin{enumerate}
\item $M_{\cup} = \sSet{\Sigma, Q_1\sqcup Q_2, (\delta_1 \bbslash \delta_2), Q_{0,1}\sqcup Q_{0,2}, F_1 \sqcup F_2}$ is a non-deterministic automaton that recognises $L_{M_1}\cup L_{M_2}$;
\item $M_\star = \sSet{\Sigma, (Q_1\setminus F_1) \sqcup (F_1\times Q_{0,2}) \sqcup (Q_2\setminus Q_{0,2}), \delta', Q_{0,1}, F_2}$, where
\[ \delta': (q,s)\mapsto \begin{cases}
\big(\delta_1(q,s)\setminus F_1\big) \sqcup \Big(\big(\delta_1(q,s)\cap F_1\big)\times Q_{0,2}\Big) & (q\in Q_1\setminus F_1) \\
\big(\delta_1(\proj_1(q),s)\setminus F_1\big) \sqcup \Big(\big(\delta_1(\proj_1(q),s)\cap F_1\big)\times Q_{0,2}\Big) \sqcup \delta_2\big(\proj_2(q), s\big) & (q\in F_1\times Q_{0,2}) \\
\delta_2(q,s) & (q\in Q_2\setminus Q_{0,2})
\end{cases} \]
is a non-deterministic automaton that recognises $L_{M_1}\concat L_{M_2}$.
\end{enumerate}
\end{proposition}

TODO: define (better syntax!!!!!!) + picture gluing of automata.

\begin{proposition}
Let $M = \sSet{\Sigma, Q, \delta, Q_{0}, F}$ be a non-deterministic automata that accept the languages $L_{M}$.
Then consider the non-deterministic automaton $M' = \sSet{\Sigma, Q', \delta', Q_{0}, F'}$, where
\begin{itemize}
\item $Q' = Q_0 \sqcup (Q\setminus F) \sqcup (F\times Q_0)$;
\item $\delta': (q,s) \mapsto \begin{cases}
\big(\delta(q,s)\setminus F\big) \sqcup \Big(\big(\delta(q,s)\cap F\big) \times Q_0\Big) & (\text{$q\in Q_0$ or $q\in Q\setminus F$}) \\
\begin{multlined}\big(\delta(\proj_1(q),s)\setminus F\big) \sqcup \Big(\big(\delta(\proj_1(q),s)\cap F\big) \times Q_0\Big) \vspace{-1em} \\ \cup \big(\delta(\proj_2(q),s)\setminus F\big) \sqcup \Big(\big(\delta(\proj_2(q),s)\cap F\big) \times Q_0\Big) \end{multlined}& (q\in F\times Q_0);
\end{cases}$
\item $F' = Q_0 \sqcup (F\times Q_0)$.
\end{itemize}
Then $M'$ recognises $L_{M}^*$.
\end{proposition}
Note the use of $\cup$ vs $\sqcup$.



\subsection{Finite automata}
\begin{definition}
A language is called a \udef{regular language} if it is recognised by a finite automaton.
\end{definition}

\begin{proposition}
Let $L$ be a language in an alphabet $\Sigma$. Then $L$ is recognised by a finite automaton \textup{if and only if} it is recognised by a finite non-deterministic automaton.
\end{proposition}
\begin{proof}
The direction $\Rightarrow$ is immediate from \ref{automatonAsNDAutomaton}.

For the converse, take a finite non-deterministic automaton $M = \sSet{\Sigma, Q, \delta, Q_0, F}$. Consider the automaton $M' = \sSet{\Sigma, \powerset{Q}, \delta', Q_0, F'}$, where
\begin{itemize}
\item $\delta': \powerset{Q} \times \Sigma \to \powerset{Q}: (A,s) \mapsto \bigcup_{q\in A}\delta(q, s)$;
\item $F' = \setbuilder{A\in \powerset(Q)}{A\mesh F}$.
\end{itemize}
Then we need to prove $L_{M} = L_{M'}$. Indeed we can prove by induction that, for all $u\in \Sigma^*$,
\[ \setbuilder{q_{-1}}{q\in e_M(u)} = e_{M'}(u)_{-1}. \]
Call this set $A$. We have that $M$ accepts $u$ iff $F\mesh A$ and $M'$ accepts $u$ iff $A\in F'$. By definition of $F'$, these cases are the same.
\end{proof}


\subsubsection{The pumping lemma}
\begin{theorem}[Pumping lemma]
Let $L$ be a regular language. Then there exists $p\in \N$ such that for all $s \in L$, we can write $s = x\concat y \concat z$ with
\begin{enumerate}
\item $x\concat y^k \concat z \in L$ for all $k\in\N$;
\item $\len(y) \geq 1$;
\item $\len(x\concat y) \leq p$.
\end{enumerate}
\end{theorem}
We also allow $k=0$, so $x\concat z$ must be an element of $L$.
\begin{proof}
Let $M = \sSet{\Sigma, Q, \delta, q_0, F}$ be a finite automaton that recognises $L$. Set $p = \#Q$. If $\len(s) \leq p$, then we can set $x=\seq{}, y= s$ and $z=\seq{}$.

Now assume $\len(s) > p$ and consider $e_M(s)$, which is a string in $Q$. By \ref{automatonExecutionLength}, we have
\[ \len(e_M(s)) = \len(s)+1 > p +1 = \#Q+1. \]
By \ref{stringPigeonholePrinciple} there must be a state in $e_M(s)[0:\#Q+1]$ that repeates. Let $k_1, k_2$ be the two different indices of this state in $e_M(s)$.

Then we may set $x = s[0:k_1]$, $y = s[k_1:k_2]$ and $z = s[k_2:]$.

Point (3) is satisfied as $\len(x\concat y) = k_2 \leq \#Q = p$.

Point (2) is satisfied as $k_1\neq k_2$.

For point (1), define the automaton $M' = \sSet{\Sigma, Q, \delta, e_M(x)_{-1}, F}$ and $M^{\prime\prime} = \sSet{\Sigma, Q, \delta, e_M(x\concat y)_{-1}, F}$.
It is enough to prove that
\[ e_M(x\concat y^k \concat z) = e_M(x)\concat \big(e_{M'}(y)[1:]\big)^k \concat \big(e_{M^{\prime\prime}}(z)[1:]\big). \]
We use \ref{automatonRunFactorisation}. We then only need to prove that $\big(e_{M'}(y^k)[1:]\big) = \big(e_{M'}(y)[1:]\big)^k$. This is evident by induction on $k$, using \ref{automatonRunFactorisation}.
\end{proof}

\begin{example}
The following languages are not regular:
\begin{itemize}
\item $\setbuilder{\seq{0}^n\seq{1}^n}{n\geq 0}$;
\item $\setbuilder{u\in \{0, 1\}^*}{\text{$u$ contains an equal number of $1$s and $0$s}}$;
\item $\setbuilder{u\concat u}{u\in \{0,1\}^*}$;
\item $\setbuilder{\seq{1}^{n^2}}{n\in \N}$;
\item $\setbuilder{\seq{0}^i\seq{1}^j}{i>j \in \N}$. We prove this by contradiction. Assume $p$ is the pumping length and consider $\seq{0}^{p+1}\seq{1}^p$, which is a string in the language. Then $y$ must consist of a non-empty string of zeros. Now the string $xy^0z = xz$ must be in the language by the pumping lemma. However in this case $xz = \seq{0}^l\seq{1}^j$ where $l\leq j$, which means that $xz$ is not an element of the language. This is a contradiction.
\end{itemize}
\end{example}

\chapter{Logic}
Proof: transitive closure consequence relation. TODO: ability to look back.

\section{Classical logic}
Implementation of ambient system.

\chapter{Type theory}
\section{Untyped lambda calculus}

\begin{example}
$(\lambda x. x x)(\lambda x. x x) \to_\beta (\lambda x. x x)(\lambda x. x x)$.

Define $\Delta \defeq \lambda x. xxx$. Then
\[ \Delta\Delta \to_\beta \Delta\Delta\Delta \to_\beta \Delta\Delta\Delta\Delta \to_\beta \ldots \]
\end{example}

\begin{proposition}
Every term has a fixed point, i.e.\ for all $L\in\Lambda$ there exists $M\in\Lambda$ such that $LM \equiv_\beta M$.

This fixed point is given by
\[ M \defeq \big(\lambda x. L(xx)\big)\big(\lambda x. L(xx)\big). \]
\end{proposition}
Note that the fixed point of $\lambda y. y$ is given by $(\lambda x. x x)(\lambda x. x x)$.
\begin{proof}
We have
\[ M = \big(\lambda x. L(xx)\big)\big(\lambda x. L(xx)\big) \to_\beta L\Big(\big(\lambda x. L(xx)\big)\big(\lambda x. L(xx)\big)\Big) = L(M). \]
\end{proof}
TODO what should the equals sign in the proof be??
\begin{corollary}
Recursive equations of the form $M \equiv_\beta f(M)$ have an explicit solution.
\end{corollary}

\begin{definition}
The \udef{(Curry) fixed point combinator} is the following term
\[ Y \defeq \lambda y. \big(\lambda x.y(xx)\big)\big(\lambda x.y(xx)\big). \]
The \udef{Turing fixed point combinator} is the following term
\[ Z \defeq \big(\lambda xy. x(yyx)\big)\big(\lambda xy. x(yyx)\big). \]
\end{definition}
The fixed point combinator maps a lambda term to its fixed point.

(There are infinitely many fixed points: $M = (\lambda x.x)M$)

\section{Simply typed lambda calculus}
Problems with untyped lambda calculus include
\begin{itemize}
\item Self-application (i.e. $xx$) is allowed.
\item Existence of normal forms is not guaranteed.
\item Each $\lambda$-term has a fixed point.
\end{itemize}

The term $xx$ is not typable.

\begin{definition}
Let $\mathbb{V}$ be a set of \udef{type variables} and $V$ a set of variables.
\begin{itemize}
\item The set $\mathbb{T}$ of \udef{function types} is defined by $\mathbb{T} \defeq \mathbb{V}|(\mathbb{T}\to \mathbb{T})$.
\item The set $\Lambda_\mathbb{T}$ of \udef{pre-typed $\lambda$-terms} is defined by $\Lambda_\mathbb{T} \defeq V | (\Lambda_\mathbb{T}\Lambda_\mathbb{T}) | (\lambda V: \mathbb{T}. \Lambda_\mathbb{T})$.
\item The set $\mathbb{S}$ of \udef{statements} is defined by $\mathbb{S} \defeq \Lambda_\mathbb{T} : \mathbb{T}$.
\item The set $\mathbb{D}$ of \udef{declarations} is defined by $\mathbb{D} \defeq \mathbb{V} : \mathbb{T}$.
\item The set $\mathbb{C}$ of \udef{contexts} is defined by $\mathbb{C} \defeq L_\mathbb{C}$.
\item The set $\mathbb{J}$ of \udef{judgements} is defined by $\mathbb{J} \defeq \mathbb{C} \vdash \mathbb{S}$.
\end{itemize}
\end{definition}
TODO interpretation of gammar. TODO aliases (like $\mathbb{C}$).

\chapter{Universal algebra}
TODO: forgetful functors.

\section{Syntax}
\subsection{Signature}
\begin{definition}
A \udef{signature} or \udef{operational type} or \udef{operator domain} is a pair $(\Omega, \alpha)$ where $\Omega$ is a set whose elements are called \udef{operator symbols} or \udef{function symbols} and $\alpha: \Omega \to \Ord$ is a function.
\begin{itemize}
    \item We call $\alpha(\omega)$ the \udef{arity} of the operator $\omega\in\Omega$.
    \item If the arity of $\omega\in\Omega$ is $n$, then we say $\omega$ is an \udef{$n$-ary} operator.
    \item If the arity of $\omega\in\Omega$ is the first limit ordinal (i.e.\ $\omega$, confusingly), we say $\omega$ has \udef{countable arity}.
\end{itemize}
\end{definition}
We also say \udef{unary} instead of $1$-ary, \udef{binary} instead of $2$-ary and \udef{ternary} instead of $3$-ary.

\subsection{Terms}
\begin{definition}
Let $(\Omega, \alpha)$ be a signature and $V$ a set of \udef{variables} such that $\Omega\perp V$. The set $T(\Omega, V)$ of \udef{$\Omega$-terms} over $V$ is a subset of $(\Omega\uplus V)^*$ which is recursively defined by
\[ t\in T(\Omega, V) \iff \begin{cases}
\exists v\in V: t = \seq{v} \\
\exists \omega\in \Omega: (t_0 = \omega) \land \Big(t[1:] \in \strConcat^{\imf}\big(T(\Omega, V)^{\alpha(\omega)}\big) \Big).
\end{cases} \]
A term $t$ is called \udef{ground} if $t\in T(\Omega, \emptyset)$. We abbreviate $T(\Omega, \emptyset)$ as $T(\Omega)$.
\end{definition}
Thus $T(\Omega)$ is the set of ground terms.

TODO: prefix notation or Polish notation.

ALTERNATIVE: $\forall \omega\in\Omega: \forall t\in T(\Omega, V)^{\alpha(\omega)}: \seq{\omega}\concat \strInterleave\Big(\seq{\LB}\seq{\SEP}^{\alpha(\omega)-1}\seq{\RB}, t\Big) \in T(\Omega, V)$

\begin{lemma} \label{initialElementUATerm}
Let $(\Omega, \alpha)$ be a signature, $V$ a set of variables and $t\in T(\Omega, V)$. Then either
\begin{itemize}
\item $t = \seq{v}$ for some $v\in V$; or
\item $t_0\in \Omega$.
\end{itemize}
In particular $\seq{}\notin T(\Omega, V)$.
\end{lemma}
\begin{proof}
TODO recursion invariant.
\end{proof}

\begin{lemma} \label{noTermHasTermAsInitialSegment}
Let $(\Omega, \alpha)$ be a signature, $V$ a set of variables and $t\in T(\Omega,V)$. Then there is no proper initial segment of $t$ that is an element of $T(\Omega, V)$.
\end{lemma}
\begin{proof}
TODO
\end{proof}

\begin{lemma}
Let $(\Omega, \alpha)$ be a signature and $V$ a set of variables. Then $\strConcat|_{T(\Omega, V)^*}: T(\Omega, V)^* \to (\Omega \uplus V)^*$ has a left inverse
\[ \splitTerms: \im\big(\strConcat|_{T(\Omega, V)^*}\big) \to T(\Omega, V)^* \]
defined resursively by
\[ \splitTerms(u) = \seq{u[:k]} \concat \splitTerms(u[k:]), \]
where $k = \min\setbuilder{k\in\N}{u[:k]\in T(\Omega,V)}$.
\end{lemma}
In particular $\splitTerms$ is defined on $\strConcat^\imf\big(T(\Omega, V)^1\big) = T(\Omega, V)$.
\begin{proof}
TODO (use \ref{noTermHasTermAsInitialSegment}??)
\end{proof}

Note (TODO): ability to make syntax forest implies ability to make syntax tree.

\subsubsection{Subterms and syntax tree}
TODO define syntax trees in general.

\begin{definition}
Let $(\Omega, \alpha)$ be a signature and $V$ a set of variables. We define the \udef{$\syntaxTree$} function $\syntaxTree: T(\Omega, V) \to \powerset\big((\Omega \uplus V \uplus \N)^*\big)$ recursively by
\[ \syntaxTree(t) = \begin{cases}
\{\seq{}, \seq{t_0}\} & (t_0\in V) \\
\{\seq{}, \seq{t_0}\} \cup \bigcup_{i=0}^{\alpha(t_0)}\setbuilder{\seq{i}\concat p}{p\in \syntaxTree\big(\splitTerms(t[1:])_i\big)} & (t_0\in \Omega)
\end{cases}. \]
Given a syntax tree $\syntaxTree(t)$ of a term $t\in T(\Omega, V)$, we call the non-terminal nodes of $\syntaxTree(t)$ the \udef{positions} in the term $t$, denoted $\positions(t)$.
\end{definition}

\begin{lemma}
Let $(\Omega, \alpha)$ be a signature and $V$ a set of variables. The $\syntaxTree$ function has a left-inverse $\treeToTerm: \im(\syntaxTree) \to T(\Omega, V)$ defined by
\[ \treeToTerm(A) = \seq{t} \concat \strConcat \seq{\treeToTerm\big(\setbuilder{u[1:]\in A}{u_1 = i}\big)}_{i:\seq{i}\in A} \]
\end{lemma}
\begin{proof}
TODO
\end{proof}


\begin{lemma} \label{positionsSyntaxTreeNumeric}
Let $(\Omega, \alpha)$ be a signature, $V$ a set of variables and $t\in T(\Omega, V)$. Then
\begin{enumerate}
\item $\positions(t) = \syntaxTree(t) \cap \N^*$;
\item a node in $\syntaxTree(t)$ is terminal \textup{if and only if} it ends with some element of $\Omega \uplus V$.
\end{enumerate}
\end{lemma}
\begin{proof}
TODO
\end{proof}

\begin{proposition} \label{mappingsTermSyntaxTreePositions}
Let $(\Omega, \alpha)$ be a signature, $V$ a set of variables and $t\in T(\Omega, V)$.
\begin{enumerate}
\item Let $\positions(t)\subseteq \N^*$ be ordered by depth-first ordering. There exists a similarity
\[ \leafAt_t: \big(0:\len(t)\big)\to \positions(t) \]
such that $\leafAt_t(k)\concat\seq{t_k}\in \syntaxTree(t)$.
\item The function
\[ \big(\syntaxTree \setminus \positions(t)\big) \to \positions(t): u \mapsto u[0..\len(u)-1] \]
is a similarity.
\end{enumerate}
\end{proposition}
The similarity $\leafAt_t$ is unique by \ref{WOSetsUniqueSimilarity}.
\begin{proof}
TODO
\end{proof}
\begin{corollary}
Let $(\Omega, \alpha)$ be a signature, $V$ a set of variables and $t\in T(\Omega, V)$. Then
\[ {\#\big(\positions(t)\big)} = \len(t) = {\#\big(\syntaxTree(t)\big)/2}. \]
\end{corollary}


\begin{definition}
Let $(\Omega, \alpha)$ be a signature and $V$ a set of variables. Let $t\in T(\Omega, V)$ be a term and $p\in \positions(t)$ a position in $t$. Then we define the \udef{subterm} $t|_p$ by
\begin{align*}
\syntaxTree(t|_p) &\defeq \setbuilder{q\in (\Omega \uplus V \uplus \N)^*}{p\concat q \in \syntaxTree(t)} \\
&= (p \concat -)^\preimf\big(\syntaxTree(t)\big).
\end{align*}
\end{definition}
Thus
\[ t|_p \defeq \treeToTerm\Big((p \concat -)^\preimf\big(\syntaxTree(t)\big)\Big). \]

\begin{lemma}
Let $(\Omega, \alpha)$ be a signature, $V$ a set of variables, $t\in T(\Omega, V)$ and $p\in \positions(t)$. Then
\[ (p \concat -)^\preimf\big(\syntaxTree(t)\big) \]
is a syntax tree and, in particular, $t|_p$ is well-defined.
\end{lemma}
\begin{proof}
TODO
\end{proof}

\begin{lemma}
Let $(\Omega, \alpha)$ be a signature, $V$ a set of variables, $t\in T(\Omega, V)$, $p \in \positions(t)$ and $u\in (\Omega\uplus V\uplus \N)^*$. Then
\begin{enumerate}
\item $p\concat u \in \syntaxTree(t)$ \textup{if and only if} $u\in \syntaxTree(t|_p)$;
\item $p\concat q \in \positions(t)$ \textup{if and only if}  $q\in \positions(t|_p)$;
\item if $p\concat q \in \positions(t)$, then $t|_{p\concat q} = (t|_p)|_q$.
\end{enumerate}
\end{lemma}
\begin{proof}
(1) Clear from the definition.

(2) From point (1) and the fact that $p\concat q$ is non-terminal if and only if $q$ is non-terminal, by \ref{positionsSyntaxTreeNumeric}.

(3) We calculate
\begin{align*}
\syntaxTree\big((t|_p)|_q\big) &= (q\concat -)^\preimf\big(\syntaxTree(t|_p)\big) \\
&= \big((q\concat -)^\preimf \circ (p\concat -)^\preimf\big) \big(\syntaxTree(t)\big) \\
&= (p\concat q\concat -)^\preimf\big(\syntaxTree(t)\big) \\
&= \syntaxTree(t|_{p\concat q}).
\end{align*}
\end{proof}

\begin{lemma}
Let $(\Omega, \alpha)$ be a signature, $V$ a set of variables and $s\in T(\Omega, V)$.
We can write $s = u\concat t \concat v$ for some $t\in T(\Omega, V)$ and some $u,v\in (\Omega\uplus V)^*$ \textup{if and only if} there exists $p\in\positions(s)$ such that $s|_p = t$.
\end{lemma}
\begin{proof}
$\boxed{\Rightarrow}$ We claim we can take $p = \leafAt_{u\concat t \concat v}\big(\len(u)\big)$. Indeed $p\concat \seq{t_0} \in \syntaxTree(u\concat t \concat v)$ by \ref{mappingsTermSyntaxTreePositions}. So the positions in $(p\concat -)^\imf(p\concat -)^{\preimf}(\syntaxTree(s)) \subseteq \syntaxTree(s)$ are mapped to an initial subsequence of $t\concat v$ (as this is an interval subset that is mapped by an order-presering map.)

Then it is enough to note that, by \ref{noTermHasTermAsInitialSegment}, for any string on $(\Omega\uplus V)^*$ at most one initial segment is an element of $T(\Omega, V)$.

$\boxed{\Leftarrow}$ The terminal nodes that follow $p$ first spell out $t$.
\end{proof}

\subsubsection{Substitution}
\begin{definition}
Let $(\Omega, \alpha)$ be a signature, $V$ a set of variables, $s,t\in T(\Omega, V)$ and $p\in \positions(s)$. Then the \udef{substitution} of $t$ at $p$ in $s$ is defined by
\[ \syntaxTree\big(s[t/p]\big) \defeq \big(\syntaxTree(s) \setminus \upset\{p\}\big) \cup (p\concat -)^{\imf}\big(\syntaxTree(t)\big). \]
\end{definition}

\begin{proposition}
Let $(\Omega, \alpha)$ be a signature, $V$ a set of variables, $s,t,r\in T(\Omega, V)$, $p\in \positions(s)$, $q\in\positions(t)$ and $n\in\positions(s|_p)$. Then
\begin{enumerate}
\item $s[t/p]|_p = t$;
\item $\big(s[t/p]\big)\big[r/(p\concat q)\big] = s[t[r/q]/p]$;
\item $s\big[t/(p\concat n)\big]|_p = (s|_p)[t/n]$;
\item $s\big[t/(p\concat n)\big][r/p] = s[r/p]$.
\end{enumerate}
If $p$ and $q$ are parallel positions in $\positions(s)$ (i.e.\ $p\not\sqsubseteq q$ and $p\not\sqsubseteq q$), then
\begin{enumerate} \setcounter{enumi}{4}
\item $s[t/p]|_q = s|_q$;
\item $\big(s[t/p]\big)[r/q] = \big(s[r/q]\big)[t/p]$.
\end{enumerate}
\end{proposition}
These proofs can also be given by induction on the length of the positions.

We can summarise
\begin{itemize}
\item point (6) as ``parallel substitutions commute''.
\end{itemize}
\begin{proof}
(1) We calculate, using the fact that $(p\concat -)$ is bijective,
\begin{align*}
\syntaxTree(s[t/p]|_p) &= (p\concat -)^\preimf\big(\syntaxTree(s[t/p])\big) \\
&= (p\concat -)^\preimf\Big(\big(\syntaxTree(s) \setminus \upset\{p\}\big) \cup (p\concat -)^{\imf}\big(\syntaxTree(t)\big)\Big) \\
&= (p\concat -)^\preimf\Big(\big(\syntaxTree(s) \setminus \upset\{p\}\big)\Big) \cup (p\concat -)^\preimf(p\concat -)^{\imf}\big(\syntaxTree(t)\big) \\
&= \emptyset \cup \syntaxTree(t) \\
&= \syntaxTree(t).
\end{align*}

(2) We calculate
\begin{align*}
\syntaxTree\big(s[t[r/q]/p]\big) &= \big(\syntaxTree(s) \setminus \upset\{p\}\big) \cup (p\concat -)^{\imf}\big(\syntaxTree(t[r/q])\big) \\
&= \big(\syntaxTree(s) \setminus \upset\{p\}\big) \cup (p\concat -)^{\imf}\Big(\big(\syntaxTree(t) \setminus \upset\{q\}\big) \cup (q\concat -)^{\imf}\big(\syntaxTree(r)\big)\Big) \\
&= \begin{multlined}[t] \big(\syntaxTree(s) \setminus \upset\{p\}\big) \cup \Big((p\concat -)^{\imf}\big(\syntaxTree(t)\big) \setminus \upset\{p\concat q\}\Big) \\ \cup (p \concat q\concat -)^{\imf}\big(\syntaxTree(r)\big) \end{multlined} \\
&= \begin{multlined}[t]\Big(\big(\syntaxTree(s) \setminus \upset\{p\}\big) \cup (p\concat -)^{\imf}\big(\syntaxTree(t)\big) \Big)\setminus \upset\{p\concat q\} \\ \cup (p \concat q\concat -)^{\imf}\big(\syntaxTree(r)\big) \end{multlined} \\
&= \big(\syntaxTree(s[t/p])\big)\setminus \upset\{p\concat q\} \cup (p \concat q\concat -)^{\imf}\big(\syntaxTree(r)\big) \\
&= \syntaxTree\Big(\big(s[t/p]\big)\big[r/(p\concat q)\big]\Big)
\end{align*}

(3) We calculate, using the fact that $(p\concat -)$ is bijective,
\begin{align*}
\syntaxTree\big((s|_p)[t/n]\big) &= \big(\syntaxTree(s|_p) \setminus \upset\{n\}\big) \cup (n\concat -)^{\imf}\big(\syntaxTree(t)\big) \\
&= (p\concat -)^\preimf\Big(\big(\syntaxTree(s) \setminus (p\concat -)^\imf(\upset\{n\})\big) \cup \big((p\concat -)^{\imf}\circ(n\concat -)^{\imf}\big)\big(\syntaxTree(t)\big)\Big) \\
&= (p\concat -)^\preimf\Big(\big(\syntaxTree(s) \setminus \upset\{p\concat n\}\big) \cup (p\concat n\concat -)^{\imf}\big(\syntaxTree(t)\big)\Big) \\
&= \syntaxTree\big(s[t/(p\concat n)]|_p\big).
\end{align*}

(4) We calculate
\begin{align*}
\syntaxTree\big(s\big[t/(p\concat n)\big][r/p]\big) &= \Big(\syntaxTree(s)\setminus\upset\{p\concat n\} \cup (p \concat n \concat -)^\imf\big(\syntaxTree(t)\big)\Big)[r/p] \\
&= \begin{multlined}[t]\Big(\syntaxTree(s)\setminus\upset\{p\concat n\} \cup (p \concat n \concat -)^\imf\big(\syntaxTree(t)\big)\Big)\setminus \upset\{p\} \\ \cup (p\concat -)^\imf\syntaxTree(r) \end{multlined} \\
&= \syntaxTree(s)\setminus\upset\{p\} \cup (p\concat -)^\imf\syntaxTree(r) \\
&= \syntaxTree\big(s[r/p]\big).
\end{align*}

(5) We calculate
\begin{align*}
\syntaxTree\big(s[t/p]|_q\big) &= (q\concat -)^{\preimf}\Big(\syntaxTree\big(s[t/p]\big)\Big) \\
&= (q\concat -)^{\preimf}\Big(\big(\syntaxTree(s)\setminus\upset\{p\}\big) \cup (p\concat -)^\imf\big(\syntaxTree(t)\big)\Big) \\
&= (q\concat -)^{\preimf}\big(\syntaxTree(s)\setminus\upset\{p\}\big) \\
&= (q\concat -)^{\preimf}\syntaxTree(s) \\
&=\syntaxTree(s|_q).
\end{align*}

(6) We calculate
\begin{align*}
\syntaxTree\Big(\big(s[t/p]\big)[r/q]\Big) &= \Big(\syntaxTree\big(s[t/p]\big) \setminus \upset\{q\}\Big) \cup (q\concat -)^\imf\syntaxTree(r) \\
&= \Big(\big((\syntaxTree(s)\setminus \upset\{p\}) \cup (p\concat -)^\imf\syntaxTree(t) \big) \setminus \upset\{q\}\Big) \cup (q\concat -)^\imf\syntaxTree(r) \\
&= \Big(\syntaxTree(s)\setminus \big(\upset\{p\} \cup \upset\{q\} \big)\Big) \cup (p\concat -)^\imf\syntaxTree(t) \cup (q\concat -)^\imf\syntaxTree(r) \\
&= \Big(\big((\syntaxTree(s)\setminus \upset\{q\}) \cup (q\concat -)^\imf\syntaxTree(r) \big) \setminus \upset\{p\}\Big) \cup (p\concat -)^\imf\syntaxTree(t) \\
&= \Big(\syntaxTree\big(s[r/q]\big) \setminus \upset\{p\}\Big) \cup (p\concat -)^\imf\syntaxTree(t) \\
&= \syntaxTree\Big(\big(s[r/q]\big)[t/p]\Big).
\end{align*}
\end{proof}

\subsubsection{Variable substitution}
\begin{definition}
Let $(\Omega, \alpha)$ be a signature and $V$ a set of variables. An \udef{elementary variable substitution} is a partial function $\hat{\sigma}\in(V\not\to T(\Omega, V))$ with finite domain of definition.

We say $\hat{\sigma}$ \udef{instantiates} $x\in V$ if $x\in \preim(\hat{\sigma})$.

Given an elementary variable substitution $\hat{\sigma}$, we also define the \udef{(extended) variable substitution} $\sigma: (\Omega \uplus V)^*\to (\Omega \uplus V)^*$, defined recursively by
\[ \sigma(u) = \begin{cases}
\seq{} & (u = \seq{}) \\
\hat{\sigma}(u_0)\concat \sigma\big(u[1:]\big) & \big(u_0\in \preim(\hat{\sigma})\big) \\
u_0\concat \sigma\big(u[1:]\big) & \big(u_0\notin \preim(\hat{\sigma})\big)
\end{cases} \]
The set of all variable substitutions is denoted $\varSubs(\Omega, V)$.
\end{definition}
TODO rewrite definition with \emph{map}.

\begin{lemma}
Let $(\Omega, \alpha)$ be a signature, $V$ a set of variables, $\hat{\sigma}: V\not\to T(\Omega, V)$ an elementary variable substitution and $t\in T(\Omega, V)$. Then $\sigma(t) \in T(\Omega, V)$. 
\end{lemma}
\begin{proof}
TODO
\end{proof}

\subsection{Syntactic consequence}
\subsubsection[Omega-identities]{$\Omega$-identities}
\begin{definition}
Let $(\Omega, \alpha)$ be a signature and $V$ a set of variables. An \udef{$\Omega$-identity} is an element of $T(\Omega, V)\times T(\Omega, V)$.

We call a set $E\subseteq T(\Omega, V)\times T(\Omega, V)$ \udef{closed under variable substitution} if for all variable substitutions $\sigma$, we have $(\sigma, \sigma)^\imf(E) \subseteq E$.

We call a set $E\subseteq T(\Omega, V)\times T(\Omega, V)$ \udef{closed under $\Omega$-operations} if for all operator symbols $\omega\in\Omega$ and $t,s\in \big(T(\Omega, V)\big)^{\alpha(\omega)}$ such that $(s_i, t_i)\in E$ for all $i\in \big(0:\alpha(\omega)\big)$, we have
\[ \big( \seq{\omega}\concat \strConcat(s), \seq{\omega}\concat \strConcat(t)\big) \in E. \]
\end{definition}

The closure of $E$ under variable substitutions is given by $\bigcup_{\sigma\in\varSubs(\Omega, V)}(\sigma, \sigma)^\imf(E)$.

\subsubsection{Reduction relations}
\begin{definition}
Let $(\Omega, \alpha)$ be a signature, $V$ a set of variables and $E$ a set of $\Omega$-identities. We define the \udef{reduction relation} $\to_E$ on $T(\Omega, V)$ by $s\to_E t \defequiv$
\[ \exists u,v\in (\Omega\uplus V)^*: \exists (r_1, r_2)\in E: \exists \sigma\in \varSubs(\Omega, V):\; \begin{cases}
s = u \concat \sigma(r_1) \concat v \in T() \\
t = u \concat \sigma(r_2) \concat v.
\end{cases}  \]
\end{definition}

\begin{lemma}
The symmetric, transitive, reflexive closure of $\to_E$ is the smallest equivalence relation that contains $E$ and is closed under variable substitution and $\Omega$-operations.
\end{lemma}
\begin{proof}

\end{proof}

\begin{definition}
We denote the relation $\equiv_E$.
\end{definition}

\subsubsection{Syntactic consequence}
\begin{definition}
Let $(\Omega, \alpha)$ be a signature, $V$ a set of variables and $E$ a set of $\Omega$-identities. Then an element of $\equiv_E\setminus E$ is a \udef{syntactic consequence} of $E$.
\end{definition}

\section{Semantics}
\subsection{Algebras}
\begin{definition}
A \udef{structure} of type $(\Omega,\alpha)$, an \udef{$\Omega$-structure} or an \udef{$\Omega$-algebra}, is a set $A$, called the \udef{carrier} or \udef{universe}, equipped with a function
\[ \omega_A: A^{\alpha(\omega)}\to A \]
for each $\omega\in\Omega$. We call $\omega_A$ the \udef{interpretation} of $\omega$ in $A$.

If we allow the interpretations $\omega_A$ to be partial functions, we call $A$ a \udef{partial $\Omega$-structure}.
\end{definition}
If $\alpha(\omega) = 0$, then
\[ \omega_A\in (A^0\to A) = \big(\{\emptyset\}\to A\big) \cong A. \]
In other words, $\omega_A$ is a constant.



$A^{\alpha(\omega)}$ is a set of strings!!
TODO notation: we write $\omega_A(x)$ for $\omega_A(\seq{x})$ and
$c_A$ for $c_A(\seq{})$. Should we drop parentheses and have just juxtaposition for function application?? I.e. $\omega_A\seq{x}$ or $\omega'_A\seq{x,y}$?

\subsubsection{Subalgebras}
\begin{definition}
Let $A$ be an $\Omega$-algebra. A \udef{subalgebra} of $A$ is a subset $B\subseteq A$ such that
\[ \omega_A^{\imf}\big(B^{\alpha(\omega)}\big) \subseteq B \]
for all $\omega \in \Omega$.

We denote the set of all subalgebras of $A$ by $\subalgebras(A)$.
\end{definition}
Note that whether a set is a subalgebra depends on the interpretation in the algebra, not just the signature.

\begin{proposition}
Let $A$ be an $\Omega$-algebra and $B\subseteq A$ a subset. Consider, for all $\omega\in \Omega$, the relation $\omega_A|_{B^{\alpha(\omega)}}^B$.

The set of these relations makes $B$ an $\Omega$-algebra \textup{if and only if} $B$ is a subalgebra of $A$.
\end{proposition}
\begin{proof}
We have that $\omega_A|_{B^{\alpha(\omega)}}^B$ is a function in $\big(B^{\alpha(\omega)} \to B\big)$ if and only if $\omega_A^{\imf}\big(B^{\alpha(\omega)}\big) \subseteq B$.
\end{proof}

\begin{lemma}
Let $A$ be an $\Omega$-algebra. Then $\subalgebras(A)$ is a complete $\wedge$-subsemilattice of $\powerset(A)$.
\end{lemma}
\begin{proof}
Let $\mathcal{B} \subset \subalgebras(A)$ be a subset of subalgebras. We need to show that $\bigcap \mathcal{B}$ is a subalgebra.

Take arbitrary $\omega\in \Omega$ and $\vec{b}\in \Big(\bigcap \mathcal{B}\Big)^{\alpha(\omega)}$. Take arbitrary $B\in \mathcal{B}$. Then $\Big(\bigcap \mathcal{B}\Big)^{\alpha(\omega)} = \bigcap_{C\in\mathcal{B}}C^{\alpha(\omega)}$ by \ref{productUnionIntersection}, so $\vec{b}\in B$, and $\omega_A(\vec{b}) \in B$. Since $B\in \mathcal{B}$ was chosen arbitrarily, we have $\omega_A(\vec{b}) \in \bigcap\mathcal{B}$. Since $\vec{b}\in \Big(\bigcap \mathcal{B}\Big)^{\alpha(\omega)}$ was chosen arbitrarily, we have $\omega_A^\imf\bigg(\Big(\bigcap \mathcal{B}\Big)^{\alpha(\omega)}\bigg) \subseteq \bigcap\mathcal{B}$. Since $\omega\in\Omega$ was chosen arbitrarily, we have that $\bigcap\mathcal{B}$ is a subalgebra of $A$.
\end{proof}

\begin{definition}
Let $A$ be an $\Omega$-algebra. We denote by $\alg_A: \powerset(A)\to \subalgebras(A)$ the Moore closure associated to $\subalgebras(A)$.

For $X\subseteq A$, we say that $X$ \udef{generates} $A$ if $\alg_A(X) = A$. We say that $A$ is \udef{finitely generated} if there exists a finite set that generates $A$.
\end{definition}

\begin{proposition}
Let $A$ be an $\Omega$-algebra. Then
\begin{enumerate}
\item $\alg_A: \powerset(A)\to \subalgebras(A)$ is an algebraic closure operator;
\item $\subalgebras(A)$ is an algebraic lattice.
\end{enumerate}
\end{proposition}
\begin{proof}
(1) Take some subset $X\subseteq A$. Consider the function
\[ E:\powerset(A)\to \powerset(A): X\mapsto X\cup \bigcup_{\omega\in \Omega}\omega_A^\imf\big(X^{\alpha(\omega)}\big) \]
and the set $Y \defeq \bigcup_{n\in\N}E^n(X)$. We claim that $Y$ is a subalgebra of $A$. Indeed, take $\omega\in \Omega$ and $\vec{y} \in Y^{\alpha(\omega)}$. Then, for all $k\in \big(0:\alpha(\omega)\big)$, we have $\vec{y}(k)\in E^{n_k}(X)$ for some $n_k\in \N$. Take $n = \max\setbuilder{n_k}{k\in 0:\alpha(\omega)}$. We have $\vec{y}\in \big(E^n(X)\big)^{\alpha(\omega)}$ and $\omega_A(\vec{y}) \in E^{n+1}(X) \subseteq Y$. Since $\omega\in \Omega$ and $\vec{y} \in Y^{\alpha(\omega)}$ were taken arbitrarily, we have that $Y\in\subalgebras(A)$ and so $\alg_A(X)\subseteq Y$.

By induction it is straightforward to prove that $E^n(X) \subseteq \bigcup \setbuilder{\alg_A(Z)}{Z\subseteq X\; \text{finite}}$ for all $n\in \N$. Thus we have
\[ \alg_A(X) \subseteq Y \subseteq \bigcup \setbuilder{\alg_A(Z)}{Z\subseteq X\; \text{finite}}, \]
which means that $\alg_A$ is an algebraic closure operator.

(2) Immediate from \ref{imageAlgebraicClosureAlgebraicLattice}.
\end{proof}

\begin{theorem}[Birkhoff and Frink]
Let $L$ be an algebraic lattice. Then there exists a signature $\Omega$ and $\Omega$-algebra $A$ such that $L\cong \subalgebras(A)$.
\end{theorem}
\begin{proof}
TODO
\end{proof}



\subsection{Homomorphisms}
\begin{definition}
Let $A,B$ be $\Omega$-algebras. A \udef{homomorphism} of $\Omega$-algebras is a function $f:A\to B$ such that
\[ \forall \omega\in\Omega: \qquad f\circ \omega_A = \omega_B\circ f^{\alpha(\omega)}. \]
If $f$ is bijective and both $f$ and $f^{-1}$ are homomorphisms, then $f$ is an \udef{isomorphism}.
\end{definition}
Note that $f^{2}$ means $(f|f)$, not $(f,f)$.

\begin{lemma} \label{inverseHomomorphism}
Let $A,B$ be $\Omega$-algebras and $f:A\to B$ a bijective homomorphism. Then $f$ is an isomorphism.
\end{lemma}
\begin{proof}
The inverse function $f^{-1}: B\to A$ exists by 
ref{bijectionInverse}. We calculate
\begin{align*}
f^{-1}\circ \omega_B &= f^{-1}\circ \omega_B \circ (f\circ f^{-1})^{\alpha(\omega)} \\
&= f^{-1}\circ \omega_B \circ f^{\alpha(\omega)} \circ (f^{-1})^{\alpha(\omega)} \\
&= f^{-1}\circ f \circ \omega_A \circ (f^{-1})^{\alpha(\omega)} \\
&= \omega_A \circ (f^{-1})^{\alpha(\omega)},
\end{align*}
so $f^{-1}$ is a homomorphism.
\end{proof}

\begin{proposition}
Let $f,g:A\to B$ be two homomorphisms between $\Omega$-algebras $A,B$. If $f,g$ agree on a generating set of $A$, then they are equal.
\end{proposition}
\begin{proof}
The set $\setbuilder{x\in A}{f(x) = g(x)}$ is a subalgebra of $A$. By hypothesis it contains a generating set of $A$ and thus it is all of $A$.
\end{proof}

\begin{proposition} \label{imageSubalgebra}
Let $f:A\to B$ be a homomorphism of $\Omega$-algebras and $X\subseteq A$ a subalgebra. Then $f^{\imf}(X)$ is a subalgebra of $B$.
\end{proposition}
In particular $\im f$ is a subalgebra of $B$.
\begin{proof}
Take some arbitrary $\omega\in\Omega$. Let $b\in f^{\imf}(X)^{\alpha(\omega)}$. Then there exists an $x\in X^{\alpha(\omega)}$ such that $b = f^{\alpha(\omega)}(x)$. So we have $\omega_B(b) = \omega_B(f^{\alpha(\omega)}(x)) = f(\omega_A(x)) \in f^\imf(X)$, since $\omega_A(x)\ in X$.
\end{proof}

\begin{proposition}
Let $(\Omega,\alpha)$ be a signature. Then the $\Omega$-algebras form a category with homomorphisms as arrows.
\end{proposition}
Consequently we have the concepts of isomorphism, endomorphism and automorphism.

\begin{proposition} \label{bijectiveHomomorphism}
Let $f:A\to B$ be a bijective homomorphism. Then $f^{-1}$ is also a homomorphism and thus $f$ is an isomorphism.
\end{proposition}
\begin{proof}
Take arbitrary $\omega\in\Omega$. Then we compute, using \ref{covarianceContravarianceComposition},
\[ \omega_A (f^{-1})^{\alpha(\omega)} = f^{-1} f\omega_A (f^{-1})^{\alpha(\omega)} = f^{-1}\omega_B f^{\alpha(\omega)} (f^{-1})^{\alpha(\omega)} = f^{-1}\omega_B (f f^{-1})^{\alpha(\omega)} = f^{-1}\omega_B. \]
\end{proof}

\subsubsection{Embeddings}
\begin{definition}
Let $A,B$ be $\Omega$-algebras. A homomorphism $f:A\to B$ is called an \udef{embedding} if $f|^{\im(f)}$ is an isomorphism.
\end{definition}

\subsection{Interpretations as algebras}
TODO: does this make sense??
\begin{definition}
Let $\sSet{\Omega, \alpha}$ be a signature with interpretation $\{\omega_A\}_{\omega\in \Omega}$ on a carier $A$.

For all $n\in \N$, the set of $n$-ary operators
\[ \Op_n \setbuilder{\omega_A}{\omega\in \alpha^{\preimf}\{n\}} \]
carries the \udef{pointwise} (TODO name?) structure of type $\sSet{\Omega, \alpha}$ defined by
\[ \omega_{\Op_n} \defeq \Op_n^{\alpha(\omega)}\to \Op_n: (f_0,\ldots, f_{\alpha(\omega)}) \mapsto \omega_A\circ (f_0,\ldots, f_{\alpha(\omega)}). \]
\end{definition}
Thus
\[ \omega_{\Op_n}(f_0,\ldots, f_{\alpha(\omega)}) = \omega_A\circ (f_0,\ldots, f_{\alpha(\omega)}). \]

\section{Relations on algebras}
\subsection{Direct product}
\begin{definition}
Let $\{A_i\}_{i\in I}$ be a family of $\Omega$-algebras. The \udef{direct product} $\prod_{i\in I} A_i$ is the $\Omega$-algebra whose carrier is the Cartesian product of $\{A_i\}_{i\in I}$ and where operations are carried out componentwise and relations are verified pointwise.

Similarly a \udef{direct power} of $A$ is a Cartesian power of $A$ with operations and relations defined componentwise.
\end{definition}

The direct product of $\{A,B\}$ is simply written $A\times B$.

\subsection{Relations as algebras}
\begin{definition}
Let $A,B$ be $\Omega$-algebras and $R$ a relation on $(A,B)$ is called \udef{$\Omega$-compatible} (or just \udef{compatible}) if $R$ is a subalgebra of $A\times B$.
\end{definition}
The requirement that $R$ be a subalgebra just means it is closed under the operations of $\Omega$. So $R$ is $\Omega$-compatible if
\[ \forall \omega\in\Omega: \qquad \omega_{A\times B}^\imf(R^{\alpha(\omega)}) \subseteq R. \]

\begin{lemma}
Let $A,B,C$ be $\Omega$-algebras and $\Gamma, \Delta$ $\Omega$-compatible relations on $(A, B)$ and $(B, C)$, respectively. Then
\begin{enumerate}
\item $\Gamma^{\transp} \subset B\times A$ is an $\Omega$-algebra;
\item $\Gamma;\Delta \subset A\times C$ is an $\Omega$-algebra;
\item for any subalgebra $A'$ of $A$, $A'\Gamma \subset B$ is an $\Omega$-algebra;
\item for any subalgebra $B'$ of $B$, $\Gamma B' \subset A$ is an $\Omega$-algebra.
\end{enumerate}
\end{lemma}

\subsection{Congruences}
\begin{definition}
Let $A$ be an $\Omega$-algebra. A \udef{congruence} $\mathfrak{q}$ on $A$ is an $\Omega$-compatible equivalence relation.
\end{definition}

\begin{example}
Any algebra has the \udef{trivial congruences} $I_A$ and $A^2$.
\end{example}

An algebra is \udef{simple} if there are no congruences on it other than the trivial ones. We assume a simple algebra is non-trivial.

\begin{lemma} \label{basicCongruenceLemma}
Let $\mathfrak{q}$ be a congruence on an $\Omega$-algebra $A$ and $B$ an $\Omega$-subalgebra of $A$. Then
\begin{enumerate}
\item $\mathfrak{q}^n$ is a congruence on $A^n$ for all $n\in \N$,
\item $\mathfrak{q}|_B^B$ is a congruence on $B$.
\end{enumerate}
\end{lemma}
\begin{proof}
(1) The extension of $\mathfrak{q}$ is an equivalence relation by \ref{relationPropertiesDirectProduct}.

TODO subalgebra of $(A^n)^2$ with canonical isomorphism.

(2) The restriction is clearly still reflexive, symmetric and transitive. It is an $\Omega$-algebra by TODO.
\end{proof}
For simplicity we may write $B/\mathfrak{q}$ instead of $B/(\mathfrak{q}|_B^B)$.

\begin{proposition} \label{kernelCongruence}
Let $f:A\to B$ be a homomorphism. Then $\ker f$ is a congruence on $A$.
\end{proposition}

\subsubsection{Lattice of congruences}

Congruences closed under intersection, so complete sublattice.

TODO universal property.

\subsubsection{Quotient algebras}
TODO: index free notation

\begin{proposition} \label{quotientAlgebra}
Let $A$ be an $\Omega$-algebra and $\mathfrak{q}$ an equivalence relation. Then there exists an interpretation of $A/\mathfrak{q}$ such that the function
\[ A \to A/\mathfrak{q}: a\mapsto [a]_\mathfrak{q} \]
is a homomorphism if and only if $\mathfrak{q}$ is a congruence.

Explicitly, this interpretation is unique and given by
\[ \omega_{A/\mathfrak{q}}([a_1]_{\mathfrak{q}},\ldots,[a_{\alpha(\omega)}]_{\mathfrak{q}}) = [\omega_A(a_1,\ldots, a_{\alpha(\omega)})]_{\mathfrak{q}} \qquad \forall \omega\in\Omega. \]\end{proposition}
\begin{proof}
The requirement that $[\cdot]_\mathfrak{q}$ be a homomorphism forces the interpretation $\omega_{A/\mathfrak{q}}$ of $\omega$ to be the one given.

We just need to show that $\omega_{A/\mathfrak{q}}$ is well-defined if and only if $\mathfrak{q}$ is a congruence. To that end, choose arbitrary $a_1, \ldots, a_{\alpha(\omega)}$ and $a'_1, \ldots, a'_{\alpha(\omega)}$ such that $a_1'\in[a_1]_\mathfrak{q}, \ldots, a'_{\alpha(\omega)}\in [a_{\alpha(\omega)}]_\mathfrak{q}$. This is equivalent to choosing $(a_1,a'_1),\ldots, (a_{\alpha(\omega)},a'_{\alpha(\omega)}) \in \mathfrak{q}$. Then
\begin{align*}
[\omega_A(a_1,\ldots, a_{\alpha(\omega)})]_{\mathfrak{q}} = [\omega_A(a'_1,\ldots, a'_{\alpha(\omega)})]_{\mathfrak{q}} &\iff (\omega_A(a_1,\ldots, a_{\alpha(\omega)}),\omega_A(a'_1,\ldots, a'_{\alpha(\omega)})) \in \mathfrak{q} \\
&\iff \omega_{A^2}((a_1,a'_1),\ldots, (a_{\alpha(\omega)},a'_{\alpha(\omega)})) \in \mathfrak{q}
\end{align*}
where the first statement is the requirement of being well-defined and the last is the requirement for being a subalgebra of $A^2$.
\end{proof}
\begin{definition}
The $\Omega$-algebra $A/\mathfrak{q}$ is called the \udef{quotient algebra} of $A$ by $\mathfrak{q}$. The function $A \to A/\mathfrak{q}: a\mapsto [a]_\mathfrak{q}$ is known as the quotient map.
\end{definition}

\begin{proposition}[Factor theorem] \label{factorTheorem}
Let $f:A\to B$ be a homomorphism of $\Omega$-algebras and $\mathfrak{q}$ a congruence on $A$ such that $\mathfrak{q}\subseteq \ker f$. Then there exists a unique homomorphism $f': A/\mathfrak{q} \to B$ such that
\[ \begin{tikzcd}
A \arrow[r, "{[\cdot]_{\mathfrak{q}}}"] \arrow[dr, swap, "f"] & A/\mathfrak{q} \arrow[d, dashed, "{f'}"] \\
& B
\end{tikzcd} \qquad\text{commutes.} \]
Further, $f'$ is injective \textup{if and only if} $\mathfrak{q} = \ker f$.
\end{proposition}
Note that $\ker f$ is a congruence by \ref{kernelCongruence}. We can also express $\mathfrak{q}\subseteq \ker f$ by saying that $f$ is constant on the $\mathfrak{q}$-equivalence classes. TODO: universal property.
\begin{proof}
We are forced to define $f'$ by $f'([a]_\mathfrak{q}) = f(a)$. To show the function is well-defined, take $a,a'\in A$ such that $[a]_\mathfrak{q} = [a']_\mathfrak{q}$, i.e.\ $(a,a')\in \mathfrak{q}$. This implies $(a,a')\in\ker f$, so $f(a) = f(a')$ and $f'$ is well-defined.

We see that $f'$ is a homomorphism by the calculation
\begin{align*}
f'(\omega_{A/\mathfrak{q}}([a_1], \ldots, [a_{\alpha(\omega)}])) &= f'([\omega_{A}(a_1, \ldots, a_{\alpha(\omega)})]) = f(\omega_{A}(a_1, \ldots, a_{\alpha(\omega)})) \\
&= \omega_B(f(a_1), \ldots f(a_{\alpha(\omega)})) = \omega_B(f'([a_1]), \ldots, f'([a_{\alpha(\omega)}])).
\end{align*}
Finally $f'$ is injective iff no two distinct $\mathfrak{q}$-classes are identified by $f'$, which is exactly the condition $\mathfrak{q} = \ker f$.
\end{proof}

\begin{lemma}
Let $A$ be an $\Omega$-algebra and $\mathfrak{q}$ a congruence on $A$. Then
\[ [(x,y)]_{\mathfrak{q}^2} = [x]_\mathfrak{q}\times [y]_\mathfrak{q}. \]
In particular $A^2/\mathfrak{q}^2 = \setbuilder{[x]_\mathfrak{q}\times [y]_\mathfrak{q}}{x,y\in A}$.
\end{lemma}
\begin{proof}
We calculate
\[ (a,b) \in [(x,y)]_{\mathfrak{q}^2} \iff a\mathfrak{q}x \land b\mathfrak{q}y \iff a\in [x]_\mathfrak{q} \land b\in [y]_\mathfrak{q} \iff (a,b)\in [x]_\mathfrak{q}\times [y]_\mathfrak{q}. \]
\end{proof}

\subsubsection{Isomorphism theorems}
\begin{theorem}[First isomorphism theorem] \label{firstIsomorphism}
Let $f:A\to B$ be a homomorphism of $\Omega$-algebras. Then we have the isomorphism
\[ A/\ker f \cong \im f. \]
\end{theorem}
\begin{proof}
From the factor theorem \ref{factorTheorem} we get an injective homomorphism $f': A/\ker f \to B$ which is made surjective by restricting the codomain to $\im f$. By \ref{bijectiveHomomorphism} this is an isomorphism.
\end{proof}

\begin{theorem}[Second isomorphism theorem]
Let $A$ be an $\Omega$-algebra, $B$ an $\Omega$-subalgebra of $A$ and $\mathfrak{q}$ a congruence on $A$. Then we have the isomorphism
\[ (\mathfrak{q}B)/\mathfrak{q} \cong B/(\mathfrak{q}\cap B^2). \]
\end{theorem}
Note that $\mathfrak{q}B = B\mathfrak{q}$ because $\mathfrak{q}$ is a congruence. Also $\mathfrak{q}\cap B^2 = \mathfrak{q}|_B^B$, so the quotient is well-defined by \ref{basicCongruenceLemma}. Further, $\mathfrak{q}$ should really be restricted in $(\mathfrak{q}B)/\mathfrak{q}$, as in \ref{basicCongruenceLemma}.
\begin{proof}
Take the homomorphism $[\cdot]_\mathfrak{q}:A \to A/\mathfrak{q}$ as defined in \ref{quotientAlgebra} and restrict it to $B$. Applying the first isomorphism theorem \ref{firstIsomorphism} yields the required result.
\end{proof}

\begin{theorem}[Third isomorphism theorem]
Let $A$ be an $\Omega$-algebra and $\mathfrak{q},\mathfrak{r}$ congruences on $A$ such that $\mathfrak{q} \subseteq \mathfrak{r}$. Then $\mathfrak{r}/\mathfrak{q}$ is a congruence on $A/\mathfrak{q}$ and we have the isomorphism
\[ (A/\mathfrak{q})/(\mathfrak{r}/\mathfrak{q}) \cong A/\mathfrak{r}. \]
\end{theorem}
This is a slight abuse of notation: clearly $\mathfrak{q}$ is a congruence on $A$, but $\mathfrak{r}\subseteq A^2$. What we mean is that we take the quotient ``pointwise'':
\[ \mathfrak{r}/\mathfrak{q} = \setbuilder{([x]_\mathfrak{q}, [y]_\mathfrak{q})}{(x,y)\in \mathfrak{r}}. \]
\begin{proof}
Applying the factor theorem \ref{factorTheorem} to the homomorphism $A\to A/\mathfrak{r}$ from \ref{quotientAlgebra}. We get a surjective homomorphism
\[ f: A/\mathfrak{q} \to A/\mathfrak{r}: [a]_\mathfrak{q} \mapsto [a]_{\mathfrak{r}}. \]
We apply the first isomorphism theorem \ref{firstIsomorphism} to this homomorphism to get $(A/\mathfrak{q})/\ker f \cong A/\mathfrak{r}$. We just need to show that $\ker f = \mathfrak{r}/\mathfrak{q}$.

Indeed
\[ ([x]_\mathfrak{q},[y]_\mathfrak{q}) \in \ker f \iff [x]_\mathfrak{r} = [y]_\mathfrak{r} \iff (x, y)\in \mathfrak{r} \iff ([x]_\mathfrak{q},[y]_\mathfrak{q}) \in \mathfrak{r}/\mathfrak{q}. \]
\end{proof}
In particular, we see that $A/\mathfrak{q}$ is simple if and only if $\mathfrak{q}$ is a maximal proper congruence on $A$.

\section{Constructions}
\subsection{Pointwise algebras of functions}
\begin{definition}
Let $X$ be a set and $A$ an $\Omega$-algebra. Then the \udef{pointwise algebra} $(X\to A)$ is the set $(X\to A)$ and each $\omega\in\Omega$ is given the interpretation
\[ \omega_{X\to A} \defeq \omega_A\circ -.  \]
\end{definition}

\chapter{Magmas}
\begin{definition}
A \udef{magma} or \udef{groupoid} is an algebra whose signature contains a single ginary operator.

Let $A$ be the carrier of the algebra and $\boldsymbol{\cdot}$ the interpretation of the operator. We denote the magma as $\sSet{A,\boldsymbol{\cdot}}$. We call $\sSet{A,\boldsymbol{\cdot}}$
\begin{itemize}
\item a \udef{semigroup} if $\boldsymbol{\cdot}$ is associative;
\item a \udef{monoid} if $\boldsymbol{\cdot}$ is associative and has an identity;
\item a \udef{group} if $\boldsymbol{\cdot}$ is associative, has an identity and every $a\in A$ has an inverse.
\end{itemize}
We call a magma \udef{commutative} if its operation is commutative.

If $\sSet{A,\boldsymbol{\cdot}}$ is a monoid or group with identity $e$, we denote the monoid/group as $\sSet{A,\boldsymbol{\cdot}, e}$.
\end{definition}
TODO: change of signature for monoid!

Let $x,y\in A$. We usually write $x\boldsymbol{\cdot} y$ instead of $\boldsymbol{\cdot}(x,y)$. (TODO ref infix notation)

\begin{definition}
We write $x^n$ to abbreviate $\underbrace{x\cdot x\cdot \ldots \cdot x}_{\text{$n$ times}}$.

If $x^2 = x$, we say $x$ is an \udef{idempotent}.
\end{definition}

\begin{lemma}
Let $\sSet{M,\cdot}$ be a magma and $a\in M$. Then $a\cdot M \subseteq M$.
\end{lemma}

\begin{definition}
Let $\sSet{A,\boldsymbol{\cdot}}$ be a magma of finite cardinality. A table containing all possible outputs of the function $\boldsymbol{\cdot}$, i.e.\ of the form
\[ \begin{array}{l|llll}
\boldsymbol{\cdot} & a_1 & a_2 & \hdots & a_n \\ \hline
a_1 & a_1\boldsymbol{\cdot}a_1 & a_1\boldsymbol{\cdot}a_2 & \hdots & a_1\boldsymbol{\cdot}a_n \\
a_2 & a_2\boldsymbol{\cdot}a_1 & a_2\boldsymbol{\cdot}a_2 & \hdots & a_2\boldsymbol{\cdot}a_n \\
\vdots & \vdots & \vdots &  & \vdots \\
a_n & a_n\boldsymbol{\cdot}a_1 & a_n\boldsymbol{\cdot}a_2 & \hdots & a_n\boldsymbol{\cdot}a_n
\end{array} \]
is called a \udef{Cayley table}.
\end{definition}
A magma is completely determined by its Cayley table.

\begin{proposition} \label{leftRightInverseMonoid}
Let $(M,\cdot,e)$ be a monoid and $a\in M$. If $a$ has both a left inverse $l$ and a right inverse $r$, then $l=r$.
\end{proposition}
\begin{proof}
We calculate
\[ l = l\cdot e = l\cdot(a\cdot r) = (l\cdot a)\cdot r= e\cdot r = r. \]
\end{proof}

\section{Semigroups}
\begin{lemma}
Let $S$ be a semigroup. If $a\in S$ is idempotent, then $\{a\}$ is a subsemigroup.
\end{lemma}
\begin{corollary}
Let $S$ be a semigroup.
\begin{enumerate}
\item If $S$ contains an identity $e$, then $\{e\}$ is a subsemigroup.
\item If $S$ contains an absorbing element $u$, then $\{u\}$ is a subsemigroup.
\end{enumerate}
\end{corollary}

\begin{proposition} \label{groupCriterion}
Let $S$ be a semigroup. Then $S$ is a group \textup{if and only if} for all $a\in S$
\[ aS = S = Sa. \]
\end{proposition}
\begin{proof}
If $S$ is a group, then we have for all $a\in S$
\[ S \supseteq aS \supseteq aa^{-1}S = S. \]
Similarly we also have $S = Sa$.

For the converse: from $aS = S$, we het that there exists an $x\in S$ such that $ax = a$. We claim $x$ is a right-identity for $S$. Indeed, take arbitrary $b\in S$. Then $b = ya$ for some $y$ and so $bx = yax = ya b$. In the same way we can also find a left-identity. So $S$ contains an identity $e$ by \ref{leftRightIdentity}.

Then for all $a$ we can find $u,v\in S$ such that $au = e = va$. This means $a$ has an inverse by \ref{leftRightInverseMonoid}.
\end{proof}


\subsection{Adjoining identities and absorbing elements}
\subsubsection{Adjoining identity}
\begin{definition}
Let $\sSet{S,\boldsymbol{\cdot}}$ be a semigroup. We define
\[ \widetilde{S} \defeq \begin{cases}
S & \text{if $S$ has an identity} \\
S\uplus \{e\} & \text{if $S$ has no identity.}
\end{cases} \]
and also
\[ \widetilde{\boldsymbol{\cdot}} \quad\defeq\quad \widetilde{S}\times \widetilde{S}\to \widetilde{S}: (a,b) \mapsto \begin{cases}
a\boldsymbol{\cdot} b & a,b\in S \\
b & a = e \\
a & b = e.
\end{cases} \]
\end{definition}


\subsubsection{Adjoining an absorbing element}
\begin{definition}
Let $\sSet{S,\cdot}$ be a semigroup. We define
\[ \widehat{S} \defeq \begin{cases}
S & \text{if $S$ has an absorbing element} \\
S\uplus \{u\} & \text{if $S$ has no absorbing element.}
\end{cases} \]
and also
\[ \widehat{\boldsymbol{\cdot}} \quad\defeq\quad \widehat{S}\times \widehat{S}\to \widehat{S}: (a,b) \mapsto \begin{cases}
a\boldsymbol{\cdot} b & a,b\in S \\
u & (a = u \lor b = u.
\end{cases} \]
\end{definition}

TODO: link with partial semigroup.

\subsection{Subsets and subsemigroups}
\subsubsection{Ideals}
\begin{definition}
Let $S$ be a semigroup and $A\subseteq S$ a non-empty subset. Then $A$ is called
\begin{itemize}
\item a \udef{left ideal} if $SA \subseteq A$;
\item a \udef{right ideal} if $AS \subseteq A$;
\item a \udef{(two-sided) ideal} if $A$ is both a left and a right ideal.
\end{itemize}
Clearly $S$ is an ideal. If $u\in S$ is an absorbing element, then $\{u\}$ is an ideal. If an ideal is neither of these two, it is called \udef{proper}.
\end{definition}

\begin{lemma}
Let $\sSet{S,\cdot}$ be a semigroup and $a\in S$. Then
\begin{enumerate}
\item $\widetilde{S}a = Sa \cup \{a\}$ is a left ideal;
\item $a\widetilde{S} = aS \cup \{a\}$ is a right ideal;
\item $\widetilde{S}a\widetilde{S} = SaS \cup Sa \cup aS \cup \{a\}$ is an ideal.
\end{enumerate}
In particular $\widetilde{S}a \subseteq S$, $a\widetilde{S} \subseteq S$ and $\widetilde{S}a\widetilde{S} \subseteq S$.
\end{lemma}

\begin{definition}
We call
\begin{itemize}
\item $\widetilde{S}a$ the principal left ideal generated by $a$; 
\item $a\widetilde{S}$ the principal right ideal generated by $a$; 
\item $\widetilde{S}a\widetilde{S}$ the principal ideal generated by $a$.
\end{itemize}
\end{definition}

\subsubsection{Generated semigroups}
TODO!

\subsubsection{Periodic semigroups}
Period and index.

\subsection{Homomorphism}

\begin{proposition}
Let $S$ be a semigroup. Then the functions
\begin{align*}
&\lambda: S \to (\widetilde{S} \to \widetilde{S}) : a\mapsto (\lambda_a: x\mapsto ax) \\
&\rho: S \to (\widetilde{S} \to \widetilde{S}): a\mapsto (\rho_a: x\mapsto xa)
\end{align*}
are injective homomorphisms.
\end{proposition}
Note that for all $s\in S$ we view $\lambda_a$ as a function $\widetilde{S} \to \widetilde{S}$. This is necessary for injectivity.
\begin{proof}
The functions $\lambda, \rho$ are homomorphisms by associativity.

For injectivity, let $\lambda_a = \lambda_b$. Then $a = a\cdot e = \lambda_a(e) = \lambda_b(e) b\cdot e = b$.
\end{proof}

\begin{definition}
We call $\lambda$ ($\rho$) the \udef{extended left (right) regular representation} of $S$.
\end{definition}

\subsubsection{Congruences}
\begin{definition}
Let $\sSet{S,\boldsymbol{\cdot}}$ be a semigroup and $R$ a relation on $S$. Then $R$ is called
\begin{itemize}
\item \udef{left compatible} if it is $\Omega$-compatible with $\Omega = \setbuilder{\lambda_a}{a\in S}$;
\item \udef{right compatible} if it is $\Omega$-compatible with $\Omega = \setbuilder{\rho_a}{a\in S}$;
\item \udef{compatible} if it is $\Omega$-compatible with $\Omega = \{\boldsymbol{\cdot}\}$.
\end{itemize}
If the relation $R$ is additionally an equivalence relation, then $R$ is called a \udef{( left / right) congruence}.
\end{definition}

In other words:
\begin{itemize}
\item $R$ is left compatible if $\forall x,y,a\in S: \; xRy \implies (ax)R(ay)$;
\item $R$ is right compatible if $\forall x,y,a\in S: \; xRy \implies (xa)R(ya)$;
\item $R$ is compatible if $\forall x,y,v,w\in S: \; xRy \land vRw \implies (xv)R(yw)$.
\end{itemize}

\begin{proposition}
A relation $R$ on a semigroup $S$ is a congruence \textup{if and only if} it is a left and a right congruence.
\end{proposition}
\begin{proof}
($\Rightarrow$) If $R$ is a congruence, then $aRa$ by reflexivity. So $xRy$ implies $(ax)R(ay)$ and $(xa)R(ya)$, meaning that $R$ is a left and a right congruence.

($\Leftarrow$) Assume $R$ a left and a right congruence. Take $x,y,v,w$ such that $xRy$ and $vRw$. Then $(xv)R(yv)$ and $(yv)R(yw)$ by left and right compatibility. We conclude $(xv)R(yw)$ by transitivity.
\end{proof}

\subsection{Green's relations}
\begin{definition}
Let $\sSet{S,\cdot}$ be a semigroup. Let
\begin{itemize}
\item $\mathcal{L}$ be a relation on $S$ defined by $a\mathcal{L}b \defequiv \widetilde{S}a = \widetilde{S}b$;
\item $\mathcal{R}$ be a relation on $S$ defined by $a\mathcal{R}b \defequiv a\widetilde{S} = b\widetilde{S}$;
\item $\mathcal{H} \defeq \mathcal{L}\cap \mathcal{R}$;
\item $\mathcal{D} \defeq \mathcal{L}\vee \mathcal{R}$; TODO: which lattice?
\item $\mathcal{J}$ be a relation on $S$ defined by $a\mathcal{J}b \defequiv \widetilde{S}a\widetilde{S} = \widetilde{S}b\widetilde{S}$.
\end{itemize}
These five relations are known as \udef{Green's relations}.
\end{definition}

Clearly we have $\mathcal{D} \subseteq \mathcal{J}$.

\begin{lemma}
Let $\sSet{S,\cdot}$ be a semigroup and $a,b\in S$. Then
\begin{enumerate}
\item $a\mathcal{L}b$ \textup{if and only if} $\exists x,y\in \widetilde{S}: (xa = b) \land (yb = a)$;
\item $a\mathcal{R}b$ \textup{if and only if} $\exists x,y\in \widetilde{S}: (ax = b) \land (by = a)$;
\item $a\mathcal{J}b$ \textup{if and only if} $\exists x,y, u,v\in \widetilde{S}: (xay = b) \land (ubv = a)$.
\end{enumerate}
\end{lemma}
\begin{proof}
We prove (1), (2) is analogous.

($\Rightarrow$) $a\in \widetilde{S}a = \widetilde{S}b$, so there exists $y\in \widetilde{S}$ such that $a = yb$. The other equation is similar.

($\Leftarrow$) Because $\widetilde{S}x \subseteq \widetilde{S}$, we have $\widetilde{S}a \subseteq \widetilde{S}xa = \widetilde{S}b$. Similarly $\widetilde{S}b \subseteq \widetilde{S}a$.
\end{proof}
\begin{corollary}
$\mathcal{L}$ is a \emph{right} congruence and $\mathcal{R}$ a \emph{left} congruence.
\end{corollary}

\begin{proposition}
The relations $\mathcal{L}$ and $\mathcal{R}$ commute.
\end{proposition}
\begin{proof}
Assume $a(\mathcal{L};\mathcal{R})b$, meaning $\exists c: a\mathcal{L}c$ and $c\mathcal{R}b$. Then there exist $x,y,u,v\in \widetilde{S}$ such that
\[ (xa = c) \land (yc = a) \;\land\; (cu = b) \land (bv = c). \]
Now define $d = ycu$. Then $a\mathcal{R}d$ because
\[ d = (yc)u = au \;\text{and}\; a = yc = ybv = ycuv = dv \]
and $d\mathcal{L}b$ because
\[ d = ycu = yb \;\text{and}\; b = cu = xau = xycu = xd. \]
So $a(\mathcal{R};\mathcal{L})b$. The other inclusion is similar.
\end{proof}
\begin{corollary}
$\mathcal{D} = \mathcal{L};\mathcal{R} = \mathcal{R};\mathcal{L}$.
\end{corollary}
In other words, $a\mathcal{D}b \iff a\mathcal{L} \mesh \mathcal{R}b \iff a\mathcal{R} \mesh \mathcal{L}b$.

\begin{proposition}
Let $S$ be a periodic semigroup. Then $\mathcal{D} = \mathcal{J}$.
\end{proposition}
\begin{proof}
The inclusion $\mathcal{D} \subseteq \mathcal{J}$ is generally true. We want to prove the other inclusion.

Suppose $a\mathcal{J}b$. Then we can find $x,y,u,v\in \widetilde{S}$ such that
\[ xay = b, \quad ubv = a. \]
We see that $a = (ux)a(yu) = (ux)^2a(yu)^2 = \ldots$. By periodicity (TODO ref) we can find an $m\in \N$ such that $(ux)^m$ is idempotent. Then set $c= xa$, so that
\[ a = (ux)^ma(yu)^m = (ux)^m(ux)^ma(yu)^m = (ux)^ma = (ux)^{m-1}uc, \]
which means that $a\mathcal{L}c$.

Similarly we can choose $n\in \N$ such that $(vy)^n$ is idempotent, so from $b = (xu)b(vy) = (xu)^2b(vy)^2 = \ldots$
we get
\begin{align*}
c &= xa = x(ux)^{n+1}a(yu)^{n+1} = (xu)^{n+1}xay(vy)^nv \\
&= (xu)^{n+1}b(vy)^{2n}v = (xu)^{n+1}b(vy)^{n+1}(vy)^{n-1}v \\
&= b(vy)^{n-1}v.
\end{align*}
This along with $cy = xay = b$, gives $c\mathcal{R}b$. Thus $a\mathcal{L};\mathcal{R}b$, i.e.\ $a\mathcal{D}b$.
\end{proof}
\begin{corollary}
If the semigroup is finite, then $\mathcal{D} = \mathcal{J}$.
\end{corollary}

\begin{proposition}
Let $S$ be a semigroup. If $\sSet{S/\mathcal{L}, \subseteq}$ and $\sSet{S/\mathcal{R}, \subseteq}$ are well-founded, then $\mathcal{D} = \mathcal{J}$.
\end{proposition}
\begin{proof}
TODO
\end{proof}

\subsubsection{Egg-box diagrams}
\begin{definition}
In an \udef{egg-box diagram} a semigroup $S$ is depicted as a grid. Each element is put in this grid such that
\begin{itemize}
\item the rows are $\mathcal{R}$-classes; and
\item the columns are $\mathcal{L}$-classes.
\end{itemize} 
\end{definition}

Thus for $a,b\in S$, $[a]_\mathcal{L} = [b]_\mathcal{L}$ if and only if $a$ and $b$ are in the same column. Similarly, $[a]_\mathcal{R} = [b]_\mathcal{R}$ if and only if $a$ and $b$ are in the same row.

\begin{lemma}
Let $S$ be a semigroup and $a,b\in S$. Then
\begin{enumerate}
\item the cells in the egg-box diagram are $\mathcal{H}$-equivalence classes;
\item $a\mathcal{D}b$ \textup{if and only if} there is an element in the intersection of the row of $a$ and the column of $b$ or vice versa.
\end{enumerate}
\end{lemma}

\begin{example}
Consider the semigroup $(\{1,2,3\} \to \{1,2,3\})$ with composition $;$. We can represent an element $f$ of this semigroup as $(f(1) f(2) f(3))$. We have
\begin{itemize}
\item $f\mathcal{L}g$ if $f$ and $g$ have the same image;
\item $f\mathcal{R}g$ if $f$ and $g$ have the same kernel.
\end{itemize}
An egg-box diagram can be drawn as follows:
\[ \begin{array}{|c|c|c|c|c|c|c|}
\hline
\mathbf{(1 1 1)} & \mathbf{(2 2 2)} & \mathbf{(3 3 3)} &&& &  \\ \hline
&& & \mathbf{(1 2 2)}, & \mathbf{(1 3 3)}, & (2 3 3), &  \\
&& & (2 1 1)  & (3 1 1)  & (3 2 2)  &  \\ \hline
&& & (2 1 2), & (3 1 3), & \mathbf{(3 2 3)},  &  \\
&& & \mathbf{(1 2 1)}  & (1 3 1)  & (2 3 2)  &  \\ \hline
&& & (2 2 1), & (3 3 1), & (3 3 2),  &  \\
&& & (1 1 2)  & \mathbf{(1 1 3)}  & \mathbf{(2 2 3)}  &  \\ \hline
&& &&& & \mathbf{(1 2 3)}, (2 3 1) (3 1 2)  \\
&& &&& & (1 3 2), (2 1 3) (3 2 1)  \\ \hline
\end{array} \]
The bold elements are idempotents.
\end{example}


\begin{proposition}[Green's lemma] \label{GreensLemma}
Let $S$ be a semigroup and $a,b,x \in S$.
\begin{enumerate}
\item If $ax = b$ and $a\mathcal{R}b$, then
\begin{enumerate}
\item $\rho_x|_{[a]_\mathcal{L}}: [a]_\mathcal{L} \to [b]_\mathcal{L}$ is a bijection;
\item if $by = a$ for some $y\in \widetilde{S}$, then $\rho_y|_{[b]_\mathcal{L}}$ is the inverse;
\item $\rho_x|_{[a]_\mathcal{L}}$ preserves $\mathcal{R}$-classes.
\end{enumerate}
\item If $xa = b$ and $a\mathcal{L}b$, then
\begin{enumerate}
\item $\lambda_x|_{[a]_\mathcal{R}}: [a]_\mathcal{R} \to [b]_\mathcal{R}$ is a bijection with inverse $\lambda_y|_{[b]_\mathcal{R}}$;
\item if $yb = a$ for some $y\in \widetilde{S}$, then $\lambda_y|_{[b]_\mathcal{R}}$ is the inverse;
\item $\lambda_x|_{[a]_\mathcal{R}}$ preserves $\mathcal{L}$-classes.
\end{enumerate} 
\end{enumerate}
In particular
\begin{enumerate}
\item if $a\mathcal{R}b$, then there exists $x\in \widetilde{S}$ such that $ax = b$ and thus $|[a]_\mathcal{L}| = |[b]_\mathcal{L}|$;
\item if $a\mathcal{L}b$, then there exists $x\in \widetilde{S}$ such that $xa = b$ and thus $|[a]_\mathcal{R}| = |[b]_\mathcal{R}|$.
\end{enumerate}
\end{proposition}
\begin{proof}
The function $\rho_x$ is well-defined: let $u\in [a]_\mathcal{L}$ so that $u = va$ for some $v\in \widetilde{S}$. Then $\rho_x(u) = vax = vb \in [b]_\mathcal{L}$.

Because $a\mathcal{R}b$, we can always find a $y\in \widetilde{S}$ such that $by = a$. The function $\rho_y|_{[b]_\mathcal{L}}$ is clearly the inverse: $\rho_y(\rho_x(u)) = \rho_y(vb) = vby = va = u$. This shows that $\rho_x$ is bijective.

It is clear that $\rho_x$ preserves $\mathcal{R}$-classes, because it operates on the right.

The arguments for $\lambda_x$ and $\lambda_y$ are completely analogous.
\end{proof}
\begin{corollary}
Let $S$ be a semigroup and $a,b\in S$ such that $a\mathcal{D}b$, then $|[a]_\mathcal{H}| = |[b]_\mathcal{H}|$.
\end{corollary}
\begin{proof}
If $a(\mathcal{L};\mathcal{R})b$, then there exists a $c\in S$ such that $c = sa$ and $b = ct$. Then $\lambda_s\circ \rho_t$ is the required bijection.
\end{proof}

\begin{theorem}[Green's theorem]
Let $S$ be a semigroup and $H$ an $\mathcal{H}$-class in $S$. Then either
\begin{enumerate}
\item $H^2\perp H$; or
\item $H^2 = H$ and $H$ is a subgroup of $S$.
\end{enumerate}
\end{theorem}
\begin{proof}
Suppose $H^2\cap H \neq \emptyset$, then there exist $a,b\in H$ such that $ab = c\in H$. By the Green's lemma \ref{GreensLemma} we have that $\rho_b:H\to H$ and $\lambda_a: H\to H$ are bijections.

Then for all $h\in H$, $\rho_b(h) = hb \in H$. Again by the Green's lemma, this means that $\lambda_h: H\to H$ is a bijection. Similarly $\rho_h: H\to H$ is a bijection for all $h$. So for all $h\in H$ we have $hH = H = Hh$. This means $H^2 = H$ and $H$ is a group by \ref{groupCriterion}.
\end{proof}
\begin{corollary} \label{GreensTheoremCorollary}
Let $S$ be a semigroup and $H$ an $\mathcal{H}$-class in $S$. Then
\begin{enumerate}
\item if $x$ is an idempotent in $H$, then $H$ is a subgroup of $S$;
\item no $\mathcal{H}$-class can contain more than one idempotent. 
\end{enumerate}
\end{corollary}

\subsubsection{Regular elements $\mathcal{D}$-classes}
\begin{definition}
Let $S$ be a semigroup. An element $a\in S$ is called \udef{regular} if there exists $x\in S$ such that $axa = a$.
\end{definition}

\begin{proposition} 
Let $S$ be a semigroup. If $a\in S$ is regular, then every element in $[a]_{\mathcal{D}}$ is regular.
\end{proposition}
So it makes sense to call a $\mathcal{D}$-class \udef{regular} if it consists of regular elements and \udef{irregular} otherwise.
\begin{corollary}
If there is an idempotent $x\in [a]_{\mathcal{D}}$, then $[a]_{\mathcal{D}}$ is regular.
\end{corollary}
\begin{proof}
An idempotent is regular: $x = xx = x(xx) = xxx$.
\end{proof}

\begin{proposition} \label{idempotentsInGreensClasses}
Let $S$ be a semigroup.
\begin{enumerate}
\item If $x\in S$ is an idempotent, then $x$ is a left identity for $[x]_{\mathcal{R}}$ and $x$ is a right identity for $[x]_{\mathcal{L}}$.
\item If $a$ is regular with $axa = a$, then $xa$ and $ax$ are idempotents.
\item If $a$ is regular with $axa = a$, then $xa\mathcal{L}a$ and $ax\mathcal{R}a$.
\item In a regular $\mathcal{D}$-class each $\mathcal{L}$-class and each $\mathcal{R}$-class contains at least one idempotent.
\end{enumerate}
\end{proposition}
\begin{proof}
(1) Let $a\in [x]_\mathcal{R}$. Then there exists a $y\in \widetilde{S}$ such that $a = xy$ and thus $xa = xxy = xy = a$. The claim of right-identity is similar.

(2) We have $(xa)(xa) = x(axa) = xa$ and $(ax)(ax) = (axa)x = ax$.

(3) If $a$ is regular with $axa = a$, then $xa$ is idempotent: $(xa)(xa) = x(axa) = xa$ and $xa \in [a]_{\mathcal{L}}$:
\[ xa = (xa) \qquad a(xa) = a \]
Similarly $ax \in [a]_{\mathcal{R}}$ and is idempotent.

(4) Let $[a]_\mathcal{L}$ be an $\mathcal{L}$-class in a regular $\mathcal{D}$-class. By regularity there exists an $x\in S$ such that $axa = a$. From (2) and (3), we have that $[a]_\mathcal{L}$ contains the idempotent $xa$ and $[a]_\mathcal{R}$ the idempotent $ax$.
\end{proof}

\begin{proposition}
Let $a,b \in S$ such that $a\mathcal{D}b$. Then $ab\in [a]_{\mathcal{R}}\cap [b]_{\mathcal{L}}$ \textup{if and only if} $[b]_{\mathcal{R}}\cap [a]_{\mathcal{L}}$ contains an idempotent.
\end{proposition}
\begin{proof}
Suppose $[b]_{\mathcal{R}}\cap [a]_{\mathcal{L}}$ contains an idempotent $x$. Then $xb = b$ by \ref{idempotentsInGreensClasses}. Then $\rho_b$ maps $[x]_{\mathcal{L}} = [a]_{\mathcal{L}}$ to $[b]_{\mathcal{L}}$ by \ref{GreensLemma}. It preserves $\mathcal{R}$-classes, so in particular it maps $[a]_{\mathcal{H}}$ to $[a]_{\mathcal{R}}\cap [b]_{\mathcal{L}}$. Thus $ab = \rho_b(a) \in [a]_{\mathcal{R}}\cap [b]_{\mathcal{L}}$.

Now assume $ab\in [a]_{\mathcal{R}}\cap [b]_{\mathcal{L}}$. Then there exists a $c\in \widetilde{S}$ such that $abc = a$. By \ref{GreensLemma} this means $\rho_c\in ([ab]_{\mathcal{L}}\to [a]_{\mathcal{L}}) = ([b]_{\mathcal{L}}\to [a]_{\mathcal{L}})$. In particular this restricts to $([b]_{\mathcal{H}}\to [b]_{\mathcal{R}}\cap[a]_{\mathcal{L}})$. Because $ab = (ab)$, $\rho_b$ is the inverse of $\rho_c$ by the same lemma.

So $\rho_c(b) = bc \in [b]_{\mathcal{R}}\cap[a]_{\mathcal{L}}$ and bc is idempotent because
\[ bcbc = (\rho_c\circ\rho_b\circ\rho_c) (b) = \rho_c(b) = bc. \]
\end{proof}

\subsubsection{Generalised inverses}
\begin{definition}
Let $S$ be a semigroup and $a\in S$. We call $a'$ a \udef{(generalised) inverse} of $a$ if
\[ aa'a = a, \qquad a'aa' = a'. \]
\end{definition}

\begin{lemma}
Let $S$ be a semigroup and $a\in S$. Then $a$ has a generalised inverse \textup{if and only if} it is regular.
\end{lemma}
\begin{proof}
Clearly every element with a generalised inverse is regular. Conversely, assume $a$ regular with $axa = a$. Then $a' = xax$ is a generalised inverse of $a$.
\end{proof}

\begin{proposition} \label{inversesIdempotentsDclass}
Let $a$ be an element of a regular $\mathcal{D}$-class $D$ in a semigroup $S$.
\begin{enumerate}
\item If $a'$ is a generalised inverse of $a$, then
\begin{enumerate}
\item $a' \in D$;
\item $[aa']_\mathcal{H} = [a]_\mathcal{R}\cap [a']_\mathcal{L}$;
\item $[a'a]_\mathcal{H} = [a']_\mathcal{R}\cap [a]_\mathcal{L}$.
\end{enumerate}
\item If $b\in S$ is such that $[a]_\mathcal{R}\cap [b]_\mathcal{L}$ contains an idempotent $x$ and $[b]_\mathcal{R}\cap [a]_\mathcal{L}$ contains an idempotent $y$, then $[b]_\mathcal{H}$ contains a generalised inverse $a'$ of $a$ such that $aa' = x$ and $a'a = y$.
\item No $\mathcal{H}$-class contains more than one generalised inverse of $a$.
\end{enumerate}
\end{proposition}
\begin{proof}
(1) Firstly notice that $[a]_\mathcal{R}\cap [a']_\mathcal{L}$ is an $\mathcal{H}$-class. Also $a\mathcal{R}aa'$ and $a'\mathcal{L}aa'$ by \ref{idempotentsInGreensClasses}.

(2) From $a\mathcal{R}x$, we deduce that there exists a $u\in\widetilde{S}$ such that $au = x$. 

Set $a' = yux$. Then, using that $x$ is a left-identity on $[a]_\mathcal{R}$ and $y$ a right-identity on $[a]_\mathcal{L}$ by \ref{idempotentsInGreensClasses},
\begin{align*}
aa'a &= a(yux)a = (ay)u(xa) = aua = (au)a = xa = a \\
a'aa' &= (yux)a(yux) = (yu)(xay)(ux) = (yu)a(ux) = (yu)(au)x = yux^2 = yux = a' \\
aa' &= a(yux) = ((ay)u)x = (au)x = x^2 = x.
\end{align*}
For the last equality, we need that $a\mathcal{L}y$ implies the existence of $v\in \widetilde{S}$ such that $va = y$. Then
\[ a'a = (yux)a = (va)u(xa) = (va)(ua) = v(au)a = v(xa) = va = y. \]
We now just need to show that $a' \in [b]_\mathcal{H}$. By \ref{idempotentsInGreensClasses} we have $a'\in [aa']_{\mathcal{L}}$ and $a'\in [a'a]_{\mathcal{R}}$, so
\[ a' \in [aa']_{\mathcal{L}} \cap [a'a]_{\mathcal{R}} = [x]_{\mathcal{L}} \cap [y]_{\mathcal{R}} = [b]_{\mathcal{L}} \cap [b]_{\mathcal{R}} = [b]_\mathcal{H}. \]

(3) Suppose $[b]_\mathcal{H}$ is an $\mathcal{H}$-class containing two generalised inverses $a_1', a_2'$ of $a$. Then $aa'_1 = aa'_2$ and $a'_1a = a'_2a$ by \ref{GreensTheoremCorollary} and thus
\[ a'_1 = a'_1(aa'_1) = a'_1(aa'_2) = (a'_2a)a'_2 = a'_2. \]
\end{proof}
\begin{corollary} \label{corollaryInversesIdempotentsDclass}
Let $S$ be a semigroup and $x,y\in S$ idempotents. Then $x\mathcal{D}y$ \textup{if and only if} we can write $x = aa'$ and $y = a'a$ for some $a\in [x]_\mathcal{R}\cap [y]_\mathcal{L}$ and $a'\in [y]_\mathcal{R}\cap [x]_\mathcal{L}$ that are generalised inverses of each other.
\end{corollary}
\begin{proof}
We have $x\mathcal{D}y$ iff there exist $a,b\in S$ such that $x\mathcal{R}a$, $a\mathcal{L}y$ and $x\mathcal{L}b$, $b\mathcal{R}y$. This means $x\in [a]_\mathcal{R}\cap [b]_\mathcal{L}$ and $y\in [b]_\mathcal{R}\cap [a]_\mathcal{L}$. So by the proposition we can find an $a'\in [b]_\mathcal{H}$ that satisfies the requirements.
\end{proof}

\begin{proposition}
Let $S$ be a semigroup and let $H,K$ be $\mathcal{H}$-classes that are subgroups and members of the same $\mathcal{D}$-class. Then $H$ and $K$ are isomorphic groups.
\end{proposition}
\begin{proof}
Let $e$ be the idempotent (and thus identity) in $H$ and $f$ the identity in $K$. By \ref{corollaryInversesIdempotentsDclass} we have mutually inverse $a\in [x]_\mathcal{R}\cap [y]_\mathcal{L}$ and $a'\in [y]_\mathcal{R}\cap [x]_\mathcal{L}$ such that $x = aa'$ and $y = a'a$.

We claim $\lambda_{a'}\circ\rho_{a}|_H$ is an isomorphism $H\to K$. Indeed it is bijective by \ref{GreensLemma}. We need to show that it is a homomorphism: take $u,v\in H$
\[ (\lambda_{a'}\circ\rho_{a})(u)(\lambda_{a'}\circ\rho_{a})(v) = a'uaa'va = a'uxva = a'uva = (\lambda_{a'}\circ\rho_{a})(uv), \]
where we have used that $x$ is the identity for $H$.
\end{proof}

\subsubsection{Regular semigroups}
\begin{definition}
A regular semigroup is a semigroup where every element is regular.
\end{definition}

\begin{lemma}
Let $S$ be a regular semigroup. Then for all $a\in S$
\[ \widetilde{S}a = Sa, \qquad  a\widetilde{S} = aS \qquad\text{and}\qquad \widetilde{S}a\widetilde{S} = SaS. \]
\end{lemma}
So we can drop all mention of $\widetilde{S}$ when working with ideal. In particular
\begin{itemize}
\item $a\mathcal{L}b$ if and only if $Sa = Sb$;
\item $a\mathcal{R}b$ if and only if $aS = bS$;
\item $a\mathcal{J}b$ if and only if $SaS = SbS$.
\end{itemize}

\subsection{Inverse semigroups}

\section{Monoids}


\begin{lemma}
A locally small category with a single object is a monoid.
\end{lemma}
TODO: \udef{delooping} $\cat{B}M$.


\subsection{Ordered monoids}
\begin{definition}
An \udef{ordered monoid} is a monoid $(M, \cdot, 0)$ on which a partial order $\preceq$ is defined that is compatible, i.e.\ $\forall x,y,z\in M$
\[ x\preceq y \implies x\cdot z \preceq y \cdot z \land z\cdot x \preceq z \cdot y. \]

Positive: $x > 0$.
\end{definition}

\subsubsection{The Archimedean property}
\begin{definition}
Let $(M,+,\leq)$ be a totally ordered monoid and $x,y\in M$ positive. Then
\begin{itemize}
\item $x$ is \udef{infinitesimal w.r.t.} $y$ or $y$ is \udef{infinite w.r.t.} $x$ if $nx<y$ for all $n\in\N$;
\item $M$ is \udef{Archimedean} if there is no pair $(x,y)$ such that $x$ is infinitesimal w.r.t. $y$.
\end{itemize}
\end{definition}
every submonoid is Archimedean.

abelian??

\subsubsection{Regular ordering for commutative monoids}
\begin{definition}
Let $\sSet{M,+,0}$ be a commutative monoid. Consider the function $m: \powerset(M\to M) \to \powerset(X^2)$ from \ref{setOfFunctionsToRelationGaloisConnection}. (TODO define higher).

The \udef{regular order} on $M$ is $m\setbuilder{\lambda_a}{a\in M}$.
\end{definition}

\begin{lemma}
The regular order is a preorder on $M$ that is compatible with $M$. It is a partial order \textup{if and only if} $M$ is cancellative.
\end{lemma}

\begin{example}
The regular order on $\N$ is the standard order on $\N$.
\end{example}

\section{Divisibility}
$m|n$ order relation.

$\sup\{n,m\} = kgv(n,m)$ and $\inf\{n,m\} = ggd(n,m)$



\chapter{Relational structures}
\begin{definition}
A \udef{relational structure} is a structured set $\sSet{A, R}$ where $R$ is a homogeneous relation on the set $A$.
\end{definition}


\section{Duality}
\begin{definition}
Let $\sSet{A,R}$ be a relational structure.

The relational structure \udef{dual} to $\sSet{A,R}$ is $\sSet{A, R}^o \defeq \sSet{A^o,R^\transp}\defeq \sSet{A,R^\transp}$.
\end{definition}



\section{Functions on relational structures}

\begin{lemma} \label{functionSubsetRelation}
Let $f: A\to A$ be a function on a relational structure $\sSet{A,R}$. Then
\[ f \subseteq R \iff \id_A \subseteq R;f^\transp. \]
\end{lemma}
\begin{proof}
We have
\[ f \subseteq R \implies \id_A \subseteq f;f^\transp \subseteq R;f^\transp \implies f \subseteq R;f^\transp;f \subseteq R. \]
\end{proof}

\begin{definition}
Let $(A, R)$ and $(B, S)$ be relational structures and $f: A\to B$ a function. We say
\begin{itemize}
\item $f$ is \udef{relation-preserving} if
\[ \forall x,y\in A: xRy \implies f(x)Sf(y); \]
\item $f$ is \udef{relation-reflecting} if
\[ \forall x,y\in A: f(x)Sf(y) \implies xRy; \]
\item $f$ is a \udef{relation embedding} if it is relation-preserving and -reflecting:
\[ \forall x,y\in A: xRy \iff f(x)Sf(y). \]
\end{itemize}
\end{definition}

\begin{proposition} \label{relationPreserving}
Let $\sSet{X, R}$ and $\sSet{Y, S}$ be relational structures and $f: X\to Y$ a function. Then the following are equivalent:
\begin{enumerate}
\item $f$ is relation-preserving;
\item $R \subseteq f;S;f^\transp$;
\item $R;f \subseteq f;S$.
\end{enumerate}
\end{proposition}
\begin{proof}
$(1) \Leftrightarrow (2)$ Is clear from the definition.

$(2) \Rightarrow (3)$ We calculate
\[ R;f \subseteq (f;S;f^\transp);f = f;S;(f^\transp;f) \subseteq f;S;\id = f;S. \]

$(3) \Rightarrow (2)$ We calculate
\[ R \subseteq R;(f;f^\transp) = (R;f);f^\transp \subseteq f;S;f^\transp. \]
\end{proof}
\begin{corollary}
Let $\sSet{X, R}$ and $\sSet{Y, S}$ be relational structures and $f: X\to Y$ a function. Then the following are also equivalent to $f$ being relation-preserving:
\begin{enumerate}
\item $f: X^o \to Y^o$ is relation preserving;
\item $R^\transp \subseteq f;S^\transp;f^\transp$;
\item $R^\transp;f \subseteq f;S^\transp$;
\item $f^\transp;R \subseteq S;f^\transp$.
\end{enumerate}
\end{corollary}
\begin{proof}
(2) Is equivalent to $R \subseteq f;S;f^\transp$ by taking the transpose. The equivalence of (1), (2) and (3) is then given by the proposition.

(4) Is equivalent to (3) by taking the transpose.
\end{proof}
\begin{corollary} \label{functionImagesPreimagesAndPrincipalImages}
Let $\sSet{A,R}$ and $\sSet{B, S}$ be relational structures and $f: A\to B$ a function. Then the following are equivalent:
\begin{enumerate}
\item $f$ is order-preserving;
\item for all $X\subseteq A$: $f[X_R] \subseteq f[X]_S$;
\item for all $x\in A$: $f[xR] \subseteq f(x)S$.
\end{enumerate}
They are also equivalent to:
\begin{enumerate} \setcounter{enumi}{3}
\item for all $Y\subseteq B$: $f^{-1}[Y]_R \subseteq f^{-1}[Y_S]$
\item for all $y\in B$: $f^{-1}[\{y\}]_R \subseteq f^{-1}[yS]$.
\end{enumerate}
\end{corollary}
TODO: this implies $R$-closure for $f^{-1}$: by preservation of union we have $f^{-1}[yS]_R \subseteq f^{-1}[yS^2] = f^{-1}[yS]$.
\begin{proof}
$(1 \Leftrightarrow 2)$ Follows by taking images of $X$ under $R;f \subseteq f;S$ and the fact that relations are completely determined by their images.

$(2 \Leftrightarrow 3)$ This is the particular case of principal images. A relation is completely characterised by its principal images. See \ref{relationFromPrincipalImages}.

$(4, 5)$ Here we are taking images of $f^\transp;R \subseteq S;f^\transp$.
\end{proof}
\begin{corollary} \label{closurePreimageRelationPreservingFunctions}
Let $\sSet{A,R}$ and $\sSet{B, S}$ be relational structures and $f: A\to B$ a relation-preserving function. Then the preimage of an $S$-closed set is $R$-closed.
\end{corollary}
\begin{proof}
Suppose $Y\subseteq B$ is an $S$-closed set, i.e.\ $Y_S\subseteq Y$. Then $f^\preimf(Y)_R \subseteq f^\preimf(Y_S)\subseteq f^\preimf(Y)$, so $f^\preimf(Y)$ is $R$-closed.
\end{proof}

\begin{note}
Useful exercise: give elementary proof of \ref{functionImagesPreimagesAndPrincipalImages}. This can be based on the calculations
\[ y\in xR \iff xRy \implies f(x)Rf(y) \iff f(y) \in f(x)R \]
and
\begin{align*}
x\in f^{-1}[\{y\}]_R &\iff \exists z:\; f(z) = y \;\land\; zRx \\
&\implies \exists z:\; f(z) = y \;\land\; f(z)Rf(x) \\
&\implies ySf(x) \iff f(x) \in yS \iff x\in f^{-1}[yS].
\end{align*}
\end{note}

\begin{lemma}
Let $(A, R)$ and $(B, S)$ be relational structures and $f: A\to B$ a function. Then
\begin{enumerate}
\item $f$ is relation-reflecting \textup{if and only if} $R \supseteq f;S;f^\transp$;
\item $f$ is a relation embedding \textup{if and only if} $R = f;S;f^\transp$.
\end{enumerate}
\end{lemma}

\begin{lemma} \label{connexityImage}
Let $f: \sSet{X,R} \to \sSet{Y,S}$ be a relation preserving function. If $X$ is connex, then so is $\imf(f)$.
\end{lemma}

\begin{definition}
A function $f: A\to A$ on a relational structure $\sSet{A, R}$ is
\begin{itemize}
\item \udef{left-restrictive} if $f;R \subseteq R$;
\item \udef{right-restrictive} if $R;f^\transp \subseteq R$;
\item \udef{left-expansive} if $R \subseteq f;R$;
\item \udef{right-expansive} if $R \subseteq R;f^\transp$.
\end{itemize}
\end{definition}

TODO: expansive, contractive, extensive.

\begin{lemma} \label{transitiveRestrictiveLemma}
Let $f: A\to B$ be a function and $R$ a transitive relation on $B$. Then $f\subseteq R$ implies $f;R\subseteq R$ and $R;f\subseteq R$.
\end{lemma}
\begin{proof}
We have $f;R\subseteq R^2 \subseteq R$ and $R;f \subseteq R^2 \subseteq R$.
\end{proof}

\begin{lemma} \label{expansiveRelationPreserving}
Let $f: \sSet{A,R} \to \sSet{A,R}$ be a relation-preserving function. Then
\[ f;R \subseteq R \implies R \subseteq R;f^\transp \]
\end{lemma}
\begin{proof}
We calculate
\[ R \subseteq f;R;f^\transp \subseteq R;f^\transp. \]
\end{proof}

\subsection{Relation isomorphisms}
\begin{definition}
Let $(A_1, R_1)$ and $(A_2, R_2)$ be relational structures. A bijection $\phi:A_1 \twoheadrightarrowtail A_2$ such that
\[ \forall (s_1,t_1)\in R_1: (\phi(s_1),\phi(t_1))\in R_2 \qquad \text{and} \qquad \forall (s_2,t_2)\in R_2: (\phi^{-1}(s_2),\phi^{-1}(t_2))\in R_1, \]
is called a \udef{(relation) isomorphism}. If there exists a relation isomorphism $A_1 \twoheadrightarrowtail A_2$, then $(A_1, R_1)$ and $(A_2, R_2)$ are \udef{isomorphic}, denoted $A_1 \cong A_2$.
\end{definition}

\begin{lemma}
A map is a relation isomorphism \textup{if and only if} it is a bijective relation embedding.
\end{lemma}
\begin{proof}
Let $f: \sSet{A, R}\to \sSet{B, }$ be a bijective map. Then $f$ is relation-reflecting iff $f^{-1}$ is relation-preserving. Indeed
\[ f;R;f^{-1} \subseteq R \iff R = f^{-1};f;R;f^{-1};f \subseteq f^{-1};R;f. \]
\end{proof}

\begin{lemma} \label{isomorphismEquivalence}
Let $(A_1, R_1)$, $(A_2, R_2)$ and $(A_3, R_3)$ be relational structures and $f:A_1 \twoheadrightarrowtail A_2$, $g:A_2 \twoheadrightarrowtail A_3$ isomorphisms. Then
\begin{enumerate}
\item $I_{A_1}: A_1 \to A_1: a\mapsto a$ is an isomorphism;
\item $f^{-1}: A_2\to A_1$ is an isomorphism;
\item $(g\circ f): A_1\to A_3$ is an isomorphism.
\end{enumerate}
\end{lemma}
Consequently, relation isomorphism would be an equivalence relation on all structured sets, except there is no set of all structured sets, by Russell's paradox. Relation isomorphism can be an equivalence relation on a (restricted) set of structured sets.

\begin{lemma}
Let $(A_1, R_1)$ and $(A_2, R_2)$ be isomorphic relational structures. Then $R_1$ has the same properties as $R_2$.
\end{lemma}
e.g\: reflexivity, symmetry, transitivity, being an equivalence relation etc.


\section{The semigroup of relation-preserving functions}
\begin{lemma}
Let $\{\sSet{A_i, R_i}\}_{i\in I}$ be a set of relational structures. Then the set of relation-preserving functions together with $\emptyset$ forms a semigroup under composition.
\end{lemma}


TODO: Full semigroup, i.e.\ if relational structure is involved, all morphisms must be present.
\begin{proposition}
Let $M$ be a semigroup of relation-preserving functions and $f: \sSet{A, R} \to \sSet{B,S}$, $g: \sSet{A, R} \to \sSet{C,T}$ relation-preserving functions. Then
\[ f\mathcal{R}g \iff (f;S;f^\transp = g;T;g^\transp)\land (\ker f = \ker g). \]
\end{proposition}
\begin{proof}
First assume $f\mathcal{R}g$, then there exist $x,y\in \tilde{M}$ such that $f = g;x$ and $g = f;y$. Now $x$ and $y$ are relation preserving: $T \subseteq x;S;x^\transp$ and $S \subseteq y;T;y^\transp$. So
\[ f;S;f^\transp = g;x;S;x^\transp;g^\transp \supseteq g;T;g^\transp \quad\text{and}\quad g;T;g^\transp = f;y;T;y^\transp;f^\transp  \supseteq f;S;f^\transp. \]

For the converse, we can find functions $x,y$ such that $f = g;x$ and $g = f;y$ because of the equality of the kernels. We just need to show that $x$ and $y$ are relation-preserving. Because $g^\transp;f = g^\transp;g;x \subseteq x$, we have
\[ T \subseteq g^\transp;g;T;g^\transp;g = g^\transp;f;S;f^\transp;g \subseteq x;S;x^\transp. \]
The argument for $y$ is similar.
\end{proof}
\begin{corollary} \label{relationPreservingGeneralisedInversesEmbeddings}
Let $a,a'$ be generalised inverses in the semigroup of relation-preserving functions. Then
\begin{enumerate}
\item $aa'R a^{\prime\transp} = aSa^\transp a^{\prime\transp}$;
\item $a'R a^{\prime\transp}a^\transp = a'aSa^\transp$;
\item $a|_{\im a'}$ and $a'|_{\im a}$ are relation embeddings.
\end{enumerate}
\end{corollary}
\begin{proof}
Let $a: \sSet{A,R} \to \sSet{B,S}$ and $a': \sSet{B,S} \to \sSet{A,R}$ be generalised inverses. From \ref{idempotentsInGreensClasses} we have $a\mathcal{R}aa'$ and $a'\mathcal{R}a'a$. The proposition then gives us $aSa^\transp = aa'Ra^{\prime\transp} a^\transp$.

(1) Multiplying this equality on the right by $a^{\prime\transp}$ and using $a^{\prime\transp} = (a'aa')^\transp = a^{\prime\transp} a^\transp a^{\prime\transp}$ gives us
\[ aSa^\transp a^{\prime\transp} = aa'R(a^{\prime\transp} a^\transp a^{\prime\transp}) = aa'Ra^{\prime\transp}. \]

(2) Similar to (1), except multiplying on the left by $a'$.

(3) By assumption $a$ and $a'$ are relation-preserving. Also, using $aSa^\transp = aa'Ra^{\prime\transp} a^\transp$, we have
\[ S \supseteq S|_{\im(a)}^{\im(a)} = a^\transp aSa^\transp a = a^\transp (aa'Ra^{\prime\transp} a^\transp) a = (a^\transp a)a'Ra^{\prime\transp} (a^\transp a) = a'|_{\im(a)}R(a'|_{\im(a)})^{\transp}. \]
This means that $a'|_{\im(a)}$ is also relation-reflecting. The argument for $a|_{\im(a')}$ is similar.
\end{proof}


\subsection{Galois connections}
\begin{definition}
Let $a: \sSet{A,R} \to \sSet{B,S}$ and $a': \sSet{B,S} \to \sSet{A,R}$ be relation-preserving generalised inverses. We say $(a,a')$ is a \udef{Galois connection} between $\sSet{A, R}$ and $\sSet{B, S}$ if
\begin{itemize}
\item $aa'$ is left-restrictive for $R$, i.e.\ $aa'R \subseteq R$; and
\item $a'a$ is left-restrictive for $S^\transp$, i.e.\ $a'aS^\transp \subseteq S^\transp$.
\end{itemize}
We call $a$ the \udef{lower adjoint} or \udef{residuated map} and $a'$ the \udef{upper adjoint} or \udef{residual}.

Sometimes a Galois connection between $\sSet{A, R}$ and $\sSet{B, S}^o$ is referred to as an \udef{antitone Galois connection} between $\sSet{A, R}$ and $\sSet{B, S}$. In this situation we may refer to the ordinary Galois connection as a \udef{monotone Galois connection} to highlight the difference.
\end{definition}
Some authors exclusively use the term ``Galois connection'' to refer to antitone Galois connections. They my call monotone Galois connections residuated mappings.

\begin{lemma}
Let $\sSet{A, R}$ and $\sSet{B, S}$ be relational structures, and $a: \sSet{A,R} \to \sSet{B,S}$ and $a': \sSet{B,S} \to \sSet{A,R}$ functions. Then $(a,a')$ is an antitone Galois connection \textup{if and only if}
\begin{enumerate}
\item $a, a'$ are relation-reversing;
\item $a, a'$ are generalised inverses;
\item $aa'R \subseteq R$ and $a'aS \subseteq S$.
\end{enumerate}
\end{lemma}

For any relation-preserving involution $f: \sSet{A,R} \to \sSet{A,R}$,  $(f,f)$ is a Galois connection. For any relation-reversing involution $f: A\to A$, $(f,f^o)$ is a Galois connection between $\sSet{A,R}$ and $\sSet{A,R}^o$, where we consider $f$ as a function $f: \sSet{A,R} \to \sSet{A,R}^o$ and $f^o$ as the function $f^o: \sSet{A,R}^o \to \sSet{A,R}$ with the same graph.

\begin{example}
\begin{itemize}
\item Let $\sSet{A, \id_A}$ and $\sSet{B, \id_B}$ be discrete relational structures. Then $f: A\to B$ and $g: B \to A$ form a Galois connection if and only if they are invertible and $f = g^{-1}$.
\item Let $A$ be a set. Then complementation $c: \powerset(A) \to \powerset(A)$ is a relation-reversing involution, so it gives a Galois connection between $\sSet{\powerset(A), \subseteq}$ and $\sSet{\powerset(A), \subseteq}^o$. In particular we have the identity
\[ \forall X, Y\in\powerset(A): \qquad X^c \subseteq Y \iff X \supseteq Y^c, \]
which is the Galois identity \ref{GaloisIdentity}.
\end{itemize}
\end{example}

\begin{lemma} \label{immediateGaloisCorollaries}
If $(a,a')$ is a Galois connection between $\sSet{A,R}$ and $\sSet{B,S}$, then
\begin{enumerate}
\item $R^\transp \subseteq aa'R^\transp$ and $S \subseteq a'aS$;
\item $Raa' \subseteq R$ and $S^\transp a'a \subseteq S^\transp$.
\end{enumerate}
\end{lemma}
\begin{proof}
(1) This is a direct application of \ref{expansiveRelationPreserving}. I can also be obtained as a corollary to \ref{GaloisIdentity} (later).

(2) Follows from the Galois condition and the fact $a'a, aa'$ are relation-preserving (\ref{relationPreserving}):
\[ Raa' \subseteq aa'R \subseteq R \qquad\text{and}\qquad S^\transp a'a \subseteq a'aS^\transp \subseteq S^\transp. \]
\end{proof}

In particular, if the relations are reflexive, we have
\[ \id_A \subseteq R^\transp \subseteq aa'R^\transp \qquad\text{and}\qquad \id_B \subseteq S \subseteq a'aS. \]
This means that for all $x\in A$ we have $ xRa'(a(x))$ and for all $y\in B$ we have $a(a'(y))Sy$.

\subsubsection{The Galois identity}
\begin{proposition} \label{GaloisIdentity}
If $(a,a')$ is a Galois connection between $\sSet{A,R}$ and $\sSet{B,S}$, then
\[ aS = Ra^{\prime \transp}. \]
\end{proposition}
This identity is particularly important because it gives also gives a sufficient condition for a pair of maps between preorders to be a Galois connection, see \ref{preorderGaloisIdentity}.
\begin{proof}
By \ref{relationPreservingGeneralisedInversesEmbeddings} we have $aa'R a^{\prime\transp} = aSa^\transp a^{\prime\transp}$. Because $a,a'$ are relation-preserving, we have
\[ aS \subseteq aa'R a^{\prime\transp} = aSa^\transp a^{\prime\transp} = aS(a'a)^\transp \subseteq aS \quad\text{and}\quad Ra^{\prime\transp} \subseteq aSa^\transp a^{\prime\transp} = aa'R a^{\prime\transp} \subseteq Ra^{\prime\transp}, \]
which implies $aS = aSa^\transp a^{\prime\transp} = aa'R a^{\prime\transp} = Ra^{\prime\transp}$.
\end{proof}
\begin{corollary} \label{reflexiveGaloisCorollary}
Let $(a,a')$ be a Galois connection between $\sSet{A,R}$ and $\sSet{B,S}$.
\begin{enumerate}
\item If $S$ is reflexive, then $aa' \subseteq R$.
\item If $R$ is reflexive, then $a'a \subseteq S^\transp$.
\end{enumerate}
\end{corollary}
We can reformulate (1) as $xR(a'\circ a)(x)$ for all $x\in A$ and (2) as $yS(a\circ a')(y)$ for all $y\in B$.
\begin{proof}
(1) We calculate $aa' \subseteq aSa' = Ra^{\prime \transp}a' \subseteq R$.

(2) Similarly, $a'a \subseteq a'R^\transp a = S^\transp a^\transp a \subseteq S^\transp$.
\end{proof}

\begin{lemma} \label{preimagesGaloisIdentity}
Let $\sSet{A, R}$ and $\sSet{B, S}$ be relationals structures and $f: A\to B$, $g: B\to A$ functions.
The following are equivalent:
\begin{enumerate}
\item $f;S = R;g^\transp$;
\item for all $x$: $f(x)S = g^{-1}[xR]$;
\item for all $y$: $f^{-1}[Sy] = Rg(y)$.
\end{enumerate}
\end{lemma}
\begin{proof}
Relations are completely characterised by their principal images / preimages. See \ref{relationFromPrincipalImages}.
\end{proof}

\begin{proposition} \label{preorderGaloisCondition}
Let $a: \sSet{A,R} \to \sSet{B,S}$ and $a': \sSet{B,S} \to \sSet{A,R}$ be order-preserving generalised inverses on preorders. Then the following are equivalent:
\begin{enumerate}
\item $(a, a')$ is a Galois connection;
\item $aa' \subseteq R$ and $a'a \subseteq S^\transp$;
\item $\id_A \subseteq aa'R^\transp$ and $\id_B \subseteq a'aS$.
\end{enumerate}
If the orders are partial orders, then we do not need the additional assumption that $a, a'$ are generalised inverses.
\end{proposition}
\begin{proof}
$(1) \Rightarrow (2)$ is given by \ref{reflexiveGaloisCorollary}.

$(2) \Rightarrow (1)$ follows by transitivity, see \ref{transitiveRestrictiveLemma}.

$(2) \Leftrightarrow (3)$ is given by \ref{functionSubsetRelation}.

Now assume the orders are anti-symmetric. We need to show that $(2,3)$ imply that $a, a'$ are generalised inverses. First, by transitivity, we have
\[ R^\transp \subseteq aa'(R^2)^\transp \subseteq aa'R^\transp \qquad\text{and}\qquad S \subseteq a'aS^2 \subseteq a'aS. \]
Then, using the fact that $a$ and $a'$ are relation preserving,
\begin{align*}
\id &\subseteq R \subseteq aSa^\transp \subseteq aa'aSa^\transp \\
\id &\subseteq R^\transp \subseteq aa'R^\transp \subseteq aa'aS^\transp a^{\transp} \\
\id &\subseteq S \subseteq a'aS \subseteq a'aa'Ra^{\prime\transp} \\
\id &\subseteq S^\transp \subseteq a'R^\transp a^{\prime\transp} \subseteq a'aa'R^\transp a^{\prime\transp}.
\end{align*}
By anti-symmetry, we have
\[ \id \subseteq a'aa'(R\cap R^\transp)a^{\prime\transp} \subseteq a'aa'a^{\prime\transp} \qquad\text{and}\qquad \id \subseteq  aa'a(S\cap S^\transp)a^\transp \subseteq aa'aa^\transp. \]
Finally \ref{functionEqualityIdComparison} gives $a = aa'a$ and $a' = a'aa'$.
\end{proof}

\begin{proposition} \label{preorderGaloisIdentity}
Let $\sSet{A,R}$ and $\sSet{B,S}$ be preorders. Let $a: A\to B$ and $a': B\to A$ be functions. If $a,a'$ are generalised inverses and
\[ aS = Ra^{\prime \transp}, \]
then $(a, a')$ is a Galois connection.

If $\sSet{A,R}$ and $\sSet{B,S}$ are partial orders, then the assumption of generalised inverses is superfluous. 
\end{proposition}
So the identity $aS = Ra^{\prime \transp}$ is sufficient for two functions $a,a'$ between posets to form a Galois connection. Indeed this is often taken as the definition of a Galois connection for posets.
\begin{proof}
We need to prove that $a,a'$ are order-preserving, generalised inverses and that $aa', a'a$ are properly restrictive.

We first verify restrictivity. By reflexivity we have
\[ aa' \subseteq aSa' = Ra^{\prime \transp}a' \subseteq R \qquad\text{and}\qquad a'a \subseteq a'R^\transp a = S^\transp a^\transp a \subseteq S^\transp. \]
By \ref{transitiveRestrictiveLemma} $aa'$ and $a'a$ are properly restrictive.

Next we prove order-preservation $aa'\subseteq R$. We first prove the identities of \ref{expansiveRelationPreserving}:
\[ R^\transp \subseteq aa'(aa')^\transp R^\transp \subseteq aa'R^\transp (aa')^\transp R^\transp = aa' (aa'R)^\transp R^\transp \subseteq aa'R^\transp R^\transp = aa'R^\transp \]
\[ S \subseteq a'a(a'a)^\transp S \subseteq a'a S (a'a)^\transp S = a'a(a'aS^\transp)^\transp S \subseteq a'a(S^\transp)^\transp S = a'aS. \]
From this relation-preservation follows easily:
\[ R \subseteq R(aa')^\transp = (Ra^{\prime \transp})a^\transp = aSa^\transp \qquad\text{and}\qquad S \subseteq a'aS = a'(aS) = a'Ra^{\prime \transp}. \]

Finally, assuming $R,S$ are anti-symmetric, then $a, a'$ are generalised inverses by \ref{preorderGaloisCondition}.
\end{proof}

\begin{proposition}
Let $\sSet{A,R}$ and $\sSet{B,S}$ be relational structures.
\begin{enumerate}
\item If $A$ is a poset, then every residuated map $a: A \to B$ has a unique residual.
\item If $B$ is a poset, then every residual map $a': B \to A$ is the residual of a unique residuated map.
\end{enumerate}
\end{proposition}
\begin{proof}
(1) Let $a$ be a residuated map with residuals $a_1'$ and $a_2'$. Then
\[ \id_B \subseteq S \subseteq a_1'Ra_1^{\prime \transp} = a_1'aS = a_1'Ra_2^{\prime \transp}. \]
Similarly $\id_B \subseteq a_2'Ra_1^{\prime \transp}$, which we can transpose to get $\id_B \subseteq a_1'R^\transp a_2^{\prime \transp}$. Together this gives
\[ \id_B \subseteq a_1'(R\cap R^\transp)a_2^{\prime \transp} = a_1'a_2^{\prime \transp}. \]
We conclude using \ref{functionEqualityIdComparison}.

(2) Similar.
\end{proof}


\begin{proposition}
Let $\sSet{A,R}$ and $\sSet{B,S}$ be partial orders. Then every residuated map $a: A \to B$ has a unique residual and every residual map $a': B \to A$ is the residual of a unique residuated map.
\end{proposition}
\begin{proof}
Let $a$ be a residuated map with residuals $a_1'$ and $a_2'$. It is enough to show that $aa_1' = aa_2'$ and $a_1'a = a_2'a$. Indeed \ref{idempotentsInGreensClasses} then shows that $a_1'\mathcal{H}a_2'$ and by \ref{inversesIdempotentsDclass} this means that $a_1' = a_2'$.

To this end we combine $\id_A \subseteq aa_1'R^\transp$, $\id_A \subseteq $
\end{proof}

\subsubsection{Derived Galois connections}
\begin{lemma}
Let $(a, a')$ be a Galois connection between $\sSet{A,R}$ and $\sSet{B,S}$. Then $(a',a)$ is a Galois connection between the dual structures $\sSet{B^o,S^\transp}$ and $\sSet{A^o,R^\transp}$.
\end{lemma}

\begin{lemma}
Let $(a, a')$ be a Galois connection between posets $\sSet{A,R}$ and $\sSet{B,S}$ and $(b, b')$ a Galois connection between posets $\sSet{B,S}$ and $\sSet{A,R}$. Then
\begin{enumerate}
\item $(ab, b'a')$ is a Galois connection between $\sSet{A,R}$ and $\sSet{A,R}$;
\item $(ba, a'b')$ is a Galois connection between $\sSet{B,S}$ and $\sSet{B,S}$.
\end{enumerate}
\end{lemma}
\begin{proof}
We prove (1). The proof of (2) is identical.
By \ref{preorderGaloisIdentity} we just need to verify the Galois identity:
\[ abR = aRb^{\prime\transp} = Ra^{\prime\transp}b^{\prime\transp} = R(b'a')^\transp. \]
\end{proof}

\begin{proposition} \label{joinResiduatedMaps}
Let $L,M$ be lattices and $\{(f_i:L\to M, g_i: M\to L)\}_{i\in I}$ a set of Galois connections. Then $\Big(\bigvee_{i\in I}f_i, \bigwedge_{i\in I}g_i\Big)$ is a Galois connection.
\end{proposition}
The meet and join are taken pointwise.
\begin{proof}
By \ref{preorderGaloisIdentity} we just need to verify the Galois identity. Take arbitrary $x\in L, y\in M$. Then
\begin{align*}
\bigvee_{i\in I}f_i(x) \leq y &\iff \forall i\in I: f_i(x) \leq y \\
&\iff \forall i\in I: x \leq g_i(y) \\
&\iff x \leq \bigwedge_{i\in I} g_i(y).
\end{align*}
\end{proof}

\subsection{Monads and comonads}
\begin{definition}
Let $\sSet{A,R}$ be a relational structure and $f: A\to A$ a function. We call $f$ a
\begin{itemize}
\item \udef{monad} if there exists a relational structure $\sSet{B,S}$ and functions $a: A\to B$ and $a': B\to A$ such that $(a, a')$ is a Galois connection and $f = aa'$;
\item \udef{comonad} if $f = a'a$.
\end{itemize}
\end{definition}

TODO: restrictive means adjoint to identity!!!!!!!!

\begin{lemma}
Let $\sSet{A,R}$ be a relational structure and $f: A \to A$ a function. Then
\begin{enumerate}
\item $f$ is a monad \textup{if and only if}
\begin{enumerate}
\item $f$ is relation-preserving;
\item $f$ is idempotent: $f^2 = f$;
\item $f$ is left-restrictive: $f;R \subseteq R$;
\end{enumerate}
\item $f$ is a comonad \textup{if and only if}
\begin{enumerate}
\item $f$ is relation-preserving;
\item $f$ is idempotent: $f^2 = f$;
\item $f$ is right-restrictive: $R;f^\transp \subseteq R$.
\end{enumerate}
\end{enumerate}
\end{lemma}
\begin{proof}
(1) The direction $\Rightarrow$ is clear. Conversely, $\Leftarrow$, we claim the inclusion $\iota: \im(f) \hookrightarrow A$ is residuated with residual $f: A\to \im(f)$.

Indeed, $\iota$ is clearly relation-preserving. Take arbitrary $f(x)\in \im(f)$ and arbitrary $y\in A$. Then 
\begin{align*}
(\iota f \iota)(f(x)) &= \iota(f^2(x)) = \iota(f(x)) \\
(f \iota f)(y) &= f^2(y) = f(y),
\end{align*}
so $\iota f \iota = \iota$ and $f\iota f = f$, meaning $f$ and $\iota$ are generalised inverses.

Finally we check
\begin{align*}
\iota f (R|^{\im f}_{\im(f)}) &\subseteq \iota f \iota (R|^{\im f}_{\im(f)}) = \iota (R|^{\im f}_{\im(f)}) \subseteq R|^{\im f}_{\im(f)} \\
f \iota R^\transp &= f R^\transp = (R;f^\transp)^\transp \subseteq R^\transp.
\end{align*}

(2) Similar.
\end{proof}

Idempotent => image set is set of fixed points.

\begin{proposition}
When is a subset $X\subseteq A$ the image of a (co)monad? For posets: enough that $\upset x \cap X$ has bottom.
\end{proposition}

\begin{proposition}
Bijection monads - images of monads.
\end{proposition}

\begin{definition}
Completeness
\end{definition}

\begin{proposition}
Let $\sSet{A,R}$ be a relational structure and $f: A\to A$ a function. Then
\begin{enumerate}
\item if $f$ is a monad, then $R; f^\transp = f;R;f^\transp$;
\item if $f$ is a comonad, then $f;R = f;R;f^\transp$.
\end{enumerate}
\end{proposition}
\begin{proof}
(1) We calculate
\[ f;R;f^\transp \subseteq R;f^\transp \subseteq f;R;(f;f)^\transp = f;R;f^\transp, \]
where we have first used left-restrictivity, then relation preservation and finally idempotency.

(2) Similarly we have
\[ f;R;f^\transp \subseteq f;R \subseteq f;f;R;f^\transp = f;R;f^\transp. \]
\end{proof}
\begin{corollary} \label{closureInclusionLemma}
Let $\sSet{A,R}$ be a relational structure and $X,Y\subseteq A$. Then $X\subseteq \Closure_R(Y) \iff \Closure_R(X)\subseteq \Closure_R(Y)$.
\end{corollary}

\subsection{Inclusion-preserving functions on powersets}
\url{file:///C:/Users/user/Downloads/(Mathematics%20and%20Its%20Applications%20565)%20Marcel%20Ern%C3%A9%20(auth.),%20K.%20Denecke,%20M.%20Ern%C3%A9,%20S.%20L.%20Wismath%20(eds.)%20-%20Galois%20Connections%20and%20Applications-Springer%20Netherlands%20(2004).pdf}

\url{https://sciendo.com/pdf/10.2478/ausm-2014-0019}

\begin{proposition} \label{polarsGaloisConnection}
Let $R$ be a relation on $(A,B)$. Then the polar functions
\[ \powerset(A)\to\powerset(B)^o: X\mapsto X^R \qquad\text{and}\qquad \powerset(B)^o\to\powerset(A): X\mapsto {^RX} \]
form a Galois connection. Every antitone Galois connection between powersets is of this form, for some relation.
\end{proposition}
\begin{proof}
As $\sSet{\powerset(A), \subseteq}^o$ and $\sSet{\powerset(B), \subseteq}$ are posets, by \ref{preorderGaloisIdentity} we just need to verify the Galois identity: $\forall X\in \powerset(A), Y\in\powerset(B):$ we have
\[ X^R \subseteq^\transp Y \iff X^R \supseteq Y \;\iff\; \Big[ \forall x\in X: \forall y\in Y: xRy \Big] \;\iff\; X \subseteq {^RY}. \]

We can give the same calculation using the language of \ref{polarsCartesianProduct}:
\[ X^R \subseteq^\transp Y \iff X\times Y \subseteq R \iff Y\times X \subseteq R^\transp \iff X \subseteq Y^R. \]

TODO semilattice morphism
\end{proof}
\begin{proposition} \label{imagePreimageGaloisConnection}
Let $R$ be a relation on $(A, B)$. Then
\begin{enumerate}
\item the image function is part of a Galois connection
\[ \powerset(A)\to\powerset(B): X\mapsto X_R \qquad\text{and}\qquad \powerset(B)\to\powerset(A): X\mapsto {^{\overline{R}}(X^c)}; \]
\item the preimage function is part of a Galois connection
\[ \powerset(B)\to\powerset(A): X\mapsto {_RX} \qquad\text{and}\qquad \powerset(A)\to\powerset(B): X\mapsto (X^c)^{\overline{R}}. \]
\end{enumerate}
These Galois connections are equivalent by replacing $R \leftrightarrow R^\transp$. Every isotone Galois connection between powersets is of this form, for some relation.
\end{proposition}
\begin{proof}
We compose the polar Galois connection of $\overline{R}$ with the Galois connection of complementation to get
\[ X_R = (X^{\overline{R}})^c \subseteq Y \iff X^{\overline{R}} \supseteq Y^c \iff X \subseteq {^{\overline{R}}(Y^c)}, \]
by \ref{imageComplementaryRelation}.

Similarly we have
\[ {_RX} = ({^{\overline{R}}X})^c \subseteq Y \iff {^{\overline{R}}}X \supseteq Y^c \iff X \subseteq (Y^c)^{\overline{R}}. \]
\end{proof}
\begin{corollary} \label{functionImagePreimageGaloisConnection}
Let $A,B$ be sets and $f:A\to B$ a function. Then
\begin{enumerate}
\item the functions
\[ f^\imf: \powerset(A)\to\powerset(B) \qquad\text{and}\qquad f^\preimf: \powerset(B)\to\powerset(A) \]
form a Galois connection $(f^\imf, f^\preimf)$;
\item the function $f^\preimf: \powerset(B)\to\powerset(A)$ is also a lower adjoint and thus preserves unions.
\end{enumerate}
\end{corollary}
\begin{proof}
(1) We just need to prove that, for arbitrary $Y\in \powerset(B)$, ${^{\overline{f}}(Y^c)} = {_fY} = f^\preimf[Y]$. Indeed, using \ref{imageComplementaryRelation} and \ref{imagePreimageUniqueness}, we have
\[ {^{\overline{f}}(Y^c)} = \big(^{\overline{f}}(Y^c)\big)^{cc} = \big(_f(Y^c)\big)^c = {_f(Y^{cc})} = {_fY} = f^\preimf[Y], \]
where we have used that $f$ is total and functional.

(2) The preimage map it the image under the transpose.
\end{proof}
We can also directly verify the Galois identity \ref{preorderGaloisIdentity}:
\[ X_f \subseteq Y \implies X \subseteq X_{f;f^\transp} \subseteq Y_{f^{\transp}} \implies X_f \subseteq Y_{f^{\transp};f} \subseteq Y, \]
using \ref{totalityEquivalences} and \ref{relationTimesTransposeSubsetIdentity}.

\begin{proposition} \label{productGaloisConnections}
Let $X,Y$ be sets and $A\subseteq X$. Then
\begin{enumerate}
\item the functions
\[ \powerset(Y)\to \powerset(X\times Y): B \mapsto A\times B \qquad\text{and}\qquad \powerset(X\times Y)\to \powerset(Y): C\mapsto A^C \]
form a Galois connection.
\end{enumerate}
\end{proposition}
\begin{proof}
(1) We need to prove $A\times B \subseteq C \iff B\subseteq A^C$ for all $B\subseteq Y$ and $C\subseteq X\times Y$. Indeed we have
\begin{align*}
A\times B \subseteq C &\iff \forall x\in A, \forall y\in B: \; (x,y)\in C \\
&\iff \forall y\in B, \forall x\in A: \; xCy \\
&\iff \forall y\in B: y\in A^C \\
&\iff B \subseteq A^C.
\end{align*}
\end{proof}

\subsubsection{Closure and dual closure}

\begin{corollary} \label{upDownsetUnionIntersection}
Let $\sSet{P,\Yleft}$ be an ordered set and $\mathcal{A}\subseteq \powerset(P)$. Then
\begin{enumerate}
\item $\upset \bigcup \mathcal{A} = \bigcup_{A\in \mathcal{A}} \upset A$ and $\downset \bigcup \mathcal{A} = \bigcup_{A\in \mathcal{A}} \downset A$;
\item $\upset \bigcap \mathcal{A} \subseteq \bigcap_{A\in \mathcal{A}} \upset A$ and $\downset \bigcap \mathcal{A} \subseteq \bigcap_{A\in \mathcal{A}} \downset A$;
\item $\upset \bigcap_{A\in \mathcal{A}} \upset A = \bigcap_{A\in \mathcal{A}} \upset A$ and $\downset \bigcap_{A\in \mathcal{A}} \downset A = \bigcap_{A\in \mathcal{A}} \downset A$.
\end{enumerate}
\end{corollary}
\begin{proof}
(1) We calculate using \ref{unionIntersectionLabelSet}:
\[ \upset \bigcup \mathcal{A} = \bigcup_{x\in \bigcup\mathcal{A}} \upset x = \bigcup_{A\in \mathcal{A}}\bigcup_{x\in A}\upset x = \bigcup_{A\in \mathcal{A}} \upset A. \]

(2) Again we calculate using \ref{unionIntersectionLabelSet}:
\[ \upset \bigcap \mathcal{A} = \bigcup_{x\in \bigcap\mathcal{A}} \upset x \subseteq \bigcap_{A\in \mathcal{A}}\bigcup_{x\in A}\upset x = \bigcap_{A\in \mathcal{A}} \upset A. \]

(3) We calculate using (2) and the fact that closures are idempotent:
\[ \bigcap_{A\in \mathcal{A}} \upset A = \bigcap_{A\in \mathcal{A}} \upset\upset A \supseteq \upset \bigcap_{A\in \mathcal{A}} \upset A \supseteq \bigcap_{A\in \mathcal{A}} \upset A. \]
\end{proof}
Also t
\begin{corollary} \label{unionIntersectionDownUpSets}
Let $P$ be an ordered set and $\{Q_i\}_{i\in I}$ be a set of down sets in $P$. Then
\begin{enumerate}
\item $\bigcup Q_i$ is a down set;
\item $\bigcap Q_i$ is a down set.
\end{enumerate}
The same is true for up sets.
\end{corollary}
\begin{proof}
This follows from $\downset \bigcup Q_i = \bigcup \downset Q_i = \bigcup Q_i$ and $\downset \bigcap Q_i \subseteq \bigcap \downset Q_i = \bigcap Q_i$ by \ref{TODO}.
\end{proof}

\subsubsection{Maps and polars}

\begin{proposition} \label{imagePolars}
Let $\sSet{A, R}$ and $\sSet{B, S}$ be relational structures, $f: A\to B$ a relation-preserving function and $X\subseteq A$ a subset. Then
\begin{enumerate}
\item $f^\imf\big(X^R\big) \subseteq f^\imf(X)^S$;
\item $f^\imf\big(\max(X)\big) \subseteq \max\big(f^\imf(X)\big)$;
\item $f^\imf\big(\min(X)\big) \subseteq \min\big(f^\imf(X)\big)$.
\end{enumerate}
For relation-reflecting functions we have reversed inclusions. For relation embeddings the inclusions become equalities.
\end{proposition}
We also have $f^\imf\big(X^{R^\transp}\big) \subseteq f^\imf(X)^{S^\transp}$ by \ref{relationPreserving}.
\begin{proof}
(1) We calculate, using \ref{boundsFromPrincipalImages} and \ref{functionImagesPreimagesAndPrincipalImages},
\[ f^\imf\big(X^R\big) = f^\imf\Big(\bigcap_{x\in X}xR\Big) \subseteq \bigcap_{x\in X}f^\imf(xR) \subseteq \bigcap_{x\in X}Sf(x) = \bigcap_{y\in f^\imf(X)} Sy =  f^\imf(X)^S. \]

(2) We calculate
\[ f[\max(X)] = f[X\cap X^R] \subseteq f[X]\cap f[X^R] \subseteq f[X]\cap f[X]^S \cap \im(f) = f[X]\cap f[X]^S = \max(f[X]). \]

(3) Dual to (2).
\end{proof}
\begin{corollary} \label{relationIsomorphismSamePolars}
Let $\sSet{A, R}$ and $\sSet{B, S}$ be relational structures, $f: A\to B$ a bijective relation-embedding and $X\subseteq A$ a subset. Then $f^\imf(X^R) = f^\imf(X)^S$.
\end{corollary}
\begin{proof}
We already know that $f^\imf\big(X^R\big) \subseteq f^\imf(X)^S$, so we just need to prove the other inclusion.

Since $f^{-1}$ is relation preserving, we have $(f^{-1})^\imf\big(f^\imf(X)^S\big) \subseteq (f^{-1}\circ f)^\imf(X)^R = X^R$, thus, by \ref{monotonicityImage}, 
\[ f^\imf(X)^S = (f\circ f^{-1})^\imf\big(f^\imf(X)^S\big) = f^\imf\Big((f^{-1})^\imf\big(f^\imf(X)^S\big)\Big) \subseteq f^\imf\big(X^R\big). \]
\end{proof}

We cannot say anything about the supremum or infimum for general relation-preserving functions, because $f[X^R] \subseteq f[X]^S$ implies $f[X^R]^{S^\transp} \supseteq (f[X]^S)^{S^\transp}$, so the calculation would be
\[ f[\sup(X)] = f[X^R\cap (X^R)^{R^\transp}] \subseteq f[X]^S \cap f[(X^R)]^{S^\transp} \supseteq f[X]^S \cap (f[X]^S)^{S^\transp} = \sup(f[X]), \]
from which we cannot conclude anything.

\begin{proposition} \label{residuationPreservesSupInf}
Let $\sSet{A, R}$ and $\sSet{B, S}$ be relational structures, $X\subseteq A$ a subset and $f,g : A\to B$ functions.
\begin{enumerate}
\item If $f$ is a residuated map, then $f[\sup(X)] \subseteq \sup(f[X])$.
\item If $g$ is a residual map, then $g[\inf(X)] \subseteq \inf(g[X])$.
\end{enumerate}
\end{proposition}
\begin{proof}
(1) Let $f': B\to A$ be a residual of $f$. From above we see that it is enough to have $f[X^R]^{S^\transp} \subseteq (f[X]^S)^{S^\transp}$.

We use $ff'R \subseteq R$ and $f'fS^\transp \subseteq S^\transp$, to get $X^{ff'R} \subseteq X^{R}$ and $X^{f'fS^\transp} \subseteq X^{S^\transp}$. This allows us to make the following calculation:
\begin{align*}
f[X^R]^{S^\transp} &\subseteq f[X^{ff'R}]^{S^\transp} \\
&\subseteq f[f'[f[X]^S]]^{S^\transp} \\
&= (f[X]^S)^{f'fS^\transp} \\
&\subseteq (f[X]^S)^{S^\transp}.
\end{align*}

(2) The proof in this case is similar. Let $g^-: B\to A$ be a residuated map of which $g$ is a residual. Now it is enough to have $g[X^{R^\transp}]^{S} \subseteq (g[X]^{S^\transp})^{S}$.

Using $X^{g^-gS}\subseteq X^S$ and $X^{gg^-R^\transp} \subseteq X^{R^\transp}$, we calculate
\begin{align*}
g[X^{R^\transp}]^{S} &\subseteq f[X^{gg^-R^\transp}]^{S} \\
&\subseteq g[g^-[g[X]^{S^\transp}]]^{S} \\
&= (g[X]^{S^\transp})^{g^-gS} \\
&\subseteq (g[X]^{S^\transp})^{S}.
\end{align*}
\end{proof}

\begin{proposition} \label{GaloisConnectionLatticePreservation}
Let $P, Q$ be partial orders.
\begin{enumerate}
\item If $P$ is a complete $\vee$-semilattice, then an order-preserving function $f: P\to Q$ is residuated \textup{if and only if} $f$ preserves joins. The residual is given by
\[ f^+: Q\to P: y\mapsto \bigvee f^{-1}[\downset y]. \]
\item If $Q$ is a complete $\wedge$-semilattice, then an order-preserving function $g: Q\to P$ is a residual map \textup{if and only if} $g$ preserves meets. It is the residual of the residuated map
\[ g^-: P\to Q: x\mapsto \bigwedge g^{-1}[\upset x]. \]
\end{enumerate}
\end{proposition}
\begin{proof}
Both direction $\Rightarrow$ are given by \ref{residuationPreservesSupInf}.

\ref{closureInclusionLemma}
\end{proof}



\begin{proposition} \label{upsetDownsetConnections}
Let $P$ be a poset. Then
\begin{enumerate}
\item if $\mathcal{J}\subseteq \powerset(P)$ is the set of subsets of $P$ that have a join, then
\[ \mathcal{J} \to P: A\mapsto \bigvee A \qquad\text{and}\qquad P\to \mathcal{J}: x\to \downset x \]
form a Galois connection and the image in $\mathcal{J}$ is the set of principal down sets;
\item if $\mathcal{M}\subseteq \powerset(P)$ is the set of subsets of $P$ that have a meet, then
\[ P\to \mathcal{M}^o: x\to \upset x \qquad\text{and}\qquad \mathcal{M}^o \to P: A\mapsto \bigwedge A \]
form a Galois connection and the image in $\mathcal{M}$ is the set of principal up sets. 
\end{enumerate}
\end{proposition}
\begin{proof}
(1) We have, for all $A\in \mathcal{J}$ and $x\in P$,
\[ \bigvee A \leq x \qquad \iff\qquad A\subseteq \downset x. \]
(2) We have, for all $A\in \mathcal{M}$ and $x\in P$,
\[ \upset x \supseteq A \qquad \iff\qquad x\leq \bigwedge A. \]
\end{proof}

TODO:
\[ f(x) \leq y \qquad\iff\qquad x\in \downset f^{\preimf}(y). \]

\begin{proposition} \label{GaloisConnectionLatticePreservation}
Let $P, Q$ be partial orders.
\begin{enumerate}
\item If $P$ is a complete $\vee$-semilattice and $f: P\to Q$ a function, then the following are equivalent:
\begin{enumerate}
\item $f$ has an upper adjoint;
\item $f$ is a lower adjoint;
\item $f$ preserves joins;
\item the inverse image under $f$ of a principal down set is a principal down set.
\end{enumerate}
In this case the upper adjoint is given by
\[ f^+: Q\to P: y\mapsto \bigvee f^{\preimf}(\downset y). \]
\item If $Q$ is a complete $\wedge$-semilattice and $g: Q\to P$ a function, then the following are equivalent:
\begin{enumerate}
\item $g$ has a lower adjoint;
\item $g$ is an upper adjoint;
\item $g$ preserves meets;
\item the inverse image under $f$ of a principal up set is a principal up set.
\end{enumerate}
In this case the lower adjoint is given by
\[ g^-: P\to Q: x\mapsto \bigwedge g^{\preimf}(\upset x). \]
\end{enumerate}
\end{proposition}
\begin{proof}
\begin{enumerate}
\item $(a)\Rightarrow (b)$ By definition.

$(b) \Rightarrow (c)$ By \ref{residuationPreservesSupInf}.

$(c) \Rightarrow (d)$ Assume $f$ preserves joins. By \ref{upsetDownsetConnections} we need to show that $\downset \bigvee f^{\preimf}(\downset y) = f^{\preimf}(\downset y)$ for all $y\in Q$. In fact it is enough to prove $\downset \bigvee f^{\preimf}(\downset y) \subseteq f^{\preimf}(\downset y)$. We calculate
\begin{align*}
f^{\imf}\big(f^\preimf(\downset y)\big) \subseteq \downset y  \iff& \bigvee f^{\imf}\big(f^\preimf(\downset y)\big) \leq y \\
\iff& f\big(\bigvee f^\preimf(\downset y)\big) \leq y \\
\iff& f\big(\bigvee f^\preimf(\downset y)\big) \in \downset y \\
\iff& f^\imf\big\{\bigvee f^\preimf(\downset y)\big\} \subseteq \downset y \\
\iff& \big\{\bigvee f^\preimf(\downset y)\big\} \subseteq f^\preimf(\downset y) \\
\iff& \big\{\bigvee f^\preimf(\downset y)\big\} \subseteq \upset f^\preimf(\downset y) \\
\iff& \upset\bigvee f^\preimf(\downset y) \subseteq \upset f^\preimf(\downset y) \\
\iff& \upset\bigvee f^\preimf(\downset y) \subseteq f^\preimf(\downset y),
\end{align*}
using \ref{functionImagePreimageGaloisConnection}, \ref{upsetDownsetConnections}, preservation of joins, \ref{closurePreimageRelationPreservingFunctions} and \ref{closureInclusionLemma}.

$(d) \Rightarrow (a)$ Take arbitrary $x\in P$ and $y\in Q$.
By \ref{upsetDownsetConnections}, the assumption implies $f^{\preimf}(\downset y) = \downset \bigvee f^{\preimf}(\downset y)$, so we can calculate
\begin{align*}
f(x) \leq y &\iff f^\imf\big(\{x\}\big) \subseteq \downset y \\
&\iff \{x\} \subseteq f^\preimf(\downset y) \\
&\iff \downset x \subseteq f^\preimf(\downset y) \\
&\iff \downset x \subseteq \downset \bigvee f^\preimf(\downset y) \\
&\iff x \leq \bigvee f^\preimf(\downset y),
\end{align*}
using \ref{closureInclusionLemma}. Thus $f$ has an upper adjoint.

\item Dual.
\end{enumerate}
\end{proof}

\begin{corollary} \label{polarOfUnion}
Let $R$ be a relation on $(A,B)$ and $\mathcal{E}\subseteq \powerset(A)$. Then
\[ \left(\bigcup\mathcal{E}\right)^R = \bigcap\setbuilder{{X^R}}{X\in \mathcal{E}}. \]
\end{corollary}
\begin{proof}
The proposition applied to the Galois connection of polar maps, in \ref{polarsGaloisConnection}.
\end{proof}

\begin{corollary} \label{completeSublattice}
Let $P$ be a partial order and $D\subseteq P$ a subset.
\begin{enumerate}
\item If $P$ is a complete lattice and $\forall S\subseteq D:\; \bigvee_P S \in D$, then $D$ is a complete sublattice and there exists a monad $f: P\to D$ such that for all $S\subseteq D$
\[ \bigvee_D S = \bigvee_P S \qquad\text{and}\qquad \bigwedge_D S = f\left[\bigwedge_P S\right]. \]
\item If $P$ is a complete lattice and $\forall S\subseteq D:\; \bigwedge_P S \in D$, then $D$ is a complete sublattice and there exists a comonad $f: P\to D$ such that for all $S\subseteq D$
\[ \bigvee_D S = f\left[\bigvee_P S\right] \qquad\text{and}\qquad \bigwedge_D S = \bigwedge_P S. \]
\end{enumerate}
\end{corollary}
\begin{proof}
(1) Saying $D$ is closed under arbitrary joins is equivalent to saying the inclusion $D\hookrightarrow P$ preservis joins. By the proposition this means the inclusion is residuated. The rest follows from TODO
\end{proof}
TODO: swap monad - comonad??

\begin{proposition} \label{joinMeetUnion}
Let $P$ be a poset. Then
\begin{enumerate}
\item if $\{A_i\}_{i\in I}\subseteq \mathcal{J}$ is a set of subsets such that $\bigcup_{i\in I}A_i \in \mathcal{J}$, then $\big\{\bigvee A_i\big\}_{i\in I} \in \mathcal{J}$ and
\[ \bigvee \Big(\bigcup_{i\in I}A_i\Big) = \bigvee_{i\in I}\Big(\bigvee A_i\Big); \]
\item if $\{A_i\}_{i\in I}\subseteq \mathcal{M}$ is a set of subsets such that $\bigcup_{i\in I}A_i \in \mathcal{M}$, then $\big\{\bigwedge A_i\big\}_{i\in I} \in \mathcal{M}$ and
\[ \bigwedge \Big(\bigcup_{i\in I}A_i\Big) = \bigwedge_{i\in I}\Big(\bigwedge A_i\Big). \]
\end{enumerate}
\end{proposition}
\begin{proof}
Application of \ref{GaloisConnectionLatticePreservation} to \ref{upsetDownsetConnections}.
\end{proof}

\subsubsection{Sets of functions and relations}
\begin{proposition} \label{setOfFunctionsToRelationGaloisConnection}
Let $X$ be a set. The function
\[ m: \sSet{\powerset(X\to X), \subseteq} \to \sSet{\powerset(X^2), \subseteq}: F \mapsto \setbuilder{(x,y)\in X^2}{\exists f\in F: \; f(x) = y} \]
is residuated.
\end{proposition}
\begin{proof}
It preserves joins ($\cup$).
\end{proof}

\begin{proposition}
Consider the function
\[ m: \powerset(X\to X) \to \powerset(X^2): F \mapsto \setbuilder{(x,y)\in X^2}{\exists f\in F: \; f(x) = y}. \]
\begin{enumerate}
\item $m(F)$ is transitive \textup{if and only if} $F$ is closed under composition;
\item $m(F)$ is reflexive \textup{if and only if} $F$ contains $\id$.
\end{enumerate}
\end{proposition}

\section{Galois connections}
\begin{proposition}
Let $\sSet{A,R'}$ and $\sSet{B, S'}$ be relational structures. Let $R\subseteq R'$ and $S\subseteq S'$ be idempotent, total and functional subsets. Then there exist functions $f: A\to B$ and $g: B\to A$ such that $R = f;g$ and $S = g;f$. We have
\begin{enumerate}
\item $f,g$ are generalised inverses;
\item $g;R = S;g$ and $R;f = f;S$;
\item $f$ and $g$ are relation preserving;
\item $f;S \subseteq R;g^\transp$ and $f^\transp ;R \subseteq S;g$;
\item $g;R;g^\transp = g;f;S;(g;f)^\transp$ and $f;S;f^\transp = f;g;R;(f;g)^\transp$;
\item $g;R;(fg)^\transp = S;f^\transp$ and $R;g^\transp = f;S;(gf)^\transp$.
\end{enumerate}
\end{proposition}
\begin{proof}
(1) TODO ref.

(2) We have $g;R = g;(f;g) = (g;f);g = S;g$ and  $R;f = (f;g);f = f;(g;f) = f;S$.

(3) From points (2), (3) using \ref{relationPreserving}.

(4) We have $f;S \subseteq f;S;g;g^\transp = f;g;f;g;g^\transp = R;g^\transp$.

(5) We have $g;R;g^\transp \subseteq g;f;S;f^\transp;g^\transp \subseteq g;f;g;R;g^\transp; f^\transp; g^\transp = g;R;g^\transp$.

(6) We have (using (5)), $g;R;(fg)^\transp = g;f;S;(gf)^\transp;f^\transp = S;f^\transp$ and $f;S;(gf)^\transp = f;g;R;(fg)^\transp; g^\transp = R;g^\transp$.
\end{proof}

\section{The category of relational structures}
\subsection{Products}
\begin{proposition}
The product is the Cartesian product with pointwise relation.
\end{proposition}

