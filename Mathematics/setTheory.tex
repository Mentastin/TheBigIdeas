\chapter{Set theory}
\url{math.colorado.edu/~monkd}

\url{philsci-archive.pitt.edu/1372/1/SetClassCat.PDF}

\url{https://mathoverflow.net/questions/22635/can-we-prove-set-theory-is-consistent}

Rethinking set theory - Leinster




\section{Some initial ideas}
\begin{enumerate}
\item Sets are defined by what is in them (extensionality);
\item Sets can be created by specifying a condition: for any definite condition $P$ there is a set
\[ A = \{x\;|\;P(x)\} \]
defined by $x\in A \iff P(x)$. This is de \udef{general comprehension principle}.
\end{enumerate}
\subsection{Russell's paradox}
Russell showed that the general comprehension principle cannot be valid. Consider
\[ R = \{x\;|\; x\;\text{is a set and}\;x\notin x\}. \]
Then $R\in R$ if and only if $R\notin R$.

There have been several proposed solutions:
\begin{enumerate}
\item We can restrict the general comprehension principle to only separation, which means that we can only apply comprehension to elements that are already in a set. In other words, we do not write
\[ \setbuilder{x}{P(x)} \qquad \text{but instead}\qquad \setbuilder{x\in B}{P(x)}\qquad \text{for some set $B$}. \]
For this to work clearly there must not be a set containing all objects in the universe. We could say the universe is too big to fit into a set.
\item We can restrict the type of objects that are put into the same set: We can put two objects that are not sets in the same set, but not a set and an object that is not a set. Such objects have type $0$. Sets of these objects have type $1$. Sets of these sets have type $2$ etc. We then say we can only form sets containing only objects of the same type. Such a set is of a type one higher. This is the essential idea behind type theory.
\end{enumerate}
In these notes we will use the first solution.

\subsection{The axiomatic setup}
For the setup of set theory we have:
\begin{enumerate}
\item A \udef{domain} or \udef{universe} $\mathcal{W}$ of objects. Some of these objects are sets. Some of these object are not sets. These are called \udef{atoms} or \udef{urelements}. A universe is called \udef{pure} if it contains only sets.
\item We have a (logical) language (usually first order logic) which allows us to express definite conditions using which we can define sets using comprehension. We assume this logical language has
\begin{enumerate}
\item a notion of identity, i.e.\ $=$;
\item a definite predicate giving sethood:
\[ \Set(x) \iff \text{$x$ is a set}; \]
\item a definite binary predicate giving membership, denoted $\in$:
\[ x\in y \iff \text{$\Set(y)$ and $x$ is a member of $y$}. \]
\end{enumerate}
\end{enumerate}

TODO purity?

\begin{note}
We abbreviate
\begin{itemize}
\item $\forall x: x\in X \implies (\ldots)$ by $\forall x\in X: (\ldots)$;
\item $\exists x: x\in X \land (\ldots)$ by $\exists x\in X: (\ldots)$.
\end{itemize}
This can be generalised to the abbreviation, for some definite condition $P$, of
\begin{itemize}
\item $\forall x: P(x) \implies (\ldots)$ by $\forall P(x): (\ldots)$;
\item $\exists x: P(x) \land (\ldots)$ by $\exists P(x): (\ldots)$.
\end{itemize}
For formal proofs it is often useful to write out the abbreviations.
\end{note}

\subsubsection{Definitions of some set-theoretic operations}
TODO: setbuilder (with expressions in creation part) and $\{\}$.
\begin{definition}
Let $A,B$ be sets. We define
\begin{itemize}
\item the \udef{emptyset}
\[ \emptyset \defeq \setbuilder{x}{x\neq x}; \]
\item the \udef{set difference} of $A$ and $B$ or \udef{relative complement} of $B$ in $A$
\[ A\setminus B \defeq \setbuilder{x}{x\in A \land x\notin B}; \]
\item the \udef{powerset} of $A$
\[ \powerset(A) \defeq \setbuilder{X}{X\subseteq A}; \]
\item the \udef{union} of $A$
\[ \bigcup A \defeq \setbuilder{x}{\exists X\in A: x\in X}; \]
\item the \udef{intersection} of $A$
\[ \bigcap A \defeq \setbuilder{x}{\forall X\in A: x\in X}; \]
\end{itemize}
We introduce some abbreviations for the union and intersection:
\begin{itemize}
\item $A\cup B \defeq \bigcup\{A,B\}$;
\item $\bigcup_\Phi \sigma \defeq \bigcup\setbuilder{\sigma(x)}{\Phi(x)}$.
\end{itemize}
And similarly for the intersection.
\end{definition}

\begin{lemma} \label{elementSubsetUnion}
Let $A,B$ be collections. Then
\[ A \in B \implies A\subseteq \bigcup B \]
\end{lemma}

\section{The Zermelo axioms}
The \udef{Zermelo axioms} are the following, except for the axiom of choice which will be discussed later:
\begin{enumerate}[(I)]
\item \textbf{Axiom of extensionality}: for any two sets $A,B$:
\[ A=B \;\iff\; \left[\forall x:x\in A\iff x\in B\right]. \]
\item \textbf{Axiom of elementary sets} or the \textbf{emptyset and pairset axioms}:
\begin{enumerate}[(1)] \setcounter{enumii}{-1}
\item There exists a set $\emptyset$ that has no members.
\item For any object $x$ in the domain, there exists a set $\{x\}$ containing only $x$.
\item For any two objects $x,y$ in the domain, there exists a set $A = \{x,y\}$ containing only $x$ and $y$:
\[ t\in A \iff [t=x\;\lor t=y]. \]
\end{enumerate}
\begin{note}
A set with only one element is a \udef{singleton}. A set with two elements is a \udef{doubleton}. The existence of singletons follows from the existence of doubletons by setting $x=y$, so part (1) is superfluous.
\end{note}
\item \textbf{Axiom of separation}: for each set $A$ and each unitary predicate $P$, there exists a set $B$ such that
\[ x\in B \iff [x\in A \land P(x)]. \]
We write
\[ B = \{x\in A\;|\; P(x)\}. \]
\begin{note}
When working in a first-order system we do not have variables for predicates and the axiom of separation becomes more properly an \emph{axiom schema}: for every property definable by a first-order formula we add a new axiom with this formula substituted for $P$.
\end{note}
\begin{note}
\begin{proposition}
Let $A$ be a set. The set
\[ r(A) \defeq \{ x\in A\;|\; x\notin x \} \]
is not a member of $A$.
\end{proposition}
\begin{corollary}
There is no set of sets.
\end{corollary}
\end{note}
\item \textbf{Power set axiom}: for each set $A$ there exists a set $\powerset(A)$ whose members are the subsets of $A$. This set is called the \udef{power set} of $A$.
\begin{note}
For this we need the definition of a \udef{subset}. We define
\[ X\subseteq A \quad \Leftrightarrow_\text{def} \quad \forall t:t\in X\implies t\in A  \]
and say that $X$ is a subset of $A$. Then $A$ is a \udef{superset} of $X$. We also write $X\subset A$. If we want to emphasise that $X\neq A$, we write $X\subsetneq A$. In this case $X$ is a \udef{proper subset}.
\begin{lemma}
Let $A$ and $B$ be sets. Then $A = B$ \textup{if and only if}
\[ (A\subseteq B) \land (B\subseteq A). \]
\end{lemma}
\end{note}
Then we can define the power set of $A$ as
\[ \powerset(A) \defeq \{X \;|\; \Set(X) \land (X\subseteq A)\}. \]
\item \textbf{Union set axiom}: for every object $\mathcal{E}$, there exists a set $\bigcup \mathcal{E}$ whose members are the members of $\mathcal{E}$:
\[ t\in \bigcup\mathcal{E} \iff \exists X\in \mathcal{E}:t\in X \]
\begin{note}
\begin{lemma}
Let $a$ be an atom. Then
\[ \bigcup a = \emptyset. \]
Also
\[ \bigcup \emptyset = \emptyset. \]
\end{lemma}
\end{note}
\begin{note}
Given two objects $A,B$, we define
\[ A\cup B \defeq \bigcup \{ A,B \}. \]
\end{note}
\item \textbf{Axiom of infinity}: there exists a set $I$ which contains
\begin{itemize}
\item the empty set $\emptyset$ and
\item the singleton of each of its members:
\[ \forall x: \quad x\in I \implies \{x\}\in I. \]
\end{itemize}
\begin{note}
A possible version of the set $I$ is
\[ I_0 = \{ \emptyset, \{\emptyset\}, \{\{\emptyset\}\}, \{\{\{\emptyset\}\}\}, \ldots \} \]
and indeed we need $I_0\subset I$, but we have not excluded the possibility that $I$ contains other elements.
\end{note}
\end{enumerate}

\section{Von Neumann-Bernays-GÃ¶del and Morse-Kelley set theory}
NBG / MK are axiomatic systems in first-order predicate logic with equality (TODO: remove equality, made definition (?), in which case make equivalence relation a lemma. Check definition of empty class and universe class.), whose only primitive notion is the membership relation $\in$. (TODO sometimes class is called primitive notion as well (?))

TODO: replacement, infinity and foundation.

\subsection{Classes}
\begin{definition}
We consider a universe $\mathcal{W}$. Let $x$ be an object in $\mathcal{W}$. Then we call $x$
\begin{itemize}
\item a \udef{class} if $\exists y: y\in x$;
\item an \udef{element} if $\exists y: x\in y$;
\item a \udef{set} if it is both a class and an element;
\item a \udef{proper class} if it is a class and not an element (or, equivalently, a class and not a set).
\end{itemize}
We define the predicates
\begin{itemize}
\item $\Class(x) \defequiv \exists y: y\in x$;
\item $\Element(x) \defequiv \exists y: x\in y$;
\item $\Set(x) \defequiv \exists y,z: y\in x \land x\in z$;
\item $\ProperClass(x) \defequiv (\exists y: y \in x)\land \neg (\exists z: x\in z)$.
\end{itemize}
\end{definition}

TODO: emptyset is not class or set?

\begin{enumerate}[(A)]
\item \textbf{Axiom of extensionality}: For any two classes $A,B$:
\[ A=B \;\iff\; \left[\forall x:x\in A\iff x\in B\right]. \]
\item \textbf{Axiom of class existence}: Let $\phi(x)$ be a proposition with free variable $x$. Then there exists a class $\setbuilder{x}{\phi(x)}$ such that
\[ \forall y: \;\; \Element(y) \;\implies\; \Big( y\in \setbuilder{x}{\phi(x)} \iff \phi(y) \Big). \]
\end{enumerate}
This is for MK. In NBG the quantifiers in $\phi$ must be bound to elements.

Let $A$ be a class and $\phi(x)$ a proposition with free variable $x$. We often abbreviate $\setbuilder{x}{x\in A \land \phi(x)}$ by $\setbuilder{x\in A}{\phi(x)}$.


\begin{proposition}[Russel's paradox] \label{russelParadox}
Let $A$ be a set. The set
\[ r(A) \defeq \setbuilder{x\in A}{ x\notin x } \]
is not a member of $A$.
\end{proposition}
\begin{corollary} \label{setOfSets}
The class of sets, $\setbuilder{x}{\Set(x)}$, is not a set.
\end{corollary}
\begin{corollary} \label{properClassExistence}
There exists a proper class.
\end{corollary}


\begin{proposition}
There exists a proper
\end{proposition}

\subsubsection{Subclasses}
\begin{definition}
Let $A,B$ be classes. We say $B$ is a \udef{subclass} of $A$, denoted $B\subseteq A$, if
\[ \forall x: \; x\in A \implies x\in B. \]
If $B$ is a subclass of $A$ and $A \neq B$, then we call $B$ a \udef{strict subclass} of $A$, denoted $B \subset A$ or $B \subsetneq A$.
\end{definition}

\begin{lemma}
Let $A,B,C$ be classes. Then
\begin{enumerate}
\item $A = B$ \textup{if and only if} $A \subseteq B$ and $B \subseteq A$;
\item if $A \subseteq B$ and $B\subseteq C$, then $A \subseteq C$.
\end{enumerate}
\end{lemma}

\begin{enumerate}[(A)] \setcounter{enumi}{2}
\item \textbf{Axiom of separation}: Any subclass of a set is a set.
\end{enumerate}
TODO: consequence of replacement.

In particular, for any set $A$ and proposition $\phi(x)$, the class $\setbuilder{x\in A}{\phi(x)}$ is a set.

\subsubsection{Class construction}
We can use the axiom of class construction to build some basic classes.

\begin{definition}
Let $A,B$ be classes. We define
\begin{itemize}
\item the \udef{union} of $A$ and $B$ as $A \cup B \defeq \setbuilder{x}{x\in A \lor x\in B}$;
\item the \udef{intersection} of $A$ and $B$ as $A \cap B \defeq \setbuilder{x}{x\in A \land x\in B}$;
\item the \udef{complement} of $A$ as $A^c \defeq \setbuilder{x}{x\notin A}$;
\item the \udef{power set} of $A$ as $\powerset(A) \defeq \setbuilder{B}{B \subseteq A}$.
\end{itemize}
Let $\mathcal{E}$ be a class. We define
\begin{itemize}
\item the \udef{union} of $\mathcal{E}$ as
\[ \bigcup \mathcal{E} \defeq \setbuilder{x}{\exists A\in \mathcal{E}: \; x\in A}; \]
\item the \udef{intersection} of $\mathcal{E}$ as
\[ \bigcap \mathcal{E} \defeq \setbuilder{x}{\forall A\in \mathcal{E}: \; x\in A}. \]
\end{itemize}
We also define
\begin{itemize}
\item the \udef{empty class} $\emptyset \defeq \setbuilder{x}{x \neq x}$;
\item the \udef{universe class} $\mathcal{U} \defeq \setbuilder{x}{x = x}$.
\end{itemize}
\end{definition}

\begin{lemma}
Let $x$ be an element and $A$ a class. Then
\begin{enumerate}
\item $x\notin \emptyset$ and $x\in \mathcal{U}$;
\item $\emptyset \subseteq A$ and $A \subseteq \mathcal{U}$.
\end{enumerate}
\end{lemma}

\begin{lemma}
The empty class is a set \textup{if and only if} there exists a set.
\end{lemma}
\begin{proof}
The direction $\Rightarrow$ is clear.

For the direction $\Leftarrow$, assume there exists a set $A$. Then $\emptyset \subseteq A$. By the axiom of separation, this means $\emptyset$ is a set.
\end{proof}

\begin{enumerate}[(A)] \setcounter{enumi}{3}
\item \textbf{Set existence}: There exists a set.
\end{enumerate}
TODO: is implied by the axiom of infinity (TODO later!)

\begin{lemma}
Let $A,B, \mathcal{E}$ be classes. Then
\begin{enumerate}
\item $\bigcap\mathcal{E}$ is either a set or $\mathcal{U}$;
\item if either $A$ or $B$ is a set, the intersection $A \cap B$ is a set.
\end{enumerate}
\end{lemma}
\begin{proof}
(1) Assume $\bigcap\mathcal{E} \neq \mathcal{U}$. Then there exists an element $x\notin \bigcap\mathcal{E}$, meaning there exists a set $A\in \mathcal{E}$ such that $x\notin A$. Now $\bigcap\mathcal{E} \subseteq A$, so it is a set by separation. 

(2) This follows from the axiom of separation and the fact that $A \cap B$ is a subclass of both $A$ and $B$.
\end{proof}

We also assert some other classes constructed from sets are sets.

\begin{enumerate}[(A)] \setcounter{enumi}{4}
\item \textbf{Power set axiom}: Let $A$ be a set. Then $\powerset(A)$ is a set.
\item \textbf{Union set axiom}: Let $\mathcal{E}$ be a set. Then $\bigcup\mathcal{E}$ is a set.
\end{enumerate}

\begin{lemma} \mbox{} \label{distinctElements}
\begin{enumerate}
\item $\emptyset \neq \powerset(\emptyset)$;
\item for any object $a$, we can find an object $b$ such that $a \neq b$.
\end{enumerate}
\end{lemma}
\begin{proof}
(1) We have $\emptyset \in \powerset(\emptyset)$, but $\emptyset \notin \emptyset$.

(2) If $a = \emptyset$, we may take $\powerset(\emptyset)$. Otherwise take $\emptyset$.
\end{proof}

\begin{definition}
Let $a,b, c \ldots$ be objects. Then
\[ \{a,b, c \ldots\} \defeq \setbuilder{x}{x = a \lor x = b \lor x = c \lor \ldots}. \]
\end{definition}

\begin{enumerate}[(A)] \setcounter{enumi}{6}
\item \textbf{Doubleton existence axiom}: Let $a,b$ be objects. Then $\{a,b\}$ is a set.
\end{enumerate}

\begin{lemma} \label{binaryUnionIntersection}
Let $A,B$ be sets. Then
\begin{enumerate}
\item $A \cup B = \bigcup\{A, B\}$;
\item $A \cap B = \bigcap\{A, B\}$;
\end{enumerate}
In particular $A\cup B$ is a set.
\end{lemma}

\begin{lemma}
Let $a,b, c \ldots$ be an object. Then
\begin{enumerate}
\item $\{a\} = \{a, a\}$;
\item $\{a\}$ is a set;
\item $a\in \{a\}$ \textup{if and only if} $\Element(a)$;
\item $\{b,c \ldots\} \subseteq \{a,b,c \ldots\}$;
\item $\{a,b, c \ldots\}$ is a set.
\end{enumerate}
\end{lemma}
\begin{proof}
(1) $\setbuilder{x}{x = a \lor x = a} = \setbuilder{x}{x = a}$.

(2) By the doubleton existence axiom.

(3) By definition.

(4) Clear.

(5) By definition we can find sets $A,B,C \ldots$ such that $a\in A, b\in B, c\in C \ldots$ Then $\{a,b, c \ldots\} \subseteq A\cup B\cup C \cup \ldots$ and thus a set by \ref{binaryUnionIntersection} and the axiom of separation.
\end{proof}

\section{Finite sets}
Nex axiomatised element: finite sets. Classes may be members of finite sets.

\section{Potter-Scott set theory}
\begin{definition}
Let $\mathcal{W}$ be a universe with urelements $\mathcal{U}$.
\begin{itemize}
\item The \udef{accumulation} of an entity $a$ is
\[ \acc(a) \defeq \setbuilder{x}{x\in \mathcal{U} \lor \left[\exists b\in a: x\in b \lor x\subseteq b\right]}. \]
\item A collection $V$ is called a \udef{history} if
\[ \forall v\in V: v = \acc(V\cap v). \]
\item The accumulation of a history is called a \udef{level}.
\end{itemize}
\end{definition}

We can write the accumulation as
\[ \acc(a) = \mathcal{U}\cup \left(\bigcup a\right) \cup \left(\bigcup\setbuilder{\powerset(b)}{b\in a}\right). \]

Lemma \ref{elementSubsetUnion} translates to:
\begin{lemma} \label{elementsSubsetAccumulation}
Let $a,b$ be collections. If $b\in a$, then $b\subseteq \acc(a)$.
\end{lemma}

\begin{example}
Let $\mathcal{W}$ be a universe with urelements $\mathcal{U}$.
\begin{enumerate}
\item $\emptyset$ is (trivially) a history (assuming it exists). Then
\[ \acc(\emptyset) = \mathcal{U} \]
is a level.
\item $V = \{\mathcal{U}\}$ is a history:
\begin{itemize}
\item $\acc(V\cap \mathcal{U}) = \acc(\emptyset) = \mathcal{U}$.
\end{itemize}
Then $\acc(\{\mathcal{U}\}) = \mathcal{U}\cup \powerset(\mathcal{U}) \eqdef L_1$ is a level.
\item $V = \{\mathcal{U}, L_1\}$ is a history:
\begin{itemize}
\item $\acc(V \cap \mathcal{U}) = \acc(\emptyset) = \mathcal{U}$;
\item $\acc(V \cap L_1) = \acc(\{\mathcal{U}\}) = L_1$.
\end{itemize}
Then $\acc(\{\mathcal{U}, L_1\}) = \mathcal{U}\cup \powerset(\mathcal{U})\cup \powerset(\powerset(\mathcal{U})) \eqdef L_2$ is a level.
\item $V = \{\mathcal{U}, L_1, L_2\}$ is a history:
\begin{itemize}
\item $\acc(V \cap \mathcal{U}) = \acc(\emptyset) = \mathcal{U}$;
\item $\acc(V \cap L_1) = \acc(\{\mathcal{U}\}) = L_1$;
\item $\acc(V \cap L_2) = \acc(\{\mathcal{U}, L_1\}) = L_2$.
\end{itemize}
Then $\acc(\{\mathcal{U}, L_1, L_2\}) = \mathcal{U}\cup \powerset(\mathcal{U})\cup \powerset(\powerset(\mathcal{U}))\cup \powerset(\powerset(\powerset(\mathcal{U}))) \eqdef L_3$ is a level.
\end{enumerate}
\end{example}

A level is supposed to contain all collections up to a certain ``depth''.

A history $V$ is supposed to be a set of levels such that for each level $L$ in $V$ all previous levels contained in $L$ are also in $V$.

Formally:
\begin{proposition}
\begin{enumerate}
\item Let $V$ be a history, then every element $l$ of $V$ is a level with history $V\cap l$.

\item Let $l,L$ be levels and $V$ a history of $L$. If $l\in L$, then $l\in V$.

\item Each level has a unique history.

\item Let $L, L'$ be levels such that $L' \subseteq L$. If $V$ is a history and $L\in V$, then $L'\in V$.
\item Let $L, L'$ be levels then $L'\subseteq L$ \textup{if and only if} $L' = L$ or $L'\in L$.
\end{enumerate}
\end{proposition}
\begin{proof}
(1) Because $V$ is a history, we have $l = \acc(V\cap l)$. So we just need to show $V\cap l$ is a history. Indeed take $A\in (V\cap l)$, then $A \subseteq \acc(V\cap l) = l$ (by \ref{elementsSubsetAccumulation}). So $A = A\cap l$ and
\[ \acc((V\cap l)\cap A) = \acc(V\cap A) = A. \]

(2) Let $L$ be a level. Assume there exist histories $V_1, V_2$ such that $\acc(V_1) = L = \acc(V_2)$.

(3)
\end{proof}




\subsection{Sets}
\begin{definition}
A collection is called a \udef{set} or \udef{grounded} if it is a subcollection of some level.
\end{definition}

\subsection{Axiom scheme of separation}
TODO $A$ level??
\begin{enumerate}[(I)]
\item \textbf{Axiom of separation}: let $P$ be a unary predicate, then for each set $A$, the collection $\setbuilder{x\in A}{P(x)}$ exists.
\end{enumerate}
These collections are automatically sets.

Only those sets describable by predicates (a countable number). (cfr. second order).

\subsection{Theory of levels}

\section{Working with sets}
\subsection{Venn diagrams}
Much reasoning about sets can be simplified by drawing sets as circles. Many set-theoretic operations can be described in this way. The resulting pictures are called \udef{Venn diagrams}.

For any given set $A$, all objects are either in $A$ or not in $A$. So we divide the paper into a region inside $A$ and a region outside $A$:
\[\begin{tikzpicture}[thick]
% Circle with label
\node[draw,
    circle,
    minimum size =2cm,
    label=135:$A$] (circle1) at (0,0){};
\end{tikzpicture} \]

Given two sets $A,B$ there are now four possibilities for all objects in the universe:
\begin{enumerate}
\item outside both $A$ and $B$;
\item inside $A$, but not inside $B$;
\item inside $B$, but not inside $A$;
\item inside both $A$ and $B$.
\end{enumerate}
We correspondingly divide the paper into four regions:
\[ \begin{tikzpicture}[thick]
% Set A
\node [draw,
    circle,
    minimum size =2cm,
    label={135:$A$}] (A) at (0,0){};
% Set B
\node [draw,
    circle,
    minimum size =2cm,
    label={45:$B$}] (B) at (1.2,0){};
\end{tikzpicture} \]

For three sets $A,B,C$ the picture becomes:
\[ \begin{tikzpicture}[thick]
% Set A
\node[draw,circle,minimum size =2cm,label={135:$A$}] (A) at (0,0) {};

% Set B
\node[draw,circle,minimum size =2cm,label={45:$B$}] (B) at (1.2,0) {};

% Set C
\node[draw,circle,minimum size =2cm,label=$C$] (C) at (0.6,1.08) {};
\end{tikzpicture} \]

If we want to show that one set is a subset of another set, e.g\ $B\subset A$, then we can represent this as follows:
\[ \begin{tikzpicture}[thick]
% Set A
\node [draw,
    rectangle,
    minimum width =4cm,
	minimum height = 2.2cm,
    label={135:$A$}] (A) at (0,0){};
% Set B
\node [draw,
    circle,
    minimum size =1.8cm,
    label={45:$B$}] (B) at (0,0){};
\end{tikzpicture} \]

Expressions talking about sets can be expressed by shading regions of Venn diagrams. For example $A\cup B$:
\[ \begin{tikzpicture}[thick,
    set/.style = {circle,
        minimum size = 2cm,
        fill=black!30}]

% Set A
\node[set,label={135:$A$}] (A) at (0,0) {};

% Set B
\node[set,label={45:$B$}] (B) at (1.2,0) {};

% Circles outline
\draw (0,0) circle(1cm);
\draw (1.2,0) circle(1cm);
\end{tikzpicture} \]

\subsection{Operations on sets}
\subsubsection{Intersection}
\begin{definition}
The \udef{intersection} of an object $\mathcal{E}$ is a set $\bigcap \mathcal{E}$ defined by
\[ \bigcap \mathcal{E} \defeq \left\{ x\in \bigcup\mathcal{E} \;|\; \forall X\in \mathcal{E}: x\in X \right\}. \]
\end{definition}
As before, for the union, we define
\[ A\cap B \defeq \bigcap \{A,B\}. \]

The intersection $A\cap B$ can be represented in a Venn diagram as follows:
\[ \begin{tikzpicture}[thick,
    set/.style = {circle,
        minimum size = 2cm}]

% Set A
\node[set,label={135:$A$}] (A) at (0,0) {};

% Set B
\node[set,label={45:$B$}] (B) at (1,0) {};

% Intersection
\begin{scope}
    \clip (0,0) circle(1cm);
    \clip (1,0) circle(1cm);
    \fill[black!30](0,0) circle(1cm);
\end{scope}

% Circles outline
\draw (0,0) circle(1cm);
\draw (1,0) circle(1cm);

% Set intersection label
\node at (0.5,0) {$A\cap B$};
\end{tikzpicture} \]

\begin{proposition}
Let $A, B$ be non-empty sets. Then
\begin{enumerate}
\item $A \subseteq B \implies \bigcap B\subseteq \bigcap A$;
\item $\bigcap(A\cup B) = (\bigcap A)\cup (\bigcap B)$.
\end{enumerate}
These statements hold for all sets $A,B$ iff we use an unrelativised intersection (TODO!).
\end{proposition}

\begin{definition}
Let $A,B$ be sets. We call $A$ and $B$ \udef{disjoint} if $A\cap B = \emptyset$. We write $A\perp B$.

A family of sets $\mathcal{E}$ is called \udef{pairwise disjoint} if $\forall A,B\in\mathcal{E}: A\perp B$.
\end{definition}
The notation $A\perp B$ is not standard in general set theory, but is somewhat standard for disjoint elements in lattice theory.

\begin{definition}
Let $A,B$ be sets. We call the union $A\cup B$ a \udef{(inner) disjoint union} if $A$ and $B$ are disjoint. We may write $A\uplus B$ for the union if it is disjoint.

If a family of sets $\mathcal{E}$ is pairwise disjoint, we may denote its union $\biguplus \mathcal{E}$.
\end{definition}

\begin{definition}
Let $\mathcal{A},\mathcal{B}$ be families of sets. We say $\mathcal{A}$ and $\mathcal{B}$ \udef{mesh}, denoted $\mathcal{A} \# \mathcal{B}$ if $A$ and $B$ are not disjoint, $A\cap B \neq \emptyset$, for all $A\in \mathcal{A}$ and $B\in\mathcal{B}$.

We write $A \# \mathcal{B}$ for $\{A\}\# \mathcal{B}$ and $A\# B$ for $\{A\}\#\{B\}$.
\end{definition}

\subsubsection{Difference}
\begin{definition}
Given two objects $A,B$, we define the \udef{difference} as
\[A\setminus B \defeq \setbuilder{x\in A}{x\notin B}. \]
\end{definition}
The difference $A\setminus B$ can be represented in a Venn diagram as follows:
\[ \begin{tikzpicture}[thick,
    set/.style = {circle,
        minimum size = 2cm}]

% Set A
\node[set,draw,fill=black!30,label={135:$A$}] (A) at (0,0) {};

% Set B
\node[set,draw,fill=white,label={45:$B$}] (B) at (1.2,0) {};

% Circles outline
\draw (0,0) circle(1cm);

% Set label
\node at (-0.36,0) {$A\setminus B$};
\end{tikzpicture} \]

\begin{proposition}[De Morgan's laws]
Let $A,B,C$ be sets. Then
\begin{align*}
C\setminus (A\cap B) &= (C\setminus A)\cup(C\setminus B) \\
C\setminus (A\cup B) &= (C\setminus A)\cap(C\setminus B)
\end{align*}
This can be extended to arbitrary families of sets:
\begin{align*}
C\setminus\left(\bigcup \mathcal{E}\right) &= \bigcap\setbuilder{C\setminus A}{A\in\mathcal{E}} \\
C\setminus\left(\bigcap \mathcal{E}\right) &= \bigcup\setbuilder{C\setminus A}{A\in\mathcal{E}}
\end{align*}
where $\mathcal{E}$ is a family of sets.
\end{proposition}
\begin{lemma}
Let $\mathcal{E}$ be a family of sets and $A$ a set. Then
\[ \bigcup \mathcal{E} \setminus A = \bigcup\setbuilder{X\setminus A}{X\in\mathcal{E}} \qquad\text{and}\qquad \bigcap \mathcal{E} \setminus A = \bigcap\setbuilder{X\setminus A}{X\in\mathcal{E}}. \]
\end{lemma}

\begin{lemma} \label{differenceProperties}
Let $A,B,C$ be sets. Then
\begin{enumerate}
\item $(A\setminus B)\setminus C = A\setminus (B\cup C)$;
\item $A\setminus (B\setminus C) = (A\setminus B) \cup (A\cap C)$;
\end{enumerate}
and
\begin{enumerate} \setcounter{enumi}{2}
\item $(A\setminus B)\cap C = (A\cap C)\setminus B = A\cap (C\setminus B)$;
\item $(A\setminus B)\cup C = (A\cup C)\setminus (B\setminus C)$;
\end{enumerate}
and
\begin{enumerate} \setcounter{enumi}{4}
\item $A\setminus A = \emptyset$;
\item $\emptyset\setminus A = \emptyset$;
\item $A\setminus \emptyset = A$.
\end{enumerate}
\end{lemma}

\subsubsection{Symmetric difference}
\begin{definition}
We define the \udef{symmetric difference} of two sets $A,B$ as
\[ A \symdiff B \defeq (A\setminus B)\cup(B\setminus A). \]
This is equivalent to $A\symdiff B = \setbuilder{x\in A\cup B}{(x\in A)\oplus (x\in B)}$.
\end{definition}

The symmetric difference $A\symdiff B$ can be represented in a Venn diagram as follows:
\[ \begin{tikzpicture}[thick,
    set/.style = {circle,
        minimum size = 2cm}]

% Set A
\node[set,draw,fill=black!30,label={135:$A$}] (A) at (0,0) {};

% Set B
\node[set,draw,fill=black!30,label={45:$B$}] (B) at (1.2,0) {};

\begin{scope}
    \clip (0,0) circle(1cm);
    \clip (1.2,0) circle(1cm);
    \fill[white](0,0) circle(1cm);
\end{scope}

% Circles outline
\draw (0,0) circle(1cm);
\draw (1.2,0) circle(1cm);
\end{tikzpicture} \]

\begin{lemma}
Let $A,B,C$ be sets. Then
\begin{align*}
A\symdiff \emptyset &= A \\
A\symdiff B = \emptyset &\iff A = B
\end{align*}
and
\begin{align*}
A \symdiff B &= B \symdiff A \\
(A \symdiff B) \symdiff C &= A \symdiff (B \symdiff C) \\
A \symdiff C &= (A \symdiff B)\symdiff(B \symdiff C).
\end{align*}
\end{lemma}

\subsection{Identities and equivalences}
\subsubsection{Identities involving families of sets}
\begin{lemma}
Let $\mathcal{F}, \mathcal{G}$ be families of sets such that $\mathcal{F}\subseteq \mathcal{G}$. Then
\begin{enumerate}
\item $\bigcup \mathcal{F} \subseteq \bigcup \mathcal{G}$;
\item $\bigcap \mathcal{F} \supseteq \bigcup \mathcal{G}$.
\end{enumerate}
\end{lemma}

\subsubsection{Set operations and statements characterised}
\begin{lemma}
Let $A,B$ be sets. Then
\begin{enumerate}
\item $\begin{aligned}[t]
A\cap B &= A\setminus (A\setminus B) \\
&= B\setminus (A\symdiff B) \\
&= A\symdiff (A\setminus B);
\end{aligned}$
\item $\begin{aligned}[t]
A\cup B &= (A\symdiff B)\cup A \\
&= (A\symdiff B)\symdiff(A\cap B) \\
&= (A\setminus B)\cup B;
\end{aligned}$
\item $\begin{aligned}[t]
A\symdiff B &= (A\cup B)\setminus (A\cap B) \\
&= (A\symdiff C)\symdiff(C\symdiff B)
\end{aligned}$

for any set $C$;
\item $\begin{aligned}[t]
A\setminus B &= A\setminus (A\cap B) \\
&= A\cap(A\symdiff B) \\
&= (A\cup B)\symdiff B \\
&= A\symdiff (A\cap B);
\end{aligned}$
\end{enumerate}
\end{lemma}

\begin{lemma}
Let $A$ be a set. Then the following are equivalent:
\begin{enumerate}
\item $A$ is empty;
\item $A\cup B\subseteq B$ for every set $B$;
\item $A\subseteq B$ for every set $B$;
\item $A\subseteq (B\setminus A)$ for some set $B$;
\item $A\subseteq (B\setminus A)$ for every set $B$;
\item $\emptyset \setminus A= A$.
\end{enumerate}
\end{lemma}

\begin{lemma} \label{inclusionCriteria}
Let $A,B$ be sets. Then following are equivalent:
\begin{enumerate}
\item $A\subseteq B$;
\item $A\cap B = A$;
\item $A\cup B = B$;
\item $A\symdiff B = B\setminus A$;
\item $A\symdiff B \subseteq B\setminus A$
\item $A\setminus B = \emptyset$.
\end{enumerate}
For any universe set $\Omega$ such that $A,B\subset \Omega$ the above is also equivalent to
\begin{enumerate}\setcounter{enumi}{4}
\item $\Omega\setminus B \subseteq \Omega\setminus A$;
\item $(\Omega\cap A)\setminus B = \emptyset$;
\item $(\Omega\setminus A)\cup B = \Omega$.
\end{enumerate}
\end{lemma}
\begin{corollary}
Let $A,B$ be sets. Then following are equivalent:
\begin{enumerate}
\item $A=B$;
\item $A\symdiff B = \emptyset$;
\item $A\setminus B = B\setminus A$.
\end{enumerate}
\end{corollary}
\begin{corollary} \label{setPerpInequality}
Let $A,B\subseteq \Omega$ be sets. Then following are equivalent:
\begin{enumerate}
\item $A\perp B$;
\item $A \subseteq \Omega\setminus B$;
\item $B \subseteq \Omega\setminus A$.
\end{enumerate}
\end{corollary}

\begin{lemma} \label{disjointSetDifference}
Let $A,B,C$ be sets. Then
\[ A\setminus B \perp C \qquad\iff\qquad A\cap C \subseteq B. \]
\end{lemma}
\begin{proof}
We have
\begin{align*}
A\setminus B \perp C &\iff (A\setminus B) \cap C = \emptyset \\
&\iff (A\cap C)\setminus B = \emptyset \\
&\iff A\cap C \subseteq B.
\end{align*}
\end{proof}

\subsubsection{Distributivity}
TODO: tables complete / correct?? TODO: only works for relativised intersection.
\begin{lemma}
We say $*$ left distributes over $\bullet$ if
\[ A*(B\bullet C) = (A*B)\bullet (A*C) \qquad\text{for all sets $A,B,C$.} \]
This gives the table
\[ \begin{array}{c | c c c c c}
\text{\diagbox{$*$}{$\bullet$}} & \cup & \cap & \symdiff & \setminus & \times \\ \hline
\cup & \checkmark & \checkmark &  & & \\
\cap & \checkmark & \checkmark & \checkmark & \checkmark & \\
\symdiff &  &  &  & & \\
\setminus &  &  &  & & \\
\times & \checkmark & \checkmark &  & \checkmark &
\end{array} \]
\end{lemma}

\begin{lemma}
We say $*$ right distributes over $\bullet$ if
\[ (A\bullet B)*C = (A*C)\bullet (B*C) \qquad\text{for all sets $A,B,C$.} \]
This gives the table
\[ \begin{array}{c | c c c c c}
\text{\diagbox{$*$}{$\bullet$}} & \cup & \cap & \symdiff & \setminus & \times \\ \hline
\cup & \checkmark & \checkmark &  & & \\
\cap & \checkmark & \checkmark & \checkmark & \checkmark & \\
\symdiff &  &  &  & & \\
\setminus & \checkmark & \checkmark & \checkmark & \checkmark & \\
\times & \checkmark & \checkmark &  & \checkmark &
\end{array} \]
\end{lemma}

TODO: intersection distributes over disjoint union.

\begin{lemma} \label{unionIntersectionLabelSet}
Let $\mathcal{I}$ be a family of index sets and let $A_i$ be a set for all $i\in \bigcup \mathcal{I}$. Then
\begin{enumerate}
\item $\bigcup_{i\in \bigcup \mathcal{I}} A_i = \bigcup_{I\in \mathcal{I}}\bigcup_{i\in I} A_i$;
\item $\bigcap_{i\in \bigcap \mathcal{I}} A_i = \bigcap_{I\in \mathcal{I}}\bigcap_{i\in I} A_i$;
\item $\bigcup_{i\in \bigcap \mathcal{I}} A_i \subseteq \bigcap_{I\in \mathcal{I}}\bigcup_{i\in I} A_i$;
\item $\bigcap_{i\in \bigcup \mathcal{I}} A_i \supseteq \bigcup_{I\in \mathcal{I}}\bigcap_{i\in I} A_i$.
\end{enumerate}
\end{lemma}
\begin{proof}
(1) We calculate
\begin{align*}
x\in \bigcup_{i\in \bigcup \mathcal{I}} A_i &\iff \exists i\in \bigcup \mathcal{I}: x\in A_i \\
&\iff \exists i: (i\in \bigcup \mathcal{I}) \land (x\in A_i) \\
&\iff \exists i: (\exists I \in \mathcal{I}: i\in I) \land (x\in A_i) \\
&\iff \exists i: \exists I: (I \in \mathcal{I}) \land (i\in I) \land (x\in A_i) \\
&\iff \exists I\in \mathcal{I}: \exists i \in I: x\in A_i \\
&\iff x\in \bigcup_{I\in \mathcal{I}}\bigcup_{i\in I} A_i
\end{align*}

(2) Replace $\exists$ by $\forall$ and $\land$ by $\Rightarrow$ in the proof of (1).

(3) We calculate
\begin{align*}
x\in \bigcup_{i\in \bigcap \mathcal{I}} A_i &\iff \exists i\in \bigcap \mathcal{I}: x\in A_i \\
&\iff \exists i: (i\in \bigcap \mathcal{I}) \land (x\in A_i) \\
&\iff \exists i: (\forall I \in \mathcal{I}: i\in I) \land (x\in A_i) \\
&\iff \exists i: (\forall I: (I \in \mathcal{I}) \Rightarrow (i\in I)) \land (x\in A_i) \\
&\implies \exists i: \forall I: (I \in \mathcal{I}) \Rightarrow ((i\in I) \land (x\in A_i)) \\
&\implies \forall I: \exists i: (I \in \mathcal{I}) \Rightarrow ((i\in I) \land (x\in A_i)) \\
&\iff \forall I: (I \in \mathcal{I}) \Rightarrow (\exists i:(i\in I) \land (x\in A_i)) \\
&\iff \forall I\in \mathcal{I}: \exists i \in I: x\in A_i \\
&\iff x\in \bigcap_{I\in \mathcal{I}}\bigcup_{i\in I} A_i
\end{align*}

(4) TODO
\end{proof}

For more identities, see \url{https://en.wikipedia.org/wiki/List_of_set_identities_and_relations}.


\chapter{Relations and functions}
\section{Pairs}
\begin{definition}
A definition of $(a,b)$ for all $a,b$ is called an \udef{(ordered) pair operation} if it satisfies
\begin{itemize}
\item $(a,b) = (x,y) \iff (a=x)\land (b=y)$;
\item for all sets $A,B$, $\setbuilder{(a,b)}{a\in A\land b\in B}$ is a set.
\end{itemize}
We call $\setbuilder{(a,b)}{a\in A\land b\in B}$ the \udef{Cartesian product} of classes $A$ and $B$ and denote it $A\times B$.
\end{definition}
Note that for the second condition it is enough to check that $A\times B$ is a subset of some set $S$. Then, by separation, $A\times B$ is the set
\[ A\times B = \setbuilder{x\in S}{\exists a\in A:\exists b\in B: x = (a,b)}. \]

\begin{lemma}
Let $A$ be a class. Then
\[ A\times \emptyset = \emptyset = \emptyset\times A. \]
\end{lemma}

\begin{lemma} \label{productUnionIntersection}
Let $A,B,C,D$ be classes. Then
\begin{enumerate}
\item $(A\cup B)\times C = A\times C \cup B\times C$;
\item $(A\uplus B)\times C = A\times C \uplus B\times C$;
\item $(A\cap B)\times C = A\times C\cap B\times C$;
\item $(A\times B)\cap (C\times D) = (A \cap C)\times (B\cap D)$.
\end{enumerate}
\end{lemma}

\begin{definition}
Let $p = (a,b)$ be a pair, we use $\pi_1(p)$ to denote the first element of $p$ and $\pi_2(p)$ to denote the second element:
\[ (a,b) = p = (\pi_1(p),\pi_2(p)). \]
We can convert a pair to a set:
\[ \operatorname{set}((a,b)) = \{a,b\}. \]
\end{definition}


\subsection{Axiomatising pairs}
Consider the ternary proposition $A = (B,C)$ as primitive. 
\begin{definition}
Consider a universe $\mathcal{W}$. Let $p$ be an object in $\mathcal{W}$. We call $p$ a \udef{pair} if $\exists x,y: p = (x,y)$.

We define the predicate
\begin{itemize}
\item $\Pair(p) \defequiv \exists x,y: \; p = (x, y)$.
\end{itemize}
\end{definition}

\begin{enumerate}[(A)] \setcounter{enumi}{0}
\item \textbf{Axiom of pair identity}: Let $p_1, p_2,x_1,x_2,y_1,y_2$ be objects such that
\[ p_1 = (x_1, y_1) \qquad \text{and}\qquad p_2 = (x_2, y_2). \]
Then
\[ p_1 = p_2 \quad\iff\quad \big[x_1 = x_2\big] \;\land\; \big[y_1 = y_2\big]. \]
\item \textbf{Axiom of pair existence}: Let $x,y$ be objects. Then $\exists p: \; p = (x,y)$ with $p\neq x $ and $p \neq y$.
\end{enumerate}

\begin{lemma}
Let $x,y$ be objects. Then $\exists! p: \; p = (x,y)$ with $p\neq x $ and $p \neq y$.
\end{lemma}
\begin{proof}
Existence is given by the axiom of pair existence. We just need to show uniqueness. Assume there exist $p_1, p_2$ such that $p_1 = (x,y)$ and $p_2 = (x,y)$. Then $p_1 = p_2$ by the axiom of pair identity.
\end{proof}

Usually an axiomatic system of pairs is integrated with a set theory.
\begin{definition}
Let $\mathcal{W}$ be a set theoretic universe satisfying the pair axioms. Let $A,B$ be classes. The \udef{Cartesian product} of $A$ and $B$ is defined as
\[ A\times B \defeq \setbuilder{p}{\exists a\in A: \exists b\in B: p = (a,b)}. \]
\end{definition}

In this case we impose the following additional axioms:
\begin{enumerate}[(A)] \setcounter{enumi}{2}
\item \textbf{Axiom of element pairs}: Let $a,b$ be elements and $p=(a,b)$. Then $p$ is an element.
\item \textbf{Cartesian product axiom}: Let $A,B$ be sets. Then $A \times B$ is a set.
\end{enumerate}

\begin{lemma}
Let $A, B$ be classes $a\in A, b\in B$ and $p = (a,b)$. Then $p\in A\times B$.
\end{lemma}
\begin{proof}
In this case $a,b$ are elements. So $p$ is an element by the axiom of element pairs and thus $p\in A\times B$ by class comprehension.
\end{proof}


\subsection{Defining pairs}
TODO: pair axioms conservative extension of ZFC.

\subsubsection{The Kuratowski pair}
\begin{definition}
The \udef{Kuratowski pair} is defined as
\[ (a,b) \defeq \{\{a\}, \{a,b\}\} \]
\end{definition}
Note that when $a=b$ we have
\[ (a,a) = \{\{a\},\{a,a\}\} = \{\{a\},\{a\}\} = \{\{a\}\}. \]
\begin{lemma}
Given a Kuratowski pair $p = (a,b)$, we can extract the first element $\pi_1(p)$ and the second element $\pi_2(p)$ as follows:
\begin{align*}
\pi_1(p) &= \bigcup\bigcap p; \\
\pi_2(p) &= \bigcup\left\{ x\in\bigcup p\;|\; \left[\bigcup p \neq \bigcap p\right] \implies \left[ x\notin \bigcap p \right] \right\}.
\end{align*}
The Kuratowski pair can be converted to a set by
\[ \operatorname{set}(p) = \bigcup p. \]
\end{lemma}
The construction ``$\left[\bigcup p \neq \bigcap p\right] \implies$'' in the formula for $\pi_2(p)$ is there so that it still works in case the first and second elements are the same.
\begin{proposition}
The Kuratowski pair is adequate, in that is satisfies
\[ (a,b) = (x,y) \iff (a=x)\land (b=y) \]
and the Cartesian product is a set.
\end{proposition}
\begin{proof}
If $(a=x)\land (b=y)$, then
\[ \{\{a\},\{a,b\}\} = \{\{x\},\{x,y\}\} \]
and thus $(a,b) = (x,y)$.

Now assume $(a,b) = (x,y)$. We consider two cases: $a=b$ and $a\neq b$.
\begin{itemize}[leftmargin=2cm]
\item[$\boxed{a=b}$] Then $(a,b) = \{\{a\},\{a,a\}\} = \{\{a\}\} = (x,y)$ and thus $\{x\} = \{x,y\} = \{a\}$ by extensionality. This implies $a=x=y$ and thus $(a=x)\land (b=y)$.
\item[$\boxed{a\neq b}$] Now $(a,b) = (x,y)$ implies
\[ \{\{a\},\{a,b\}\} = \{\{x\},\{x,y\}\}. \]
By extensionality, either $\{x\} = \{a\}$ or $\{x\} = \{a,b\}$. In the second option $a=x=b$ and thus $a=b$ which is a contradiction. So $x=a$.

Again by extensionality, either $\{x,y\} = \{a\}$ or $\{x,y\} = \{a,b\}$. In the first case $(x,y)$ would be a singleton and then by equality so would $(a,b)$, yielding a contradiction. Thus $\{x,y\} = \{a,b\}$. We know $a=x$ and $b\neq a$, so by extensionality $b=y$.
\end{itemize}
To prove the Cartesian product $A\times B$ is a set, notice that
\begin{align*}
a\in A, b\in B &\implies \{a\},\{a,b\}\subseteq A\cup B \implies \{a\},\{a,b\}\in \powerset(A\cup B)\\
&\implies \{\{a\},\{a,b\}\}\subseteq \powerset(A\cup B) \implies \{\{a\},\{a,b\}\}\in \powerset(\powerset(A\cup B)) \\
&\implies (a,b) \in \powerset(\powerset(A\cup B)).
\end{align*}
and $\powerset(\powerset(A\cup B))$ is a set. So
\[ A\times B = \{ x\in \powerset(\powerset(A\cup B))\;|\; \exists a\in A:\exists b\in B: x = (a,b) \} \]
is a set.
\end{proof}
\subsubsection{The short variant}
We can also define a pair as
\[ (a,b) \defeq \{a,\{a,b\}\} \]
The advantage of this short definition is fewer braces. Some disadvantages include:
\begin{enumerate}
\item If $a$ and $b$ have the same type, $a$ and $\{a,b\}$ do not have the same type.
\item In order to prove adequacy, we need a new axiom, the axiom of regularity.
\end{enumerate}
\subsubsection{Using $0,1$}
Suppose we have decided on two special, distinct objects $0,1$. Then we can define
\[ (a,b) \defeq \{\{0,a\},\{1,b\}\}. \]
\begin{proposition}
This definition satisfies the requirements for a pair.
\end{proposition}
\begin{proof}
Assuming $(a=x)\land (b=y)$, it is clear that $(a,b)=(x,y)$ as sets by extensionality.

Now assume $(a,b)=(x,y)$. In this implementation a pair always has two elements as a set. The reasoning by extensionality is simple and only slightly more difficult if $a,b,x,y$ are equal to $0$ or $1$.

The Cartesian product is a subset of $\powerset(\powerset(A\cup B\cup \{0,1\}))$ and thus a set.
\end{proof}
\subsubsection{Wiener pair}
The Wiener definition of a pair is
\[ (a,b) \defeq \{\{\emptyset,\{a\}\},\{\{b\}\}\}. \]
\begin{proposition}
This definition satisfies the requirements for a pair.
\end{proposition}

\subsection{Structured classes and sets}
\begin{definition}
A \udef{structured class} is a pair $U = (A,S)$ where $A$ is a class and $S$ is an arbitrary object.
\begin{itemize}
\item $A$ is the \udef{field} or \udef{space} of $U$, written $\operatorname{Field}(U)$;
\item $S$ is the \udef{frame} of $U$.
\end{itemize}
If we write $x\in U$, we mean $x\in \operatorname{Field}(U)$.

In particular if $A$ is a set, then we call $U$ a \udef{structured set}.
\end{definition}

Often the frame $S$ is a $n$-tuple. In this case we may write the structured class as an $n+1$-tuple by concatenating the field and the frame. e.g\ $(A,(S_1,S_2,S_3))$ becomes $(A,S_1,S_2,S_3)$.

\section{Relations}
\begin{definition}
Let $A,B$ be classes and $G$ any subclass of the Cartesian product $A\times B$. A \udef{(binary) relation} $R$ on $(A, B)$ is a tuple $(G,(A,B))$. The \udef{graph} of the binary relation $R$ is the class $\graph(R) \defeq G$.

We write
\[ xRy \defequiv (x,y)\in \graph(R) \]
and say $x$ is \udef{left related} to $y$ or $y$ is \udef{right related} to $x$.

We call
\begin{itemize}
\item $\dom(R) \defeq A$ the \udef{domain} of the relation;
\item $\codom(R) \defeq B$ the \udef{codomain} of the relation.
\end{itemize}
A relation $R$ is \udef{homogeneous} or an \udef{endorelation} if $\dom(R) = \codom(R)$.
If we say $R$ is a (homogenous) relation on $A$, we mean $\dom(R) = A = \codom(R)$. 

A relation is \udef{heterogeneous} is the domain and codomain are different.
\end{definition}

Often we will write $R \subseteq S$ as a shorthand for $\graph(R)\subseteq \graph(S)$.

\begin{lemma}
Let $R,S$ be relations on $(A,B)$. Then
\begin{enumerate}
\item $R\cup S \defeq \sSet{\graph(R)\cup \graph(S), (A,B)}$ is a relation on $(A,B)$;
\item $R\cap S \defeq \sSet{\graph(R)\cap \graph(S), (A,B)}$ is a relation on $(A,B)$.
\end{enumerate}
\end{lemma}

\begin{definition}
Let $A,B$ be classes. We have the following relations:
\begin{itemize}
\item the \udef{empty relation} $E_{A,B}$ on $(A, B)$ has graph $\emptyset$;
\item the \udef{universal relation} $U_{A,B}$ on $(A, B)$ has graph $A\times B$;
\item the \udef{identity relation} $\id_A$ on $A$ has graph $\setbuilder{(x,y)\in A\times A}{x=y}$.
\end{itemize}
We may also write $U_A$ instead of $U_{A,A}$ and $E_A$ instead of $E_{A,A}$.
\end{definition}
The identity relation on $A$ is also known as the \udef{diagonal relation} on $A$.

\begin{lemma}
Let $A,B,C,D$ be classes. Then
\begin{enumerate}
\item $\id_{A\cup B} = \id_A\cup \id_B$ and $\id_{A\cap B} = \id_A\cap \id_B$;
\item $E_{A\cup C, B\cup D} = E_{A,B}\cup E_{C,D}$ and $E_{A\cap C, B\cap D} = E_{A,B}\cap E_{C,D}$;
\item $U_{A\cap C, B\cap D} = U_{A,B}\cap U_{C,D}$.
\end{enumerate}
\end{lemma}
Note that the equalities mean the graphs are equal. The relations are not the same as they have different domains and codomains.
\begin{proof}
(1) Assume $(x,x)\in \id_{A\cup B}$. We have the equivalences
\[ (x\in A)\lor (x\in B) \iff \Big((x,x)\in \id_A\Big) \lor \Big((x,x)\in\id_B\Big) \iff (x,x)\in \id_A\cup \id_B. \]
For the second part replace $\lor$ with $\land$.

(2) Trivial because all sets are $\emptyset$.

(3) Take $(x,y)\in U_{A\cap C, B\cap D}$. We have the equivalences
\begin{align*}
(x\in A\cap C) \land (y\in B\cap D) &\iff (x\in A)\land (y\in B)\land(x\in C)\land(y\in D) \\
&\iff \big((x,y)\in U_{A, B})\big)\land\big((x,y)\in U_{A, B}\big) \\
&\iff (x,y)\in U_{A,B}\cap U_{C,D}.
\end{align*}
\end{proof}


\begin{definition}
Let $R$ be a binary relation. We say
\begin{itemize}
\item $x$ is \udef{related to} or \udef{comparable with} $y$ if $xRy$ or $yRx$; we denote this $x\nparallel_R y$ or just $x\nparallel y$;
\item $x$ is \udef{unrelated to}, \udef{incomparable with} or \udef{parallel with} $y$ if neither $xRy$ nor $yRx$; we denote this $x\parallel_R y$ or just $x\parallel y$.
\end{itemize}
\end{definition}

\subsection{Relations and subclasses}
\subsubsection{Images and preimages}
\begin{definition}
Let $R$ be a relation on $(A, B)$.
\begin{itemize}
\item The \udef{image} of a subclass $X\subset A$ under $R$ is the class
\[ X_R \defeq \setbuilder{b\in B}{\exists x\in X: xRb}. \]
\item The \udef{preimage} of a subclass $Y\subset B$ under $R$ is the class
\[ _RY \defeq \setbuilder{a\in A}{\exists y\in Y: aRy}. \]
\end{itemize}
In particular for $X=A$ and $Y=B$:
\begin{enumerate}
\item The class $A_R$ is the \udef{active codomain}, \udef{codomain of definition}, \udef{image} or \udef{range} of the relation, also denoted $\im(R)$.
\item The class $_RB$ is the \udef{active domain}, \udef{domain of definition}, \udef{preimage} or \udef{prerange} of the relation, also denoted $\preim(R)$.
\end{enumerate}
In particular for $X = \{x\}$ and $Y = \{y\}$ we define:
\begin{itemize}
\item $xR \defeq \{x\}_R$;
\item $Ry \defeq {_R\{x\}}$.
\end{itemize}
We call such images and preimages \udef{principle} images and preimages.
\end{definition}

A relation is completely characterised by its principal images.
\begin{lemma} \label{relationFromPrincipalImages}
Let $R$ be a relation on $(A, B)$, $x\in A$ and $y\in B$. Then
\[ x\in Ry \iff xRy \iff xR \ni y. \]
\end{lemma}
Principal images atoms in lattice of images??

\begin{lemma}
Let $R$ be a relation on $(A, B)$, $X\subseteq A$ and $Y\subseteq B$. Then
\begin{enumerate}
\item $X_R = {_{R^\transp}X}$;
\item $_RX = X_{R^\transp}$.
\end{enumerate}
In particular $xR = R^\transp x$ and $Ry = yR^\transp$ for all $x\in A$ and $y\in B$.
\end{lemma}

TODO: atomicity / atomistic ??
\begin{lemma}
Let $R$ be a relation on $(A, B)$, $X\subseteq A$ and $Y\subseteq B$. Then
\begin{enumerate}
\item $X_R = \displaystyle\bigcup_{x\in X}xR = \bigcup \setbuilder{xR}{x\in X}$;
\item $_RY = \displaystyle\bigcup_{y\in Y}Ry = \bigcup \setbuilder{Ry}{y\in Y}$.
\end{enumerate}
\end{lemma}


\begin{corollary} \label{monotonicityImage}
Let $R$ be a relation on $(A, B)$ and $X,Y\subset A$. Then
\begin{enumerate}
\item if $X\subseteq Y$, then $X_R \subseteq Y_R$;
\item if $X\subseteq Y$, then ${_RX} \subseteq {_RY}$.
\end{enumerate}
\end{corollary}
\begin{proof}
(1) We can write $Y = X \cup (Y\setminus X)$. Then
\[ Y_R = \bigcup \setbuilder{xR}{x\in Y} = \bigcup \setbuilder{xR}{x\in X}\cup\setbuilder{xR}{x\in (Y\setminus X)} = X_R \cup (Y\setminus X)_R \supseteq X_R. \]

(2) Similar.
\end{proof}
\begin{corollary} \label{imageRelation} \label{preimageRelation}
Let $R$ be a relation on $(A, B)$, $X,Y\subset A$ and $Z,W\subset B$. Then
\begin{enumerate}
\item $(X\cup Y)_R = X_R\cup Y_R$;
\item $(X\cap Y)_R \subseteq X_R\cap Y_R$;
\item $(X\setminus Y)_R \supseteq X_R\setminus Y_R$;
\item $(X\symdiff Y)_R \supseteq X_R\symdiff Y_R$.
\end{enumerate}
and
\begin{enumerate}
\item $_R(Z\cup W) = {_RZ}\cup {_RW}$;
\item $_R(Z\cap W) \subseteq {_RZ}\cap {_RW}$;
\item $_R(Z\setminus W) \supseteq {_RZ}\setminus {_RW}$;
\item $_R(Z\symdiff W) \supseteq {_RZ}\symdiff {_RW}$.
\end{enumerate}
\end{corollary}
\begin{proof}\mbox{}

(1) $\begin{aligned}[t]
(X\cup Y)_R &= \bigcup \setbuilder{xR}{x\in (X\cup Y)} = \bigcup \setbuilder{xR}{x\in X}\cup \setbuilder{xR}{x\in Y} \\
&= \left(\bigcup \setbuilder{xR}{x\in X}\right)\cup \left(\bigcup \setbuilder{xR}{x\in Y}\right) = X_R \cup Y_R.
\end{aligned}$

(2) We have both $X\cap Y \subseteq X$ and $X\cap Y \subseteq Y$, so $(X\cap Y)_R \subseteq X_R$ and $(X\cap Y)_R \subseteq Y_R$ by \ref{monotonicityImage}. Thus $(X\cap Y)_R \subseteq X_R\cap Y_R$.

TODO: use lattice properties

(3), (4) TODO
\end{proof}


\subsubsection{Left and right bounds}
\begin{definition}
Let $R$ be a relation on $(A, B)$, $X\subseteq A$ and $Y\subseteq B$.
\begin{itemize}
\item A \udef{right bound} (or \udef{upper bound}) of $X$ under $R$ is an element $b\in B$ such that $b$ is right related to all $x\in X$. We denote the class of right bounds by
\[ X^R \defeq \setbuilder{b\in B}{\forall x\in X: xRb}. \]
\item A \udef{left bound} (or \udef{lower bound}) of $Y$ under $R$ is an element $a\in A$ such that $a$ is left related to all $y\in Y$. We denote the class of left bounds by
\[ ^RY \defeq \setbuilder{a\in A}{\forall y\in Y: aRy}. \]
\end{itemize}
The classes $X^R$ and $^RY$ are also called \udef{polars}.\footnote{According to Birkhoff (TODO ref), the term ``polar'' was chosen due to the link with the polars of conic sections.}

In particular for $X=A$ and $Y=B$:
\begin{enumerate}
\item The class $A^R$ is referred to as the \udef{top} of $\sSet{R,(A,B)}$.
\item The class $^RB$ is the \udef{bottom} of $\sSet{R,(A,B)}$.
\end{enumerate}
\end{definition}
Note that the definitions of the polars is similar to the definition of the image/preimage. The only difference is that ``$\exists$'' is replaced by ``$\forall$''.

Consequently, we can state results similar to the ones above.

\begin{lemma}
Let $R$ be a relation on $(A, B)$, $X\subset A$ and $Y\subset B$. Then
\begin{enumerate}
\item $X^R = {^{R^\transp}X}$;
\item $^RX = X^{R^\transp}$.
\end{enumerate}
\end{lemma}

\begin{lemma} \label{boundsFromPrincipalImages}
Let $R$ be a relation on $(A, B)$, $X\subset A$ and $Y\subset B$. Then
\begin{enumerate}
\item $X^R = \displaystyle\bigcap_{x\in X}xR = \bigcap \setbuilder{xR}{x\in X}$;
\item $^RY = \displaystyle\bigcap_{y\in Y}Ry = \bigcap \setbuilder{Ry}{y\in Y}$.
\end{enumerate}
In particular for $x\in A$ and $y\in B$:
\begin{enumerate}
\item $\{x\}^R = xR = \{x\}_R$;
\item $^R\{y\} = Ry = {_R\{y\}}$.
\end{enumerate}
\end{lemma}
TODO this only works for empty sets if we relativise the intersection!

\begin{lemma} \label{polarsCartesianProduct}
Let $R$ be a relation on $(A,B)$ and $X\subseteq A, Y\subseteq B$. Then
\[ Y\subseteq X^R \iff X\times Y \subseteq R. \]
\end{lemma}

\begin{corollary} \label{monotonicityPolars}
Let $R$ be a relation on $(A, B)$ and $X,Y\subset A$. Then
\begin{enumerate}
\item if $X\subseteq Y$, then $X^R \supseteq Y^R$;
\item if $X\subseteq Y$, then ${^RX} \supseteq {^RY}$.
\end{enumerate}
\end{corollary}
\begin{proof}
(1) We can write $Y = X \cup (Y\setminus X)$. Then
\[ Y^R = \bigcap \setbuilder{xR}{x\in Y} = \bigcap \setbuilder{xR}{x\in X}\cap\setbuilder{xR}{x\in (Y\setminus X)} = X^R \cap (Y\setminus X)^R \subseteq X^R. \]

(2) Similar.
\end{proof}
\begin{corollary} \label{polarasRelation}
Let $R$ be a relation on $(A, B)$, $X,Y\subset A$ and $Z,W\subset B$. Then
\begin{enumerate}
\item $(X\cup Y)^R \subseteq X^R\cap Y^R$;
\item $(X\cap Y)^R \supseteq X^R\cup Y^R$;
\item $(X\setminus Y)^R ? X^R\setminus Y^R$;
\item $(X\symdiff Y)^R ? X^R\symdiff Y^R$.
\end{enumerate}
and
\begin{enumerate}
\item $^R(Z\cup W) \subseteq {^RZ}\cup {^RW}$;
\item $^R(Z\cap W) \supseteq {^RZ}\cap {^RW}$;
\item $^R(Z\setminus W) ? {^RZ}\setminus {^RW}$;
\item $^R(Z\symdiff W) ? {^RZ}\symdiff {^RW}$.
\end{enumerate}
\end{corollary}
\begin{proof}\mbox{}
(1) We have both $X\cup Y \supseteq X$ and $X\cup Y \supseteq Y$, so $(X\cup Y)^R \subseteq X^R$ and $(X\cup Y)^R \subseteq Y^R$ by \ref{monotonicityImage}. Thus $(X\cup Y)^R \subseteq X^R\cap Y^R$.

(2) TODO ref order reversing function on lattice.

(3), (4) TODO
\end{proof}

\subsubsection{Extending the relation to powersets}
\begin{definition}
Let $R$ be a relation on $(A,B)$. Let $X\subseteq A$ and $Y\subseteq B$ be classes. Then we write $X\aset{R}Y$ if
\[ \forall x\in X: \forall y\in Y: \; xRy. \]
\end{definition}

\begin{lemma}
Let $R$ be a relation on $(A,B)$. Let $X\subseteq A$ and $Y\subseteq B$ be classes. Then
\[ X \aset{R} Y \quad\iff\quad X \subseteq {^RY} \quad\iff\quad Y \subseteq X^R. \]
\end{lemma}

\subsubsection{Greatest and least elements}
\begin{definition}
Let $\sSet{A, R}$ be a relational structure and $X\subseteq A$ a subclass.
\begin{itemize}
\item A \udef{greatest element}, \udef{largest element} or \udef{maximum} of $X$ is an upper bound of $X$ that is an element of $X$. We denote the class of maxima by $\max(X) \defeq X^R\cap X$.
\item A \udef{least element}, \udef{smallest element} or \udef{minimum} of $X$ is a lower bound of $X$ that is an element of $X$. We denote the class of minima by $\min(X) \defeq {^RX}\cap X$.
\end{itemize}
We also call
\begin{itemize}
\item an element of $\sup(S) \defeq \min(X^R) = X^R \cap (X^R)^{R^\transp}$ a \udef{least upper bound}, \udef{supremum}, or \udef{join};
\item an element of $\inf(S) \defeq \max({^RX}) = X^{R^\transp} \cap (X^{R^\transp})^R$ a \udef{greatest lower bound}, \udef{infimum}, or \udef{meet}.
\end{itemize}
\end{definition}

\begin{lemma} \label{minMaxSingletons}
If $\sSet{A, R}$ is an antisymmetric relational structure and $X\subseteq A$, then $\max(X), \min(X), \sup(X)$ and $\inf(X)$ are either singletons or empty.
\end{lemma}
\begin{proof}
We prove for $\max(X)$. The other cases follow dually or a fortiori. Let $x,y\in \max(X)$. Then $xRy$ and $yRx$, so $x=y$ by antisymmetry.
\end{proof}
In this case we use $\max/\min/\sup/\inf$ to denote the contents of the singleton rather than the singleton itself. If the set is empty, we say the $\max/\min/\sup/\inf$ does not exist.

\begin{lemma} \label{greatestLeastElementsSubsetPoset}
Let $\sSet{P, \precsim}$ be a poset and $R\subseteq S\subseteq P$.
\begin{enumerate}
\item If $\max(R)$ and $\max(S)$ exists, then $\max(R) \precsim \max(S)$.
\item If $\min(R)$ and $\min(S)$ exists, then $\min(R) \succsim \min(S)$.
\end{enumerate}
\end{lemma}
\begin{proof}
By definition $\max(S) \succsim x$ for all $x \in S$. Now $\max(R)\in R\subseteq S$, so in particular $\max(R) \precsim \max(S)$.
\end{proof}

TODO: set to class?
\begin{lemma} \label{maxSupMinInf}
If $\sSet{P, \Yleft}$ is a relational structure and $S\subseteq P$, then
\begin{enumerate}
\item $\max(S)\subset \sup(S)$;
\item $\min(S)\subset \inf(S)$.
\end{enumerate}
\end{lemma}
\begin{proof}
For (1) we calculate $\max(S) = S \cap S^u \subseteq (S^u)^l \cap S^u = \sup(S)$; (2) is dual.

TODO: post Galois??
\end{proof}

\subsubsection{Maximal and minimal elements}
\begin{definition}
Let $\sSet{A, R}$ be a relational structure and $X\subseteq A$ a subclass. We say
\begin{itemize}
\item $x\in X$ is \udef{strictly maximal} if $xR\cap X = \emptyset$;
\item $x\in X$ is \udef{maximal} if $xR\cap X \subseteq \{x\}$;
\item $x\in X$ is \udef{loosely maximal} if $xR\cap X \subseteq Rx$;
\end{itemize}
and
\begin{itemize}
\item $x\in X$ is \udef{strictly minimal} if $Rx\cap X = \emptyset$;
\item $x\in X$ is \udef{minimal} if $Rx\cap X \subseteq \{x\}$;
\item $x\in X$ is \udef{loosely minimal} if $Rx\cap X \subseteq xR$.
\end{itemize}
We write
\begin{itemize}
\item $\lmax(X)$ for the class of maximal elements in $X$;
\item $\llmax(X)$ for the class of loosely maximal elements in $X$;
\item $\lmin(X)$ for the class of minimal elements in $X$;
\item $\llmin(X)$ for the class of loosely minimal elements in $X$.
\end{itemize}
\end{definition}

\begin{lemma} \label{maximalMinimalEquivalents}
Let $\sSet{A, R}$ be a relational structure and $X\subseteq A$ a subclass. Then
\begin{enumerate}
\item $x\in X$ is strictly maximal in $X$ \textup{if and only if} $xR \perp X$;
\item $x\in X$ is maximal in $X$ \textup{if and only if} $xR\setminus\{x\} \perp X$;
\item $x\in X$ is loosely maximal in $X$ \textup{if and only if} $xR\setminus Rx \perp X$;
\end{enumerate}
and
\begin{enumerate}
\item $x\in X$ is strictly minimal in $X$ \textup{if and only if} $Rx \perp X$;
\item $x\in X$ is minimal in $X$ \textup{if and only if} $Rx\setminus\{x\} \perp X$;
\item $x\in X$ is loosely minimal in $X$ \textup{if and only if} $Rx\setminus xR \perp X$.
\end{enumerate}
\end{lemma}
\begin{proof}
Immediate from \ref{disjointSetDifference}.
\end{proof}

\begin{lemma} \label{maximalMinimalImplications}
Let $\sSet{A, R}$ be a relational structure, $X\subseteq A$ a subclass and $x\in X$. Then
\[ \text{$x$ is strictly maximal in $X$} \;\implies\; \text{$x$ is maximal in $X$} \;\implies\; \text{$x$ is loosely maximal in $X$}; \]
and
\[ \text{$x$ is strictly minimal in $X$} \;\implies\; \text{$x$ is minimal in $X$} \;\implies\; \text{$x$ is loosely minimal in $X$}. \]
\end{lemma}

\begin{lemma} \label{maximumIsMaximal}
Let $R$ be a relation on $A$ and $X\subseteq A$. Then
\begin{enumerate}
\item every maximum of $X$ is loosely maximal in $X$;
\item every minimum of $X$ is loosely minimal in $X$.
\end{enumerate}
If $\sSet{X, R|_X^X}$ is connex, then the converses also hold.
\end{lemma}
\begin{proof}
(1) Let $x\in X$ be a maximum. Then $x\in X^R$, so
\[ \{x\} \subseteq X^R \iff X\subseteq {^R\{x\}} = Rx \implies xR \cap X \subseteq Rx, \]
which means that $x$ is loosely maximal.

(2) Dual to (1).

(Converses for connex subsets) Let $x\in X$ be loosely maximal. For all $y\in X$ we have either $x\mathrel{R}y$ or $y\mathrel{R}x$. In the first case, $y\in xR\cap X$, so $y\in Rx$ by definition of loose maximality. Thus $y\mathrel{R}x$ in both cases, so $x\in X^R\cap X = \max(X)$.

The other converse is dual.
\end{proof}

\subsection{Converse relation}
\begin{definition}
Let $R$ be a relation on $(A, B)$. The \udef{converse} $R^\transp$ of $R$ is the relation on $B\times A$ with graph
\[ \graph(R^{\transp}) = \setbuilder{(y,x)}{(x,y)\in \graph(R)} \subset B\times A. \]
It is also known as the \udef{inverse}, \udef{transpose}, \udef{reciprocal}, \udef{opposite} or \udef{dual} of $R$.
\end{definition}

\begin{lemma}
Let $R,S$ be relations on $(A, B)$, $X\subseteq A$ and $Y\subseteq B$. Then
\begin{enumerate}
\item $(R^\transp)^\transp = R$;
\item $(R \cup S)^\transp = R^\transp \cup S^\transp$;
\item $(R \cap S)^\transp = R^\transp \cap S^\transp$;
\item $\dom(R^\transp) = \codom(R)$ and $\codom(R^\transp) = \dom(R)$;
\item $_{R^\transp}X = X_R$ and $Y_{R^\transp} = {_RY}$;
\item $\im(R^\transp) = \preim(R)$;
\item if $R\subseteq S$, then $R^\transp \subseteq S^\transp$.
\end{enumerate}
\end{lemma}

\begin{lemma}
Let $A,B$ be classes. Then
\begin{enumerate}
\item $U_{A,B}^\transp = U_{B,A}$;
\item $E_{A,B}^\transp = E_{B,A}$;
\item $\id_A^\transp = \id_A$.
\end{enumerate}
\end{lemma}

\subsection{Complementary relation}
\begin{definition}
Let $R$ be a binary relation on $(A, B)$. The \udef{complementary relation} $\overline{R}$ of $R$ is the relation on $(A, B)$ with graph
\[ \graph(\overline{R}) = \setbuilder{(x,y)}{\neg xRy}. \]
\end{definition}
\begin{lemma} \label{relationalComplementProperties}
Let $R,S$ be binary relations.
\begin{enumerate}
\item $\overline{\overline{R}} = R$;
\item $\overline{R^\transp} = \overline{R}^\transp$;
\item $\overline{R\cup S} = \overline{R}\cap \overline{S}$;
\item $\overline{R\cap S} = \overline{R}\cup \overline{S}$;
\item $U = R \cup \overline{R}$;
\item if $R \subseteq S$, then $\overline{R} \supseteq \overline{S}$.
\end{enumerate}
\end{lemma}


\begin{lemma} \label{imageComplementaryRelation}
Let $R$ be a relation on $(A,B)$, $x\in A$ and $y\in B$. Then
\begin{enumerate}
\item $x\overline{R} = B\setminus (xR)$;
\item $\overline{R}y = A\setminus (Ry)$.
\end{enumerate}
If $X\subseteq A$ and $Y\subseteq B$. Then
\begin{enumerate} \setcounter{enumi}{2}
\item $X_{\overline{R}} = B\setminus X^R$;
\item $_{\overline{R}}Y = A\setminus {^RY}$.
\end{enumerate}
\end{lemma}
\begin{proof}
(1) We calculate
\[ y \in x\overline{R} \iff \neg xRy \iff \neg (y\in xR) \iff y\in B\setminus (xR). \]

(2) Similar.

(3) We calculate, using (1),
\[ X_{\overline{R}} = \bigcup_{x\in X}x\overline{R} = \bigcup_{x\in X}B\setminus (xR) = B\setminus \left(\bigcap_{x\in X}xR\right) = B\setminus X^R. \]

(4) Similar.
\end{proof}
\begin{corollary}
Let $X\subseteq A$ be classes. Then
\[ X^c = X^{\overline{\id_A}}, \]
where the complement is taken with respect to $A$.
\end{corollary}
\begin{proof}
We have $X = X_{\id_A} = (X^{\overline{\id_A}})^c$.
\end{proof}

\subsection{Composition of relations}
\begin{definition}
Let $R$ be a relation on $(A, B)$ and $S$ a relation on $(B, C)$. Then the \udef{composition} of $R$ and $S$ is a new relation $R;S$ on $(A, C)$ with graph
\[ \graph(R;S) = \setbuilder{(x,z)\in A\times C}{\exists y\in B: xRy \land ySz}. \]
If $R$ and $S$ are relations such that the codomain of one is the domain of the other, they are called \udef{composable}.

If $R$ and $S$ are composable we also define the notation
\[ S\circ R \defeq R;S. \]
\end{definition}
\begin{lemma} \label{relationalComposition}
Let $R,S,T$ be composable relations.
\begin{enumerate}
\item The composition is associative: $R;(S;T) = (R;S);T$.
\item $(R;S)^\transp = S^\transp ; R^\transp$;
\item $(R\cup S);T = (R;T) \cup (S;T)$;
\item $(R\cap S);T \subseteq R;T \cap S;T$.
\end{enumerate}
\end{lemma}
\begin{proof}
TODO
\end{proof}
TODO: equality for $\cap$ with functions!!

\begin{lemma} \label{setOfRelationComposition}
Let $R,S$ be composable relations. Then for all $x,y$
\begin{enumerate}
\item $x(R;S)y \iff xR \mesh Sy$;
\item $x(\overline{R;S})y \begin{aligned}[t]
&\iff xR\perp Sy \\
&\iff xR \subseteq \overline{S}y;
\end{aligned}$
\item $x(\overline{R;\overline{S}})y \iff xR \subseteq Sy$.
\end{enumerate}
\end{lemma}
\begin{proof}
TODO
\end{proof}
\begin{corollary}
Let $R,S$ be composable relations. If $R$ is right unique, then $\overline{R;\overline{S}} = R;S$.
\end{corollary}


\begin{lemma}
Let $A,B,C,D$ be relations such that $A \subseteq B$ and $C\subseteq D$ and both $A,B$ and $C,D$ are composable, then $A;C\subseteq B;D$.
\end{lemma}
\begin{proof}
Assume the hypotheses of the lemma and let $(x,y) \in \graph(A;C)$. Then there exists a $z$ such that $xAz$ and $zCy$. By hypothesis this means $xBz$ and $zDy$, so $x(B;D)y$.
\end{proof}

\begin{lemma} \label{universalQuantificationForCompositionSuperset}
Let $R,S$ be composable and $T$ a relation. Then
\[ R;S \subseteq T \qquad\iff\qquad \forall x,y,z:\; xRy \land ySz \implies xTz. \]
\end{lemma}

\begin{lemma} \label{compositionCanonicalRelations}
Let $A,B,X, Y$ be classes and $R$ a relation on $(A, B)$. Then
\begin{enumerate}
\item $\id_A;R = R = R;\id_B$;
\item if $S,T\subseteq A$, then $\id_{S};\id_{T} = \id_{S\cap T}$;
\item $E_{X,A};R = E_{X,B}$ and $R; E_{B,Y} = E_{A,Y}$;
\item $U_{X,A};R = \U_{X,A_R}$ and $R; U_{B,Y} = U_{_RB, Y}$;
\item $U_{X,A};R;U_{B,Y} = \begin{cases}
U_{X,Y} & \graph(R) \neq \emptyset \\
E_{X,Y} & \graph(R) = \emptyset.
\end{cases}$
\end{enumerate}
\end{lemma}

\begin{lemma} \label{kernelInclusions}
Let $R$ be a relation. Then
\begin{enumerate}
\item $\id_{\preim(R)} \subseteq R;R^\transp \subseteq U_{\preim(R)}$;
\item $\id_{\im(R)} \subseteq R^\transp;R \subseteq U_{\im(R)}$.
\end{enumerate}
\end{lemma}
\begin{corollary}
Let $R$ be a relation on $(A,B)$, then
\begin{enumerate}
\item $R \subseteq R;R^\transp;R$;
\item $(\id_A \cap R;R^\transp);R = R = R;(\id_{B}\cap R^\transp;R)$.
\end{enumerate}
\end{corollary}
\begin{corollary}
Let $R$ be a relation on $(A,B)$. Then
\begin{enumerate}
\item $\id_A \;\subseteq\; R;R^\transp \cup \overline{R};\overline{R}^\transp$;
\item $\id_A \;\subseteq\; R^\transp;R \cup \overline{R}^\transp;\overline{R}$.
\end{enumerate}
\end{corollary}

\begin{lemma}
Let $R$ be a relation on $(A, B)$ and $S$ a relation on $(B, C)$. Let $X\subset A$ and $Y\subset C$. Then
\begin{enumerate}
\item $X_{R;S} = (X_R)_S = X_{S\circ R}$;
\item $_{R;S}Y = {_R({_SY})} = {_{S\circ R}Y}$.
\end{enumerate}
\end{lemma}

\begin{lemma}
Let $R$ be a relation on $(A,B)$ and $S$ a relation on $(B,C)$. Let $X\subseteq A$. Then $(X^R)_S \subseteq X^{R;S}$
\end{lemma}
\begin{proof}
We have
\[ z\in (X^R)_S \iff \Big[\exists y\in B: \forall x\in X: xRy \land ySz\Big] \implies \Big[\forall x\in X:\exists y\in B: xRy \land ySz\Big] \iff \Big[\forall x\in X: x(R;S)z\Big] \iff z\in X^{R;S}. \] 
\end{proof}

\begin{proposition}[Dedekind formula] \label{DedekindFormula}
Let $R,S,T$ be compatible relations. Then
\[ (R;S)\cap T \subseteq (R\cap (T; S^\transp));(S\cap (R^\transp;T)). \]
\end{proposition}
\begin{proof}
Take $(x,z)\in \graph((R;S)\cap T)$. Then $xTy$ and $xR \mesh Sy$, meaning we can take a $z\in xR\cap Sy$, i.e.\ satisfying $xRz$ and $zSy$. It is then easy to show that $x(R\cap (T; S^\transp))z$ and $z(S\cap (R^\transp;T))y$.
\end{proof}

\begin{lemma}
Let $R,S,T, Q$ be relations. Then $R^\transp; S \subseteq T$ implies $R;Q\cap S \subseteq R; (Q\cap T)$.
\end{lemma}

\begin{definition}
Let $R$ be a homogeneous relation on a class $A$. Then we can define $R^n$ as the $n$-fold composition of $R$:
\[ R^n \defeq \underbrace{R;R; \ldots ;R}_{\text{$n$ times}}. \]
We call $R$ \udef{idempotent} if $R^2 = R$.
\end{definition}

TODO: refine
\begin{proposition}
\begin{itemize}
\item transitive equivalent with $\graph(R^2) \subseteq \graph(R)$
\item reflexive implies $\graph(R) \subseteq \graph(R^2)$
\end{itemize}
\end{proposition}
so preorder sufficient, but not necessary for idempotent.

\subsubsection{Left and right residuals}
\begin{definition}
Let $R,S$ be relations.
\begin{itemize}
\item If $R,S$ have the same codomain, we define the \udef{right residual} as $R\diagup S \defeq \overline{\overline{R}; S^\transp}$.
\item If $R,S$ have the same domain, we define the \udef{left residual} as $S\diagdown R \defeq \overline{S^\transp; \overline{R}}$.
\end{itemize}
\end{definition}

\begin{lemma} \label{residuals}
Let $R,S,T$ be relations. Then
\begin{enumerate}
\item $(R\diagdown S)^\transp = R^\transp\diagup S^\transp$ and $(R\diagup S)^\transp = R^\transp\diagdown S^\transp$;
\item $R^\transp\diagdown S = \overline{R}\diagup \overline{S}^\transp$ and $R^\transp\diagup S = \overline{R}\diagdown \overline{S}^\transp$;
\item $R \diagdown (T\cap S) = R\diagdown T \cap R\diagdown S$ and $(T\cap S)\diagup R = T\diagup R \cap S\diagup R$;
\item $R \diagdown (T\cup S) = R\diagdown T \cup R\diagdown S$ and $(T\cap S)\diagup R = T\diagup R \cup S\diagup R$;
\item $(R\cap S) \diagdown T = R\diagdown T \cup S\diagdown T$ and $T\diagup (R\cap S) = T\diagup R \cup T\diagup S$;
\item $(R\cup S) \diagdown T = R\diagdown T \cap S\diagdown T$ and $T\diagup (R\cup S) = T\diagup R \cap T\diagup S$;
\item if $R\subseteq T$, then $R\diagup S \subseteq T\diagup S$ and $S\diagdown R \subseteq S\diagdown T$;
\item if $S\subseteq T$, then $R\diagup S \supseteq R\diagup T$ and $S\diagdown R \supseteq T\diagdown R$.
\end{enumerate}
\end{lemma}

As an aide-mÃ©moire: the residuals are monotone in the ``numerator'' and antitone in the ``denominator'', where the numerator and denominator refer the the relation above, resp. below, the line in both residuals. The left residual has the denominator on the left; the right residual has it on the right.

\begin{proposition}[SchrÃ¶der rule] \label{SchroderRule}
Let $R,S,T$ be relations. Then
\begin{align*}
R;S \subseteq T &\quad\iff\quad \overline{R} \supseteq \overline{T};S^\transp \quad\iff\quad R \subseteq T\diagup S \\
&\quad\iff\quad \overline{S} \supseteq R^\transp ; \overline{T} \quad\iff\quad S \subseteq R\diagdown T
\end{align*}
\end{proposition}
\begin{proof}
The second line follows from the first by applying the first to $S^\transp;R^\transp \subseteq T^\transp$. The second equivalence is immediate by \ref{relationalComplementProperties} and $\overline{\overline{T};S^\transp} = T\diagup S$. For the first equivalence we only need to prove the direction $\Rightarrow$: applying this implication to $\overline{T};S^\transp \subseteq \overline{R}$ gives $\overline{\overline{T}}\supseteq \overline{\overline{R}};S^{\transp\transp}$. i.e.\ $R;S \subseteq T$.

So assume $R;S \subseteq T$. By \ref{universalQuantificationForCompositionSuperset} this is equivalent to
\[ \forall x,y,z:\; xRy \land ySz \implies xTz. \]
Fix arbitrary $x,y,z$. Assume $ySz$ and $\neg xTz$. This means we must have $\neg xRy$, or we could also derive $xTz$, leading to a contradiction. Thus $ySz \land x\overline{T}z$ imply $x\overline{R}y$. Using \ref{universalQuantificationForCompositionSuperset} again, we get $\overline{T};S^\transp \subseteq \overline{R}$.
\end{proof}
We can also give a proof using image and preimage classes.
\begin{proof}
As before it is enough to prove the first implication. So assume $R;S \subseteq T$; we want to prove $R \subseteq T\diagup S = \overline{\overline{T}; S^\transp}$.

Take $x,y$ such that $xRy$. Then $yS \subseteq xT$, because
\[ \forall z: \quad ySz \implies xRy\land ySz \implies x(R;S)z \implies xTz. \]
We have the following equivalences:
\[ yS \subseteq xT \iff S^\transp y \subseteq xT \iff \overline{S^\transp}y \supseteq \overline{xT} \iff x(\overline{\overline{T}; S^\transp})y, \]
using \ref{setOfRelationComposition} for the last equivalence.
\end{proof}
\begin{corollary} \label{GaloisConnectionFromSchroderRule}
Let $T,S$ be relations. Then
\begin{enumerate}
\item $(R\diagup S);S \subseteq R$ and $S;(S\diagdown R) \subseteq R$;
\item $(R;S)\diagup S \supseteq R$ and $R\diagdown (R;S) \supseteq S$;
\item $((R;S)\diagup S);S = R;S$ and $R;(R\diagdown(R;S)) = R;S$.
\end{enumerate}
\end{corollary}
\begin{proof}
(1) Setting $R$ in the proposition to $R\diagup S$, we get that the truth $R\diagup S \subseteq R\diagup S$ implies $(R\diagup S);S \subseteq R$. The case for $S\diagdown R$ is similar.

(2) Now we set $T$ in the proposition to $R;S$.

(3) This is a combination of (1) and (2): Set the $R$ in (1) to $R;S$ to get $((R;S)\diagup S);S \subseteq R;S$. From (2) we see that $(R;S)\diagup S \supseteq R$, so $((R;S)\diagup S);S \supseteq R;S$.
\end{proof}
\begin{corollary}
Let $R,S,T$ be relations. Then
\[ \overline{R}^\transp;\overline{S}^\transp \subseteq T \quad\iff\quad \overline{S}^\transp;\overline{T}^\transp \subseteq R \quad\iff\quad \overline{T}^\transp;\overline{R}^\transp \subseteq S. \]
\end{corollary}

Suppose we have relations $R$ and $T$ with the same domain and we are interested in finding a relation $X$ such that
\[ R;X = T. \]
It will not always be possible to find such an $X$. It is, however, always possible to find an $X$ such that $R;X \subseteq T$ (for example we could take the empty relation). The SchrÃ¶der rule says that $R\diagdown T$ is the largest $X$ satisfying this inequality (i.e.\ for all such $X$ we have $X\subseteq R\diagdown T$).

So, if the equation $R;X = T$ has a solution, then it must be the left residual $X = R\diagdown T$. There is a similar result for the right residual.

\begin{corollary}
Let $R,T$ be relations and suppose they have the same domain. Then
\begin{align*}
\text{There exists an $X$ such that $R;X = T$} \quad&\iff\quad R;(R\diagdown T) = T \quad\iff\quad R;(R\diagdown T) \supseteq T \\
&\implies\quad X = R\diagdown T.
\end{align*}
Suppose $R$ and $T$ have the same codomain, then
\begin{align*}
\text{There exists an $X$ such that $X;R = T$} \quad&\iff\quad (T\diagup R);R = T \quad\iff\quad (T\diagup R);R \supseteq T \\
&\implies\quad X = T\diagup R.
\end{align*}
\end{corollary}

\subsubsection{Symmetric quotient}
\begin{definition}
Let $R,S$ be composable relations. We define the \udef{symmetric quotient} of $R$ and $S$ as
\[ R \syq S \defeq \overline{R;\overline{S}} \;\cap\; \overline{\overline{R};S}. \]
\end{definition}
Usually in the literature the first argument of the symmetric quotient transposed, i.e.\ it is defined as $R^\transp \syq S$.

\begin{lemma}
Let $R,S$ be composable relations. Then
\begin{align*}
R\syq S &= R^\transp\diagdown S \cap R\diagup S^\transp \\
&= \overline{R}\diagup \overline{S}^\transp \cap \overline{R}^\transp \diagdown \overline{S}.
\end{align*}
\end{lemma}

\begin{lemma}
Let $R,S$ be composable relations. Then
\[ x(R\syq S)y \qquad\iff\qquad xR = Sy. \]
\end{lemma}
\begin{proof}
Immediate from \ref{setOfRelationComposition}.
\end{proof}

\subsection{Restrictions and extensions}
\begin{definition}
Let $R$ be a relation on $(A, B)$, $X\subseteq A$ and $Y \subseteq B$. The \udef{restriction} of $R$ to $(X,Y)$ is the relation $R|^Y_X$ on $(X,Y)$ with graph
\[ \graph(R|^Y_X) = \graph(R)\cap (X\times Y). \]
\begin{itemize}
\item If $Y = B$, then the restriction is called the \udef{left-restriction} of $R$ to $X$ and denoted $\left.R\right|_X$.
\item If $X = A$, then the restriction is called the \udef{right-restriction} of $R$ to $Y$ and denoted $\left.R\right|^Y$.
\end{itemize}
If $S$ is a restriction of $R$, then $R$ is called an \udef{extension} of $S$.
\end{definition}

\begin{lemma}
Let $R$ be a relation on $(A, B)$, $X\subseteq A$ and $Y \subseteq B$. Then
\[ R|^Y_X = \id_X;R;\id_Y. \]
\end{lemma}
\begin{corollary}
Let $R$ be a relation on $(A, B)$, $X_1,X_2\subseteq A$ and $Y_1,Y_2 \subseteq B$. Then
\[ \left.\left(R|_{X_1}^{Y_1}\right)\right|_{X_2}^{Y_2} = R|_{X_1\cap X_2}^{Y_1\cap Y_2}. \]
\end{corollary}
\begin{proof}
Use \ref{compositionCanonicalRelations}.
\end{proof} 

\begin{lemma}
Let $R$ be a relation on $(A,B)$, $X\subseteq A$ and $Y\subseteq B$. Then
\begin{enumerate}
\item $X_R = \im(R|_X) = \im(\id_X;R)$;
\item $_RY = \preim(R|^Y) = \preim(R;\id_Y)$.
\end{enumerate}
\end{lemma}

\subsection{Galois connections}
\begin{proposition}
Consider a monoid $M$ of relations under composition. Then for $R\in M$ the following maps form a Galois connection:
\[ \rho_R: M\to M: S \mapsto S;R \qquad\text{and}\qquad \rho_R^+: M\to M: S \mapsto S\diagup R \]
as do the following:
\[ \lambda_R: M\to M: S \mapsto R;S \qquad\text{and}\qquad \lambda_R^+: M\to M: S \mapsto R\diagdown S. \]
\end{proposition}
\begin{proof}
The is just a restatement of \ref{GaloisConnectionFromSchroderRule}.
\end{proof}

\begin{proposition}
We can order relations by image, $\leq_i$ or by preimage $\leq_p$:
\[ R \leq_i S \defequiv \im(R) \subseteq \im(S) \qquad R \leq_p S \defequiv \preim(R) \subseteq \preim(S). \]
These orders are preorders, but not partial orders.
\begin{enumerate}
\item If we order relations by image, then $X\mapsto \id_X$ and $\im$ form a Galois connection;
\item If we order relations by preimage, then $X\mapsto \id_X$ and $\preim$ form a Galois connection.
\end{enumerate}
\end{proposition}

\begin{lemma}
Let $R$ be a relation on $(A,B)$, $X\subseteq A$ and $Y\subseteq B$, then
\begin{enumerate}
\item $X_R = \im(\id_X; R)$ and $_RX = \preim(R;\id_X)$;
\item $X^R = B\setminus \im(\overline{\id_X}; R)$ and $^RX = A\setminus \preim(R;\overline{\id}_X)$.
\end{enumerate}
\end{lemma}

\begin{proposition}
Let $R$ be a relation on $(A,B)$. Then
\begin{enumerate}
\item $\powerset(A)\to \powerset(B): X\to X^R$ and $\powerset(B)\to \powerset(A): X\to {^RX}$ form a Galois connection;
\item $\powerset(A)\to \powerset(B): X\to X^{\overrightarrow{R}}$ and $\powerset(B)\to \powerset(A): X\to {^{\overleftarrow{R}}X}$ form a Galois connection.
\end{enumerate}
\end{proposition}

\subsubsection{Closures}
TODO use Galois theory
\begin{definition}
Let $R$ be a homogeneous relation on a class $A$.
\begin{itemize}
\item The \udef{reflexive closure} of $R$ is the relation $R^=$ on $A$ with graph
\begin{align*}
\graph(R^=) &= \bigcap\setbuilder{\graph(R')}{\text{$R'$ extends $R$ and is reflexive}} \\
&= \setbuilder{(x,x)\in A\times A}{x\in A}\cup \graph(R); \\
&= \graph(\id_A)\cup \graph(R).
\end{align*}
\item The \udef{reflexive reduction} of $R$ is the relation $R^{\neq}$ on $A$ with graph
\[ \graph{R^{\neq}} = \graph(R)\setminus \setbuilder{(x,x)\in A\times A}{x \in A}. \]
\item The \udef{transitive closure} of $R$ is the relation $R^{+}$ on $A$ with graph
\[ \graph(R^+) = \bigcap\setbuilder{\graph(R')}{\text{$R'$ extends $R$ and is transitive}}. \]
\item The \udef{symmetric closure} of $R$ is the relation $R^{\leftrightarrow}$ on $A$ with graph
\begin{align*}
\graph(R^\leftrightarrow) &= \bigcap\setbuilder{\graph(R')}{\text{$R'$ extends $R$ and is symmetric}} \\
&=  \graph(R)\cup \graph(R^\transp).
\end{align*}
\end{itemize}
\end{definition}

\begin{lemma}
Let $R$ be a homogeneous relation on a class $A$.
\begin{enumerate}
\item The reflexive closure $R^=$ is the smallest reflexive relation on $A$ that extends $R$.
\item The reflexive reduction $R^{\neq}$ is the largest irreflexive relation on $A$ that is a restriction of $R$.
\item The transitive closure $R^{+}$ is the smallest transitive relation on $A$ that extends $R$.
\item The symmetric closure $R^{\leftrightarrow}$ is the smallest symmetric relation on $A$ that extends $R$.
\end{enumerate}
\end{lemma}

\begin{lemma}
The closures (and reduction) are monotone: if $R$ extends $S$, then $R^a$ extends $S^a$ for all $a,b\in\{=,+,\leftrightarrow,\neq\}$.
\end{lemma}

\begin{lemma}
Let $R$ be a homogeneous relation over a class $A$ and $x,y\in A$. Then $x\mathrel{R^+}y$ \textup{if and only if} there exists a finite sequence $\seq{z_0, \ldots, z_n}$ such that $xRz_0$, $z_nRy$ and $\forall i<n: z_iRz_{i+1}$.
\end{lemma}
\begin{proof}
The proof of the direction $\Leftarrow$ is by induction on $n$.

For the direction $\Rightarrow$
\end{proof}

\begin{lemma}
Let $R$ be a homogeneous relation over a class $A$. Then
\begin{enumerate}
\item $\big(R^=\big)^\leftrightarrow = \big(R^\leftrightarrow\big)^=$;
\item $\big(R^=\big)^+ = \big(R^+\big)^=$;
\item $\big(R^\leftrightarrow\big)^+ \neq \big(R^+\big)^\leftrightarrow$.
\end{enumerate}
all closures commute, i.e.\
\[ R^a = R^b \qquad \forall a,b\in\{=,+,\leftrightarrow\}. \]
\end{lemma}
\begin{proof}
(1) $\big(R^=\big)^\leftrightarrow = R^=\cup \big(R^=\big)^\transp = (R\cup \id)\cup \big(R \cup \id\big)^\transp = R\cup R^\transp \cup \id = \big(R^\leftrightarrow\big)^=$.

(2) Take arbitrary $x,y\in A$. First assume $x\mathrel{\big(R^+\big)^=}y$. Then either $x=y$ or $x\mathrel{R^+}y$. In the first case we clearly have $x\mathrel{R^=}y$ and thus $x\mathrel{\big(R^=\big)^+}y$. In the second, we have $R^+ \subseteq \big(R^=\big)^+$ by monotonicity of the closure, so $x\mathrel{\big(R^=\big)^+}y$.

Now assume $x\mathrel{\big(R^=\big)^+}y$. Then
\end{proof}
\begin{proof}
Only the equations involving $R^+$ are non-trivial. For example take $(R^\leftrightarrow)^+ = (R^+)^\leftrightarrow$. Now $(R^+)^\leftrightarrow$ is transitive, because transitivity is preserved under taking the symmetric closure, and contains $R^\leftrightarrow$, so $(R^\leftrightarrow)^+$ is extended by $(R^+)^\leftrightarrow$.

Conversely, take an $x\in (R^+)^\leftrightarrow$. Then either $x\in R^+$ or $x\in (R^\transp)^+$ and both $R^+\subseteq (R^\leftrightarrow)^+$ and $(R^\transp)^+\subseteq (R^\leftrightarrow)^+$. So $(R^+)^\leftrightarrow$ is extended by $(R^\leftrightarrow)^+$
\end{proof}

\begin{lemma}
Let $R$ be a homogeneous relation over a class $A$.
\begin{enumerate}
\item The reflexive transitive closure $R^*$ is the smallest preorder containing $R$.
\item The reflexive transitive symmetric closure $\equiv_R$ is the smallest equivalence relation containing $R$.
\end{enumerate}
\end{lemma}
TODO: equivalence relations are defined below.

\begin{definition}
The reflexive transitive closure $R^*$. The reflexive transitive symmetric closure $\equiv_R$.
\end{definition}

\subsection{Direct product}
TODO: extend: heterogeneous relations + direct product of two different relations.
\begin{definition}
Let $R$ be a homogeneous relation over a class $A$. We can turn $R$ into a relation over $(A, A)$ as follows:
\[ (a,b)R(c,d) \iff aRc \land bRd. \]
\end{definition}
\begin{lemma} \label{relationPropertiesDirectProduct}
The following properties of binary endorelations are conserved under taking the direct product:
\begin{enumerate}
\item all forms of reflexivity;
\item all forms of symmetry;
\item all forms of transitivity;
\item left and right Euclideanness;
\item density.
\end{enumerate}
The following properties are not necessarily conserved:
\begin{enumerate}
\item connexity;
\item semi-connexity;
\item trichotomy.
\end{enumerate}
\end{lemma}

\subsection{Homogeneous relations}
\begin{lemma} \label{selfRelatedElements}
Let $R$ be a homogeneous relation on $A$. Then
\begin{enumerate}
\item $R\cap \id_A = R^\transp\cap \id_A \subseteq R^\transp$;
\item $\id_A \cap R \subseteq R\cap R^\transp$;
\item $\id_A \cap R\cap \overline{R}^\transp \subseteq E_A$;
\item $R\cap \overline{R}^\transp \subseteq \overline{\id_A}$.
\end{enumerate}
\end{lemma}
\begin{proof}
(1) Assume $x(R\cap \id_A)y$, then $x=y$ and $xRy$. So $xRx$, meaning $xR^\transp x$ and thus $xR^\transp y$.

(2) Clearly $\id \cap R \subseteq R$. Combining this with (1) gives the result.

(3, 4) Follow from \ref{setPerpInequality}.
\end{proof}

\subsubsection{Reflexivity and fixed points}
\begin{definition}
Let $R$ be a homogeneous binary relation on a class $A$. The \udef{fixed points} of $R$ are the elements of the class
\[ \Fixedpoints(R) \defeq \setbuilder{a\in A}{aRa}. \]
\end{definition}


\begin{definition}
Let $R$ be a homogeneous binary relation on a class $A$. We say
\begin{itemize}
\item $R$ is \udef{reflexive} if $\Fixedpoints(R) = A$;
\item $R$ is \udef{irreflexive} or \udef{anti-reflexive} if $\Fixedpoints(R) = \emptyset$;
\item $R$ is \udef{quasi-reflexive} if every element that is related to some element is related to itself;
\item $R$ is \udef{left quasi-reflexive} if every element that is left related to some element is related to itself;
\item $R$ is \udef{right quasi-reflexive} if every element that is right related to some element is related to itself;
\item $R$ is \udef{coreflexive} if $xRy$ implies $x=y$.
\end{itemize}
\end{definition}

\begin{lemma} \label{relationalReflexivityEquivalents}
Let $R$ be a homogeneous relation on $A$. Then $R$ is
\begin{enumerate}
\item reflexive $\begin{aligned}[t]
&\text{\textup{if and only if}}\; \id_A \subseteq R \\
&\text{\textup{if and only if}}\; \id_A \perp \overline{R};
\end{aligned}$
\item irreflexive $\begin{aligned}[t]
&\text{\textup{if and only if}}\; \id_A \subseteq \overline{R} \\
&\text{\textup{if and only if}}\; \id_A \perp R;
\end{aligned}$
\item left quasi-reflexive \textup{if and only if} $\id_{\preim(R)} \subseteq R$;
\item right quasi-reflexive \textup{if and only if} $\id_{\im(R)} \subseteq R$;
\item quasi-reflexive \textup{if and only if} $\id_{\preim(R)\cup \im(R)} \subseteq R$;
\item coreflexive \textup{if and only if} $\begin{aligned}[t]
&\text{\textup{if and only if}}\; R \subseteq \id_A \\
&\text{\textup{if and only if}}\; R \perp \overline{\id}_A.
\end{aligned}$
\end{enumerate}
\end{lemma}

\begin{lemma}
Let $R$ be a homogeneous relation on $A$.
\begin{enumerate}
\item If $R$ is left quasi-reflexive, then $R^\transp$ is right quasi-reflexive.
\item If $R$ is right quasi-reflexive, then $R^\transp$ is left quasi-reflexive.
\item If $R$ is reflexive / irreflexive / coreflexive, then $R^\transp$ is too.
\end{enumerate}
\end{lemma}
\begin{proof}
(1) Assume $\id_{\preim(R)} \subseteq R$, then $\id_{\preim(R)} = \id_{\im(R^\transp)} = \id_{\im(R^\transp)}^\transp$. So $\id_{\im(R^\transp)} \subseteq R^\transp$.

(2) Similar.

(3) Follow simply because the converse preserves inclusions.
\end{proof}

\begin{lemma} \label{reflexiveIrreflexive}
Let $R$ be a homogeneous relation on $A$. Then $R$ is reflexive \textup{if and only if} $\overline{R}$ is irreflexive.
\end{lemma}

\begin{lemma}
Let $R$ be a relation. Then $R\diagup R$ and $R\diagdown R$ are reflexive.
\end{lemma}
\begin{proof}
We have $\id; R = R \subseteq R$, so $\id \subseteq R\diagup R$ by the SchrÃ¶der rule \ref{SchroderRule}. The other case is similar.
\end{proof}

\subsubsection{Transitivity}
\begin{definition}
Let $R$ be a homogeneous binary relation on a class $A$. We say
\begin{itemize}
\item $R$ is \udef{transitive} if $\forall x,y,z\in A: [xRy \land yRz] \implies xRz$;
\item $R$ is \udef{intransitive} if it is not transitive;
\item $R$ is \udef{anti-transitive} if it is never transitive:
\[ \forall x,y\in A: (xRy\land yRz) \implies \neg xRz.\]
\end{itemize}
\end{definition}

\begin{lemma}
Let $R$ be a homogeneous relation on $A$. Then $R$ is
\begin{enumerate}
\item transitive \textup{if and only if} $R; R \subseteq R$;
\item anti-transitive \textup{if and only if} $R; R \subseteq \overline{R}$.
\end{enumerate}
\end{lemma}

\begin{lemma}
Let $R$ be a homogeneous relation on $A$. If $R$ is transitive / anti-transitive, then $R^\transp$ is too.
\end{lemma}


\begin{lemma}
\begin{enumerate}
\item An anti-transitive relation is always irreflexive.
\item An irreflexive and left- (or right-) unique relation is always anti-transitive.
\item An anti-transitive relation on a class of more than four elements elements is never connex.
\end{enumerate}
\end{lemma}

\subsubsection{Symmetry}
\begin{definition}
Let $R$ be a homogeneous binary relation on a class $A$. We say
\begin{itemize}
\item $R$ is \udef{symmetric} if $\forall x,y\in A: xRy \implies yRx$;
\item $R$ is \udef{asymmetric} if $\forall x,y\in A: xRy \implies \neg yRx$;
\item $R$ is \udef{antisymmetric} if $\forall x,y\in A: (xRy\land yRx) \implies x=y$.
\end{itemize}
\end{definition}

\begin{lemma} \label{relationalSymmetryEquivalents}
Let $R$ be a homogeneous relation on $A$. Then $R$ is
\begin{enumerate}
\item symmetric \textup{if and only if} $R = R^\transp$;
\item asymmetric $\begin{aligned}[t]
&\text{\textup{if and only if}}\; R \subseteq \overline{R}^\transp \\
&\text{\textup{if and only if}}\; R = R \cap \overline{R}^\transp \\
&\text{\textup{if and only if}}\; R \cap R^\transp = E_A;
\end{aligned}$
\item antisymmetric $\begin{aligned}[t]
&\text{\textup{if and only if}}\; R\cap R^\transp \subseteq \id_A \\
&\text{\textup{if and only if}}\; R^\transp\subseteq \overline{R}\cup \id_A.
\end{aligned}$
\end{enumerate}
\end{lemma}
\begin{proof}
(1) The inclusion $R\subseteq R^\transp$ follows straight from the definition. The other inclusion is obtained by taking the converse.

(2) The third equation is a consequence of \ref{setPerpInequality}.

(3) For the second equivalence we calculate using \ref{setPerpInequality}:
\[ R\cap R^\transp \subseteq \id_A \iff R\cap R^\transp \cap\overline{\id_A} = E_A \iff R^\transp \subseteq \overline{R \cap \overline{\id_A}} = \overline{R} \cup \id_A. \]
\end{proof}
\begin{corollary} \label{asymmetryAntisymmetry}
Asymmetry implies antisymmetry.
\end{corollary}

\begin{lemma}
Let $R$ be a homogeneous relation on $A$.
\begin{enumerate}
\item If $R$ is symmetric / asymmetric / antisymmetric, then $R^\transp$ is too.
\item If $R$ is symmetric / asymmetric, then $\overline{R}$ is too.
\end{enumerate}
\end{lemma}

\begin{lemma} \label{asymmetricIrreflexive}
Let $R$ be a relation. Then
\begin{enumerate}
\item if $R$ is asymmetric \textup{if and only if} $R$ is irreflexive and antisymmetric;
\item if $R$ is transitive, then $R$ is asymmetric iff $R$ is irreflexive.
\end{enumerate}
\end{lemma}
\begin{proof}
(1) Assume $R$ asymmetric. Then  $E_A = R \cap R^\transp \supseteq \id_A\cap R \supseteq E_A$ from \ref{selfRelatedElements}. Thus $\id_A\cap R = E_A$, which means $R$ is irreflexive.

Also $R\cap R^\transp = E_A \subseteq \id_A$, so $R$ is antisymmetric by \ref{relationalSymmetryEquivalents}.

Now assume $R$ antisymmetric and irreflexive. Then $R\cap R^\transp \subseteq \id_A$, so $R\cap R^\transp = \id_A \cap R\cap R^\transp$, but $\id_A\cap R = \emptyset$ by \ref{relationalReflexivityEquivalents}, so $R\cap R^\transp = E_A$ and thus $R$ is asymmetric by \ref{relationalSymmetryEquivalents}.

(2) Assume $R$ transitive and irreflexive. Then $R;R \subseteq R \subseteq \overline{\id}_A$. By SchrÃ¶der's rule, \ref{SchroderRule}, we have $R;\id_A \subseteq \overline{R}^\transp$ and thus $R\perp R^\transp$ by \ref{setPerpInequality}.
\end{proof}

\begin{proposition} \label{symmetricAsymmetricDecomposition}
Let $R$ be a homogeneous relation. Then $R$ can be decomposed as $R = R_S \cup R_A$ where
\begin{enumerate}
\item $R_S \defeq R \cap R^\transp$ is symmetric; and
\item $R_A \defeq R \cap \overline{R}^\transp$ is asymmetric.
\end{enumerate}
\end{proposition}
\begin{proof}
We have
\[ R = R\cap U = R\cap (R^\transp \cup \overline{R}^\transp) = (R \cap R^\transp) \cup (R \cap \overline{R}^\transp) = R_S \cup R_A. \]
(1) From $R_S^\transp = (R \cap R^\transp)^\transp = R^\transp \cap R = R_S$, we see that $R_S$ is symmetric.

(2) From
\[ R_A \cap R_A^\transp = R \cap \overline{R}^\transp \cap R^\transp \cap \overline{R} = (R \cap \overline{R}) \cap (R^\transp \cap \overline{R}^\transp) = E_A, \]
we see that $R_A$ is asymmetric.
\end{proof}\

Using this decomposition we can rephrase the antisymmetry property as $R_S \subseteq \id_A$.

\begin{lemma} \label{symmetricMaximalityMinimality}
Let $R$ be a relation on $A$, $X\subseteq A$ and $x\in X$.
\begin{enumerate}
\item If $R$ is antisymmetric, then
\begin{enumerate}
\item $x$ is maximal in $X$ \textup{if and only if} $x$ is loosely maximal in $X$;
\item $x$ is minimal in $X$ \textup{if and only if} $x$ is loosely minimal in $X$.
\end{enumerate}
\item If $R$ is asymmetric, then
\begin{enumerate}
\item strictly maximality, maximality and loose maximality in $X$ are equivalent;
\item strictly minimality, minimality and loose minimality in $X$ are equivalent.
\end{enumerate}
\end{enumerate}
\end{lemma}
\begin{proof}
(1) We prove (a); point (b) is dual.

We only need to prove that loose maximality implies maximality. Let $x$ be loosely maximal. Then $xR \cap X \subseteq Rx$, which implies $xR\cap X \subseteq xR \cap Rx \subseteq \{x\}$, where the last inclusion follows from antisymmetry. Thus $x$ is maximal.

(2) We prove (a); point (b) is dual.

We only need to prove that loose maximality implies strict maximality. Let $x$ be loosely maximal. Then $xR \cap X \subseteq Rx$, which implies $xR\cap X \subseteq xR \cap Rx \subseteq \emptyset$, where the last inclusion follows from asymmetry. Thus $x$ is strictly maximal.
\end{proof}

\subsubsection{Connexity}
\begin{definition}
Let $R$ be a homogeneous binary relation on a class $A$. We say
\begin{itemize}
\item $R$ is \udef{connex} (or \udef{connected} or \udef{complete}) if $\forall x,y\in A: xRy \lor yRx$;
\item $R$ is \udef{semi-connex} (or \udef{weakly connected} or \udef{total}) if $\forall x,y\in A: xRy \lor yRx \lor x=y$;
\item $R$ is \udef{trichotomous} if $\forall x,y\in A$, exactly one of $xRy, yRx$ or $x=y$ holds.
\end{itemize}
\end{definition}

\begin{lemma}
Let $R$ be a homogeneous relation on $A$. Then
\begin{enumerate}
\item $\begin{aligned}[t]
R \;\text{is connex} &\iff U_A = R\cup R^\transp \iff E_A = \overline{R}\cap \overline{R}^\transp\\
&\iff \overline{R}\subseteq R^\transp \iff \overline{R}\; \text{is asymmetric};
\end{aligned}$
\item $\begin{aligned}[t]
R\; \text{is semi-connex} &\iff U_A = R\cup R^\transp \cup \id_A \iff \overline{\id}_A\subseteq R\cup R^\transp \\
&\iff \overline{R}\cap \overline{R}^\transp \subseteq \id_A \iff \overline{R}\; \text{is antisymmetric}
\end{aligned}$;
\item $\begin{aligned}[t]
R\; \text{is trichotomous} &\iff U_A = R\symdiff R^\transp \symdiff \id_A \\
&\iff \begin{cases}
U_A = R\cup R^\transp \cup \id_A \\
E_A = R\cap R^\transp \cap \id_A
\end{cases} \iff R\cup R^\transp = \overline{\id}_A \\
&\iff \begin{cases}
U_A = R\cup R^\transp \cup \id_A \\
E_A = R\cap \id_A \\
E_A = R \cap R^\transp
\end{cases} \iff R \; \text{is}\;\begin{cases}
\text{semi-connex} \\ \text{irreflexive} \\ \text{asymmetric}
\end{cases} \\
&\iff R \; \text{is}\;\begin{cases}
\text{semi-connex} \\ \text{asymmetric}
\end{cases} \iff \overline{R} \; \text{is}\;\begin{cases}
\text{antisymmetric} \\ \text{connex}
\end{cases}.
\end{aligned}$
\end{enumerate}
\end{lemma}

\begin{corollary} \label{connexityConsequences}
Let $R$ be a homogeneous relation. Then
\begin{enumerate}
\item if $R$ is connex, then $R$ is reflexive.
\end{enumerate}
\end{corollary}
\begin{proof}
(1) We have
\[ R \; \text{connex} \iff \overline{R} \; \text{asymmetric} \implies \overline{R} \; \text{irreflexive} \iff R \; \text{reflexive}, \]
using \ref{asymmetricIrreflexive} and \ref{reflexiveIrreflexive}. 
\end{proof}

\begin{lemma}
Let $R$ be a homogeneous relation on $A$. If $R$ is connex / semi-connex / trichotomous, then $R^\transp$ is too.
\end{lemma}

\subsubsection{Euclideanness}
\begin{definition}
Let $R$ be a homogeneous binary relation on a class $A$. We say
\begin{itemize}
\item $R$ is \udef{(right) Euclidean} if $\forall x,y,z\in A: xRy \land xRz \implies yRz$;
\item $R$ is \udef{left Euclidean} if $\forall x,y,z\in A: yRx \land zRx \implies yRz$.
\end{itemize}
\end{definition}

\begin{lemma}
Let $R$ be a homogeneous relation on $A$. Then $R$ is
\begin{enumerate}
\item Euclidean \textup{if and only if} $R^\transp; R \subseteq R$;
\item left Euclidean \textup{if and only if} $R; R^\transp \subseteq R$.
\end{enumerate}
\end{lemma}
\begin{lemma}
Let $R$ be a homogeneous relation on $A$. If
\begin{enumerate}
\item $R$ is right Euclidean, then $R^\transp$ is left Euclidean;
\item $R$ is left Euclidean, then $R^\transp$ is right Euclidean.
\end{enumerate}
\end{lemma}

\subsubsection{Density}
\begin{definition}
Let $R$ be a homogeneous binary relation on a class $A$. We say
\begin{itemize}
\item $R$ is \udef{dense} if $\forall x,y\in A: xRy \implies [\exists z\in A: xRz \land zRy]$.
\end{itemize}
\end{definition}

\begin{lemma}
A homogeneous relation $R$ is dense \textup{if and only if} $R \subseteq R;R$.
\end{lemma}
\begin{lemma}
If $R$ is reflexive, then $R$ is dense.
\end{lemma}
\begin{proof}
Assume $R$ reflexive, i.e.\ $\id_A\subseteq R$. Then $R = \id_A ;R \subseteq R;R$.
\end{proof}

\begin{lemma}
Let $R$ be a homogeneous relation on $A$. If $R$ is dense, then $R^\transp$ is dense.
\end{lemma}

\subsection{Equivalence relations and generalisations}
\begin{definition}
An \udef{equivalence relation} is a binary relation that is reflexive, symmetric and transitive.
\end{definition}

\begin{lemma}
Let $A,B$ be classes. Then the empty relation on $(A,B)$, the universal relation $U_{A,B}$ and the identity relation $\id_A$ are equivalence relations.
\end{lemma}

\subsubsection{Equivalence classes and partitions}
\begin{definition}
Let $\sim$ be an equivalence relation on $A$. Let $x\in A$. The \udef{equivalence class} of $x$ is the set
\[ [x]_\sim \defeq x\sim \; = \; \sim x = \setbuilder{y\in A}{x\sim y}. \]
Then $x$ is called a \udef{representative} of this equivalence class.

If $A$ is a \emph{set}, there is a set of all equivalence classes. This is called the \udef{quotient set} of $A$ by $\sim$
\[ A/\sim \defeq \{ [x]_\sim \in \powerset(A) \;|\; x\in A \}. \]
\end{definition}
So the equivalence classes are the principle images / preimages of the equivalence relation.

\begin{proposition}
Let $\sim$ be an equivalence relation on a set $A$. The quotient set of $A$ by $\sim$ defines a \udef{partition} of $A$:
\begin{enumerate}
\item Every equivalence class is non-empty (each equivalence class has a representative);
\item every element of $A$ is in an equivalence class, i.e.\
\[ A = \bigcup (A/\sim); \]
\item any two equivalence classes are either disjoint or the same:
\[ \forall x,y\in A: \qquad[x]_\sim \perp [y]_\sim \quad \lor \quad [x]_\sim = [y]_\sim. \]
\end{enumerate}
Conversely, every partition defines an equivalence relation.
\end{proposition}

\subsubsection{Egg-box diagrams and multiple equivalences}
\begin{lemma}
Let $A$ be a class and $R_1, R_2$ equivalence relations on $A$. Then $R_1 \cap R_2$ is an equivalence relation.
\end{lemma}

\begin{definition}
Let $A$ be a class and $R_1, R_2$ two equivalence relations. We can draw the elements of $A$ in a grid such that
\begin{itemize}
\item two elements are in the same column \textup{if and only if} they are $R_1$-equivalent;
\item two elements are in the same row \textup{if and only if} they are $R_2$-equivalent.
\end{itemize}
The cells in the grid are then $R_1\cap R_2$-equivalence classes.

Such a diagram is called an \udef{egg-box diagram}.
\end{definition}

Usually the term ``egg-box diagram'' specifically refers to the case when $R_1, R_2$ are the Green's relations $\greensL$ and $\greensR$ of a semigroup.

\begin{example}
Consider the set $\powerset(\{1,2,3,4\})$ with equivalence relations
\begin{itemize}
\item $aR_1 b$ if subsets $a$ and $b$ have the number of elements;
\item $aR_2 b$ if subsets $a$ and $b$ have the number of even elements.
\end{itemize}
Then the egg-box diagram of $R_1,R_2$ is
\[ \begin{array}{|c|c|c|c|c|}
\hline
\emptyset & \{1\}, \{3\} & \{1,3\} && \\ \hline
& \{2\}, \{4\} & \{1,2\}, \{1,4\}, & \{1,2,3\}, \{1,3,4\} & \\
&  & \{2,3\}, \{3,4\} &  & \\ \hline
&& \{2,4\} & \{1,2,4\}, \{2,3,4\}  & \{1,2,3,4\}    \\ \hline
\end{array} \]
\end{example}

\begin{proposition} \label{commutingEquivalenceRelations}
Let $A$ be a class and $R_1, R_2$ equivalence relations on $A$. Then the following are equivalent:
\begin{enumerate}
\item $R_1;R_2$ is symmetric;
\item $R_1;R_2 = R_2;R_1$;
\item $R_1;R_2$ is an equivalence relation;
\item the egg-box diagram of $R_1, R_2$ decomposes into blocks, i.e.\
\begin{itemize}
\item a block consists of a rectangular region of cells;
\item each cell in the block is occupied;
\item no cell not included in the block, but in the same row / column as a cell in the block is occupied;
\end{itemize}
these blocks are $R_1;R_2$-equivalence classes;
\item for any four cells that are the corners of a rectangle in the egg-diagram: if any three of these cells are occupied, all four cells are occupied.
\end{enumerate}
In this case $R_1;R_2$ is the smallest equivalence relation containing $R_1\cup R_2$.
\end{proposition}
TODO $R_1; R_2$ is transitive closure of $R_1\cup R_2$.
\begin{proof}
$(1)\Rightarrow (2)$ We have $R_1;R_2 = (R_1;R_2)^\transp = R_2^\transp; R_1^\transp = R_2;R_1$.

$(2)\Rightarrow (3)$ We verify
\begin{itemize}
\item \emph{reflexivity}: from $\id_A \subseteq R_1$ and $\id_A \subseteq R_2$, we get $\id_A = \id_A^2 \subseteq R_1;R_2$;
\item \emph{symmetry}: we have $(R_1;R_2)^\transp = R_2^\transp; R_1^\transp = R_2;R_1 = R_1;R_2$;
\item \emph{transitivity}: we have
\[ (R_1;R_2);(R_1; R_2) = R_1;R_1;R_2;R_1 = R_1;R_2. \]
\end{itemize}

$(3)\Rightarrow (1)$ Immediate.

$(2)\Leftrightarrow (4, 5)$ On reflection, one may understand that (4) and (5) are equivalent.

First assume (2) and take any three occupied cells that lie on the corners of a rectangle. Take $a,b$ from the diagonally opposing cells. Then $a(R_1;R_2)b$, because there exists a $c$ in the third cell. So also $a(R_2;R_1)b$, meaning there exists an element in the fourth sell, so (5) holds.

We can run the argument in reverse for the converse.

(Final observation) We first show that $R_1\cup R_2 \subseteq R_1;R_2$. Because $\id_A \subseteq R_1, R_2$, we have
\[ R_1\cup R_2 \subseteq R_1;(R_1\cup R_2);R_2 = R_1;R_1;R_2 \cup R_1;R_2;R_2 = R_1;R_2. \]
Now assume $R$ is an equivalence class containing $R_1\cup R_2$, then
\[ R \supseteq (R_1\cup R_2);(R_1\cup R_2) = R_1 \cup R_1;R_2 \cup R_2;R_1 \cup R_2 = R_1;R_2. \]
\end{proof}

\subsubsection{Tolerance relations}
\begin{definition}
A \udef{tolerance relation} is a binary relation that is reflexive and symmetric.

If $T$ is a tolerance relation on a class $X$, then $\sSet{X,T}$ is called a \udef{tolerance space}.
\end{definition}
A tolerance relation expresses the idea of `resembling' or `being within tolerance'.

\subsubsection{Quasi-equivalence relations}
\begin{definition}
A \udef{quasi-equivalence relation} is a binary relation $R$ such that
\begin{itemize}
\item $R$ is symmetric;
\item $R$ is transitive.
\end{itemize}
\end{definition}

\begin{lemma} \label{quasiEquivalenceLemma}
Let $R$ be a quasi-equivalence relation on a class $A$ and $x\in A$. If $xR$ is not empty, then $xRx$.
\end{lemma}
\begin{proof}
If $xR$ is not empty, then there exists an $a\in xR$, i.e.\ $xRa$. By symmetry and transitivity, we have $xRaRx$, so $xRx$.
\end{proof}

\begin{definition}
Let $X$ be a set. We call $P\in\powerset^2(X)$ a \udef{quasi-partition} if $\emptyset\notin P$ and any two elements are either disjoint or the same:
\[ \forall A,B\in P: \quad A\perp B \quad\lor\quad A=B. \]
\end{definition}

\begin{proposition}
Let $X$ be a set. The function
\[ \operatorname{QP}: \{\text{quasi-equivalence relations on $X$}\} \to \{\text{quasi-partitions on $X$}\}: R\mapsto \setbuilder{xR}{x\in X} \]
is bijective and its inverse is given by
\[ \operatorname{QP}^{-1}(P) = \setbuilder{(x,y)\in X^2}{\exists A\in P: \{x,y\}\subseteq A}. \]
\end{proposition}
\begin{proof}
We first prove that $\operatorname{QP}$ is well-defined, i.e.\ $\operatorname{QP}(R)$ is a quasipartition on $X$ for each quasi-equivalence relation $R$ on $X$.

Take $xR,yR\in \operatorname{QP}(R)$ and assume that $xR\mesh yR$. We will show that in this case $xR = yR$. By assumption we can find a $z\in xR\cap yR$. Take $a\in xR$, so that we have $aRx, zRx$ and $zRy$. Then by symmetry and transitivity, we have $aRy$, because $aRxRzRy$. This gives us $xR\subseteq yR$. Similarly $yR\subseteq xR$, so $xR=yR$.

Next we show that $\operatorname{QP}^{-1}$ is a left-inverse.
Let $R$ be a quasi-equivalence relation on $X$ and take $(a,b)\in R$. Then $\{a,b\}\in aR$ by \ref{quasiEquivalenceLemma} and thus $(a,b)\in \operatorname{QP}^{-1}(\operatorname{QP}(R))$.
Now take $(a,b)\in \operatorname{QP}^{-1}(\operatorname{QP}(R))$. Then there exists $z\in X$ such that $\{a,b\}\subseteq zR$. Thus $aRzRb$ and so $(a,b)\in R$.

Finally we show that $\operatorname{QP}^{-1}$ is a right-inverse. Take a quasi-partition $P$ on $X$, $A\in P$ and $a\in A$ (by definition $A\neq \emptyset$). Then
\begin{align*}
P \ni A &= a\setbuilder{(a,b)}{b\in A} \\
&= a\setbuilder{(a,b)}{\exists A\in P: b\in A} \\
&= a\setbuilder{(a,b)}{\exists A\in P: \{a,b\}\subseteq A} \\
&= a\operatorname{QP}^{-1}(P) \in \operatorname{QP}(\operatorname{QP}^{-1}(P)).
\end{align*}
This shows that $P = \operatorname{QP}(\operatorname{QP}^{-1}(P))$.
\end{proof}

\subsection{Uniqueness and totality}
\begin{definition}
Let $R$ be a relation on $(A, B)$. We call $R$
\begin{itemize}
\item \udef{left-total}, \udef{serial} or simply \udef{total} if $A = {_RB}$;
\item \udef{right-total} or \udef{surjective} or \udef{onto} if $A_R = B$;
\item \udef{left-unique} or \udef{injective} if
\[ \forall x_1,x_2\in A: \forall y\in B: \; x_1Ry \land x_2Ry \implies x_1=x_2; \]
\item \udef{right-unique} or \udef{functional} if
\[ \forall x\in A: \forall y_1,y_2\in B: \; xRy_1 \land xRy_2 \implies y_1=y_2. \]
\end{itemize}
We may also call a binary relation
\begin{itemize}
\item \textbf{one-to-one} if it is injective and functional;
\item \textbf{one-to-many} if it is injective and not functional;
\item \textbf{many-to-one} if it is not injective and functional;
\item \textbf{many-to-many} if it is not injective and not functional.
\end{itemize}
\end{definition}

\begin{lemma}
Let $R$ be a relation. Then
\begin{enumerate}
\item $R$ is right-unique \textup{if and only if} $R^\transp$ is left-unique;
\item $R$ is right-total \textup{if and only if} $R^\transp$ is left-total.
\end{enumerate}
\end{lemma}

\subsubsection{Totality}
\begin{lemma} \label{totalityEquivalences}
Let $R$ be a relation on $(A, B)$. Then
\begin{enumerate}
\item the following are equivalent to $R$ being left-total:
\begin{enumerate}
\item $U_{A,B} = R;U_{B,B}$
\item $\id_A \subseteq R;R^\transp$;
\item $\overline{R}\subseteq R;\overline{\id}_B$;
\item for all relations $S$: $S;R = E \implies S = E$;
\end{enumerate}
\item the following are equivalent to $R$ being right-total:
\begin{enumerate}
\item $U_{A,B} = U_{A,A};R$
\item $\id_B \subseteq R^\transp;R$;
\item $\overline{R}\subseteq \overline{\id}_A;R$;
\item for all relations $S$: $R;S = E \implies S = E$.
\end{enumerate}
\end{enumerate}
\end{lemma}
\begin{proof}
$(a \Rightarrow b)$ We calculate using the Dedekind rule:
\[ \id = U\cap \id = R;U\cap \id \subseteq (R\cap \id;U^\transp);(U\cap R^\transp;\id) = R;R^\transp. \]
\end{proof}

\subsubsection{Uniqueness}
\begin{lemma} \label{relationTimesTransposeSubsetIdentity}
Let $R$ be a relation. Then
\begin{enumerate}
\item $R$ is functional \textup{if and only if} $R^\transp; R \subseteq \id_{\codom(R)}$;
\item $R$ is injective \textup{if and only if} $R; R^\transp \subseteq \id_{\dom(R)}$.
\end{enumerate}
We also have
\begin{enumerate} \setcounter{enumi}{2}
\item $R$ is functional \textup{if and only if} $R^\transp; R = \id_{\im(R)}$;
\item $R$ is injective \textup{if and only if} $R; R^\transp = \id_{\preim(R)}$.
\end{enumerate}
\end{lemma}
\begin{proof}
(1) Assume that there exist $x,y_1,y_2$ such that $xRy_1$ and $xRy_2$. This means $y_1R^\transp x$ and $xRy_2$, so $y_1(R^\transp; R) y_2$. Then $R$ is functional iff $y_1 = y_2$ iff $R^\transp; R \subseteq \id_{\codom(R)}$.

(2) Similar.

(3, 4) Due to the inclusions in \ref{kernelInclusions}.
\end{proof}
\begin{corollary}
Let $R, S$ be relations. Then
\begin{enumerate}
\item if $R$ and $S$ are left/right-unique, then $R;S$ is left/right-unique;
\item $R$ is right-unique \textup{if and only if} $R \subseteq R^\transp \diagdown \id$;
\item $R$ is left-unique \textup{if and only if} $R\subseteq \id \diagup R^\transp$.
\end{enumerate}
\end{corollary}
\begin{proof}
(1) Assume $R$ and $S$ are right-unique. Then
\[ (R;S)^\transp; (R;S) = S^\transp;R^\transp;R;S \subseteq S^\transp;\id_{\dom(S)};S = S^\transp;S \subseteq \id_{\codom(S)} = \id_{\codom(R;S)}. \]

(2, 3) Applications of SchrÃ¶der's rule.
\end{proof}

\begin{lemma}
Let $R,S, T$ be composable relations. Then
\begin{enumerate}
\item if $R$ is right-unique, then $\begin{aligned}[t]
R;(S\cap T) &= R;S \cap R;T\\
S\cap T;R &= (S;R^\transp \cap T);R
\end{aligned}$
\item if $R$ is left-unique, then $\begin{aligned}[t]
(S\cap T);R &= S;R \cap T;R \\
R;S\cap T &= R;(S\cap R^\transp;T) .
\end{aligned}$
\end{enumerate}
\end{lemma}
\begin{proof}
(1a) The inclusion $\subseteq$ is in \ref{relationalComposition}. For the other inclusion we can use the Dedekind formula \ref{DedekindFormula}:
\begin{align*}
R;S \cap R;T &\subseteq (R\cap (R;T;S^\transp));(S\cap R^\transp;R;T) \\
&\subseteq R;(S\cap R^\transp;R;T) \\
&\subseteq R;(S\cap T),
\end{align*}
where we have used the right-uniqueness for the last inclusion: $R^\transp;R;T \subseteq T$.

(1b) We use the Dedekind formula twice:
\begin{align*}
S\cap T;R &\subseteq (T\cap S;R^\transp);(R\cap T^\transp;S) \subseteq (T\cap S;R^\transp);R \\
&\subseteq (S\cap T;R);(R^\transp\cap S^\transp;T);R \subseteq (S\cap T;R);R^\transp;R \\
&\subseteq S\cap T;R,
\end{align*}
where we have used the right-uniqueness for the last inclusion: $(S\cap T;R);R^\transp;R \subseteq (S\cap T;R)$.

(2a) The calculation is similar to (1a):
\begin{align*}
S;R \cap T;R &\subseteq (S\cap (T;R;R^\transp));(R\cap S^\transp;T;R) \\
&\subseteq (S\cap (T;R;R^\transp));R \\
&\subseteq (S\cap T);R.
\end{align*}

(2b) The calculation is similar to (1b):
\begin{align*}
R;S\cap T &\subseteq (R\cap T;S^\transp);(S\cap R^\transp;T) \subseteq R;(S\cap R^\transp;T) \\
&\subseteq R;(R^\transp\cap S;T^\transp);(T\cap R;S) \subseteq R;R^\transp;(T\cap R;S) \\
&\subseteq T\cap R;S.
\end{align*}
\end{proof}

\begin{lemma} \label{uniquenessResiduals}
Let $R,S$ be composable relations.
\begin{enumerate}
\item If $R$ is right-unique, then $\begin{aligned}[t]
\overline{R;S} &= R;\overline{S} \cup \overline{R;U} \\
R;\overline{S} &= R;U\cap \overline{R;S} \\
\overline{R;\overline{S}} &= \overline{R;U} \cup R;S.
\end{aligned}$
\item If $S$ is left-unique, then $\begin{aligned}[t]
\overline{R;S} &= \overline{R};S \cup \overline{U;S} \\
\overline{R};S &= U;S\cap \overline{R;S} \\
\overline{\overline{R};S} &= \overline{U;S}\cup R;S.
\end{aligned}$
\end{enumerate}
\end{lemma}

\begin{lemma} \label{imagePreimageUniqueness}
Let $R$ be a relation on $(A, B)$, $X,Y\subset A$ and $Z,W\subset B$. If $R$ is injective, then
\begin{enumerate}
\item $(X\cup Y)_R = X_R\cup Y_R$;
\item $(X\cap Y)_R = X_R\cap Y_R$;
\item $(X\setminus Y)_R = X_R\setminus Y_R$;
\item $(X\symdiff Y)_R = X_R\symdiff Y_R$.
\end{enumerate}
If $R$ is functional, then
\begin{enumerate} \setcounter{enumi}{4}
\item $_R(Z\cup W) = {_RZ}\cup {_RW}$;
\item $_R(Z\cap W) = {_RZ}\cap {_RW}$;
\item $_R(Z\setminus W) = {_RZ}\setminus {_RW}$;
\item $_R(Z\symdiff W) = {_RZ}\symdiff {_RW}$.
\end{enumerate}
If $R$ is injective and surjective, then
\begin{enumerate} \setcounter{enumi}{8}
\item $(X^c)_R = (X_R)^c$.
\end{enumerate}
If $R$ is total and functional, then
\begin{enumerate} \setcounter{enumi}{8}
\item ${_R}(X^c) = ({_RX})^c$.
\end{enumerate}
\end{lemma}
TODO: similar for totality and polars?

\subsubsection{Kernels}

\begin{definition}
Let $R$ be a relation on $(A, B)$.
\begin{itemize}
\item The \udef{kernel} of $R$ is $\ker R \defeq \setbuilder{(x,y)\in A\times A}{xR \mesh yR}$.
\item The \udef{cokernel} of $R$ is $\coker R \defeq \setbuilder{(x,y)\in B\times B}{Rx \mesh Ry}$.
\end{itemize}
\end{definition}

\begin{lemma}
Let $R$ be a relation on $(A, B)$. Then
\begin{enumerate}
\item $\ker R$ is a symmetric relation on $A$;
\item if $R$ is left total, then $\ker$ is a tolerance relation on $A$;
\item $\ker R = R;R^\transp = R^{\transp}\circ R$.
\end{enumerate}
\end{lemma}


\subsection{Constant relations and points}
\begin{definition}
Let $A,B$ be classes and $R$ a relation on $A,B$. We call $R$
\begin{itemize}
\item \udef{right-constant} if $\forall x\in A, \forall y,z \in B: \; xRy \iff xRz$;
\item \udef{left-constant} if $\forall x, y\in A, \forall z \in B: \; xRz \iff yRz$;
\item a \udef{point} if $R = \{x\}\times B$ for some $x\in A$.
\end{itemize}
Let $x\in A$. We define $\point{x} \defeq \{x\}\times A$.
\end{definition}

\begin{lemma}
Let $R$ be a relation. Then $R$ is right-constant \textup{if and only if} $R^\transp$ is left-constant.
\end{lemma}

\begin{lemma}
Let $R$ be a relation on $(A, B)$. Then
\begin{enumerate}
\item $R$ is right-constant \textup{if and only if} $R = R;U_{B,B}$;
\item $R$ is left-constant \textup{if and only if} $R = U_{A,A};R$;
\item $R$ is a point \textup{if and only if} $R$ is right-constant, non-zero and injective.
\end{enumerate}
\end{lemma}

\begin{lemma}
Let $R$ be a relation on $(A,B)$, $x\in A$ and $y\in B$. Then
\begin{enumerate}
\item $R;\point{y}$ is a point;
\item $\point{x}^\transp; R$ is the converse of a point;
\item $Ry = \preim(R;\point{y})$;
\item $xR = \im(\point{x}^\transp; R)$.
\end{enumerate}
\end{lemma}

\section{Functions}
TODO: equiv for equality!

\begin{definition}
A \udef{function} is a binary relation that is functional and serial.
\end{definition}
If a relation $f$ on $(A, B)$ is a function, then for every $x\in A$, there is a unique $y\in B$ such that $xfy$. We write $f(x)$ to denote this unique element.

Conceptually we can rephrase this as saying that for each ``input'' in the domain $A$, the function $f$ produces a unique ``output'' in the codomain $B$.

\begin{note}
We write
\[f:A \to B: x\mapsto f(x) \]
to show $f$ is a function with domain $A$ and codomain $B$ that maps $x\in A$ to $f(x)\in B$. We say $f$ is a function from $A$ to $B$ or $f$ maps $A$ to $B$. 

If $A, B$ are sets, we can consider the  set of all functions from $A$ to $B$. This set is denoted $(A\to B)$.
\end{note}

Depending on the context, functions may also be called \udef{maps} or \udef{transformations}. These are synonyms with slightly different connotations.

\begin{lemma}
Let $f_1: A_1\to B_1$ and $f_2: A_2\to B_2$ be functions. Then $f_1$ and $f_2$ are the same functions \textup{if and only if}
\begin{enumerate}
\item $A_1 = A_2$ and $B_1 = B_2$;
\item $\forall x\in A_1: f_1(x) = f_2(x)$.
\end{enumerate}
\end{lemma}

\begin{lemma}
Let $f$ be a relation. Then $f$ is a function \textup{if and only if} $f;\overline{\id} = \overline{R}$.
\end{lemma}

\begin{lemma} \label{functionEqualityIdComparison}
Let $f,g: A\to B$ be functions. Then $f = g$ \textup{if and only if} $\id_A \subseteq f;g^\transp$.
\end{lemma}

\subsection{Image and preimage}
\subsubsection{Functions associated to a relation}
We can associate to any relation $R$ on $(A,B)$
\begin{itemize}
\item an \udef{image function} $R^{\imf}: \powerset(A) \to \powerset(B): X \mapsto X_R$;
\item a \udef{preimage function} $R^{\preimf}: \powerset(B) \to \powerset(A): X \mapsto {_RX}$;
\item a \udef{right bounds function} $\powerset(A) \to \powerset(B): X \mapsto X^R$;
\item a \udef{left bounds function} $\powerset(B) \to \powerset(A): X \mapsto {^RX}$.
\end{itemize}

Clearly $R^{\preimf} = (R^\transp)^\imf$.

\begin{lemma}
Let $R,S$ be composable relations. Then $(R;S)^\imf = R^\imf;S^\imf$.
\end{lemma}
\begin{proof}
Take some arbitrary $A\subseteq \dom(R)$. Then for all $y\in \codom(S)$ we have
\begin{align*}
y \in (R;S)^\imf(A) &\iff \exists x\in A:\; x(R;S)y \\
&\iff \exists x\in A:\exists z\in \dom(S) = \codom(R): \; xRz\;\wedge\; zSy \\
&\iff \exists z\in \dom(S) = \codom(R):\exists x\in A: \; xRz\;\wedge\; zSy \\
&\iff \exists z\in R^\imf(A): zSy \\
&\iff y\in S^\imf(R^\imf(A)) = (R^\imf;S^\imf)(A).
\end{align*}
\end{proof}
\begin{corollary}
For any relation $R$, $\ker(R)^\imf = R^\imf;R^\preimf = R^\preimf\circ R^\imf$.
\end{corollary}

\subsubsection{Applying functions inside sets}
As functions are relations they have images, preimages and associated image and preimage functions.

\begin{lemma}
Let $A,B$ be classes and $f:A\to B$ a function. Then
\begin{enumerate}
\item $f^{\imf}: \powerset(A) \to \powerset(B): X\mapsto \setbuilder{f(x)\in B}{x\in X}$;
\item $f^{\preimf}: \powerset(B) \to \powerset(A): Y\mapsto \setbuilder{x\in A}{f(x) \in Y}$.
\end{enumerate}
\end{lemma}

Image and preimage functions are also functions and thus also have images, preimages and associated image and preimage functions.

We have, for a function $f:A\to B$,
\begin{itemize}
\item $f^{\imf\imf}\defeq (f^{\imf})^\imf: \powerset^2(A) \to \powerset^2{B}$;
\item $f^{\preimf\preimf}\defeq (f^{\preimf})^\preimf: \powerset^2(A) \to \powerset^2{B}$;
\item $f^{\imf\preimf}\defeq (f^{\imf})^\preimf: \powerset^2(B) \to \powerset^2{A}$;
\item $f^{\preimf\imf}\defeq (f^{\preimf})^\imf: \powerset^2(B) \to \powerset^2{A}$;
\end{itemize}

Note that in general $f^{\imf\preimf} \neq f^{\preimf\imf}$ and $f^{\preimf\preimf} \neq f^{\imf\imf}$.

\begin{example}
Let $A = \{a,b\}$ and $B = \{c\}$. Consider the unique (constant) function in $(A\to B)$. Then
\begin{itemize}
\item $\begin{aligned}[t]
f^{\preimf\imf}(\{\{c\}\}) &= \setbuilder{f^\preimf(X)}{X\in \{\{c\}\}} \\
&= \{f^\preimf(\{c\})\} \\
&= \{\{a,b\}\};
\end{aligned}$
\item $\begin{aligned}[t]
f^{\imf\preimf}(\{\{c\}\}) &= \setbuilder{X}{f^\imf(X)\in \{\{c\}\}} \\
&= \setbuilder{X}{f^\imf(X) = \{c\}} \\
&= \{ \{a\}, \{b\}, \{a,b\} \}.
\end{aligned}$
\end{itemize}
\end{example}

\begin{lemma}
Let $A,B$ be classes, $f:A\to B$ a function, $x\in A$ and $Y\subseteq B$. Then $x\in f^\preimf(Y) \iff f(x)\in Y$.
\end{lemma}
TODO Galois connection.

\begin{proposition}
Let $A,B$ be classes and $f:A\to B$ a function. Then
\begin{enumerate}
\item $(f^\imf,f^\preimf)$ is a Galois connection between $\sSet{\powerset(A), \subseteq}$ and $\sSet{\powerset(B), \subseteq}$.
\end{enumerate}
Also $(f^\imf\circ f^{\preimf})(Y) = Y\cap \im(f)$.
\end{proposition}
\begin{proof}
We have
\[ f^\imf(X) \subseteq Y \iff \forall x\in X: f(x) \in Y \iff X \subseteq f^{\preimf}(Y). \]

Take $Y\in \powerset(B)$. Then
\begin{align*}
y\in (f^\imf\circ f^{\preimf})(Y) &\iff \exists x\in f^{\preimf}:\; f(x) = y \\
&\iff \exists x\in A: \;f(x)\in Y \land f(x) = y \\
&\iff \exists x\in A: \;y \in Y \land f(x) = y \\
&\iff y\in Y\cap \im(f).
\end{align*}
\end{proof}





\begin{lemma}
Let $f$ be a function. Then $f^{\preimf}\big(\biguplus \mathcal{E}\big) = \biguplus f^\preimf(\mathcal{E})$.
\end{lemma}

\begin{lemma} \label{functionUpperbound}
Let $A,B,C$ be classes, $f: A\to B$ a function and $R$ a relation on $(B,C)$. Let $X \subseteq A$. Then $f^\imf(X)^R = X^{f;R}$.
\end{lemma}
\begin{proof}
We calculate
\[ (X_f)^{R} = (X_{f;\overline{R}})^c = X^{\overline{f;\overline{R}}} = X^{f;R \cup \overline{f;U_{B,C}}} = X^{f;R}, \]
where we have used the uniqueness and totality of $f$ in \ref{uniquenessResiduals} and \ref{totalityEquivalences}.

Alternatively we can give the following calculation:
\[ y\in f^\imf(X)^R \iff \forall x\in X: f(x)Ry \iff \forall x\in X: x(f;R)y \iff y\in X^{f;R}. \]
\end{proof}

\subsection{Injectivity, surjectivity and bijectivity}
\begin{definition}
The terms injective and surjective are commonly applied to functions. A function that is both injective and surjective is \udef{bijective}.
\end{definition}
In the context of functions the notions of injectivity and one-to-one coincide.
\begin{lemma}
Let $f:A\to B$ be a function. We say
\begin{itemize}
\item $f$ is injective, denoted $f: A\rightarrowtail B$, if
\[ \forall x_1,x_2\in A: f(x_1) = f(x_2) \implies x_1 = x_2; \]
\item $f$ is surjective, denoted $f: A\twoheadrightarrow B$, if
\[ \forall y\in B: \exists x\in A: f(x) = y; \]
\item $f$ is bijective, denoted $f: A\twoheadrightarrowtail B$, if
\[ \forall y\in B: \exists! x\in A: f(x) = y; \]
\end{itemize}
We also say $f$ is an injection, a surjection or a bijection if it is injective, surjective or bijective, respectively.

We will also sometimes write $A \leftrightarrow B$, instead of $A\twoheadrightarrowtail B$, to denote a bijection between $A$ and $B$.
\end{lemma}

\begin{lemma}
If $A\subseteq B$ classes, then there exists a canonical injection $\iota: A\to B$, the \udef{inclusion map}
\[ \iota: A\to B: a\mapsto a. \]
The inclusion map is often denoted $A\hookrightarrow B$.
\end{lemma}

\begin{lemma}
Let $f:A\to B$ be a function. Then $\ker f$ is an equivalence relation.
\end{lemma}

\begin{definition}
Let $f: A\to B$ be a function between sets. An equivalence class $[x]_{\ker f}$ is called a \udef{fibre} of $f$.
\end{definition}

\begin{proposition}
Let $f:A\to B$ be a function between sets. We can associate to $f$
\begin{enumerate}
\item a surjective function $f': A\to f[A]: x\mapsto f(x)$;
\item an injective function $f'': A/(\ker f) \;\to B: [x]_{\ker f}\mapsto f(x)$;
\item a bijective function $f''': A/(\ker f) \;\to f[A]: [x]_{\ker f}\mapsto f(x)$.
\end{enumerate}
\end{proposition}
Whenever a function on a quotient set defines an image of an equivalence class using an element of said equivalence class, we need to verify this definition is \emph{well-defined}, i.e.\ it does not depend on the chosen element in the equivalence class. (In other words it is properly a function of the equivalence class, not of the elements of the equivalence classes.)
\begin{proof}
We show $f''$ is well-defined. Let $[x]_{\ker f}\in A/(\ker f)$ and let $x_1,x_2\in [x]_{\ker f}$. Then $f(x) = f(x_1) = f(x_2)$ and
\[ f''([x_1]_{\ker f}) = f(x_1) = f(x_2) = f''([x_2]_{\ker f}), \]
so $f''$ is well-defined.
\end{proof}



\subsection{Constructing new functions}
Constructions defined for relations are in particular applicable to functions.

\subsubsection{Restriction and extension}
\begin{lemma}
Let $f: A\to B$ be a function and $S\subset A$. Then $f|_S$ is a function.
\end{lemma}
When talking about the restriction of a function, this left restriction is always the one that is meant. Right restrictions $f|^K$ are sometimes called \udef{corestrictions} and are in general not functions.

\begin{definition}
Let $A\subset B$ and $C$ be classes. Let $f: A\to C$ be a function. A function $\tilde{f}: B\to C$ such that $\tilde{f}|_A = f$ is called an \udef{extension} of $f$.
\end{definition}
Given a function, a different function with as codomain a superset of the original codomain, which is otherwise identical, is sometimes called a \udef{coextension} of the function.

When given a function prescription, we may need to verify the function is \emph{well-defined} in the sense that the prescription always gives an element in the codomain for every element in the domain.

\subsubsection{Composition}
\begin{lemma}
The functions $f:A\to B$ and $g:B\to C$ are composable as relations and the relation
\[ f;g = g\circ f \]
is a function. In particular it has functional form
\[ g\circ f: A\to C: x\mapsto g(f(x)). \]
\end{lemma}
Because of the simplicity of $(g\circ f)(x) = g(f(x))$, the notation $\circ$ is almost exclusively used when dealing with functions.

\begin{definition}
Let $f, g:A\to A$ be functions. We say $f$ and $g$ \udef{commute} if $f\circ g = g\circ f$.
\end{definition}

\begin{note}
Let $X,Y,Z$ be classes. Using composition we can view any function $f: X\to Y$ also as a function
\[ f: (Z\to X)\to (Z\to Y): g\mapsto f(g) = (z\mapsto (f\circ g)(z)). \]
\end{note}

\subsubsection{Pre- and post-composition}
\begin{definition}
Let $A,B,C$ be sets and $f\in (A\to B)$. Then we define
\begin{itemize}
\item the \udef{post-composition function} of $f$ as $f_*: (C\to A) \to (C\to B): g\mapsto f\circ g$.
\item the \udef{pre-composition function} of $f$ as $f^*: (B\to C) \to (A\to C): g\mapsto g\circ f$.
\end{itemize}
The post-composition function is also known as the \udef{pointwise} application or extension of $f$.
\end{definition}

\begin{lemma} \label{covarianceContravarianceComposition}
Let $A,B,C, D$ be sets, $f\in (A\to B)$ and $g\in(B\to C)$. Then
\begin{enumerate}
\item $(g\circ f)_* = g_*\circ f_*$;
\item $(g\circ f)^* = f^*\circ g^*$.
\end{enumerate}
\end{lemma}
\begin{proof}
(1) Let $h\in (D\to A)$. Then
\[(g\circ f)_*(h) = (g\circ f)\circ h = g\circ(f\circ h) = g_*(f_*(h)) = (g_*\circ f_*)(h). \]

(2) Let $h\in (C\to D)$. Then, similarly, 
\[ (g\circ f)^*(h) = h\circ (g\circ f) = (h\circ g)\circ f = (g^*(h))\circ f = f^*(g^*(h)) = (f^*\circ g^*)(h). \]
\end{proof}

\subsubsection{Inverses of functions}
All identity relations are functions.

\begin{definition}
Let $f:X\to Y$ be a function.
\begin{itemize}
\item A \udef{left inverse} (or \udef{retraction}) of $f$ is a function $g: Y\to X$ such that
\[ g\circ f = \id_X. \]
\item A \udef{right inverse} (or \udef{section}) of $f$ is a function $h: Y\to X$ such that
\[ f\circ h = \id_Y. \]
\item A \udef{(two-sided) inverse} of $f$ is a function that is both a left and a right inverse.
\end{itemize}
\end{definition}

\begin{lemma} \label{injectiveInverse}
Let $f:X\to Y$ be a function. The following are equivalent:
\begin{enumerate}
\item $f$ has a left inverse $g$;
\item $f^\transp$ is a partial function from $X$ to $Y$; 
\item $\graph(f^\transp) \subseteq \graph(g)$;
\item $f$ is injective.
\end{enumerate}
\end{lemma}
There is also a result linking the existence of a right inverse and surjectivity, but this in general only holds assuming the axiom of choice. (TODO ref)

\begin{lemma} \label{leftRightInverse}
If $f$ has a left inverse $g$ and a right inverse $h$, then $g=h$.
\end{lemma}
\begin{proof}
By the simple calculation
\[ g = g\circ (f\circ h) = (g\circ f) \circ h = h. \]
\end{proof}
Thus the two-sided inverse of $f$ is unique and exists \textup{if and only if} $f$ has a left and a right inverse. The unique two-sided inverse is denoted $f^{-1}$.

\begin{lemma}
Let $f:X\to Y$ be a function. The following are equivalent:
\begin{enumerate} 
\item the inverse exists;
\item the inverse exists and $f^{-1} = f^\transp$;
\item $f^\transp$ is a function from $X$ to $Y$;
\item $f$ is a bijection;
\item $f^\transp$ is a bijective function from $X$ to $Y$.
\end{enumerate}
\end{lemma}

\begin{lemma} \label{commutationInverse}
Let $f, g:A\to A$ be commuting and bijective functions. Then $f^{-1}$ and $g^{-1}$ commute.
\end{lemma}
\begin{proof}
We calculate
\[ f^{-1}\circ g^{-1} = f^{-1}\circ g^{-1}\circ (f\circ g \circ g^{-1} \circ f^{-1}) = f^{-1}\circ g^{-1}\circ (g\circ f) \circ g^{-1} \circ f^{-1} = g^{-1} \circ f^{-1} \]
\end{proof}

\subsubsection{Constant functions}
\begin{definition}
Let $X,Y$ be classes. A function $f:X\to Y$ is called \udef{constant} if there exists a $y_0$ such that $\forall x\in X: f(x) = y_0$.

We denote this function $\constant{y_0}$.
\end{definition}

A function is constant if and only if its range is a singleton.

\begin{lemma}
Let $X,Y$ be classes and $y\in Y$. Then
\[ \graph(\constant{y}) = X\times \{y\}. \]
\end{lemma}

\subsection{Partial functions}
\begin{definition}
A \udef{partial function} is a relation that is functional (but not necessarily serial). If we wish to emphasise a function is both functional and serial, we may call it a \udef{total function}.
\end{definition}
If $f\subset A\times B$ is a partial function, we write $A\not \to B$. The set of all partial functions from $A$ to $B$ is
\[ (A\not \to B) = \bigcup _{S\subseteq A}(S\to B). \]

For all $a\in A$ we write
\[ f(a)\downarrow \defequiv a\in\dom(f),\qquad f(a)\uparrow \defequiv a\notin\dom(f) \]
We can read $f(a)\downarrow$ as ``$f$ converges at $a$'' and $f(a)\uparrow$ as ``$f$ diverges at $a$''.

\begin{lemma} \label{partialFunctionExtension}
Let $f: A \not\to B$ be a partial function. Then we can construct a total function
\[ \widehat{f}: A \to B^+ \]
where $B^+ = B\cup \{e\}$ for some $e\notin B$, such that $\widehat{f}|_{\preim(f)}^B = f|_{\preim(f)}$.
\end{lemma}
\begin{proof}
We can always find an element $e$ by \ref{russelParadox}. Then we let $\widehat{f}$ map all elements in $A\setminus\preim(f)$ to $e$.
\end{proof}

\begin{proposition} \label{partialFunctionSubset}
Let $A,B$ be sets and $f,g\in(A\not\to B)$. Then the following are equivalent:
\begin{enumerate}
\item $f\subseteq g$;
\item $\ker(f) \subseteq \ker(g)$ and $\im(f)\subseteq \im(f\cap g)$;
\item $\ker(f\cup g) \subseteq \ker(g)$ and $\im(f)\subseteq \im(g)$.
\end{enumerate}
TODO: give proper meaning to $\ker(f\cup g)$
\end{proposition}
\begin{proof}
(1) clearly implies (2) and (3).

$(2) \Rightarrow (1)$. Take $(x,f(x)) \in f$. Now $f(x)\in \im(f)$, so $f(x)\in\im(f\cap g)$, meaning there exists a $u\in A$ such that $(u,f(x))\in f\cap g$. Because $(u,x)\in \ker(f)\subseteq \ker(g)$, we have $(x,f(x))\in g$.

$(3) \Rightarrow (1)$. Take $(x,f(x)) \in f$. Now $f(x)\in \im(f)$, so $f(x)\in\im(g)$ and we can find a $u\in A$ such that $(u,f(x))\in g$. Then $(x,f(x)) \in f\cup g$ and $(u,f(x))\in f\cup g$, so $(x,u)\in \ker(f\cup g)$ and thus $(x,u)\in\ker(g)$. This means $(x,f(x))\in g$.
\end{proof}

\subsubsection{Singleton unpacking}
\begin{definition}
Let $A$ be a class. We define the partial function
\[ \sunp_A: \powerset{A} \not\to A: X \mapsto \begin{cases}
x & \text{if $X = \{x\}$} \\
\text{undefined} & \text{otherwise}.
\end{cases} \]
We may also write simply $\sunp$ if the class is clear from context.
\end{definition}

\subsection{Functional dependence}
\begin{definition}
Let $A,B$ be classes and $\mathcal{F} \subseteq (A\to B)$ a subclass.
\begin{itemize}
\item The relation $[\mathcal{F}]$ on $(A,B)$ is defined by
\[ \forall a\in A, b\in B: \qquad a[\mathcal{F}]b \iff \exists f\in \mathcal{F}: \; a = f(b). \]
We say $a$ \udef{depends on} $b$ under $\mathcal{F}$.
\item The relation $[\mathcal{F}]^!$ on $(A,B)$ is defined by
\[ \forall a\in A, b\in B: \qquad a[\mathcal{F}]b \iff \exists! f\in \mathcal{F}: \; a = f(b). \]
We say $a$ \udef{uniquely depends on} $b$ under $\mathcal{F}$.
\end{itemize}
\end{definition}

Note that $[\mathcal{F}] = \bigcup\mathcal{F}$.

\section{Binary functions}
We can easily give a function multiple inputs from multiple domains by first joining them into an $n$-tuple, i.e.\ considering the Cartesian product of the domains as the domain of the function.

\begin{example}
A function $f$ that takes an input in $A$ and one in $B$ to generate an output in $C$ can be written as
\[ f: A\times B \to C: (a,b)\mapsto f(a,b). \]
\end{example}

We can consider the class of binary functions between sets.
\begin{lemma}
There does not exist a class of binary functions between classes.
\end{lemma}
\begin{proof}
There exists a proper class $\mathcal{U}$ by \ref{properClassExistence}. Then
\[ \mathcal{U}\times \{\emptyset\}\to \mathcal{U}: (x,\emptyset) \mapsto x \]
is a proper class by replacement (TODO ref! + necesary?) and thus an element. However, it would have to be an element of a class of binary functions between classes. This is a contradiction.
\end{proof}

\subsection{Input permutation}

Let $A,B$ be classes. Then we can define a swap function as follows:
\[ \swap_{A,B}: A\times B \to B\times A: (a,b) \mapsto (b,a). \]
We may write $\swap$ instead of $\swap_{A,B}$ is the classes are clear from the context.

\begin{lemma}
Let $A, B$ be classes. Then $\swap_{B,A}\circ \swap_{A,B} = \id_{A\times B}$.
\end{lemma}

\begin{definition}
Let $A, B, C$ be classes and $f: A\times B \to C$ a binary function. We define the \udef{dual} function $f^d: B\times A \to C$ of $f$ as $f^d \defeq f\circ \swap$. 
\end{definition}

If we restrict ourselves to the class of binary functions between sets, then $\swap$ can be considered a function.

\begin{lemma}
Let $A, B, C$ be classes and $f: A\times B \to C$ a binary function. Then $(f^d)^d = f$.
\end{lemma}

\subsection{Currying and evaluation}
\subsubsection{Currying}
TODO cfr residuation

\begin{definition}
Let $A,B,C$ be \emph{sets}.

Given a function $f: A\times B \to C$, we can \udef{curry} it in the first argument to obtain a new function
\[ \curry_1(f): A \to (B\to C): a\mapsto f(a,-) \qquad \text{where $f(a,-): B \to C: b\mapsto f(a,b)$} \]
or in the second argument to obtain
\[ \curry_2(f): B \to (A\to C): b\mapsto f(-,b) \qquad \text{where $f(-,b): A \to C: a\mapsto f(a,b)$}. \]
\end{definition}
\begin{lemma}
For given sets $A,B,C$ the act of currying defines two bijective functions
\begin{align*}
&\curry_1: (A\times B \to C) \twoheadrightarrowtail (A \to (B\to C)); \\
&\curry_2: (A\times B \to C) \twoheadrightarrowtail (B \to (A\to C))
\end{align*}
\end{lemma}

\subsubsection{The evaluation map}
\begin{definition}
Let $A,B$ be sets. We define the \udef{evaluation map}
\[ \evalMap: (A\to B)\times A \to B: (f,x) \mapsto f(x). \]
Often we will consider partial applications of the evaluation map in the second argument, i.e.\ for $x\in A$
\[ \evalMap_x: (A\to B) \to B: f\mapsto f(x), \]
which is also called an evaluation map.
\end{definition}
We have $\evalMap_x = \curry_2(\evalMap)(x)$.

\begin{lemma}
Let $A,B,C$ be sets and $f: A\to (B\to C)$. Then
\begin{enumerate}
\item $\curry_1^{-1}(f) = \evalMap\circ (f, \id_B)$;
\item $\curry_2^{-1}(f) = \evalMap\circ (f, \id_B)\circ \transp$.
\end{enumerate}
\end{lemma}

\subsubsection{Functoriality}
\begin{proposition}
Let $f: A\to B$ be a function between sets and $X$ a set. Then there exists a unique $f^X: (X\to A)\to (X\to B)$ such that
\[ \curry_1(f\circ g) = f^X\circ \curry_1(g) \qquad \forall g\in \big(Y\times X \to A\big). \]
This is given by $f^X = f\circ -$.
\end{proposition}
\begin{proof}
Let $\evalMap_1$ be the evaluation map $\evalMap_1: (X\to A)\times X \to A$ and $\evalMap_2$ the evaluation map $\evalMap_2: (A\to B) \times A \to B$.
then we can calculate
\begin{align*}
f \circ g &= f \circ \curry_1^{-1}\big(\curry_1(g)\big) \\
&= f \circ \evalMap_1 \circ \big(\curry_1(g), \id_X\big) \\
&= \curry_1^{-1}\big(\curry_1(f \circ \evalMap_1)\big) \circ \big(\curry_1(g), \id_X\big) \\
&= \evalMap_2\circ \big(\curry_1(f \circ \evalMap_1), \id_X\big) \circ \big(\curry_1(g), \id_X\big) \\
&= \evalMap_2\circ \big(\curry_1(f \circ \evalMap_1) \circ \curry_1(g), \id_X\big) \\
&= \curry_1^{-1}\big(\curry_1(f \circ \evalMap_1) \circ \curry_1(g)\big).
\end{align*}
Setting $f^X \defeq \curry_1(f \circ \evalMap_1) = f\circ -$, we clearly have existence. For uniqueness, note that $f\circ h = g \circ h$ for arbitrary $h$ implies $f=g$. And we can choose $\curry_1(g)$ arbitrarily.
\end{proof}
\begin{corollary}
Let $f: A\to B$ and $g: B\to C$ be functions between sets and $X$ some other set. Then $(g\circ f)^X = g^X\circ f^X$.
\end{corollary}
\begin{proof}
Take arbitrary $h: Y\times X \to A$. Then
\[ (g\circ f)^X\circ \curry_1(h) = \curry_1(g\circ f\circ h) = g^X\circ \curry_1(f\circ h) = g^X \circ f^X \circ \curry_1(h). \]
\end{proof}

\begin{proposition}
Let $f: A\to B$ be a function between sets and $X$ a set. Then there exists a unique $X^f: (B\to X) \to (A\to X)$ such that
\[ \curry_1\big(g\circ (\id_Y, f)\big) = X^f\circ \curry_1(g) \qquad \forall g\in \big(Y\times B \to X\big). \]
This is given by $X^f = -\circ f$.
\end{proposition}
\begin{proof}
Let $\evalMap_1$ be the evaluation map $\evalMap_1: (B\to X)\times B \to X$ and $\evalMap_2$ the evaluation map $\evalMap_2: (A\to X) \times A \to X$.
then we can calculate
\begin{align*}
g\circ (\id_Y, f) &= \curry_1^{-1}\big(\curry_1(g)\big)\circ (\id_Y, f) \\
&= \evalMap_1 \circ \big(\curry_1(g), \id_B\big)\circ (\id_Y, f) \\
&= \evalMap_1 \circ (\id_{B\to X}, f) \circ \big(\curry_1(g), \id_A\big) \\
&= \curry_1^{-1}\Big(\curry_1\big(\evalMap_1 \circ (\id_{B\to X}, f)\big)\Big) \circ \big(\curry_1(g), \id_A\big) \\
&= \evalMap_2\circ\Big(\curry_1\big(\evalMap_1 \circ (\id_{B\to X}, f)\big), \id_A\Big) \circ \big(\curry_1(g), \id_A\big) \\
&= \evalMap_2\circ\Big(\curry_1\big(\evalMap_1 \circ (\id_{B\to X}, f)\big)\circ \curry_1(g), \id_A\Big) \\
&= \curry_1^{-1}\Big(\curry_1\big(\evalMap_1 \circ (\id_{B\to X}, f)\big)\circ \curry_1(g) \Big).
\end{align*}
Setting $X^f \defeq \curry_1(\evalMap_1\circ (\id_{B\to X}, f)) = -\circ f$, we clearly have existence. For uniqueness, note that $f\circ h = g \circ h$ for arbitrary $h$ implies $f=g$. And we can choose $\curry_1(g)$ arbitrarily.
\end{proof}
\begin{corollary}
Let $f: A\to B$ and $g: B\to C$ be functions between sets and $X$ some other set. Then $X^{g\circ f} = X^f\circ X^g$.
\end{corollary}
\begin{proof}
Take arbitrary $h: Y\times B \to X$. Then
\begin{align*}
X^{g\circ f}\circ \curry_1(h) &= \curry_1\big(h \circ (\id_Y, g\circ f)\big) \\
&= \curry_1\big(h \circ (\id_Y, g)\circ (\id_Y, f)\big) \\
&= X^f\circ \curry_1\big(h \circ (\id_Y, g)\big) \\
&= X^f\circ X^g \circ \curry_1(h).
\end{align*}
\end{proof}

\subsubsection{Partial application}
\begin{definition}
Let $f: A\times B \to C$ be a function, $a\in A$ and $b\in B$. We write
\begin{itemize}
\item $f(a, -)$ to mean $\curry_1(f)(a)$; and
\item $f(-, b)$ to mean $\curry_2(f)(b)$.
\end{itemize}
Any function of the form $f(a, -)$ or $f(-,b)$ is called a \udef{partial application} of $f$.
\end{definition}

\subsection{Homogenous binary operators}
\begin{definition}
Let $A$ be a class and $f: A\times A \to A$ a binary function. We call $f$
\begin{itemize}
\item \udef{associative} if $\forall x,y, z\in A: \; f(f(x,y),z) = f(x,f(y,z))$;
\item \udef{commutative} if $\forall x,y\in A: \; f(x,y) = f(y,x)$;
\item \udef{idempotent} if $\forall x\in A:\; f(x,x) = x$.
\end{itemize}
If something is equal to an undefined quantity, we require it to be undefined.
\end{definition}

\subsubsection{Duality}
Let $A$ be a class and $f: A\times A \to A$ a homogeneous binary function. Then $f^d: A\times A \to A$ is also a homogeneous binary function.

Often a property of $f$ can be translated to a different property of $f^d$. In this case we say the properties are \udef{dual} to each other.

\begin{proposition}
If a certain logical dependence holds between certain properties of binary homogenous functions, for all binary homogenous functions, then the same logical dependence holds between the duals of these properties.
\end{proposition}
\begin{proof}
If the logical dependence holds for all functions, it in particular holds for all functions of the form $f^d$.
\end{proof}

\subsubsection{Notation for binary operators}
Prefix, infix, postfix, Polish, necessity of brackets.

\subsubsection{Identity and absorbing elements}
\begin{definition}
Let $A$ be a class and $f: A\times A \to A$ a binary function. 
We say
\begin{itemize}
\item $f$ has a \udef{left-identity} $e_L$ if $\forall x\in A:\; f(e_L, x) = x$;
\item $f$ has a \udef{right-identity} $e_R$ if $\forall x\in A:\; f(x, e_R) = x$;
\item $f$ has an \udef{identity} $e$ if $e$ is both a left- and a right-identity of $f$.
\end{itemize}
We say
\begin{itemize}
\item $f$ has a \udef{left-absorbing element} $u_L$ if $\forall x\in A:\; f(u_L, x) = u_L$;
\item $f$ has a \udef{right-absorbing element} $u_R$ if $\forall x\in A:\; f(x, u_R) = u_R$;
\item $f$ has an \udef{absorbing element} $u$ if $u$ is both a left- and a right-absorbing element of $f$.
\end{itemize}
\end{definition}

Left and right identity are dual. Left and right absorbing are also dual.

TODO require that absorbing element is no identity?

\begin{lemma} \label{leftRightIdentity}
Let $A$ be a class and $f: A\times A \to A$ a binary operator.
\begin{enumerate}
\item If $f$ has both a left-identity $e_L$ and a right-identity $e_R$, then $f$ has an identity $e$ and
\[ e = e_L = e_R. \]
\item If $f$ has both a left-absorbing element $u_L$ and a right-absorbing element $u_R$, then $f$ has an absorbing element $u$ and
\[ u = u_L = u_R. \]
\end{enumerate}
\end{lemma}
\begin{proof}
(1) Assume $f$ has a left- and a right-identity. Then $e_L = f(e_L, e_R) = e_R$.

(2) Assume $f$ has a left- and a right-absorbing element. Then $u_L = f(u_L, u_R) = u_R$.
\end{proof}
\begin{corollary}
A binary operator may have multiple left-identities or multiple right-identities, but if it has both, then the identity is unique.

An absorbing element is similarly unique.
\end{corollary}

\begin{definition}
Let $A$ be a class and $f: A\times A \to A$ a binary operator. We define
\[ \widetilde{A} \defeq \begin{cases}
A & \text{if $f$ has an identity} \\
A\uplus \{e\} & \text{if $f$ has no identity.}
\end{cases} \]
and also
\[ \widetilde{f} \quad\defeq\quad \widetilde{A}\times \widetilde{A}\to \widetilde{A}: (a,b) \mapsto \begin{cases}
f(a, b) & a,b\in A \\
b & a = e \\
a & b = e.
\end{cases} \]
\end{definition}

\begin{definition}
Let $A$ be a class and $f: A\times A \to A$ a binary operator. We define
\[ \widehat{A} \defeq \begin{cases}
A & \text{if $A$ has an absorbing element} \\
A\uplus \{u\} & \text{if $A$ has no absorbing element.}
\end{cases} \]
and also
\[ \widehat{f} \quad\defeq\quad \widehat{A}\times \widehat{A}\to \widehat{A}: (a,b) \mapsto \begin{cases}
f(a, b) & a,b\in A \\
u & (a = u \lor b = u).
\end{cases} \]
\end{definition}

TODO: should we add absorbing element regardless of prior existance??

\begin{lemma}
Let $A$ be a class and $f: A\times A \to A$ an associative partial binary function with absorbing element $u$. Then we can extend $f$ to an associative total function $\widehat{f}: A \times A \to A$
by setting
\[ (x,y) \in A\times A \setminus \preim(f) \quad\implies\quad \widehat{f}(x,y) = u. \]
\end{lemma}
\begin{proof}
We just need to verify associativity.

We have $\widehat{f}(\widehat{f}(x,y),z) = \widehat{f}(x,\widehat{f}(y,z))$ if $f(f(x,y),z)$ and $f(x,f(y,z))$ are defined.

If $f(f(x,y),z)$ is not defined, we claim $\widehat{f}(\widehat{f}(x,y),z) = u$. Indeed,
\begin{itemize}
\item if $f(x,y)$ is defined, then $f(\widehat{f}(x,y),z) = f(f(x,y),z)$ is undefined and thus equal to $u$;
\item if $f(x,y)$ is undefined, then $\widehat{f}(\widehat{f}(x,y),z) = \widehat{f}(u,z) = f(u,z) = u$.
\end{itemize}

Similarly, if $f(x, f(y, z))$ is not defined, we have $\widetilde{f}(x, \widetilde{f}(y, z)) = u$.
\end{proof}

\subsubsection{Closure}
TODO Galois connection.
\begin{definition}
Let $f:A\times A\to A$ be a binary function and $B\subseteq A$. Then we call $B$ \udef{closed under $f$} if $f(B,B) \subseteq B$.
\end{definition}

\subsubsection{Distributivity}
\begin{definition}
Let $A$ be a class and $f,g: A\times A \to A$ two binary functions. We say
\begin{itemize}
\item $f$ is \udef{left-distributive} over $g$ if
\[ \forall x,y,z\in A: \; f(x,g(y,z)) = g(f(x,y),f(x,z)); \]
\item $f$ is \udef{right-distributive} over $g$ if
\[ \forall x,y,z\in A: \; f(f(x,y), z) = g(f(x,z),f(y,z)); \]
\item $f$ is \udef{distributive} over $g$ if it is left- and right-distributive;
\item $f$ is \udef{self-distributive} if it is distributive over itself.
\end{itemize}
\end{definition}

\subsubsection{The absorption law}
\begin{definition}
Let $A$ be a class and $f,g: A\times A \to A$ two binary functions.
We say $f, g$ are linked by the \udef{absorption law} if
\[ \forall x,y\in A:\; f(x,g(x,y)) = x = g(x,f(x,y)). \]
\end{definition}

\begin{lemma} \label{absorptionIdempotency}
Let $A$ be a class and $f,g: A\times A\to A$ binary functions. If $f$ and $g$ are linked by the absorption law, then they are both idempotent.
\end{lemma}
\begin{proof}
For all $x\in A$ we have $f(x,x) = f(x,g(x,f(x,x))) = x$, where the last equality follows from the absorption law with $y = f(x,x)$.
\end{proof}


\section{Associative classes}
\begin{definition}
Let $A$ be a class and $f: A\times A \not\to A$ an associative binary partial function. We call $\sSet{A,f}$ an \udef{associative class.}

We will often abbreviate $f(x,y)$ by $xy$.
\end{definition}
TODO all functions are $\lambda - \rho$ in larger space.

In particular, the following are equivalent for all $x,y,z\in A$:
\begin{itemize}
\item $f\big(f(x,y),z\big)$ is defined;
\item $f\big(x, f(y, z)\big)$ is defined;
\item $f(x, y)$ and $f(y,z)$ are defined.
\end{itemize}
TODO: proper definition of when composition is defined!

Notice in particular, that the third point implies the first two.

\subsection{Undefined operations}
We can simulate a partial function by adding an absorbing element $u$ and mapping undefined operations to $u$. The problem with this is that elements can then only be cancellative if they can be composed with anything. Indeed, if $a,b\in A$ such that $f(a,b) = u$. Then $f(a,b) = u = f(a,u)$ and the only way $a$ can be left-cancellative is by having $b=u$.

The problem is that we have made any two undefined operations the same, while we really want any two undefined operations to be different.

TODO: modify set theory to allow $u\neq u$??

\subsubsection{Connections}
\begin{definition}
Let $A$ be an associative class and $x,y\in A$. We call
\begin{itemize}
\item $\leftconnections{x} \defeq \setbuilder{y\in A}{\text{$yx$ is defined}}$ the class of \udef{left connections};
\item $\rightconnections{x} \defeq \setbuilder{y\in A}{\text{$xy$ is defined}}$ the class of \udef{right connections}.
\end{itemize}
We write
\begin{itemize}
\item $x \preceq_L y$ if $\leftconnections{x} \subseteq \leftconnections{y}$;
\item $x \preceq_R y$ if $\rightconnections{x} \subseteq \rightconnections{y}$.
\end{itemize}
\end{definition}

\begin{lemma}
Let $A$ be an associative class and $x,y,z\in A$. Then
\begin{enumerate}
\item $\leftconnections{xy} = \leftconnections{x}$;
\item $\rightconnections{xy} = \rightconnections{y}$;
\item $x \preceq_L y \iff xz \preceq_L y \iff x \preceq_L yz$ if the relevant terms are defined;
\item $x \preceq_R y \iff zx \preceq_R y \iff x \preceq_R zy$ if the relevant terms are defined.
\end{enumerate}
\end{lemma}


\subsection{Distinguishability, cancellation, identity and inverses}
\subsubsection{Distinguishability}
\begin{definition}
Let $A$ be an associative class and $x,y\in A$. 
We say
\begin{itemize}
\item $x$ and $y$ are \udef{left-distinguishable} if
\[ x\neq y \quad\implies\quad \exists a\in A: \;\text{$ax$ or $ay$ is defined and $ax \neq ay$}; \]
\item $x$ and $y$ are \udef{right-distinguishable} if
\[ x\neq y \quad\implies\quad \exists a\in A: \; \text{$xa$ or $ya$ is defined and $xa \neq ya$}; \]
\item $x$ and $y$ are \udef{distinguishable} if they are left- \emph{or} right-distinguishable;
\item $x$ and $y$ are \udef{bidistinguishable} if they are left- \emph{and} right-distinguishable.
\end{itemize}
We say
\begin{itemize}
\item $A$ is left-distinguishable if every two elements in $A$ are left-distinguishable;
\item $A$ is right-distinguishable if every two elements in $A$ are right-distinguishable;
\item $A$ is distinguishable if every two elements in $A$ are distinguishable;
\item $A$ is bidistinguishable if every two elements in $A$ are bidistinguishable.
\end{itemize}
\end{definition}

\begin{lemma}
Let $A$ be an associative class and $x,y\in A$. 
Then
\begin{enumerate}
\item $x$ and $y$ are left-distinguishable \textup{if and only if}
\[ x = y \quad\iff\quad \forall a\in A: \;\Big(\text{$ax$ or $ay$ is defined} \implies ax = ay\Big); \]
\item $x$ and $y$ are right-distinguishable \textup{if and only if}
\[ x = y \quad\iff\quad \forall a\in A: \; \Big(\text{$xa$ or $ya$ is defined} \implies xa = ya\Big). \]
\end{enumerate}
In both cases the direction $\Rightarrow$ is automatic.
\end{lemma}

\subsubsection{Cancellation}
\begin{definition}
Let $A$ be an associative class and $x\in A$. 
We call $x$
\begin{itemize}
\item \udef{left-cancellative} or \udef{monic} if $x\cdot -: y\mapsto xy$ is injective;
\item \udef{right-cancellative} or \udef{epic} if $-\cdot x: y\mapsto yx$ is injective.
\end{itemize}
\end{definition}

Left and right cancellative are dual properties.

\begin{lemma}
Let $A$ be an associative class and $x,y$ in $A$.
\begin{enumerate}
\item If $x$ and $y$ are left-(resp. right-)cancellative, then $xy$ is left-(resp. right-)cancellative.
\item If $xy$ is left-cancellative, then $y$ is left-cancellative.
\item If $xy$ is right-cancellative, then $x$ is right-cancellative.
\end{enumerate}
\end{lemma}
\begin{proof}
Let $z_1, z_2\in A$.

(1) Assume that $x$ and $y$ are left-cancellative and $(xy)z_1 = (xy)z_2$. By associativity, we have $x(yz_1) = x(yz_2)$. Thus by injectivity we get first $yz_1 = yz_2$ and then $z_1 = z_2$.

Right-cancellation is similar.

(2) Assume $yz_1 = yz_2$. Then $xyz_1 = xyz_2$, so $z_1 = z_2$ because $xy$ is left-cancellative.

(3) Assume $z_1x = z_2x$. Then $z_1xy = z_2xy$ so $z_1 = z_2$ because $xy$ is right-cancellative.
\end{proof}

\begin{lemma}
Let $A$ be an associative class.
\begin{enumerate}
\item If $\forall x\in A$ there exists a left-cancellative element $a_x$ such that $a_xx$ exists, then $A$ is left-distinguishable.
\item If $\forall x\in A$ there exists a right-cancellative element $a$ such that $ax$ exists, then $A$ is right-distinguishable.
\end{enumerate}
\end{lemma}
\begin{proof}
(1) Take $x,y\in A$ and assume $\forall b\in A: \Big(\text{$bx$ or $by$ is defined} \implies bx = by\Big)$. In particular, this means that $a_xx = a_xy$. By left-cancellation, we have $x=y$.

(2) Dual to (1).
\end{proof}

\subsubsection{Identity and objects}
\begin{definition}
Let $A$ be a class, $f: A\times A \not\to A$ a binary partial function and $e\in A$ an idempotent (i.e.\ $e^2 = e$).

We call $e$
\begin{itemize}
\item a \udef{centre identity} if $xy = xey$ for all $x,y\in A$ such that both sides are defined;
\item a \udef{left identity} if $x = ex$ for all $x\in A$ such that $ex$ is defined;
\item a \udef{right identity} if $x = xe$ for all $x\in A$ such that $xe$ is defined;
\item an \udef{identity} if $e$ is both a left and a right identity.
\end{itemize}

We call $e$
\begin{itemize}
\item a \udef{weak left identity} if $x = ex$ for all $x\in A$ such that $ex$ is defined and $\leftconnections{e} = \leftconnections{x}$;
\item a \udef{weak right identity} if $x = xe$ for all $x\in A$ such that $xe$ is defined and $\rightconnections{e} = \rightconnections{x}$;
\item a \udef{weak identity} if $e$ is both a weak left and a weak right identity.
\end{itemize}
\end{definition}

\begin{lemma}
Let $A$ be an associative class and $e\in A$ an idempotent.
Then
\begin{enumerate}
\item $e$ is a left identity \textup{if and only if} $e$ is left-cancellative;
\item $e$ is a right identity \textup{if and only if} $e$ is right-cancellative.
\end{enumerate}
\end{lemma}
\begin{proof}
(1) First assume $e$ is a left identity. Let $x,y\in A$ be such that $ex = ey$. Then $x = ex = ey = y$.

Now assume that $e$ is left-cancellative and that $ex$ is defined. Then $ex = eex$ by idempotency and thus $x = ex$ by left-cancellation.

(2) Dual.
\end{proof}

\begin{lemma} \label{uniquenessIdentity}
Let $A$ be an associative class and $e,e'\in A$. Then
\begin{enumerate}
\item if $e,e'$ are weak left identities such that $ee' = e'e$, then $e=e'$;
\item if $e,e'$ are weak right identities such that $ee' = e'e$, then $e=e'$.
\end{enumerate}
Also
\begin{enumerate} \setcounter{enumi}{2}
\item if $e$ is a left identity and $e'$ a right identity such that $ee'$ is defined, then $e=e'$;
\end{enumerate}
and
\begin{enumerate} \setcounter{enumi}{3}
\item if $e,e'$ are identities and there exists $x\in A$ such that $ex$ and $e'x$ are both defined, then $e = e'$;
\item if $e,e'$ are identities and there exists $x\in A$ such that $xe$ and $xe'$ are both defined, then $e = e'$.
\end{enumerate}
\end{lemma}
\begin{proof}
(1) We have $\leftconnections{e} = \leftconnections{ee'} = \leftconnections{e'e} = \leftconnections{e'}$, so $e = e'e = ee' = e'$.

(2) Dual.

(3) We have $e = ee' = e'$.

(4) We have $x = ex = ee'x$, so $ee'$ is defined. We conclude with (3).

(5) Dual to (4).
\end{proof}

\begin{lemma} \label{distinguishableIdentity}
Let $A$ be an associative class and $e\in A$.
\begin{enumerate}
\item If $e$ is a left identity and $A$ is right-distinguishable, then $e$ is a weak right identity.
\item If $e$ is a right identity and $A$ is left-distinguishable, then $e$ is a weak left identity.
\end{enumerate}
\end{lemma}
\begin{proof}
(1) Take $x\in A$ such that $xe$ is defined and $\rightconnections{e} = \rightconnections{x}$. Take arbitrary $a\in A$. If $xa$ is defined, then $xea$ is also defined and $xea = xa$. By right-distinguishability, we have $xe = x$. Thus $e$ is a right identity.

(2) Dual.
\end{proof}

\begin{lemma} \label{identityConnection}
Let $A$ be an associative class and $e,x\in A$. Then
\begin{enumerate}
\item if $e$ is a left identity such that $ex$ is defined, then $\leftconnections{e} = \leftconnections{x}$;
\item if $e$ is a right identity such that $xe$ is defined, then $\rightconnections{e} = \rightconnections{x}$;
\end{enumerate}
and
\begin{enumerate} \setcounter{enumi}{2}
\item if $e$ is a left identity such that $xe$ is defined, then $e \preceq_R x$;
\item if $e$ is a right identity such that $ex$ is defined, then $e \preceq_L x$.
\end{enumerate}
\end{lemma}
\begin{proof}
(1) We have $\leftconnections{e} = \leftconnections{ex} = \leftconnections{x}$.

(2) Dual.

(3) Take $a\in \rightconnections{e} = \rightconnections{xe}$. Then $xea$ is defined and $xea = xa$, so $a\in \rightconnections{x}$.

(4) Dual.
\end{proof}


\subsubsection{Inverses}
\begin{definition}
Let $A$ be an associative class and $x\in A$. 
We say an element $y\in A$ is
\begin{itemize}
\item a \udef{left-inverse} of $x$ if $yx$ is a left-identity;
\item a \udef{right-inverse} of $x$ if $xy$ is a right-identity;
\item a \udef{(two-sided) inverse} of $x$ it is both a left- and a right-inverse.
\end{itemize}
We say $(x,y)\in A^2$ is a pair of
\begin{itemize}
\item \udef{mutual left-inverses} if $x$ is a left-inverse of $y$ and $y$ a left-inverse of $x$;
\item \udef{mutual right-inverses} if $x$ is a right-inverse of $y$ and $y$ a right-inverse of $x$.
\end{itemize}
We call $x$ \udef{invertible} if it has a (left/right) mutual inverse.
\end{definition}

\begin{lemma}
Let $A$ be an associative class and $x\in A$.
\begin{enumerate}
\item If $x$ has a left-inverse, then it is left-cancellative.
\item If $x$ has a right-inverse, then it is right-cancellative.
\end{enumerate}
\end{lemma}
\begin{proof}
(1) Let $y\in A$ be a left-inverse of $x$. Take arbitrary $a,b\in A$. Assume $xa = xb$. Then $yxa = yxb$ and so $a = b$.

(2) Dual.
\end{proof}

\begin{proposition}
Let $A$ be an associative class and $x,y_1,y_2,l,r \in A$.
\begin{enumerate}
\item If $A$ is right-distinguishable and both $(x, y_1)$ and $(x,y_2)$ are pairs of mutual left-inverses, then $y_1 = y_2$.
\item If $A$ is left-distinguishable and both $(x, y_1)$ and $(x,y_2)$ are pairs of mutual right-inverses, then $y_1 = y_2$.
\end{enumerate}
Also
\begin{enumerate} \setcounter{enumi}{2}
\item If $l$ is a left-inverse of $x$ and $r$ a right-inverse of $x$, then $l = r$.
\item If $x$ has an inverse, then this inverse is unique.
\end{enumerate}
\end{proposition}
\begin{proof}
(1) We have $y_1 = (y_2x)y_1 = y_2(xy_1)$, so the latter is defined, which implies $xy_1 \preceq_R y_2$ by \ref{identityConnection}. Thus $y_1 \preceq y_2$. Similarly $y_1xy_2$ is defined and this implies $y_2 \preceq y_1$. Thus $\rightconnections{xy_1} = \rightconnections{y_1} = \rightconnections{y_2}$. By \ref{distinguishableIdentity} $xy_1$ is a weak right identity, so $\rightconnections{xy_1} = \rightconnections{y_2}$ implies $y_1 = y_2xy_1 = y_2$.

(2) Dual.

(3) We have $l = l(xr) = (lx)r = r$.

(4) Any inverse of $x$ is both a left- and a right-inverse.
\end{proof}

If $x$ is invertible, we denote the unique inverse by $x^{-1}$.




\begin{lemma}
Let $A$ be an associative class and $x,y \in A$ such that $xy$ is defined.
\begin{enumerate}
\item If $x$ has left-inverse $x^{-L}$ and $y$ has a left-inverse $y^{-L}$, then $xy$ has a left-inverse $y^{-L}x^{-L}$.
\item If $x$ has right-inverse $x^{-R}$ and $y$ has a right-inverse $y^{-R}$, then $xy$ has a right-inverse $y^{-R}x^{-R}$.
\item If $x$ has inverse $x^{-1}$ and $y$ has inverse $y^{-1}$, then $xy$ has inverse $y^{-1}x^{-1}$.
\item If $xy$ has ya left-inverse $z$, then $y$ has a left-inverse $zx$.
\item If $xy$ has a right-inverse $z$, then $x$ has a right-inverse $yz$.
\end{enumerate}
\end{lemma}
\begin{proof}
(1) Set $e = x^{-L}x$. We calculate
\[ y^{-L}x^{-L}xy = y^{-L}ey = y^{-L}y, \]
which is a left identity. Then we just need to show that $xyy^{-L}x^{-L}xy = xy$. Indeed
\[ xyy^{-L}x^{-L}xy = xyy^{-L}ey = x(yy^{-L}y) = xy. \]

(2) Dual to (1).

(3) Follows from (1) and (2).

(4) Set $e = z(xy)$. We calculate
\[ e = z(xy) = (zx)y, \]
so $zx$ is a left-inverse of $y$.

\end{proof}



\begin{lemma}
Let $\sSet{A, f}$ be an associative class and $x,y$ in $A$ with identity $e$. Then
\begin{enumerate}
\item if $x$ has a left inverse, it is left-cancellative;
\item if $x$ has a right inverse, it is right-cancellative;
\item if $x$ has a left inverse and is right-cancellative, it is invertible;
\item if $x$ has a right inverse and is left-cancellative, it is invertible.
\end{enumerate}
\end{lemma}
\begin{proof}
(1) Let $l$ be a left inverse of $x$ and assume $f(x, z_1) = f(x,z_2)$, then $f(l, f(x,z_1)) = f(l, f(x,z_2))$ and thus
\[ z_1 = f(e,z_1) = f(f(l,x), z_1) = f(l, f(x,z_1)) = f(l, f(x,z_2)) = f(f(l,x), z_2) = f(e,z_2) = z_2. \]

(2) Similar.

(3) Let $l$ be a left inverse of $x$. It is enough to show that $l$ is also a right inverse of $x$. We calculate
\[ f(f(x,l), x) = f(x, f(l,x)) = f(x, e) = x = f(e,x). \]
Beacuse $x$ is right-cancellative, this means $f(x,l) = e$ and thus that $l$ is a right inverse.

(4) Similar.
\end{proof}


\subsection{Left and right relation}
\begin{definition}
Let $\sSet{A, f}$ be an associative class and $x, y\in A$. Then
\begin{itemize}
\item let $L$ be the relation defined by $xLy \defequiv \exists a: f(a, x) = y$;
\item let $R$ be the relation defined by $xRy \defequiv \exists a: f(x, a) = y$;
\item let $L'$ be the relation defined by $xL^!y \defequiv  \exists! a: f(a, x) = y$;
\item let $R'$ be the relation defined by $xR^!y \defequiv \exists! a: f(x, a) = y$.
\end{itemize}
\end{definition}

The relations $L$ and $R$ are dual. The relations $L^!$ and $R^!$ are dual.

\begin{lemma}
The relations $L$ and $R$ are transitive.
\end{lemma}
\begin{proof}
Let $\sSet{A, f}$ be an associative class and $x, y, z\in A$ such that $xLy$ and $yLz$. Then there exist $a,b\in A$ such that $f(a,x) = y$ and $f(b,y) = z$. Then
\[ z = f(b,y) = f\big(b,f(a,x)\big) = f\big(f(b,a), x\big), \]
so $xLz$. The statement for $R$ is dual.
\end{proof}

\begin{lemma}
Let $\sSet{A, f}$ be an associative class and $x\in A$. Then the following are equivalent:
\begin{enumerate}
\item $x$ is right-cancellative
\item $xL \subseteq xL^!$;
\item $xL = xL^!$.
\end{enumerate}
As are the following:
\begin{enumerate}
\item $x$ is left-cancellative
\item $xR \subseteq xR^!$;
\item $xR = xR^!$.
\end{enumerate}
\end{lemma}
\begin{proof}
$(1) \Rightarrow (2)$ Take $y\in xL$. Then there exists $a\in A$ such that $f(a,x) = y$. Assume there exists another $b\in A$ such that $f(b,x) = y$. Then $f(a,x) = f(b,x)$, so $a=b$. Thus the $a\in A$ is unique and $y\in xL^!$.

$(2) \Rightarrow (3)$ The inclusion $xL \supseteq xL^!$ is immediate.

$(3) \Rightarrow (1)$ Take $a,b\in A$ and assume $f(a,x) = f(b,x) = y$. Then $xLy$, so $xL^!y$, so $a=b$.

The proof of the second part is dual.
\end{proof}

\begin{lemma}
Let $\sSet{A, f}$ be an associative class. Then
\begin{enumerate}
\item $L = \bigcup_{a\in A}f(a, -)$;
\item $R = \bigcup_{a\in A}f(-, a)$.
\end{enumerate}
\end{lemma}

For given and fixed $f$, we will often write
\begin{itemize}
\item $\lambda_a: A\to A$ for $f(a, -)$;
\item $\rho_a: A\to A$ for $f(-, a)$.
\end{itemize}

\begin{lemma} \label{lambdaRhoCommute}
For all $a,b\in A$, we have $\lambda_a\circ \rho_b = \rho_b \circ \lambda_a$.
\end{lemma}
\begin{proof}
We calculate, for arbitrary $x\in A$,
\[ \lambda_a\big(\rho_b(x)\big) = f\big(a, f(x,b)\big) = f\big(f(a,x), b\big)  = \rho_b\big(\lambda_a(x)\big). \]
\end{proof}
\begin{corollary} \label{LRcommute}
Let $A$ be a class and $f: A\times A \to A$ an associative binary function. Then $L;R = R;L$.
\end{corollary}
\begin{proof}
Let $x,y\in A$. Then $x(L;R)y$ iff there exist $a,b\in A$ such that the top path in
\[ \begin{tikzcd}
x \ar[r, maps to, "\lambda_a"] \ar[d, maps to, swap, "\rho_b"] & f(a, x) \ar[d, maps to, "\rho_b"] \\
f(x, b) \ar[r, maps to, swap, "\lambda_a"] & y
\end{tikzcd} \]
holds. By \ref{lambdaRhoCommute} this is equivalent to the bottom path holding. The bottom path implies $x(R;L)y$.
\end{proof}

\begin{proposition} \label{functionsLeftRightRelations}
Let $g,h$ be functions in the assocative class of functions with composition $\circ$. Then
\begin{enumerate}
\item $gLh$ \textup{if and only if} $\ker g \subseteq \ker h$;
\item $gRh$ \textup{if and only if} $\im g \supseteq \im h$. 
\end{enumerate}
\end{proposition}

\subsubsection{Principal ideals}
\begin{definition}
Let $\sSet{A, f}$ be an associative class and $x, y\in A$. Then
\begin{itemize}
\item the \udef{left principal ideal} generated by $x$ is $f(\widetilde{A}, x) = f(A, x)\cup \{x\}$;
\item the \udef{right principal ideal} generated by $x$ is $f(x, \widetilde{A}) = f(x,A)\cup \{x\}$.
\end{itemize}
\end{definition}

\begin{lemma} \label{idealAbsorption}
Let $\sSet{A, f}$ be an associative class and $x, y\in A$. Then
\begin{enumerate}
\item $f(A, f(x,y)) \subseteq f(A, y)$;
\item $f(f(x,y), A) \subseteq f(x, A)$.
\end{enumerate}
\end{lemma}
\begin{proof}
(1) Take $z\in f(A, f(x,y))$. Then there exists $z'\in A$ such that
\[ z = f(z', f(x,y)) = f(f(z', x), y) \in f(A, y). \]

(2) By duality.
\end{proof}

\begin{lemma}
LLet $\sSet{A, f}$ be an associative class and $x, y\in A$. Then
\begin{enumerate}
\item $f(A, x) \subseteq f(A,y)$ \textup{if and only if} $\forall a\in A: \exists b\in A: \; f(a, x) = f(b, y)$;
\item $f(x, A) \subseteq f(y, A)$ \textup{if and only if} $\forall a\in A: \exists b\in A: \; f(x, a) = f(y, b)$.
\end{enumerate}
If $A$ contains an identity $e$, then
\begin{enumerate} \setcounter{enumi}{2}
\item $f(A, x) \subseteq f(A,y)$ \textup{if and only if} $\exists b\in A: \; x = f(b, y)$;
\item $f(x, A) \subseteq f(y, A)$ \textup{if and only if} $\exists b\in A: \; x = f(y, b)$.
\end{enumerate}
\end{lemma}

\begin{proposition} \label{invertibilityFromPrincipalIdeals}
Let $\sSet{A, f}$ be an associative class. Then $f$ has an identity and every $x\in A$ is invertible \textup{if and only if}
\[ \forall x\in A: \quad f(x, A) = A = f(A,x). \]
\end{proposition}
\begin{proof}
$\Rightarrow$ We clearly have $f(x, A) \subseteq A$. The other inclusion follows from \ref{idealAbsorption}: $A = f(A, e) = f(A, f(x^{-1}, x)) \subseteq f(A, x)$.

$\Leftarrow$ Pick some $x\in A$, so $x\in f(x,a)$, meaning there exists an $a\in A$ such that $x = xa$. We claim $a$ is a right-identity for $f$. Indeed, take arbitrary $y\in A$. Then $y = f(b,x)$ for some $b\in A$ and so
\[ f(y, a) = f(f(b,x), a) = f(b,f(x,a)) = f(b,x) = y. \]
In the same way we can also find a left-identity. So $A$ contains an identity $e \defeq a$ by \ref{leftRightIdentity}.

Now for all $x\in A$ we have $e\in A = f(x,A)$, so we can find a right-inverse of $x$. Similarly, we can find a left-inverse of $x$. This means $x$ is invertible by \ref{leftRightInverse}.
\end{proof}


\subsubsection{Green's relations}
\begin{definition}
Let $\sSet{A, f}$ be an associative class.
The \udef{Green's relations} of $f$ are relations on $A$ defined as
\begin{itemize}
\item $\greensL$ is the reflexive closure of the symmetric part of $L$;
\item $\greensR$ is the reflexive closure of the symmetric part of $R$;
\item $\greensH \;\defeq\; \greensL \cap\greensR$;
\item $\greensD \;\defeq\; \greensL;\greensR$.
\end{itemize}
\end{definition}
The relations $\greensL$ and $\greensR$ are dual.

\begin{lemma}
Let $\sSet{A, f}$ be an associative class. Then the relations $\greensL$ and $\greensR$ are equivalence relations.
\end{lemma}

\begin{lemma}
Let $\sSet{A, f}$ be an associative class and $x, y\in A$. Then the following are equivalent:
\begin{enumerate}
\item $x \greensL y$;
\item $x\big((L\cap L^\transp) \cup \id_A\big)y$
\item $\exists a,b\in \widetilde{A}: (f(a, x) = y) \land (f(b, y) = x)$;
\item $\begin{tikzcd}[sep=large]
x \ar[r, maps to, shift left, "\exists a: \lambda_a"] & y \ar[l, maps to, shift left, "\exists b: \lambda_b"]
\end{tikzcd}$
\item $f(\widetilde{A},x) = f(\widetilde{A}, y)$;
\item $f(A,x) = f(A, y)$;
\end{enumerate}
as are
\begin{enumerate}
\item $x \greensR y$;
\item $x\big((R\cap R^\transp) \cup \id_A\big)y$
\item $\exists a,b\in \widetilde{A}: (f(x, a) = y) \land (f(y, b) = x)$;
\item $\begin{tikzcd}[sep=large]
x \ar[r, maps to, shift left, "\exists a: \rho_a"] & y \ar[l, maps to, shift left, "\exists b: \rho_b"]
\end{tikzcd}$
\item $f(x, \widetilde{A}) = f(y, \widetilde{A})$;
\item $f(x, A) = f(y, A)$.
\end{enumerate}
\end{lemma}

\begin{lemma} \label{lambdaRhoPreservation}
Let $\sSet{A, f}$ be an associative class and $x, y, z\in A$.
\begin{enumerate}
\item If $x\greensL y$, then $\rho_z(x)\greensL \rho_z(y)$.
\item If $x\greensR y$, then $\lambda_z(x)\greensR \lambda_z(y)$.
\end{enumerate}
\end{lemma}



\subsubsection{Egg-box diagrams}
\begin{proposition} \label{greensDequivalence}
The relation $\greensD$ is an equivalence relation.
\end{proposition}
This is equivalent to $\greensL;\greensR = \greensR;\greensL$ by \ref{commutingEquivalenceRelations}. 
\begin{proof}
Assume $x(\greensR;\greensL)z$, meaning $\exists y: x\greensR y$ and $y\greensL z$. Then there exist $a,b,c,d\in \widetilde{A}$ such that
\[ \begin{tikzcd}
x \ar[r, maps to, shift left, "\rho_a"] & y \ar[l, maps to, shift left, "\rho_b"] \ar[r, maps to, shift left, "\lambda_c"] & z \ar[l, maps to, shift left, "\lambda_d"]
\end{tikzcd}. \]
Using \ref{lambdaRhoCommute}, we can rearrange such that we also get the mappings along the left and bottom sides of
\[ \begin{tikzcd}[sep=large]
x \ar[r, maps to, shift left, "\rho_a"] \ar[d, maps to, shift left, "\lambda_c"] & y \ar[l, maps to, shift left, "\rho_b"] \ar[d, maps to, shift left, "\lambda_c"] \\
y' \ar[u, maps to, shift left, "\lambda_d"] \ar[r, maps to, shift left, "\rho_a"] & z \ar[u, maps to, shift left, "\lambda_d"] \ar[l, maps to, shift left, "\rho_b"]
\end{tikzcd} \]
for some $y' \in A$. Thus $x(\greensL;\greensR)y$. The other inclusion is similar.
\end{proof}

From \ref{commutingEquivalenceRelations} we also know that the $\greensL,\greensR$-egg-box diagram decomposes into blocks, which are $\greensD$-equivalence classes. The columns are $\greensL$-equivalence classes, the rows are $\greensR$-equivalence classes, and the cells are $\greensH$-equivalence classes.

\begin{example}
Let $A = (\{1,2,3\} \to \{1,2,3\})$ with the binary function $A\times A \to A: (f,g)\mapsto f;g$. We can represent an element $f$ of $A$ as $(f(1) f(2) f(3))$. We have
\begin{itemize}
\item $f\greensL g$ if $f$ and $g$ have the same image;
\item $f\greensR g$ if $f$ and $g$ have the same kernel.
\end{itemize}
An egg-box diagram can be drawn as follows:
\[ \begin{array}{|c|c|c|c|c|c|c|}
\hline
\mathbf{(1 1 1)} & \mathbf{(2 2 2)} & \mathbf{(3 3 3)} &&& &  \\ \hline
&& & \mathbf{(1 2 2)}, & \mathbf{(1 3 3)}, & (2 3 3), &  \\
&& & (2 1 1)  & (3 1 1)  & (3 2 2)  &  \\ \hline
&& & (2 1 2), & (3 1 3), & \mathbf{(3 2 3)},  &  \\
&& & \mathbf{(1 2 1)}  & (1 3 1)  & (2 3 2)  &  \\ \hline
&& & (2 2 1), & (3 3 1), & (3 3 2),  &  \\
&& & (1 1 2)  & \mathbf{(1 1 3)}  & \mathbf{(2 2 3)}  &  \\ \hline
&& &&& & \mathbf{(1 2 3)}, (2 3 1), (3 1 2)  \\
&& &&& & (1 3 2), (2 1 3), (3 2 1)  \\ \hline
\end{array} \]
The bold elements are idempotents.
\end{example}


\begin{proposition}[Green's lemma] \label{GreensLemma}
Let $\sSet{A, f}$ be an associative class and $x, y\in A$.
\begin{enumerate}
\item If $x\greensL y$ with $\begin{tikzcd}
x \ar[r, maps to, shift left, "\lambda_a"] & y \ar[l, maps to, shift left, "\lambda_b"]
\end{tikzcd}$, then
\begin{enumerate}
\item $\lambda_a|_{[x]_\greensR}: [x]_\greensR \to [y]_\greensR \qquad \text{is a bijection with inverse} \qquad \lambda_b|_{[y]_\greensR}: [y]_\greensR \to [x]_\greensR$;
\item $\lambda_a|_{[x]_\greensH}: [x]_\greensH \to [y]_\greensH \qquad \text{is a bijection with inverse} \qquad \lambda_b|_{[y]_\greensH}: [y]_\greensH \to [x]_\greensH$.
\end{enumerate}
\item If $x\greensR y$ with $\begin{tikzcd}
x \ar[r, maps to, shift left, "\rho_a"] & y \ar[l, maps to, shift left, "\rho_b"]
\end{tikzcd}$, then
\begin{enumerate}
\item $\rho_a|_{[x]_\greensL}: [x]_\greensL \to [y]_\greensL \qquad \text{is a bijection with inverse} \qquad \rho_b|_{[y]_\greensL}: [y]_\greensL \to [x]_\greensL$;
\item $\rho_a|_{[x]_\greensH}: [x]_\greensH \to [y]_\greensH \qquad \text{is a bijection with inverse} \qquad \rho_b|_{[y]_\greensH}: [y]_\greensH \to [x]_\greensH$.
\end{enumerate}
\end{enumerate}
\end{proposition}
\begin{proof}
Take some arbitrary $x'\in [x]_\greensR$. Then there exist $c,d\in \widetilde{A}$ such that $\begin{tikzcd}
x \ar[r, maps to, shift left, "\rho_c"] & x' \ar[l, maps to, shift left, "\rho_d"]
\end{tikzcd}$. Then, by \ref{lambdaRhoCommute},
\[ \begin{tikzcd}
x' \ar[r, maps to, shift left, "\rho_d"] & x \ar[l, maps to, shift left, "\rho_c"] \ar[r, maps to, shift left, "\lambda_a"] & y \ar[l, maps to, shift left, "\lambda_b"]
\end{tikzcd} \qquad\text{implies that} \qquad \begin{tikzcd}
x' \ar[r, maps to, shift left, "\lambda_a"] & y' \ar[l, maps to, shift left, "\lambda_b"] \ar[r, maps to, shift left, "\rho_d"] & y \ar[l, maps to, shift left, "\rho_c"]
\end{tikzcd} \]
Thus, for all $x'\in [x]_\greensR$, we have
\begin{itemize}
\item $\lambda_a(x') \in [y]_\greensR$, meaning that $\lambda_a|_{[x]_\greensR}: [x]_\greensR \to [y]_\greensR$ is well-defined;
\item by similar reasoning, we can see that $\lambda_b|_{[y]_\greensR}: [y]_\greensR \to [x]_\greensR$ is also well-defined;
\item $\lambda_b(\lambda_a(x')) = x'$, so the functions are inverse of each other.
\end{itemize}
If $x'\in [x]_\greensH$, then $\lambda_a(x')\greensL \lambda_a(x) = y$ by \ref{lambdaRhoPreservation}, so $\lambda_a(x')\in [y]_\greensH$. This means that $\lambda_a|_{[x]_\greensH}: [x]_\greensH \to [y]_\greensH$ is well-defined.

Point (2) is dual.
\end{proof}
\begin{corollary} \label{greensDisomorphism}
Let $\sSet{A, f}$ be an associative class and $x, y\in A$ such that $x\greensD y$. Then there exist $a,b,c,d\in \widetilde{A}$ such that
\[ \lambda_a\circ\rho_b|_{[x]_\greensH}: [x]_\greensH \to [y]_\greensH \qquad \text{is a bijection with inverse} \qquad \lambda_c\circ \rho_d|_{[y]_\greensH}: [y]_\greensH \to [x]_\greensH. \]
\end{corollary}
\begin{proof}
There exists a $z\in A$ such that $x\greensL z$ and $z\greensR y$. We then just compose the bijections in Green's lemma, keeping in mind that $\lambda$ and $\rho$ commute.
\end{proof}
\begin{corollary}
Let $\sSet{A, f}$ be an associative class and $x\in A$. If $x$ is an idempotent, then
\[ \lambda_x|_{[x]_\greensR} = \id_{[x]_\greensR} \qquad \text{and} \qquad \rho_x|_{[x]_\greensL} = \id_{[x]_\greensL}. \]
Thus $x$ is a left identity for $[x]_\greensR$ and a right identity for $[x]_\greensL$.
\end{corollary}
\begin{proof}
Take $y\in [x]_\greensR$. Then there exist $a,b\in \widetilde{A}$ such that $\begin{tikzcd}
x \ar[r, maps to, shift left, "\rho_a"] & y \ar[l, maps to, shift left, "\rho_b"]
\end{tikzcd}$. Then we have
\[ xy = xxb = xb = y. \]
The other claim is dual.
\end{proof}

\begin{theorem}[Green's theorem]
Let $\sSet{A, f}$ be an associative class and $H$ an $\mathcal{H}$-class in $A$. Then either
\begin{enumerate}
\item $H^2\perp H$; or
\item $H^2 = H$, $f|_{H\times H}$ has an identity and each $x\in H$ is invertible.
\end{enumerate}
\end{theorem}
\begin{proof}
Suppose $H^2\cap H \neq \emptyset$, then there exist $a,b\in H$ such that $ab = c\in H$. By the Green's lemma \ref{GreensLemma} we have that $\rho_b:H\to H$ and $\lambda_a: H\to H$ are bijections.

Then for all $h\in H$, $\rho_b(h) = hb \in H$. Again by the Green's lemma, this means that $\lambda_h: H\to H$ is a bijection. Similarly $\rho_h: H\to H$ is a bijection for all $h$. So for all $h\in H$ we have $hH = H = Hh$. The result follows by \ref{invertibilityFromPrincipalIdeals}.
\end{proof}
\begin{corollary} \label{GreensTheoremCorollary}
Let $\sSet{A, f}$ be an associative class and $H$ an $\mathcal{H}$-class in $A$.Then
\begin{enumerate}
\item if $x$ is an idempotent in $H$, then we have the second case;
\item no $\mathcal{H}$-class can contain more than one idempotent. 
\end{enumerate}
\end{corollary}

\subsection{Regular elements and generalised inverses}
\begin{definition}
Let $\sSet{A, f}$ be an associative class and $x, y\in A$. We call
\begin{itemize}
\item $x$ \udef{regular} if $\exists a\in A: \; x = f(f(x, a), x)$
\item $x$ and $y$ \udef{generalised inverses} if $x = f(f(x, y), x)$ and $y = f(f(y, x), y)$.
\end{itemize}
\end{definition}

\begin{proposition} 
Let $\sSet{A, f}$ be an associative class. If $x\in A$ is regular, then every element in $[x]_{\greensD}$ is regular.
\end{proposition}
So it makes sense to call a $\greensD$-class \udef{regular} if it consists of regular elements and \udef{irregular} otherwise.
\begin{proof}
Let $x$ be regular with $x = xx'x$ and $x\greensD y$. Then we have $a,b,c,d \in \widetilde{A}$ such that
$\lambda_a\circ\rho_b|_{[x]_\greensH}: [x]_\greensH \to [y]_\greensH$ is a bijection with inverse $\lambda_c\circ \rho_d|_{[y]_\greensH}: [y]_\greensH \to [x]_\greensH$, as in \ref{greensDisomorphism}. Then we have
\[ y = (\lambda_a\circ\rho_b)(x) = (\lambda_a\circ\rho_b)(xx'x) = axx'xb = a(\lambda_c\circ\rho_d)(y)x'(\lambda_c\circ\rho_d)(y)b = ydx'cy. \]
So $y$ is regular.
\end{proof}
\begin{corollary}
If there is an idempotent $x\in [a]_{\greensD}$, then $[a]_{\greensD}$ is regular.
\end{corollary}
\begin{proof}
An idempotent is regular: $x = f(x,x) = f(f(x,x), x)$.
\end{proof}

\begin{proposition}
Let $\sSet{A, f}$ be an associative class. Then $x$ is regular \textup{if and only if} it has a generalised inverse.
\end{proposition}
\begin{proof}
Clearly every element with a generalised inverse is regular. Conversely, assume $x$ regular with $x = xax$. Then $y = axa$ is a generalised inverse of $x$: $x(axa)x = xax = x$ and $(axa)x(axa) = a(xax)axa = axaxa = axa$.
\end{proof}
Note that we do not have that $x = xyx$ implies $y = yxy$.

\begin{proposition} \label{greensRelationsRegularElements}
Let $\sSet{A, f}$ be an associative class and $x\in A$ a regular element with $x = f(f(x, y), x)$. Then
\begin{enumerate}
\item $f(x,y)$ and $f(y,x)$ are idempotent;
\item $f(y,x) \greensL x$ and $x \greensR f(x, y)$.
\end{enumerate}
\end{proposition}
\begin{proof}
(1) We calculate
\[ f(f(x,y), f(x,y)) = f(f(f(x,y), x), y) = f(x, y)\] and \[f(f(y,x), f(y,x)) = f(y, f(x, f(y,x))) = f(y,x). \]

(2) Using \ref{idealAbsorption}, we have
\[ f(A, x) = f(A, f(x,f(y,x))) \subseteq f(A, f(y,x)) \subseteq f(A,x). \]
Thus $f(A, x) = f(A, f(y,x))$. The second part is dual.
\end{proof}
\begin{corollary}
In a regular $\mathcal{D}$-class each $\mathcal{L}$-class and each $\mathcal{R}$-class contains at least one idempotent.
\end{corollary}
\begin{proof}
Let $[x]_\mathcal{L}$ be an $\mathcal{L}$-class in a regular $\mathcal{D}$-class. By regularity there exists a $y\in A$ such that $xyx = x$. From the proposition, we have that $[x]_\mathcal{L}$ contains the idempotent $yx$ and $[x]_\mathcal{R}$ the idempotent $xy$.
\end{proof}
\begin{corollary} \label{idempotentsHclass}
If $x,x'\in A$ are generalised inverses, then $[xx']_\mathcal{H} = [x]_\mathcal{R}\cap [x']_\mathcal{L}$ and $[x'x]_\mathcal{H} = [x']_\mathcal{R}\cap [x]_\mathcal{L}$.
\end{corollary}
\begin{proof}
From $x\greensR (xx')$ and $(xx')\greensL x'$, we get the first equality. The second is dual.
\end{proof}
We can depict the situation in the corollary as follows:
\[ \hspace{-8.4em} \exists a,b,c,d \in \widetilde{A}: \qquad \begin{tikzcd}[sep=large]
x \ar[r, maps to, shift left, "\rho_a"] \ar[d, maps to, shift left, "\lambda_c"] & xx' \ar[l, maps to, shift left, "\rho_b"] \ar[d, maps to, shift left, "\lambda_c"] \\
x'x \ar[u, maps to, shift left, "\lambda_d"] \ar[r, maps to, shift left, "\rho_a"] & x' \ar[u, maps to, shift left, "\lambda_d"] \ar[l, maps to, shift left, "\rho_b"]
\end{tikzcd} \]

So generalised inverses along one diagonal imply idempotents along the other. In fact, the other direction also holds:
\begin{proposition}
Let $\sSet{A, f}$ be an associative class and $e,f$ idempotents in $A$ such that $e\greensD f$. Then there exist $x\in [e]_\greensR\cap [f]_\greensL$ and $x'\in [e]_\greensL\cap [f]_\greensR$ such that
\begin{itemize}
\item $x,x'$ are generalised inverses;
\item $e = xx'$ and $f = x'x$.
\end{itemize}
\end{proposition}
\begin{proof}
Because $e\greensD f$, we can find $x,x'\in A$ such that
\[ \hspace{-8.4em} \exists a,b,c,d \in \widetilde{A}: \qquad \begin{tikzcd}[sep=large]
e \ar[r, maps to, shift left, "\rho_a"] \ar[d, maps to, shift left, "\lambda_c"] & x \ar[l, maps to, shift left, "\rho_b"] \ar[d, maps to, shift left, "\lambda_c"] \\
x' \ar[u, maps to, shift left, "\lambda_d"] \ar[r, maps to, shift left, "\rho_a"] & f \ar[u, maps to, shift left, "\lambda_d"] \ar[l, maps to, shift left, "\rho_b"]
\end{tikzcd} \]
Then
\begin{align*}
xx' &= (df)(fb) = dfb = e \\
x'x &= (ce)(ea) = cea = f \\
xx'x &= ex = eea = ea = x \\
x'xx' &= fx' = ffb = fb = x',
\end{align*}
which completes the proof.
\end{proof}
\begin{corollary}
Let $\sSet{A, f}$ be an associative class, $y\in A$ and $e,f$ idempotents in $A$. Then $e\greensD f$ \textup{if and only if} there exist generalised inverses $x,x'$ such that $e = xx'$ and $f = x'x$.
\end{corollary}
\begin{proof}
The direction $\Rightarrow$ follows from the proposition. The converse from \ref{greensRelationsRegularElements}.
\end{proof}

\begin{lemma}
Let $\sSet{A, f}$ be an associative class, $x\in A$. Then no $\greensH$-class contains more than one generalised inverse of $x$.
\end{lemma}
\begin{proof}
Assume $x$ has two generalised inverses, $x_1'$ and $x_2'$. From \ref{idempotentsHclass} and \ref{GreensTheoremCorollary} we get that $xx_1' = xx_2'$ and $x_1'x = x_2'x$. Thus
\[ x_1' = x_1'(xx_1') = x_1'xx_2' = (x_1'x)x_2' =  x_2'xx_2' = x_2'. \]
\end{proof}

\begin{proposition}
Let $\sSet{A, f}$ be an associative class and $x,y\in A$. Then $xy\in [x]_\greensR \cap [y]_\greensL$ \textup{if and only if} $[x]_\greensL \cap [y]_\greensR$ contains an idempotent.
\end{proposition}
\begin{proof}
First assume $[x]_\greensL \cap [y]_\greensR$ contains an idempotent $e$. We can depict the situation as
\[ \hspace{-8.4em} \exists a,b,c,d \in \widetilde{A}: \qquad \begin{tikzcd}[sep=large]
x \ar[r, maps to, shift left, "\rho_a"] \ar[d, maps to, shift left, "\lambda_c"] &  \ar[l, maps to, shift left, "\rho_b"] \ar[d, maps to, shift left, "\lambda_c"] \\
e \ar[u, maps to, shift left, "\lambda_d"] \ar[r, maps to, shift left, "\rho_a"] & y \ar[u, maps to, shift left, "\lambda_d"] \ar[l, maps to, shift left, "\rho_b"]
\end{tikzcd} \]
Then we can calculate
\[ xy = deea = dea = xa \in [x]_\greensR \cap [y]_\greensL. \]
Now assume $xy\in [x]_\greensR \cap [y]_\greensL$.
We can depict the situation as
\[ \hspace{-8.4em} \exists a,b,c,d \in \widetilde{A}: \qquad \begin{tikzcd}[sep=large]
x \ar[r, maps to, shift left, "\rho_a"] \ar[d, maps to, shift left, "\lambda_c"] & xy \ar[l, maps to, shift left, "\rho_b"] \ar[d, maps to, shift left, "\lambda_c"] \\
e \ar[u, maps to, shift left, "\lambda_d"] \ar[r, maps to, shift left, "\rho_a"] & y \ar[u, maps to, shift left, "\lambda_d"] \ar[l, maps to, shift left, "\rho_b"]
\end{tikzcd} \]
Now we need to show that $e$ is idempotent. Indeed, starting from the three other corners, we see that $e = cx$ and $e = yb$ and $e = c(xy)b = (cx)(yb) = ee$.
\end{proof}

\subsection{Commutation}
\begin{definition}
Let $\sSet{A,f}$ be an associative class and $x,y \in A$. We say $x$ and $y$ \udef{commute} if $f(x,y) = f(y,x)$. We write $x\commute y$.
\end{definition}


\subsubsection{Centraliser or commutant}
\begin{definition}
Let $\sSet{A,f}$ be an associative class and $B\subseteq A$ a subclass. The \udef{centraliser} or \udef{commutant} of $B$ is defined as $Z_A(B) \defeq B^\commute$.

In particular we define the \udef{centre} of $A$ as the centraliser of all of $A$: $Z_A \defeq Z_A(A)$.
\end{definition}
Thus
\[ Z_A(B) = \setbuilder{x\in A}{\forall b\in B:\;f(x,b) = f(b,x)}. \].

Note that taking the commuting forms a Galois connection. In particular $B \subseteq B^{\commute\commute}$.

\begin{lemma}
Let $\sSet{A,f}$ be an associative class and $B\subseteq A$. If $f$ is commutative, then $Z_A(B) = A$.
\end{lemma}

\begin{proposition}
Let $\sSet{A,f}$ be an associative class and $B\subseteq A$. Then $Z_A(B)$ is closed under $f$.
\end{proposition}
\begin{proof}
Take arbitrary $x,y\in Z_A(B)$. Take arbitrary $b\in B$. Then
\[ f(f(x,y),b) = f(x,f(y,b)) = f(x,f(b,y)) = f(f(x,b),y) = f(f(b,x),y) = f(b,f(x,y)), \]
which means that $f(x,y)\in Z_A(B)$.
\end{proof}

\subsection{Normaliser}
\begin{definition}
Let $\sSet{A,f}$ be an associative class and $B\subseteq A$ a subclass. An element $x\in A$ is said to \udef{normalise} $B$ if $f(x,B) = f(B,x)$.

The \udef{normaliser} of $B$ in $A$ is the set of all elements in $A$ that normalise $B$:
\[ N_A(B) \defeq \setbuilder{x\in A}{f(x,B) = f(B,x)}. \]
\end{definition}

\begin{proposition}
Let $\sSet{A,f}$ be an associative class and $B\subseteq A$. Then
\begin{enumerate}
\item $N_A(B)$ is closed under $f$;
\item $Z_A(B) \subseteq N_A(B)$;
\item $Z_A(\{a\}) = N_A(\{a\})$ for all $a\in A$.
\end{enumerate}
\end{proposition}
\begin{proof}
(1) Take arbitrary $x,y\in N_A(B)$. Then
\[ f(f(x,y),B) = f(x,f(y,B)) = f(x,f(B,y)) = f(f(x,B),y) = f(f(B,x),y) = f(B,f(x,y)), \]
which means that $f(x,y)\in N_A(B)$.

(2) If $f(x,b) = f(b,x)$ for all $b\in B$, then $f(x,B) = f(B,x)$.

(3) $f(x,\{a\}) = f(x,a)$ and $f(\{a\}, x) = f(a,x)$.
\end{proof}

\subsection{Composition of relations}
\begin{definition}
Let $\mathfrak{R}$ be the class of all relations, with absorbing element $\mathrm{NULL}$ adjoined.
\end{definition}

\begin{proposition}
Let $R,S \in \mathfrak{R}$ be relations. Then
\begin{enumerate}
\item $R \greensL S$ \textup{if and only if} $R$ and $S$ have the same image and cokernel;
\item $R \greensR S$ \textup{if and only if} $R$ and $S$ have the same preimage and kernel.
\end{enumerate}
\end{proposition}
\begin{proof}
TODO
\end{proof}

\chapter{The natural numbers}
\begin{definition}
A \udef{system of natural numbers} or \udef{Peano system} is a structured set $(N,(0,S)) = (N,0,S)$ which satisfies
\begin{enumerate}
\item $N$ is a set containing $0$;
\item $S$ is an injective function on the set $N$;
\item for all $n\in N: S(n) \neq 0$;
\item the induction principle: $\forall X\subset N$
\[ [(0\in X) \land (\forall n\in N: n\in X \implies Sn \in X)] \implies X = N. \]
\end{enumerate}
We call $0$ the \udef{zero} and $S$ the \udef{successor function}. These axioms are the \udef{Peano axioms}. An object $n\in N$ is called a \udef{successor} if $\exists m\in N: n = S(m)$.
\end{definition}
The most involved axiom is the induction principle. Note that it is not formulated in first order logic. Thus the Peano axioms are not subject to the LÃ¶wenheim-Skolem theorem and we can obtain a uniqueness result (despite the fact that, as we will see, $N$ is infinite).

\begin{lemma} \label{successor}
Let $(N,0,S)$ be a Peano system. Then every element $n\neq 0$ is a successor and for each $n\in N: S(n) \neq n$.
\end{lemma}
\begin{proof}
We wish to prove that the set
\[ X = \{n\in N\;|\; (n=0)\lor(\exists m\in N: n = S(m))\} \]
equals $N$. It is obvious that both $0\in X$ and $\forall n\in N: n\in X \implies Sn \in X$, so we can apply the induction principle to obtain $X=N$. The second claim then follows by injectivity.
\end{proof}
\section{Recursion and induction}
\subsection{Recursion}
\begin{theorem}[Recursion theorem]
Assume $(N,0,S)$ is a Peano system, $E$ is some set, $a\in E$, and $h:E\to E$ is some function.

There is exactly one function $f: N\to E$ which satisfies
\[ \begin{cases}
f(0) = a, \\
f(Sn) = h(f(n)) & (n\in N).
\end{cases} \]
\end{theorem}
Functions defined using this theorem are said to be defined \udef{recursively}.\footnote{The terms ``recursion'' and ``induction'' are often used synonymously. We
will usually distinguish recursive definitions from inductive
proofs (using the induction principle).}
\begin{proof}
We consider the set $\mathcal{A}$ of ``approximations'' of the function $f$:
\begin{align*}
\mathcal{A} = \{ p: X\to E \;|\; &(X\subset N)\land \\
&(0\in X)\;\land \\
&[\forall n\in N: Sn\in X \implies (n\in X \land p(Sn) = h(p(n)))] \}.
\end{align*}
In words we may say that $X$ is a downwards closed subset of $N$ and $p$ satisfies the recursion conditions. Some examples of elements of $\mathcal{A}$ include
\begin{align*}
&\{(0,a)\} \\
&\{(0,a), (S0, h(a))\} \\
&\{(0,a), (S0, h(a)), (SS0, h(h(a)))\} \\
&\;\;\ldots
\end{align*}

Any function $f$ with domain $N$ satisfying the recursion conditions, as in the theorem must be an element of $\mathcal{A}$. Thus to prove the theorem we need to prove that $\mathcal{A}$ contains exactly one function with domain $N$.

We prove this using a lemma.
\begin{lemma*}
For all $p,q\in \mathcal{A}$ and $n\in N$,
\[ n\in \dom(p)\cap\dom(q) \implies p(n) = q(n). \]
\end{lemma*}
\begin{proof}[Proof of lemma] \renewcommand{\qedsymbol}{$\dashv$ (Lemma)}
We need to prove that the set of $n\in N$ for which this is true,
\[ Y = \{n\in N \;|\; \forall p,q\in\mathcal{A}:\left[ n\in \dom(p)\cap\dom(q) \implies p(n) = q(n) \right] \} \]
is exactly $N$. We prove this with the principle of induction.

Clearly $0\in Y$, because every $p\in\mathcal{A}$ satisfies $p(0) = a$. Now let $n\in Y$ and $p,q\in\mathcal{A}$ such that $Sn\in \dom(p)\cap\dom(q)$. Then
\[ p(Sn) = h(p(n)) = h(q(n)) = q(Sn) \]
so $Sn\in Y$. By the induction principle $Y = N$.
\end{proof}
The lemma immediately implies there is at most one suitable function $f$ with domain $N$. We show such a function exists. Indeed it is given by $f = \bigcup \mathcal{A}$. Using the lemma we see this must be a function. It is not difficult to see that $f\in \mathcal{A}$. We then just need to verify that $\dom(f) = N$. This is again an application of the induction principle: $0\in \dom(f)$ and if $n\in \dom(f)$, then there exists some $p\in\mathcal{A}$ with $n\in\dom(p)$ and we have
\[ q = p\cup \{(Sn, h(p(n)))\}\in \mathcal{A}, \]
so that $Sn\in\dom(q)\subseteq \dom(f)$.
\end{proof}
\begin{corollary}[Recursion with parameters]
Let $(N,0,S)$ be a Peano system, $Y,E$ sets and functions
\[ g: Y\to E,\qquad h:E\times Y\to E. \]

There is exactly one function $f: N\times Y\to E$ which satisfies
\[ \begin{cases}
f(0,y) = g(y), & (y\in Y) \\
f(Sn,y) = h(f(n,y),y) & (y\in Y, n\in N).
\end{cases} \]
\end{corollary}
\begin{proof}
For any $y\in Y$ we can apply the normal recursion theorem the obtain a function $f_y: N\to E$. Then set $f(n,y) = f_y(n)$.
\end{proof}
\begin{corollary}[Recursion with the argument as parameter]
Let $(N,0,S)$ be a Peano system, $E$ a set, $a\in E$ and $h: E\times N\to E$ a function.

There is exactly one function $f: N\to E$ which satisfies
\[ \begin{cases}
f(0) = a, \\
f(Sn) = h(f(n),n) & (n\in N).
\end{cases} \]
\end{corollary}
\begin{proof}
Consider the function $\phi: N \to N\times E$ which returns both the required result and the successor of its argument. As the argument is returned by the function, it can be used in the normal recursion theorem if we replace $E$ by $N\times E$. Then just define $f(n)$ to be the second component of $\phi(n)$.
\end{proof}
More version of recursion can be cooked up, such as
\begin{itemize}
\item \udef{complete recursion} where at each step of the recursion. $h$ is passed not just the latest function value, but the whole partial function created so far:
\[ h: (\N \not\to E)\to E. \]
\item recursion with both the argument as parameter and other parameters;
\item simultaneous recursion that defines two functions $f_1,f_2$ and the next step depends on the current step of both functions:
\[ f_1(Sn) = h_1(f_1(n),f_2(n)) \qquad \text{and}\qquad f_2(Sn) = h_2(f_1(n),f_2(n)). \]
\end{itemize}

\subsection{Induction}
\begin{lemma}[Mathematical induction]
We can prove a definite statement $P(n)$ holds for all $n\in \N$ by proving
\begin{enumerate}
\item the \udef{base case} $P(0)$; and
\item the \udef{induction step} $\forall k\in \N: P(k)\implies P(Sk)$.
\end{enumerate}
We call ``$\forall k\in \N: P(k)$'' the \udef{induction hypothesis}.
\end{lemma}
\begin{proof}
Consider the set
\[ X = \{ n\in \N\;|\; P(n) \}. \]
The statement $P(n)$ holds for all $n\in \N$ if $X=\N$. Using the base case we have $0\in X$ and using the induction step we have
\[ \forall k\in\N: k\in X \implies Sn\in X. \]
By induction we conclude $X=\N$ and thus $P(n)$ for all $n\in \N$.
\end{proof}
\begin{corollary}
We can prove a definite statement $P(n)$ holds for all $n\geq n_0$ by proving
\begin{enumerate}
\item the base case $P(n_0)$; and
\item the induction step $\forall k\geq n_0: P(k)\implies P(Sk)$.
\end{enumerate}
\end{corollary}

\begin{lemma}[Complete (strong) induction]
We can prove a definite statement $P(n)$ holds for all $n\in \N$ by proving
\begin{enumerate}
\item the base case $P(0)$; and
\item the \udef{strong induction step} $\forall k\in \N: [\forall j\leq k:  P(j)] \implies P(Sk)$.
\end{enumerate}
\end{lemma}
The definition of $\leq$ follows later.
\begin{proof}
A strong inductive proof (i.e.\ proving these two steps) is a normal inductive proof of
\[ Q(n) \defequiv \forall m\leq n: P(m) \]
for all $n$. Clearly $Q(n)$ implies $P(n)$.
\end{proof}
Conversely we can prove nothing new using strong induction: every strong inductive proof is in particular also a (weak) inductive one.

\section{Existence and uniqueness of the natural numbers}
\begin{theorem} \label{existenceUniquenessPeano}
There exists a Peano system $\sSet{N,0,S}$. For any two Peano systems $\sSet{N_1,0_1,S_1}$ and
$(N_2,0_2,S_2)$ there exists a unique bijection $\pi: N_1 \to N_2$ such that
\[ \begin{cases}
\pi(0_1) = 0_2, \\
\pi(S_1n) = S_2\pi(n) & (n\in N_1).
\end{cases} \]
\end{theorem}
Such a bijection is called an \udef{isomorphism} of Peano systems. The theorem says any two Peano systems are (uniquely) isomorphic. So all Peano systems are essentially the same. We denote the all in the same way: $\sSet{N,0,S}$.
\begin{proof}
We first prove existence and then uniqueness.
\begin{itemize}
\item[\textbf{Existence}] By the axiom of infinity we have the set $I$ with properties
\[ \emptyset\in I \qquad \text{and}\qquad \forall n\in I: \{n\}\in I. \]
We then define
\[ \mathcal{J} = \{ X\subseteq I\;|\;[\emptyset\in X] \land [\forall n\in X: \{n\} \in X] \} \]
Then we set
\[ \N = \bigcap \mathcal{J},\qquad 0 = \emptyset, \qquad S: \N\to\N: n\mapsto \{n\}. \]
Note that by constructing $\mathcal{J}$ and then taking the intersection, we have removed possible other elements of $I$ and are left with
\[ \N = \{ \emptyset, \{\emptyset\}, \{\{\emptyset\}\}, \{\{\{\emptyset\}\}\}, \ldots \}. \]

With these definitions verifying the Peano axioms is not hard. The induction principle follows from the intersection.
\item[\textbf{Uniqueness}] By the recursion theorem we can a unique function $\pi$ satisfying the identities. What remains the be shown is that $\pi$ is bijective.
\begin{itemize}
\item[Surjectivity] We need to show that $\pi[N_1] = N_2$. To that end we use the induction principle on $(N_2,0_2, S_2)$.
\begin{itemize}
\item Obviously $0_2\in \pi[N_1]$, since $0_2=\pi(0_1)$.
\item Let $m\in\pi[N_1]$. Then $\exists n\in N_1: m=\pi(n)$. Applying $S_2$ gives
\[ S_2m = S_2\pi(n) = \pi(S_1 n). \]
This implies $S_2m\in \pi[N_1]$.
\end{itemize}
The induction principle then gives $\pi[N_1] = N_2$.
\item[Injectivity] We verify that the set
\[ X = \{ n\in N_1\;|\; \forall m\in N_1: \pi(m)=\pi(n) \implies m=n \} \]
equals the set $N_1$. This is again done using the induction principle.
\begin{itemize}
\item Firstly, if $m\neq 0_1$, then $m=S_1m'$ for some $m'\in N_1$, by lemma \ref{successor}. This implies
\[ \pi(m) = \pi(S_1m') = S_2\pi(m') \neq 0_2 \]
and so $0_1\in X$.
\item We need to show that, if $n\in X$,
\[ \pi(m) = \pi(S_1n) \implies m = S_1n. \]
Assume the antecendent. By hypothesis $\pi(m) = \pi(S_1n) = S_2\pi(n) \neq 0_2$ and thus $m\neq 0_1$. Again by lemma \ref{successor} $\exists m'\in N_1: m = S_1m'$. So
\[ S_2\pi(n) = \pi(m) = \pi(S_1m') = S_2\pi(m') \]
implying $n=m'$ and thus $m=S_1m'=S_1n$.
\end{itemize}
The induction principle then gives $X=N_1$ and thus the surjectivity of $\pi$.
\end{itemize}
\end{itemize}
\end{proof}

\subsection{Zermelo ordinals}
The natural numbers constructed in the existence proof are called \udef{Zermelo ordinals}. They are defined by
\[ 0 = \emptyset \qquad \text{and} \qquad S(a) = \{a\}. \]
Then
\begin{align*}
0 &= \emptyset \\
1 &= \{0\} = \{\emptyset\} \\
2 &= \{1\} =  \{\{\emptyset\}\} \\
3 &= \{2\} = \{\{\{\emptyset\}\}\} \\
&\hdots
\end{align*}
\subsection{(Finite) Von Neumann ordinals}
The \udef{Von Neumann ordinals} are an alternate construction. They are defined by
\[ 0 = \emptyset \qquad \text{and} \qquad S(a) = a\cup\{a\}. \]
Then
\begin{align*}
0 &= \emptyset \\
1 &= 0\cup \{0\} = \{\emptyset\} \\
2 &= 1\cup \{1\} = \{0,1\} = \{\emptyset, \{\emptyset\}\} \\
3 &= 2\cup \{2\} = \{0,1,2\} = \{ \emptyset, \{\emptyset\}, \{\emptyset, \{\emptyset\}\} \} \\
&\hdots
\end{align*}
Unlike the Zermelo ordinals, the Von Neumann ordinals can be readily generalised to infinite ordinals (see later).
\section{Operations and relations on natural numbers}
We can use the recursion theorem to define addition and multiplication.
\begin{definition}
The \udef{addition function} $+:\N\times \N \to \N$ on the natural numbers is defined by the recursion (with parameter)
\[ \begin{cases}
+(0,n) = n \\
+(Sm, n) = S(m+n)
\end{cases}. \]
The \udef{multiplication function} $\cdot:\N\times \N \to \N$ on the natural numbers is defined by the recursion (with parameter)
\[ \begin{cases}
\cdot(0,n) = 0 \\
\cdot(Sm, n) = (m\cdot n)+n
\end{cases}. \]
We will usually write $m+n$ and $m\cdot n$ or $mn$ instead of $+(m,n)$ and $\cdot(m,n)$.
\end{definition}

\begin{proposition}
Addition has the following properties:
\begin{enumerate}
\item It is associative: $(k+n)+m = k+(n+m)$;
\item $0$ is a neutral element: $0+n = n$ and $n+0 = n$;
\item for all $m,n\in \N: Sm+n = m+Sn$;
\item it is commutative: $n+m = m+n$.
\end{enumerate}
\end{proposition}
\begin{proof}
All are proven by induction on $m$. The proofs of later claims make use of earlier ones.
\end{proof}
\begin{lemma}
For all $n\in \N$, the function $\N\to \N: s\mapsto n+s$ is 1-1, so
\[n+s = n+t \implies s=t.\]
\end{lemma}

\begin{definition}
The binary relation $\leq$ defined by
\[ n \leq m \defequiv \exists s\in \N: n+s = m \]
is called the ordering of the natural numbers.

We abbreviate $\neg(m\leq n)$ by $n < m$.
\end{definition}

\begin{lemma} \label{orderingN}
Let $\N$ be ordered by $\leq$. Then $\forall n\in\N$
\begin{enumerate}
\item $0\leq n$;
\item there is no $m$ such that $n<m<n+1$.
\end{enumerate}
\end{lemma}
TODO proof

\begin{proposition} \label{proposition:wellOrderingN}
The endorelation $\leq$ on the natural numbers has the following properties:
\begin{enumerate}
\item it is transitive;
\item it is reflexive;
\item it is antisymmetric;
\item it is connex (i.e.\ any two numbers are comparable);
\item every non-empty subset $S$ of $\N$ contains an element $x\in S$ that is left related to all elements of $S$: $\forall y\in S: x\leq y$.
\end{enumerate}
These are exactly the properties of a well-ordering.
\end{proposition}
\begin{proof}
Take a non-empty set $S\subset \N$ and define the set
\[ L = \setbuilder{n\in\N}{\forall m\in S: n\leq m}. \]
We need to show that $L\cap S$ is non-empty. Assume, towards a contradiction, that $L\cap S = \emptyset$.
Now
\begin{itemize}
\item $0\in L$.
\item If $n\in L$, then $n+1\in L$. Indeed if $n+1 \notin L$, then there exists a $z\in S$ such that $n\leq z<n+1$. But by \ref{orderingN} this would mean that $z=n$ and $n\in L\cap S = \emptyset$.
\end{itemize}
By induction $L=\N$, so $S = L\cap S = \emptyset$. This is a contradiction.
\end{proof}


The element $x$ in the last property is called the least element or minimum of $S$. It is unique by antisymmetry and denoted $\min(S)$.

Some subsets $S$ of $\N$ contain an element $x\in S$ that is right related to all elements of $S$: $\forall y\in S: y\leq x$. If it exists, it is called the greatest element or maximum of $S$. It is again unique by antisymmetry and denoted $\max(S)$.

\begin{lemma} \label{naturalNumbersInequalityInclusion}
Let $m,n\in \N$. Then the following are equivalent:
\begin{enumerate}
\item $n\leq m$; 
\item $\interval[co]{0,n} \subseteq \interval[co]{0,m}$.
\end{enumerate}
\end{lemma}
\begin{proof}
By \ref{orderingInitialSegments}. TODO superfluous?
\end{proof}
TODO: this is Dedekind / Yoneda principle??

\subsection{Intervals}
\begin{definition}
Let $n,m\in \N$. Then
\begin{itemize}
\item $n:m \defeq \interval[co]{n,m}$;
\item $:n \defeq 0:m$;
\item $n: \defeq \interval[co]{n,\infty} = \setbuilder{k\in \N}{k\geq n}$.
\end{itemize}
\end{definition}

\subsection{Enumerating pairs}
It will turn out to be useful to have a bijection
\[ \rho: \N\times \N \to \N. \]
We give two examples, the first due to GÃ¶del, the second due to Zermelo.
\begin{lemma} \label{pairEnumeration}
The functions
\[\rho_1 : \N\times\N \to \N: (m,n)\mapsto \frac{(m+n)(m+n+1)}{2}+m \]
and
\[ \rho_1 : \N\times\N \to \N: (m,n)\mapsto \begin{cases}
(m+1)^2-1 & (m=n) \\
n^2 + m & (m<n) \\
m^2+m+n & (m>n)
\end{cases} \]
are bijections.
\end{lemma}
TODO pictures!

TODO: Stern-Brocot -> all fractions listed in most simplified form without repeating

\section{Sequences }
TODO: lower!
\begin{definition}
A \udef{sequence} in a set $A$ is a function
\[ x:I\subseteq\N\to A. \]
The domain $I$ is called the \udef{index set}. It is usually well-ordered.

We usually write $x_i$ instead of $x(i)$ and we denote the function $x$ as $\seq{x_i}_{i\in I}$ (or $\seq{x_i}$ if the index is clear).

The set of all sequences in $A$ with domain $I$ is denoted $A^I$.

\begin{itemize}
\item If $u \subseteq v$, we say $u$ is a \udef{subsequence} of $v$.
\item If $u$ is a subsequence of $v$ and the index set of $u$ is downwards closed in the index set of $v$, then we call $u$ an \udef{initial segment} of $v$, denoted $u \initSeq v$.
\item If $u$ is a subsequence of $v$ and the index set of $u$ is upwards closed in the index set of $v$, then we call $u$ a \udef{tail} of $v$.
\end{itemize}
Note: often the notion of subsequence is generalised by allowing the index set of $u$ to be order-embedded in the index set of $v$.
\end{definition}
The choice of the index set is irrelevant up to a bijection. Thus which theorems hold depends on the cardinality of the index set (see later).


\subsection{Inverse and complementary sequences}
TODO: Hofstadter Figure-Figure sequence
\subsubsection{Inverse sequences}
\url{https://www.math.hkust.edu.hk/excalibur/v4_n1.pdf}
\url{https://www.jstor.org/stable/2308078}
\begin{definition}
Let $s:\N\to\N$ be a non-decreasing sequence of natural numbers.
\end{definition}


\subsection{Tuples}
\begin{definition}
Let $\{A,B,C \ldots \}$ be a finite set of classes and $a\in A, b\in B, c\in C \ldots$. We define
\begin{itemize}
\item $(a,b,c,\ldots) \defeq (a, (b,(c,\ldots)))$;
\item $A\times B\times C\times\ldots \defeq A\times(B\times (C\times \ldots))$.
\end{itemize}
\end{definition}
Clearly $(a,b,c,\ldots)\in A\times B\times C\times\ldots$.

TODO link tuples - finite sequences.

\subsubsection{Transposition of tuples}
\begin{definition}
Let $\mathcal{E}$ be the class of all elements and $x,X$ elements. Then we define the function $^\ttransp: \mathcal{E}\to \mathcal{E}$ recursively by
\[ x^\ttransp \defeq \begin{cases}
((a,c), (b,d)^t) & \exists a,b,c,d:\; x = ((a,b), (c,d)) \\
\setbuilder{p^\ttransp}{p\in x} & \text{$x$ is a set} \\
x & \text{$x$ is not of these forms.}
\end{cases} \]
\end{definition}
TODO: why valid recursion??
\begin{lemma}
Let $X$ be a set. Then
\[ X^\ttransp \defeq \begin{cases}
(A\times C) \times (B\times D)^t & \exists A,B,C,D:\; X = (A\times B)\times (C\times D) \\
x & \text{$x$ is not of this form.}
\end{cases} \]
\end{lemma}
\begin{proof}
TODO!
\end{proof}

\subsubsection{Tuples of functions}
\begin{definition}
Let $f: A\to B$ and $g: X\to Y$ be functions. Then the \udef{tuple function} of $f$ and $g$ is the function
\[ (f,g): A\times X \to G\times Y: (a,x) \mapsto (f(a), g(x)). \]

In particular if $f=g$, we say the tuple function is the \udef{pointwise application} of $f$. We write $f$ instead of $(f,f)$.
\end{definition}

TODO extend??

\subsubsection{Functions on finite sequences}
Let $f: A^{(m)}\to A^{(n)}$. We write
\[ f_k(a) = f(a)(k) \]
to denote the $k^\text{th}$ component of $f(a)$.