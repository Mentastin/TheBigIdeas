\chapter{Normed and Banach spaces}
In this chapter we will always use either $\mathbb{F} = \R$ or $\mathbb{F} = \C$.

\begin{definition}
\begin{itemize}
\item A \udef{normed space} is a vector space equipped with a norm.
\item A \udef{Banach space} is a normed vector space that is complete as a metric space.
\end{itemize}
\end{definition}

A finite-dimensional normed space is automatically a Banach by proposition \ref{finiteDimComplete}.

Every proper subspace $U$ of a normed vector space $V$ has empty interior.
A nice consequence of this is that any closed proper subspace is necessarily nowhere dense. So if V is a Banach space, the Baire category theorem implies that V cannot be a countable union of closed proper subspaces. In particular, an infinite dimensional Banach space cannot be a countable union of finite dimensional subspaces. This means, for example, that a vector space of countable dimension (e.g\ the space of polynomials) cannot be equipped with a complete norm.

The space $\Bounded(V,W)$ is a Banach space.


Complemented subspace problem: \url{https://arxiv.org/pdf/math/0501048v1.pdf}


TODO: \url{https://math.stackexchange.com/questions/2151779/normed-vector-spaces-over-finite-fields/2568231}

\section{Normed spaces}

\begin{lemma}
A subspace of a normed vector space is a normed space, with the norm given by the restriction of the norm in the larger space.
\end{lemma}

\begin{definition}
A vector with norm 1 is called a \udef{unit vector}. Unit vectors are often written with a hat:
\[ \norm{\vhat{v}} = 1. \]
\end{definition}

\subsection{Uniform norm}
\begin{lemma} \label{vectorSpaceUniformNorm}
Let $\sSet{V,\norm{\cdot}}$ be a normed vector space and $\sSet{X,d}$ a metric space. The uniform norm on $(X\to V)$ is a norm.
\end{lemma}
By \ref{groupUniformNorm}, the norm convergence of this norm is the uniform convergence. Note that this norm is \emph{not} the operator norm.
\begin{proof}
It is a group norm by \ref{groupUniformNorm}. We just need to show that it is positively homogeneous:
\[ \norm{\lambda f}_u = \sup_{x\in X}\norm{\lambda f(x)} = \sup_{x\in X}|\lambda|\norm{f(x)} = |\lambda|\sup_{x\in X}\norm{f(x)} = |\lambda|\norm{f}_u. \]
\end{proof}

\subsection{TODO from TVS theory}
\begin{proposition} \label{dualNormTopologyStrong}
Let $\sSet{V, \norm{\cdot}}$ be a normed space. The norm topology on $\dual{V}$ is equal to the strong topology $\beta(\dual{V}, V)$.
\end{proposition}
\begin{proof}
TODO!
\end{proof}

\begin{lemma} \label{polarOfBall}
Let $\sSet{V, \norm{\cdot}}$ be a normed space and $\epsilon >0$. Then $\cball_V(0,\epsilon)^\pol = \cball_{\dual{V}}(0,\epsilon)$.
\end{lemma}
\begin{proof}
We have
\begin{align*}
f\in \cball_V(0,\epsilon)^\pol &\iff \forall x\in \cball_V(0,\epsilon): \; \abspair{f,x} \leq 1 \\
&\iff \forall x\in \cball_V(0,1): \; \abspair{f,\epsilon^{-1}x} \leq 1 \\
&\iff \forall x\in \cball_V(0,1): \; \abspair{f,x} \leq \epsilon \\
&\iff \norm{f} \leq \epsilon \\
&\iff f\in \cball_{\dual{V}}(0,\epsilon).
\end{align*}
\end{proof}

\begin{proposition}
Let $\sSet{V, \norm{\cdot}}$ be a normed space. Then $\cball_{\dual{V}}(0, 1)$ is pointwise compact.
\end{proposition}
\begin{proof}
By \ref{polarOfBall} and \ref{alaogluTheorem}.
\end{proof}

\subsection{The topology of a normed space}
\begin{definition}
Let $\sSet{V,\norm{\cdot}}$ be a normed space. The initial vector space convergence w.r.t. the norm is called the \udef{norm convergence}.
\end{definition}
The norm convergence is topological TODO ref(!). Its topology is called the \udef{norm topology}.

\begin{example}
The norm convergence is \emph{not} the initial convergence w.r.t. to the norm.

In the initial convergence w.r.t. to the norm, all vectors of the same norm are indistinguishable, so this convergence space is not $T_0$.

On the other hand, $\{0\}$ is closed in $\R$ and thus its preimage $\{0\} \subset V$ is closed in the norm topology (TODO ref preimage closed is closed). By \ref{HausdorffCriterionConvergenceGroup}, we have that the norm convergence must be Hausdorff, or $T_2$.
\end{example}


\begin{proposition}
The norm convergence is topological and metric.

Every normed space can be viewed as a metric space with the metric $d:V\times V \to \interval[co]{0,\infty}$ given by
\[ d(x,y) = \norm{x-y}. \]
This metric has the properties of
\begin{itemize}[leftmargin=6cm]
\item[\textbf{Translation invariance}] $d(x+a, y+a) = d(x,y)$;
\item[\textbf{Scaling}] $d(\lambda x, \lambda y) = |\lambda|d(x,y)$.
\end{itemize}
Conversely, any metric with translation invariance and scaling determines a norm:
\[ \norm{x} = d(x,\vec{0}). \]
Passing from norm to metric back to norm, we recover the original norm.
\end{proposition}
\begin{lemma}
A linear map $L:V\to W$ between normed spaces is an isometry for the metric \textup{if and only if} it preserves the norm, i.e.\
\[ \forall v\in V: \quad \norm{v}_V = \norm{L(v)}_W. \]
\end{lemma}
\begin{proof}
Assume $L$ is an isometry, then
\[ \norm{v} = d(v,\vec{0}) = d(L(v),L(\vec{0})) = \norm{L(v) - L(\vec{0})} = \norm{L(v) - \vec{0}} = \norm{L(v)}. \]
Assume $L$ preserves the norm, then
\[ d(L(v_1), d(v_2)) = \norm{L(v_1)-L(v_2)} = \norm{L(v_1-v_2)} = \norm{v_1-v_2} = d(v_1,v_2). \]
\end{proof}

\begin{proposition}
Let $V$ be a normed vector space, then the norm $\norm{\cdot}:V\to \R$ is a continuous map.
\end{proposition}
\begin{proof}
The reverse triangle inequality, $|\norm{v}-\norm{w}| \leq \norm{v-w}$, implies that the norm is Lipschitz continuous with Lipschitz constant $1$, so we can use \ref{LipschitzcontinuousContinuous}.
\end{proof}

\subsubsection{Subsets of normed spaces}

\begin{lemma}
Every proper subspace $U$ of a normed vector space $V$ has empty interior.
\end{lemma}
\begin{proof}
Suppose $U$ has a non-empty interior. Then it contains some ball $B(u,\epsilon)$. Now every vector in $V$ can be translated and rescaled to fit inside the ball $B(u,\epsilon)$. Indeed let $v\in V$ and set $u' = u+ \frac{\epsilon}{2\norm{v}}v \in B(u,\epsilon)$. Then, since $U$ is a subspace $v = \frac{2\norm{v}}{\epsilon}(u'-u)\in U$. So $U=V$.
\end{proof}

\begin{lemma}[Riesz's lemma] \label{RieszsLemma}
Let $V$ be a normed vector space. Given a non-dense subspace $X$ and a number $\theta<1$, there exists a unit vector $v\in V$ such that
\[ \theta \leq d(X,v) = \inf_{x\in X}\norm{x-v}. \]
\end{lemma}
\begin{proof}
Take a vector $v_1$ not in the closure of $X$ and put $a = \inf_{x\in X}\norm{x-v_1}$. Then $a>0$ by lemma \ref{sequencesSupInf}. For $\epsilon > 0$, let $x_1\in X$ be such that $\norm{x_1+v_1}<a+\epsilon$. Then take
\[ v = \frac{v_1 - x_1}{\norm{v_1-x_1}} \qquad \text{so} \qquad \norm{v}=1. \]
And
\[ \inf_{x\in X}\norm{x-v} = \inf_{x\in X}\norm{x-\frac{v_1 - x_1}{\norm{v_1-x_1}}} = \inf_{x\in X}\norm{\frac{x-v_1 + x_1}{\norm{v_1-x_1}}} = \frac{\inf_{x\in X}\norm{x-v_1}}{\norm{v_1-x_1}} \geq \frac{a}{a+\epsilon}. \]
By choosing $\epsilon >0$ small, $a/(a+\epsilon)$ can be made arbitrarily close to $1$.
\end{proof}
For finite-dimensional spaces we can even take $\theta=1$.

\begin{lemma} \label{boundedSetNormedSpace}
Let $V$ be a normed space and $B\subseteq V$ a subset. Then the following are equivalent:
\begin{enumerate}
\item $B$ is bounded;
\item $B$ is vN bounded;
\item $B\subseteq \cball(0, M)$.
\end{enumerate}
\end{lemma}
\begin{proof}
Points (1) and (2) are equivalent by \ref{boundednessTVS}. To show the equivalence of (2) and (3) using \ref{vonNeumannBoundednessAbsorption}.

First assume $B$ is vN bounded. Then $B$ is absorbed by $\cball(0,1)$, so there exists $\epsilon > 0$ such that $\cball(0,\epsilon)\cdot B \subseteq \cball{0,1}$. This implies $B\subseteq \cball(0,1)\cdot B \subseteq \cball(0,\epsilon^{-1})$. Setting $M\defeq \epsilon^{-1}$ gives point (3).

Finally assume $B\subseteq \cball(0, M)$, so $M^{-1}B \subseteq \cball(0,1)$. Take an arbitrary neighbourhood $U$ of $0$. Then $\cball(0,\epsilon) \subseteq U$ for some $\epsilon > 0$. We have
\[ \cball(0, \epsilon M^{-1})\cdot B = \cball(0, \epsilon)\cdot M^{-1}B \subseteq \cball(0, \epsilon)\cdot \cball(0, 1) = \cball(0, \epsilon) \subseteq U. \]
Thus $B$ is absorbed by $U$.
\end{proof}

\subsubsection{Continuous operators}
\begin{theorem} \label{boundedLinearMaps}
Let $L$ be a linear operator between normed spaces $V,W$. The following are equivalent:
\begin{enumerate}
\item $L$ is continuous;
\item $L$ is continuous at $0$;
\item $L$ is uniformly continuous;
\item $L$ is Lipschitz continuous.
\end{enumerate}
\end{theorem}
\begin{proof}
The equivalences $(1) \Leftrightarrow (2) \Leftrightarrow (3)$ are given by \ref{uniformContinuityGroupHomomorphism}. The implication $(4)\Rightarrow (3)$ is given by \ref{LipschitzcontinuousContinuous}.

Finally we prove $(2)\Rightarrow (4)$. From continuity at zero, there exists a $\delta>0$ such that $\norm{L(h)} = \norm{L(h)-L(0)} \leq 1$ for all $h\in \dom(L)$ with $\norm{h}\leq \delta$. Thus for all nonzero $v\in \dom(L)$
\[ \norm{L(v)} = \norm{\frac{\norm{v}}{\delta}L(\delta \frac{v}{\norm{v}})} = \frac{\norm{v}}{\delta}\norm{L(\delta \frac{v}{\norm{v}})}\leq \frac{\norm{v}}{\delta}. \]
\end{proof}
\begin{corollary}
A linear operator $L:V\to W$ between normed spaces is a homeomorphism \textup{if and only if} there exists $C_1,C_2> 0$ such that
\[ \forall x\in V:\qquad C_1\norm{x}\leq \norm{L(x)} \leq C_2\norm{x}. \]
\end{corollary}

\begin{definition}
An operator $L$ between normed vector spaces is called \udef{bounded} if it is (Lipschitz) continuous.

The set of bounded operators from $V$ to $W$ is denoted $\Bounded(V,W)$. If $V=W$, we write $\Bounded(V)$.
\end{definition}
In other words, bounded means there exists an $M>0$ such that $\forall v\in \dom(L)$
\[ \norm{L(v)} \leq M \norm{v}. \]

\begin{proposition} \label{boundedAntiLinearMaps}
An anti-linear map between complex vector spaces is continuous \textup{if and only if} it is bounded.
\end{proposition}
\begin{proof}
An anti-linear map $A:V\to W$ is an $\R$-linear map $A:V_\R\to W_\R$. Now $V_\R, W_\R$ have the same norms as $V,W$ and thus the same topology. So $A:V\to W$ is continuous if and only if $A:V_\R\to W_\R$ is continuous.
\end{proof}


\subsubsection{Equicontinuity}
\begin{proposition}
Let $X,Y$ be normed space and $K\subseteq \contLin(X,Y)$. Then $K$ is equicontinuous \textup{if and only if} $\sup_{T\in K}\norm{T} < \infty$.
\end{proposition}
\begin{proof}
By \ref{equicontinuityGroupHomomorphisms} we have that the equicontinuity of $K$ is equivalent to
\begin{align*}
\upset \evalMap^{\imf\imf}\big(\{K\}\otimes \neighbourhood_{X}(0)\big) \to 0 &\iff \upset \evalMap^{\imf\imf}\big(\{K\}\otimes \{\cball_X(0,\epsilon)\}_{\epsilon > 0}\big) \to 0 \\
&\iff \upset \evalMap^{\imf\imf}\big(\{K\}\otimes \{\cball_X(0,1)\}\big)\cdot \{\cball_{\R}(0,\epsilon)\}_{\epsilon > 0} \to 0 \\
&\iff \text{$\evalMap^{\imf}\big(K\times \cball_X(0,1)\big)$ is vN bounded} \\
&\iff \exists M\geq 0: \; \sup_{\substack{T\in K \\ x\in \cball_X(0,1)}} \norm{Tx} \leq M \\
&\iff \exists M\geq 0: \; \sup_{T\in K} \norm{T} \leq M \\
&\iff \sup_{T\in K} \norm{T} < \infty,
\end{align*}
where we have used \ref{boundedSetNormedSpace}.
\end{proof}


\subsubsection{Comparison of norm topologies}
\begin{definition}
Let $V$ be a vector space and $\norm{\cdot}_1$, $\norm{\cdot}_2$ two norms on $V$. We say
\begin{itemize}
\item $\norm{\cdot}_1$ is \udef{bounded} by $\norm{\cdot}_2$ if there exists $C\in \R$ such that $\forall v\in V: \norm{v}_1 \leq C\norm{v}_2$;
\item $\norm{\cdot}_1$ and $\norm{\cdot}_2$ are \udef{equivalent} if each is bounded by the other.
\end{itemize}
\end{definition}

\begin{lemma}
Let $V$ be a vector space and $\norm{\cdot}_1$, $\norm{\cdot}_2$ two norms on $V$. These norms are equivalent \textup{if and only if} there exists a $C>0$ such that
\[ \frac{1}{C}\norm{\cdot}_1 \leq \norm{\cdot}_2 \leq C\norm{\cdot}_1. \]
\end{lemma}

\begin{proposition} \label{normComparison}
Let $V$ be a vector space and $\norm{\cdot}_1$, $\norm{\cdot}_2$ two norms on $V$. Then the following are equivalent:
\begin{enumerate}
\item $\norm{\cdot}_2$ is bounded by $\norm{\cdot}_1$;
\item $\id_V: \sSet{V,\norm{\cdot}_1} \to \sSet{V,\norm{\cdot}_2}$ is uniformly continuous;
\item the norm topology of $\norm{\cdot}_1$ is finer than the norm topology of $\norm{\cdot}_2$.
\end{enumerate}
\end{proposition}
\begin{proof}
$(1) \Leftrightarrow (2)$ By \ref{boundedLinearMaps} both are equivalent to
\[ \exists C>0: \forall v\in V: \qquad \norm{v}_2 = \norm{\id_V((v))}_2 \leq C\norm{v}_1. \]

$(2) \Leftrightarrow (3)$ Follows straight from \ref{identityContinuity}.
\end{proof}
\begin{corollary}
Equivalent norms induce the same topology.
\end{corollary}

\subsection{Properties of balls}
\begin{lemma} \label{ballAdherenceInherence}
Let $V$ be a normed vector space over $\F$. Then
\begin{enumerate}
\item $\ball(0,1)$ is $\mathfrak{a}$-open;
\item $\cball(0,1)$ is $\mathfrak{a}$-closed;
\item $\inh_\mathfrak{a}\big(\cball(0,1)\big) = \ball(0,1)$;
\item $\adh_\mathfrak{a}\big(\ball(0,1)\big) = \cball(0,1)$.
\end{enumerate}
\end{lemma}
\begin{proof}
(1,2) Since $\ball(0,1)$ is open and $\cball(0,1)$ is closed, \ref{metricConvergenceNeighbourhood}, and $\mathfrak{a}$ is stronger than the metric convergence, by \ref{algebraicConvergenceStrongerThanVectorConvergence}, the results follow from \ref{openClosedConvergenceInclusions}.

(3) First note that
\[ \ball(0,1) = \interior_{\norm{\cdot}}\big(\ball(0,1)) \subseteq \interior_{\norm{\cdot}}\big(\cball(0,1)) \subseteq \inh_{\mathfrak{a}}\big(\cball(0,1)), \]
by \ref{interleavedAdherenceInherenceInclusion} and \ref{principalInherenceAdherenceProperties} (since $\mathfrak{a}$ is stronger than the norm convergence).

For the converse, take $x\in \inh_{\mathfrak{a}}\big(\cball(0,1))$. Then, by \ref{constructionsInAlgebraicConvergence} (and since $x\in V$), there exists $\Gamma\in \neighbourhood_{\F}(0)$ such that $x+ \Gamma\cdot x \subseteq \cball(0,1)$. Then there exists $\epsilon >0$ such that $\ball_\F(0,\epsilon) \subseteq \Gamma$. This implies that
\[ (1+ \epsilon/2)x = x + \frac{\epsilon}{2} x \in x+ \Gamma\cdot x \subseteq \cball(0,1), \]
so $(1+\epsilon/2)\norm{x} \leq 1$ and thus $\norm{x} \leq \frac{1}{1+\epsilon / 2} < 1$, which implies $x\in \ball(0,1)$.

(4) As before, we have
\[ \cball(0,1) = \closure_{\norm{\cdot}}\big(\cball(0,1)\big) \supseteq \closure_{\norm{\cdot}}\big(\ball(0,1)\big) \supseteq \adh_{\mathfrak{a}}\big(\ball(0,1)\big), \]
by \ref{interleavedAdherenceInherenceInclusion} and \ref{principalInherenceAdherenceProperties}.

For the converse, take $x\in \cball(0,1)$. We aim to show $x\in \adh_\mathfrak{a}\big(\ball(0,1)\big)$ using \ref{constructionsInAlgebraicConvergence}. To that end, set $v = x$ and take an arbitrary $\Gamma\in \neighbourhood_\F(0)$. Then there exists $0<\epsilon <2$ such that $\ball_\F(0,\epsilon) \subseteq \Gamma$. Then $(1-\epsilon /2)x \in x + \Gamma\cdot x$ and
\[ \norm{\Big(1-\frac{\epsilon}{2}\Big)x} = \Big(1-\frac{\epsilon}{2}\Big)\norm{x} \leq 1-\frac{\epsilon}{2} < 1, \]
so $(1-\epsilon /2)x\in \ball(0,1)$. Thus $\big(x + \Gamma\cdot x\big)\mesh \ball(0,1)$.
\end{proof}

\begin{lemma} \label{extremePointsUnitBall}
Let $V$ be a real or complex normed vector space. Then
\begin{enumerate}
\item $\ext\big(\ball(0,1)\big) = \emptyset$;
\item $\ext\big(\cball(0,1)\big) \subseteq \cball(0,1)\setminus \ball(0,1)$.
\end{enumerate}
\end{lemma}
\begin{proof}
(1) Take arbitrary $x\in \ball(0,1)$. Then $\norm{x}< 1$, so we have $0 < \frac{1}{2} + \frac{\norm{x}}{2} < 1$ and $-\frac{1}{2} \leq \frac{3}{2}\norm{x} - \frac{1}{2} < \frac{3}{2} - \frac{1}{2} = 1$. Set $a \defeq \big(\frac{1}{2} + \frac{\norm{x}}{2}\big) \frac{x}{\norm{x}}$ and $b \defeq \big(\frac{3}{2}\norm{x} - \frac{1}{2}\big)\frac{x}{\norm{x}}$. Then $a,b\in\ball(0,1)$, $a\neq x$ and
\[ \frac{1}{2}(a+b) = \frac{1}{2}\bigg(\Big(\frac{1}{2} + \frac{1}{2}\norm{x}\Big)\frac{x}{\norm{x}} + \Big(\frac{3}{2}\norm{x} - \frac{1}{2}\Big)\frac{x}{\norm{x}}\bigg) = \frac{1}{2}\Big(\frac{4}{2}\norm{x}\frac{x}{\norm{x}}\Big) = x, \]
so $x\notin \ext\big(\ball(0,1)\big)$ by \ref{notExtremePointLemma}.

(2) This follows immediately from (1) and \ref{extremePointsSubset}.
\end{proof}

\begin{lemma} \label{strictConvexityUnitBall}
Let $V$ be a real normed vector space. Then the following are equivalent:
\begin{enumerate}
\item $\cball(0,1)$ is strictly convex;
\item $\cball(0,1)\setminus\ball(0,1) \subseteq \ext\big(\cball(0,1)\big)$;
\item $\cball(0,1)\setminus\ball(0,1) = \ext\big(\cball(0,1)\big)$;
\item $\norm{x+y} = \norm{x}+\norm{y}$ implies $\exists \lambda \geq 0: x = \lambda y$ for all $x,y \in V$;
\item $\norm{rx+(1-r)y}< 1$ for all $x\neq y\in \cball(0,1)$ and $0< r < 1$;
\item $\norm{x+y}< 2$ for all $x\neq y\in \cball(0,1)$.
\end{enumerate}
\end{lemma}
\begin{proof}
$(1) \Leftrightarrow (2)$ Immediate from \ref{strictConvexityEquivalentsConvexSubset} and \ref{ballAdherenceInherence}.

$(2) \Rightarrow (3)$ Immediate from \ref{extremePointsUnitBall}.

$(3) \Rightarrow (4)$ Suppose $x,y\in V$ are such that $\norm{x+y} = \norm{x} + \norm{y}$. WLOG we may assume $\norm{x}\leq \norm{y}$. Then
\begin{align*}
2 &\geq \norm{\frac{x}{\norm{x}} + \frac{y}{\norm{y}}} \\
&= \frac{1}{\norm{x}}\norm{x + \frac{\norm{x}}{\norm{y}}y} \\
&= \frac{1}{\norm{x}}\norm{x + y - \Big(1-\frac{\norm{x}}{\norm{y}}\Big)y} \\
&\geq \frac{1}{\norm{x}}\bigg|\norm{x + y} - \Big(1-\frac{\norm{x}}{\norm{y}}\Big)\norm{y}\bigg| \\
&= \frac{1}{\norm{x}}\bigg|\norm{x} + \norm{y} - \big(\norm{y}- \norm{x}\big)\bigg| \\
&= \frac{1}{\norm{x}}2\norm{x} = 2,
\end{align*}
so $\norm{\frac{1}{2}\big(\frac{x}{\norm{x}} + \frac{y}{\norm{y}}\big)} = 1$, which means that $\frac{1}{2}\big(\frac{x}{\norm{x}} + \frac{y}{\norm{y}}\big) \in \cball(0,1)\setminus\ball(0,1) = \ext\big(\cball(0,1)\big)$. Since $\frac{x}{\norm{x}}, \frac{y}{\norm{y}}\in\cball(0,1)$, we must have $\frac{x}{\norm{x}} = \frac{y}{\norm{y}}$ by \ref{notExtremePointLemma}. Thus $x = \frac{\norm{x}}{\norm{y}}y$.

$(4) \Rightarrow (5)$ Take arbitrary $x,y\in \cball(0,1)$ and $0<r<1$. By the triangle inequality we have
\[ \norm{rx + (1-r)y} \leq r\norm{x} + (1-r)\norm{y} \leq 1. \]
If either $\norm{x}<1$ or $\norm{y}<1$ we are done.

Now suppose $\norm{x} = 1 \norm{y}$. Suppose, towards a contradiction, that $\norm{rx+(1-r)y} = 1 = \norm{rx} + \norm{(1-r)y}$. Then, by assumption, $rx = \lambda (1-r) y$. Taking norms gives $r = r\norm{x} = \lambda (1-r)\norm{y} = \lambda (1-r)$, so $\lambda = \frac{r}{1-r}$ and $x = \lambda \frac{1-r}{r}y = y$, which contradicts the assumption $x\neq y$.

$(5) \Rightarrow (6)$ Set $r = \frac{1}{2}$.

$(6) \Rightarrow (2)$ Take $x\in \cball(0,1)\setminus \ball(0,1)$. Suppose, towards a contradiction, that $x\notin \ext\big(\cball(0,1)\big)$. Then $x = frac{a+b}{2}$ for some $a\neq b\in \cball(0,1)$, by \ref{notExtremePointLemma}. By assumption $\norm{x} = \frac{1}{2}\norm{a+b} < 1$, so $x\notin \cball(0,1)$. This is a contradiction.
\end{proof}

\begin{example}
The unit ball of an inner product space is strictly convex, since, by the parallelogram law, we have
\[ \norm{v+w}^2 = 2\big(\norm{v}^2 + \norm{w}^2\big) - \norm{v-w}^2 \leq 4 - \norm{v-w}^2 < 4 \]
and so $\norm{v+w} <2$ for all $v\neq w \in \cball(0,1)$.
\end{example}

\subsection{Linear independence and bases in normed spaces}
\url{https://math.stackexchange.com/questions/1518029/are-uncountable-schauder-like-bases-studied-used}

\subsection{Finite-dimensional normed (sub)spaces}

\begin{lemma} \label{coordinateContinuity}
Let $V$ be a normed vector space and $\{x_1, \ldots, x_n\}$ a linearly independent set of vectors. There exists a $c>0$ such that $\forall \alpha_1,\ldots, \alpha_n \in \mathbb{F}$:
\[ \norm{\alpha_1x_1 + \ldots + \alpha_nx_n} \geq c(|\alpha_1|+\ldots+|\alpha_n|) . \]
\end{lemma}
\begin{proof}
TODO ref locally convex spaces? Local compactness?
\end{proof}
TODO This is equivalent with continuity of coordinate functions.

\begin{proposition} \label{finiteDimComplete}
Every finite-dimensional subspace of a normed vector space is complete.
\end{proposition}
\begin{proof}
Take a basis $\{e_i\}_{i=1}^n$ and let $c$ be as in lemma \ref{coordinateContinuity}. Consider an arbitrary Cauchy sequence $(v_k)_{k\in\N}$. We can write
\[ v_k = \alpha_{k,1}e_1 + \ldots + \alpha_{k,n}e_n. \]
We claim that $(\alpha_{k,i})_{k\in\N}$ is Cauchy in $\mathbb{F}$ for all $1\leq i\leq n$. Indeed, take an $\epsilon>0$. By the Cauchy nature of $(v_k)_{k\in\N}$ we can find a $k_0$ such that $\forall k', k''>k_0:$
\[ c\epsilon > \norm{v_{k'} - v_{k''}} \geq \norm{\sum_{i=1}^n (\alpha_{k',i}-\alpha_{k'',i})e_i}\geq c\sum_{i=1}^n |\alpha_{k',i}-\alpha_{k'',i}| \geq c |\alpha_{k',i}-\alpha_{k'',i}|. \]
Dividing left and right by $c$ gives exactly the Cauchy condition for each $1\leq i\leq n$. By the completeness of $\R$ or $\C$, each of these sequences has a limit $\alpha_i$.
Then $v= \sum_{i=1}^n\alpha_ie_i$ is an element of the subspace. The sequence $(v_k)$ converges to $v$ because
\[ \norm{v_k-v} = \norm{\sum_{i=1}^n (\alpha_{k,i}-\alpha_i)e_i} \leq \sum_{i=1}^n |\alpha_{k,i}-\alpha_i|\norm{e_i} \]
and the right-hand side goes to zero as $k\to \infty$.
\end{proof}
\begin{corollary} \label{finiteDimClosed}
Every finite-dimensional subspace of a normed vector space is closed.
\end{corollary}
TODO ref for proof.

\begin{proposition}
On a finite-dimensional vector space all norms are equivalent.
\end{proposition}
\begin{proof}
Let $\{e_i\}_{i=1}^n$ be a basis and take an arbitrary vector $v = \sum_{i=1}^nv_ie_i$. Let $\norm{\cdot}_1$ and $\norm{\cdot}_2$ be two norms.
We calculate
\[ \norm{v}_1 \leq \sum_{i=1}^n|v_i|\norm{e_i}_1 \leq k\sum_{i=1}^n|v_i| \leq \frac{k}{c_2}\norm{v}_2 \]
where the first inequality is the triangle inequality, the second comes from $k=\max\norm{e_i}_1$ and the third is lemma \ref{coordinateContinuity}. A similar calculation gives the other necessary inequality.
\end{proof}

\begin{proposition}
In a finite-dimensional normed space $V$, any subset $M \subseteq V$ is compact if and only if $M$ is closed and bounded.
\end{proposition}
\begin{proof}
TODO + ref Heine Borel property
\end{proof}


TODO: move up?
\begin{proposition} \label{compactnessUnitBall}
The closed unit ball of a vector space is compact \textup{if and only if} the vector space is finite-dimensional.
\end{proposition}
\begin{proof}
One direction is given by the previous proposition. For the other direction, we show the contrapositive: let the vector space be infinite-dimensional.
We define a sequence of unit vectors $(e_i)_{i\in\N}$ recursively as follows:
\begin{itemize}
\item $e_1$ is just a unit vector;
\item for $e_{n+1}$ apply Riesz's lemma \ref{RieszsLemma} to the subspace $\Span\{e_i\}_{i=1}^n$ and $\theta = 1/2$. This subspace cannot be dense, because it is a closed (by corollary \ref{finiteDimClosed}) finite-dimensional subspace of an infinite-dimensional vector space.
\end{itemize}
This yields a sequence such that for all $m,n$
\[ \norm{e_m - e_n}\geq \frac{1}{2}. \]
This sequence is not Cauchy and thus not convergent.
\end{proof}





\section{Bounded operators}
Bounded operators are Lipschitz continuous operators.

An operator between normed spaces is bounded iff it is continuous, see \ref{boundedLinearMaps}.

\begin{lemma}
Let $V,W$ be normed spaces and $T:V\to W$ a linear operator. Then $T$ is bounded \textup{if and only if} $T^{\preimf}[\ball(\vec{0},1)]$ has non-empty interior.
\end{lemma}
\begin{proof}
Assume $T$ is bounded, then $\ball(\vec{0}, \norm{T}^{-1}) \subseteq T^{\preimf}[\ball(\vec{0},1)]$, indeed for all $v\in \ball(\vec{0}, \norm{T}^{-1})$ we have
\[ \norm{Tv} \leq \norm{T}\;\norm{v} < \norm{T}\;\norm{T}^{-1} = 1.  \]
As $\ball(\vec{0}, \norm{T}^{-1})$ is open, it is contained in the interior, which is thus non-empty.

Now assume $T^{\preimf}[\ball(\vec{0},1)]$ has non-empty interior, then we can pick some $x$ in the interior and $T^{-\preimf}[\ball(\vec{0},1)]$ is a neighbourhood of $x$. Then we have that
\[ T^{\preimf}[\ball(\vec{0},1)] - x = T^{\preimf}[\ball(\vec{0},1)- T(x)] \]
is a neighbourhood of $0$. Now $T$ is bounded on $T^{\preimf}[\ball(\vec{0},1)- T(x)]$, so it is continuous by \ref{boundedOnVicinityImpliesContinuous}.
\end{proof}

\begin{lemma} \label{kerClosed}
Let $T$ be a bounded linear operator. Then $\ker(T)$ is closed.
\end{lemma}
\begin{proof}
Suppose $T$ bounded and thus continuous. Then $\ker L = L^{-1}[\{0\}]$ and thus closed, by proposition \ref{continuity}.
\end{proof}
\begin{proof}
Let $v\in \overline{\ker(T)}$. Then find a sequence $(v_n)$ in $\ker(T)$ that converges to $v$. Then by continuity $(Tv_n)$ converges to $Tv$, but for all $n\in\N: Tx_n = 0$, so the limit is $Tv=0$. Thus $v\in\ker(T)$, making it closed.
\end{proof}

\begin{proposition}\label{continuousMapCriterion}
Let $L:V\to W$ be a linear map between normed spaces.
\begin{enumerate}
\item If $V$ is finite-dimensional, then $L$ is continuous.
\item If $W$ is finite-dimensional, then $L$ is continuous \textup{if and only if} $\ker L$ is closed.
\end{enumerate}
\end{proposition}
TODO: true for general TVS
\begin{proof}
\begin{enumerate}
\item This follows from a consideration of the graph norm $\norm{v}_L = \norm{v}+\norm{Lv}$ and the fact that on a finite-dimensional space any two norms are equivalent: for all $v$ we can choose an $M$ such that
\[ \norm{Lv}\leq \norm{v}_L \leq M\norm{v}. \]
\item Assume $W$ finite-dimensional. Consider the map $\bar{L}:V/\ker L\to W: v+\ker{L}\mapsto L(v)$, defined in proposition \ref{splittingMap}. Then $V/\ker L$ is isomorphic to a subspace of $W$ and thus is finite-dimensional. By the first point, $\bar{L}$ must be continuous. Let $\pi: V\to V/\ker L$ denote the quotient map, which is continuous (TODO is this where closure of $\ker L$ is used?). Then $L = \bar{L}\circ \pi$ is a composition of continuous maps and thus continuous.

Conversely, we have the lemma \ref{kerClosed}.
\end{enumerate}
\end{proof}

\begin{example}
Let $\seq{e_n}$ be a basis of unit vectors of an infinite dimensional real vector space. Then consider the map $e_n\mapsto n$ and extend by linearity. This is an unbounded linear operator with finite dimensional codomain.
\end{example}


\subsection{The algebra of bounded operators}
\begin{lemma} \label{existenceOperatorNorm}
Let $(V,\norm{\cdot}_V)$ and $(W,\norm{\cdot}_W)$ be normed spaces and $L\in\Lin(V, W)$. Then $L$ is bounded \textup{if and only if}
\[ \sup\setbuilder{\frac{\norm{Lx}_W}{\norm{x}_V}}{x\in V\setminus\{0\}} \] 
is finite.
\end{lemma}
\begin{definition}
Let $(V,\norm{\cdot}_V)$ and $(W,\norm{\cdot}_W)$ be normed spaces and $L\in\Lin(V, W)$ bounded. Then
\[ \norm{L} \defeq \sup\setbuilder{\frac{\norm{Lx}_W}{\norm{x}_V}}{x\in V\setminus\{0\}} \]
is called the \udef{operator norm} of $L$.
\end{definition}

\begin{proposition} \label{operatorNorm}
Let $L\in\Bounded(V,W)$ be a bounded operator and let $B(\vec{0},\epsilon)$ be an open ball centered at $\vec{0}$. Then
\begin{align*}
\norm{L} &= \frac{\sup L[B(\vec{0},\epsilon)]}{\epsilon} \\
&= \frac{\sup L[\overline{B}(\vec{0},\epsilon)]}{\epsilon} \\
&= \sup\setbuilder{\norm{Lx}}{\norm{x} = 1}.
\end{align*}
\end{proposition}
\begin{proof}
TODO
\end{proof}

\begin{proposition} \label{operatorNormIsNorm}
Let $S,T$ be compatible bounded operators. Then
\begin{enumerate}
\item $\norm{\lambda S} = |\lambda|\;\norm{S}$ for all $\lambda\in \F$;
\item $\norm{S+T} \leq \norm{S}+\norm{T}$;
\item $\norm{ST} \leq \norm{S}\norm{T}$.
\end{enumerate}
\end{proposition}
\begin{proof}
(1) We calculate
\[ \norm{\lambda S} = \sup_{\norm{x}=1}\norm{\lambda Sx} = \sup_{\norm{x}=1}|\lambda|\; \norm{Sx} = |\lambda| \sup_{\norm{x}=1}\norm{Sx} = |\lambda| \norm{S}. \]

(2) We calculate
\[ \norm{S+T} = \sup_{\norm{x}=1}\norm{Sx+Tx} \leq \sup_{\norm{x}=1}\big(\norm{Sx}+\norm{Tx}\big)\leq \sup_{\norm{x}=1}\big(\norm{S} + \norm{Tx}\big) = \norm{S} + \norm{T}. \]

(3) We calculate
\[ \norm{ST} = \sup_{\norm{x}=1}\norm{STx} \leq \sup_{\norm{x}=1}\big(\norm{S}\;\norm{Tx}\big) = \norm{S}\;\norm{T}. \]
\end{proof}
\begin{corollary} \label{BoundedSpace}
Let $(V,\norm{\cdot}_V)$ and $(W,\norm{\cdot}_W)$ be normed spaces. Then the set $\Bounded(V,W)$ of bounded linear maps is a normed subspace of $\Lin(V,W)$ when equipped with the operator norm.
\end{corollary}
\begin{proof}
By \ref{linearMapsVectorSpace}, $\Lin(V,W)$ is a vector space. Closure under addition and scalar multiplication follows from the proposition and \ref{operatorNorm}.

The proposition also immediately gives that the operator norm is a seminorm.

To show that it is in fact a norm, we just need to show that it is point-separating. Assume $S\in\Bounded(V,W)$ is such that $\norm{S} = 0$. Then $\sup_{\norm{x}=1}\norm{Sx} = 0$, which implies that $\norm{Sx} = 0$ for all unit vectors. Because the norm on $W$ is point-separating, this means that $Sx = 0$ for all unit vectors. Now for arbitrary $v\in V$, we have $Sv = \norm{v}\cdot S\left(\frac{v}{\norm{v}}\right) =\norm{v} \cdot 0 = 0$. Thus $S = 0$.
\end{proof}

\begin{lemma} \label{normCauchyPointwiseConvergentImpliesNormConvergent}
Let $V,W$ be normed spaces and $\seq{T_n}\in\Bounded(V,W)^\N$. If $\seq{T_n}$ is norm-Cauchy and pointwise convergent, then $\seq{T_n}$ is norm-convergent.
\end{lemma}
\begin{proof}
Let $T_n\overset{\text{ptwise}}{\longrightarrow} T$. Fix $\epsilon > 0$. Then there exists $N$ such that $\norm{T_m-T_n}\leq \epsilon$ for all $m,n\geq N$. Take arbitrary $v\in \cball_V(0,1)$. Then
\begin{align*}
\norm{(T-T_n)(v)} &= \norm{Tv - T_nv} \\
&= \lim_{m\to\infty}\norm{T_mv-T_nv} \\
&= \lim_{m\to\infty}\norm{(T_m-T_n)v} \\
&= \limsup_{m\to\infty}\norm{(T_m-T_n)v} \\
&\leq \sup_{m\geq N}\norm{(T_m-T_n)v} \\
&\leq \sup_{m\geq N}\norm{T_m-T_n} \\
&\leq \epsilon.
\end{align*}
Since $v\in \cball_V(0,1)$ was taken arbitrarily, we have $\norm{T-T_n} \leq \epsilon$. We conclude that $\seq{T_n}$ converges to $T$ is norm.
\end{proof}

\begin{proposition} \label{boundedOperatorsFormBanachSpace}
Let $X$ be a Banach space and $Y$ a normed space. Then
\begin{enumerate}
\item if $Y$ is complete, then $\Bounded(X,Y)$ is complete;
\item if $X\neq \{0\}$ and $\Bounded(X,Y)$ is complete, then $Y$ is complete.
\end{enumerate}
\end{proposition}
Thus, supposing $V$ is non-trivial, $\Bounded(V,W)$ is a Banach space \textup{if and only if} $W$ is a Banach space.
\begin{proof}
(1) Since $(X,Y)$ is a Banach-Steinhaus pair and $Y$ is complete (and thus quasi-complete), we can use \ref{quasiCompletenessFunctionSpaces} to conclude that $\contLin_p(X,Y)$ is quasi-complete and thus sequentially compelete by \ref{quasiCompleteImpliesSequentiallyComplete}.

Since $\Bounded(X,Y)$ is sequential, it is enough to show that it is sequentially complete, by (TODO ref!).

Now let $\seq{T_n}$ be a Cauchy sequence in $\Bounded(X,Y)$. Then it is a Cauchy sequence in  $\contLin_p(X,Y)$, which means it has a pointwise limit by sequential completeness. By \ref{normCauchyPointwiseConvergentImpliesNormConvergent} this pointwise limit is also a norm-limit.

(2) TODO ???
\end{proof}



\begin{proposition}[Bounded linear extension] \label{BLT}
Let $T:\dom(T)\subseteq X\to Y$ be a bounded operator between normed spaces. Then $T$ has a unique extension
\[ \widetilde{T}:\overline{\dom(T)}\to Y \]
where $\widetilde{T}$ is a bounded operator with $\norm*{\widetilde{T}} = \norm{T}$.
\end{proposition}
\begin{proof}
Normed vector spaces have the unique extension property because they are Hausdorff, \ref{uniqueExtensionHausdorff}. We just need to show the norm stays the same:

Clearly $\norm*{\tilde{T}} \geq \norm{T}$. For the converse take any $x\in X$. As $\overline{\dom(T)} = X$, there exists a sequence $\seq{x_i}\subset \dom(T)$ that converges to $x$. Then
\[ \norm*{\tilde{T}(x)}_Y = \norm{T\left(\lim_{i\to\infty}x_i\right)}_Y = \lim_{i\to\infty}\norm{T(x_i)}_Y \leq \lim_{i\to\infty}\norm{T}\;\norm{x_i}_X = \norm{T}\;\norm{x}_X. \]
\end{proof}


\subsubsection{The dual space}
\begin{lemma}
Let $X$ be a normed space and $Z\subset X$ a subspace. Any bounded linear functional in $\dual{Z}$ can be extended to a bounded linear functional in $\dual{X}$ with the same norm.
\end{lemma}
\begin{proof}
Let $f:Z\to \mathbb{F}$ be such a functional. Extend $f$ with the Hahn-Banach theorem \ref{seminormHahnBanach}, using $p(x) = \norm{f}_Z\norm{x}$.
\end{proof}
\begin{corollary} \label{existenceBoundedFunctionalOfSameNorm}
Let $X$ be a normed space and $x_0\neq 0$ an element of $X$. Then there exists a bounded linear functional $\omega_{x_0}$ such that
\[ \norm{\omega_{x_0}} = 1 \qquad \text{and} \qquad \omega_{x_0}(x_0)=\norm{x_0}. \]
\end{corollary}
\begin{proof}
Extend the functional $f: \Span\{x_0\}\to \mathbb{F}$ defined by
\[ f(x) = f(ax_0) = a\norm{x_0}. \]
\end{proof}
\begin{corollary} \label{normFromContinuousFunctionals}
Let $X$ be a normed space. Then $\forall x\in X:$
\[ \norm{x} = \sup_{\substack{f\in \dual{X} \\ f\neq 0}}\frac{|f(x)|}{\norm{f}} = \sup_{\substack{f\in \dual{X} \\ \norm{f} = 1}}|f(x)| = \sup_{\substack{f\in \dual{X} \\ 0< \norm{f} \leq 1}}|f(x)|. \]
\end{corollary}
\begin{proof}
We calculate
\[ \norm{x} \geq \sup_{\substack{f\in X' \\ f\neq 0}}\frac{|f(x)|}{\norm{f}} \geq \frac{|\omega_{x}(x)|}{\norm{\omega_{x}}} = \frac{\norm{x}}{1} = \norm{x} \]
where the first inequality follows from $|f(x)|\leq \norm{f}\norm{x}$ for all $f\in \dual{X}, x\in X$. The other two equalities follow because a maximum is reached by a norm-one functional.
\end{proof}
\begin{corollary} \label{uniformConvergenceWeakTopologyGivesNormTopology}
Let $X$ be a normed space, $\seq{x_i}_{i\in I} \in X^I$ and $x \in X$. Then $f(x_i) \to f(x)$ uniformly for $f\in\dual{X}$ with $\norm{f} = 1$ \textup{if and only if} $x_i \to x$ in the norm topology.
\end{corollary}
\begin{proof}
We have that
\[ \forall \epsilon > 0: \exists I_0\in I: \forall i\geq I_0: \forall \norm{f} = 1: \; |f(x_i-x)| \leq \epsilon \]
is equivalent to
\[ \forall \epsilon > 0: \exists I_0\in I: \forall i\geq I_0: \; \norm{x_i-x} = \sup_{\norm{f}=1} |f(x_i-x)| \leq \epsilon. \]
\end{proof}

\begin{lemma} \label{dualNormedSpaceBanach}
Let $X$ be a normed space. Then $\dual{X}$ is a Banach space.
\end{lemma}
\begin{proof}
The completeness of $\dual{X}$ follows from the completeness of $\F$ by \ref{boundedOperatorsFormBanachSpace}.
\end{proof}

\subsubsection{The bidual}

\begin{proposition} \label{canonicalIsometryIsometry}
Let $X$ be a normed space. Then function
\[ \evalMap_-: X\mapsto \bidual{X}: x\mapsto \evalMap_x|_{\dual{X}} \]
is an isometry.
\end{proposition}
\begin{proof}
We calculate
\[ \norm{\evalMap_x} = \sup_{f\in \dual{X}\setminus\{0\}} \frac{\norm{\evalMap_x(f)}}{\norm{f}} = \sup_{f\in \dual{X}\setminus\{0\}} \frac{\norm{f(x)}}{\norm{f}} = \norm{x}, \]
where we have used the definition of the norm in $\bidual{X}$ and \ref{normFromContinuousFunctionals}.
\end{proof}
\begin{corollary} \label{normedReflexiveIFFSemireflexive}
A normed space is reflexive \textup{if and only if} it is semi-reflexive.
\end{corollary}
\begin{proof}
The direction $\Rightarrow$ is immediate, for the direction $\Leftarrow$, we just need to observe that $\evalMap_-: X\mapsto \bidual{X}$ is an embedding, since it is an isometry (\ref{isometryLemma}).
\end{proof}

\subsubsection{Reflexive normed space}
\begin{proposition}
Let $X$ be a reflexive normed space. Then $X$ is a Banach space.
\end{proposition}
\begin{proof}
This follows from $X\cong \bidual{X}$ and \ref{dualNormedSpaceBanach}.
\end{proof}

\begin{lemma}
Let $X$ be a reflexive Banach space. Then $\evalMap_-: \sSet{X,\sigma} \to \contLin(\dual{X}, \F)_p$ is a homeomorphism.
\end{lemma}
\begin{proof}
TODO immediate from $f = \evalMap_f\circ \evalMap_-$ for all $f\in \dual{X}$ and the fact that $\evalMap_-$ is a linear homeomorphism.
\end{proof}
\begin{corollary} \label{ReflexiveBanachSpaceWeaklyQuasiComplete}
Let $X$ be a reflexive Banach space. Then $\sSet{X,\sigma}$ is quasi-complete.
\end{corollary}
\begin{proof}
Since $\evalMap_-$ is linear, it is also uniformly continuous. TODO
\end{proof}

\begin{example}
Banach space that is not weakly sequentially complete: \url{https://math.stackexchange.com/questions/866650/c0-1-is-not-weakly-sequentially-complete}. See also \url{https://arxiv.org/pdf/1602.04718.pdf}.
\end{example}

\subsubsection{Adjoints}
\begin{proposition} \label{adjointMapIsometric}
Let $X,Y$ be normed spaces and $T\in \Bounded(X,Y)$ a bounded operator. Then $T$ has a unique adjoint $T^*: \dual{Y}\to \dual{X}$ and $\norm{T} = \norm{T^*}$.
\end{proposition}
\begin{proof}
The existence and uniqueness of the adjoint is given by \ref{existenceAdjointWeaklyContinuousFunction}. We just need to show that $\norm{T} = \norm{T^*}$. We calculate
\begin{align*}
\norm{T^*} &= \sup_{f\in \dual{Y}\setminus\{0\}}\frac{\norm{T^*(f)}}{\norm{f}} \\
&= \sup_{f\in \dual{Y}\setminus\{0\}}\frac{\norm{f\circ T}}{\norm{f}} \\
&= \sup_{f\in \dual{Y}\setminus\{0\}}\sup_{x\in X\setminus\{0\}}\frac{\norm{(f\circ T)(x)}}{\norm{f}\,\norm{x}} \\
&= \sup_{x\in X\setminus\{0\}}\sup_{f\in \dual{Y}\setminus\{0\}}\frac{\norm{f(Tx)}}{\norm{f}\,\norm{x}} \\
&= \sup_{x\in X\setminus\{0\}}\frac{\norm{Tx}}{\norm{x}} \\
&= \norm{T},
\end{align*}
where we have repeatedly used the definition of the operator norm, as well as \ref{normFromContinuousFunctionals}.
\end{proof}

\subsection{The uniform boundedness principle}
TODO: \url{https://arxiv.org/pdf/1005.1585.pdf}

\begin{theorem}[Uniform boundedness principle] \label{uniformBoundednessPrinciple}
Let $\mathcal{F}\subset \Bounded(X,Y)$ be a family of bounded operators where $X$ is a Banach space and $Y$ a normed space, such that
\[ \sup\setbuilder{\norm{Tx}}{T\in\mathcal{F}} < \infty \qquad \text{for all $x\in X$}. \]
Then $\sup\setbuilder{\norm{T}}{T\in\mathcal{F}} < \infty$.
\end{theorem}
\begin{proof}
The proof is an application of the Baire category theorem. Define the closed subsets $K_n$ as
\[ K_n = \setbuilder{x\in X}{\forall T\in\mathcal{F}: \norm{Tx}\leq n}. \]
These are closed because the functional $f_T: X\to \R: x\mapsto \norm{Tx}$ is bounded and
\[ K_n = \bigcap_{T\in\mathcal{F}}f_T^{-1}[\,[0,n]\,]. \]
By assumption, $X=\bigcup_{n\in\N} K_n$. As $X$ is a Banach space, and thus a complete metric space, we can apply the Baire category theorem, \ref{BaireCategory}, to conclude that there is a $K_n$ with non-empty interior (by contraposition of the Baire condition). Take $x_0\in K_n^\circ$, then $-x_0+K_n^\circ \subset K_{n2}$. So $\vec{0}\in (K_{2n})^\circ$ and we can find a $\rho$ such that $B(\vec{0},\rho)\subset K_{2n}$. By proposition \ref{existenceOperatorNorm} we have $\norm{T}\leq 2n/\rho$ for all $T\in\mathcal{F}$.
\end{proof}
\begin{corollary}[Banach-Steinhaus] \label{BanachSteinhaus}
Let $X$ be a Banach space and $Y$ a normed space. Let $T_n: X\to Y$ be a sequence of bounded operators that converges pointwise to $T$. Then
\begin{enumerate}
\item $T$ is bounded;
\item $\seq{T_n}$ converges in the continuous convergence.
\end{enumerate}
\end{corollary}
\begin{proof}
For all $x\in X$ we have $\norm{T_nx} \to \norm{Tx}$, so $\seq{\norm{T_nx}}$ is a bounded sequence and $\sup_{n}\norm{T_nx} <\infty$. By the uniform boundedness principle, $\sup_{n}\norm{T_n}$ is bounded by some constant $M$.

Now for all $x\in X$ we have $\norm{T_nx} \leq M$ for all $n\in\N$ and thus $\norm{Tx}\leq M$. This means that $T$ is bounded and $\norm{T} \leq M$.
\end{proof}
This does not imply that $\seq{T_n}$ converges to $T$ in norm!

\begin{proposition} \label{weaklyConvergentSequenceNormBounded}
Let $X$ be a normed space and $\seq{x_n}$ a weakly convergent sequence. Then $\{x_n\}_{n\in \N}$ is norm-bounded.
\end{proposition}
Note that not every weakly convergent \emph{net} is norm-bounded. TODO: compare \ref{weaklyBoundedIffBounded}
\begin{proof}
Take arbitrary $f\in \dual{X}$. Since $\seq{x_n}$ is weakly convergent to some $x\in X$, we have
\[ |\evalMap_{x_n}(f)| = |f(x_n)| \to |f(x)| = |\evalMap_x(f)|, \]
so the sequence $\seq{\evalMap_{x_n}}$ is pointwise convergent in $\bidual{X}$. By \ref{imageCauchySequenceTotallyBounded}, this implies that the set $\{\evalMap_{x_n}\}$ is pointwise bounded. Since $\bidual{X}$ is a Banach space (by \ref{dualNormedSpaceBanach}), $(\bidual{X}, \dual{X})$ is a Banach-Steinhaus pair and thus $\{\evalMap_{x_n}\}$ is uniformly bounded, so
\[ \sup_{n\in \N}\norm{\evalMap_{x_n}} = \sup_{n\in \N}\norm{x_n} < \infty, \]
using the fact that $\evalMap_-$ is an isometry \ref{canonicalIsometryIsometry}. Thus $\seq{x_n}$ is a bounded sequence.
\end{proof}

\begin{proposition}
Let $X,Y$ be normed spaces and $T\in \Lin(X,Y)$. Then the following are equivalent:
\begin{enumerate}
\item $T$ is norm continuous;
\item $T$ is weakly continuous;
\item $T$ is weakly sequentially continuous.
\end{enumerate}
\end{proposition}
\begin{proof}
$(1) \Rightarrow (2)$ Immediate by \ref{continuityImpliesWeakContinuity}.

$(2) \Rightarrow (3)$ Immediate by \ref{continuityImpliesSequentialContinuity}.

$(3) \Rightarrow (1)$ The proof is by contraposition. Suppose $T$ is not bounded. Then for all $M\geq 0$ there exists a unit vector $x\in X$ such that $\norm{Tx} \geq M$. In particular, for all $n^2$, there exists a unit vector $x_n$ such that $\norm{Tx_n} \geq n^2$.

Set $y_n \defeq n^{-1}x_n$, so $\norm{y_n} = n^{-1}$. This implies that $\seq{y_n}$ converges to $0$ in norm, and thus also weakly. This implies that $\seq{Ty_n} \to 0$ weakly. Now $\norm{Ty_n} = n^{-1}Tx_n \leq n^{-1}n^2 = n$, so $\{Ty_n\}_{n\in\N}$ is not bounded, which implies $T$ is not weakly sequentially continuous by \ref{weaklyConvergentSequenceNormBounded}.
\end{proof}

\subsection{Open mapping and closed graph theorems}

\begin{proposition} \label{openUnitBall}
Let $X,Y$ be Banach spaces and $T:X\to Y$ a surjective bounded operator.  Then the image of the open unit ball $B(\vec{0},1)\subset X$ contains an open ball about $\vec{0}\in Y$.
\end{proposition}
\begin{proof}
We first prove $0\in \overline{T[B(\vec{0},r)]}^\circ$ for every $r>0$: (TODO: make computations lemma.)
\begin{itemize}
\item Using $X = \bigcup_{n=1}^\infty B(\vec{0},n)$, we see by surjectivity
\[ Y = T[X] = T\left[\bigcup_{n=1}^\infty B(\vec{0},n)\right] = \bigcup_{n=1}^\infty T[B(\vec{0},n)]. \]
Because $Y$ has the Baire property (theorem \ref{BaireCategory}) and $Y$ is both open and non-empty, it may not be meagre, by lemma \ref{BaireEquivalents}. So for some $n\in\N$, $T[B(\vec{0},n)]$ is non-rare, meaning that $\overline{T[B(\vec{0},n)]}$ has non-empty interior.
\item Because
\[ \overline{T[B(\vec{0},n)]} = \overline{2nT[B(\vec{0},1/2)]} = 2n\overline{T[B(\vec{0},1/2)]}, \]
$\overline{T[B(\vec{0},1/2)]}$ must have non-empty interior. Let $B(y_0,\epsilon)\subset \overline{T[B(\vec{0},1/2)]}$.
\item Note $B(0,\epsilon) = y_0 - B(y_0,\epsilon) \subset \overline{T[B(\vec{0},1)]}$ and thus $B(0,r\epsilon) \subset \overline{T[B(\vec{0},r)]}$.
\end{itemize}
We then prove $\overline{T[B(\vec{0},1/2)]} \subset T[B(\vec{0}, 1)]$, proving the proposition.
\begin{itemize}
\item Choose some $y_0\in \overline{T[B(\vec{0},1/2)]}$. Then every neighbourhood $B(y_0,\epsilon/4)$ intersects $T[B(\vec{0},1/2)]$.
\item Then
\[ B(y_0,\epsilon/4) = y_0 - B(\vec{0},\epsilon/4) \subset y_0 - \overline{T[B(\vec{0},1/4)]}, \]
so $y_0 - \overline{T[B(\vec{0},1/4)]}$ intersects $T[B(\vec{0},1/2)]$. Take a $y_1 \in \overline{T[B(\vec{0},1/4)]}$ such that $y_0-y_1$ is in this intersection. Then we have an $x_0\in B(\vec{0},1/2)$ such that $T(x_0) = y_0-y_1$.
\item We can continue recursively choosing $y_{n+1}\in \overline{T[B(\vec{0}, 2^{-(n+1)})]}$ and $x_n \in B(\vec{0}, 2^{-n})$ such that $y_n-y_{n+1} = T(x_n)$.
\item Consider the sequence $\sum_{k=0}^nx_k$. It is a Cauchy sequence in $X$. Call its limit $x$. Then $x\in B(\vec{0},1)$.
\item Because $\norm{y_n}\leq 2^{-n}\norm{T}$, $(y_n)$ converges to zero. Then
\[ \left( T\left(\sum^n_{k=1}x_k\right) \right)_{n\in\N} = \left( y_0-y_{n+1} \right)_{n\in\N} \]
converges to $y_0$. Thus $T(x) = y_0 \in T[B(\vec{0},1)]$.
\end{itemize}
\end{proof}

\begin{proposition} \label{zeroInInteriorOfImageImpliesOpen}
Let $X,Y$ be normed spaces and $T: X\to Y$ a linear map. If $\vec{0}$ lies in the interior of $T[B(\vec{0},r)]$ for some $r>0$, then $T$ is open.
\end{proposition}
\begin{proof}
TODO: make computations lemma.
Given the assumption, $0$ lies in the interior of $T[B(\vec{0},\epsilon)]$ for all $\epsilon>0$.
Because $T[B(x,\epsilon)] = T(x) + T[B(\vec{0},\epsilon)]$, $T(x)$ lies in the interior of $T[B(x,\epsilon)]$, for all $x\in X$.
Thus for all neighbourhoods $U(x)\subset X$, $T(x)\subset T[U]^\circ$ and so $T[U] \subset T[U]^\circ$, so $T[U]$ is open.
\end{proof}

\begin{theorem}[Open mapping]
Let $X,Y$ be Banach spaces and $T:X\to Y$ a surjective bounded operator. Then $T$ is an open map.
\end{theorem}
\begin{proof}
This is the consequence of propositions \ref{openUnitBall} and \ref{zeroInInteriorOfImageImpliesOpen}.
\end{proof}
\begin{corollary}[Bounded inverse theorem] \label{boundedInverse}
Let $X,Y$ be Banach spaces. If $T:X\to Y$ is is continuous, linear and bijective, then $T$ is a homeomorphism.
\end{corollary}


\begin{proposition}
Let $T: \dom(T)\subset X\to Y$ be a bounded linear operator. Then
\begin{enumerate}
\item if $\dom(T)$ is a closed subset of $X$, then $T$ has closed graph;
\item if $T$ has closed graph and $Y$ is complete, then $\dom(T)$ is a closed subset of $X$.
\end{enumerate}
\end{proposition}
\begin{proof}
We use proposition \ref{closedGraphEquivalence} twice: First assume $(x_n)$ and $(Tx_n)$ converge to $x$ and $y$, respectively. Then $x\in\dom(T)$ by closure and $y = Tx$ by continuity.

Now assume $T$ has closed graph and $Y$ is complete. Take $x\in\overline{\dom(T)}$ and $(x_n)\subset \dom(T)$ converging to $x$. Since $T$ is bounded:
\[ \norm{Tx_n - Tx_m} = \norm{T(x_n-x_m)} \leq \norm{T}\norm{x_n-x_m}, \]
so $(Tx_n)$ is Cauchy by \ref{CauchyCriterion} and thus by completeness has a limit, say $y$. Then $Tx=y$ by continuity. Since $T$ has closed graph, $x\in\dom(T)$. So $\overline{\dom(T)}\subseteq \dom(T)$ and $\dom(T)$ is closed. 
\end{proof}

\begin{theorem}[Closed graph theorem] \label{BanachClosedGraphTheorem}
Let $X,Y$ be Banach spaces and $T:X\to Y$ a linear operator with $\dom(T) = X$. Then $T$ is continuous \textup{if and only if} $T$ is a closed operator.
\end{theorem}
\begin{proof}
TODO
\end{proof}

\subsection{Convergences on sets of bounded operators}
\begin{example}
Let $X, Y$ be normed spaces. The norm function $\norm{\cdot}: \Bounded(X,Y)\to \R^+: T\mapsto \norm{T}$ may be discontinuous when $\Bounded(X,Y)$ is equipped with the strong operator topology (and thus also when it is equipped with the weak operator topology).

TODO: consider $\Bounded(H)$, where $H$ is an infinite-dimensional Hilbert space. Let $\{e_n\}_{n\in\N}$ be an orthonormal set of vectors. Let $P_n$ be the orthogonal projector on $\overline{\Span}\{e_k\}_{k\geq n}$. Now $\seq{P_n}$ converges strongly to $0$:
take arbitrary $v = x+y \in \overline{\Span}\{e_k\}_{k\geq 0} \oplus \overline{\Span}\{e_k\}_{k\geq 0}^\perp$.

Then, by \ref{sumExpansionOrthogonalProjector}, $P_nv = P_nx = \sum_{k\geq n}\inner{e_k, x}e_k = x - \sum_{k\leq n}\inner{e_k, x}e_k$, so, by the Plancherel formula \ref{plancherel},
\[ \norm{P_n} = \norm{x - \sum_{k\leq n}\inner{e_k, x}e_k} = \norm{x - \sum_{k=0}^n\inner{e_k, x}e_k} \to 0. \]

Since $\norm{P_n} = 1$ for all $n\in\N$, the sequence $\seq{\norm{P_n}}$ does not converge to $\norm{0} = 0$.
\end{example}

\begin{example}
Multiplication is not continuous in the weak or strong operator topology.

Counterexample: nilpotent operators of order 2 are strongly dense (TODO?). Take some operator $T$ that is not nilpotent and a net $\seq{T_i}$ of of nilpotent operators that converges strongly to $T$. Then $T_i\cdot T_i = T_i^2 = 0$, so $T_i^2 \to 0 \neq T^2$.
\end{example}

\begin{lemma}
Let $X, Y$ be normed spaces, $\seq{T_i}_{i\in I} \in \Bounded(X, Y)^I$ and $T \in \Bounded(X, Y)$. Then
\begin{enumerate}
\item $T_i \to T$ in the strong operator topology \textup{if and only if} $f(T_ix) \to f(Tx)$ uniformly for $f\in\dual{X}$ with $\norm{f} = 1$;
\item $T_i \to T$ in the norm topology \textup{if and only if} $T_ix\to Tx$ uniformly for $x\in X$ with $\norm{x} = 1$.
\end{enumerate}
\end{lemma}
\begin{proof}
(1) Immediate from \ref{uniformConvergenceWeakTopologyGivesNormTopology}.

(2) By a similar argument to \ref{uniformConvergenceWeakTopologyGivesNormTopology}.
\end{proof}

\begin{proposition}
Let $X,Y$ be normed spaces, then
\begin{enumerate}
\item the adjoint map $*: \Bounded(X, Y) \to \Bounded(\dual{Y}, \dual{X})$ is norm-norm continuous;
\item if $X$ is reflexive, then the adjoint map $*: \Bounded(X, Y) \to \Bounded(\dual{Y}, \dual{X})$ is WOT-WOT continuous.
\end{enumerate}
\end{proposition}
In general the adjoint map is not SOT-SOT continuous, even for Hilbert spaces. See \ref{adjointMapNotSOTContinuous}.
\begin{proof}
(1) Continuity in norm is follows from the fact that the adjoint map is isometric \ref{adjointMapIsometric}.

(2) Since $X$ is reflexive, we have $\dual{X}= \{\evalMap_x\}_{x\in X}$. Now we calculate, for $x\in X, f\in \dual{Y}, T\in \Bounded(X,Y)$,
\[ \pair{\evalMap_x\otimes f, T^*} = \evalMap_x\big(T^*f\big) = \evalMap_x(f\circ T) = f\big(Tx\big) = \pair{f\otimes v, T}. \]
Thus $\pair{\evalMap_x\otimes f, -}\circ (-)^* = \pair{\evalMap_x\otimes f, (-)^*} = \pair{f\otimes x, -}$, which means that $(-)^*$ is continuous by \ref{characteristicPropertyInitialFinalConvergence}.
\end{proof}

\begin{example}
If $X$ is not reflexive, then the adjoint map may not be continuous in the weak operator topology.

Consider the Banach space $c_0$. Then $\dual{(c_0)} = \ell^1$ and $\dual{\dual{(c_0)}} = \ell^\infty$. Consider $S_l^n: c_0 \to c_0$, the left-shift by $n$. Then $(S_l^n: c_0 \to c_0)^* = S_r^n: \ell^1 \to \ell^1$. Then, for all $\seq{x_k} \in c_0$ and $\seq{y_k}\in \ell^1$, we have
\[ |\pair{S_l^n\seq{x_k}, \seq{y_k}}| = \left|\sum_{k=1}^\infty x_{k+n}y_k \right| \leq \sup_{k\geq n}|x_k|\left|\sum_{k=1}^\infty y_k \right| = \sup_{k\geq n}|x_k|\,\norm{\seq{y_n}}_1 \to 0, \]
so $S_l^n \overset{WOT}{\longrightarrow} 0$.

But $(S_l^n)^* = S_r^n: \ell^1\to \ell^1$ does not converge to $0$ in the WOT for $\Bounded(\ell^1)$. Indeed, take non-zero $\seq{y_k}\in \ell^1$ and $\seq{z_k} = \underline{1} \in \ell^\infty$.
Then
\[ |\pair{S_r^n\seq{y_k}, \seq{z_k}}| = \left|\sum_{k=1+n}^\infty y_{k+n}\cdot z_k \right| = \left|\sum_{k=1+n}^\infty y_{k+n}\cdot 1 \right| = \left|\sum_{k=1}^\infty y_{k} \right| = \norm{\seq{y_k}}_1 \neq 0. \]
\end{example}

\begin{proposition}
Let $X, Y$ be a Banach spaces. Then
\begin{enumerate}
\item $\Bounded_{\text{SOT}}(X,Y)$ is quasi-complete;
\item if $Y$ is reflexive, then $\Bounded_{\text{WOT}}(X,Y)$ is quasi-complete.
\end{enumerate}
\end{proposition}
\begin{proof}
(1) Since $Y$ is complete, it is also quasi-complete. By (TODO ref), $(X,Y)$ is a Banach-Steinhaus pair. By \ref{quasiCompletenessFunctionSpaces}, $\Bounded(X,Y)_\text{SOT} = \contLin_p(X,Y)$ is quasi-complete.

(2) We have $\Bounded(X,Y)_\text{SOT} = \contLin_p(X,\sSet{Y,\sigma})$ and $\sSet{Y,\sigma}$ is quasi-complete by \ref{ReflexiveBanachSpaceWeaklyQuasiComplete}. Then $\Bounded(X,Y)_\text{SOT}$ is quasi-complete by \ref{quasiCompletenessFunctionSpaces}.
\end{proof}



\subsection{Compact operators}
\begin{definition}
A linear map $L:V\to W$ between normed spaces is called \udef{compact} if $L^\imf\big(\cball(\vec{0}, 1)\big)$ is relatively compact.

The space of compact maps from $V$ to $W$ is denoted $\Compact(V,W)$.
\end{definition}
In other words, an operator is compact if the image of the closed unit ball has compact closure.

These operators were introduced to study equations of the form
\[ (T-\lambda I)x(t) = p(t). \]

\begin{proposition}
Let $L\in\Lin(V,W)$. The following are equivalent:
\begin{enumerate}
\item $L$ is compact;
\item the image of any bounded subset of $V$ is relatively compact in $W$;
\item there exists a neighbourhood $U$ of $0$ in $V$ such that the image of $U$ is a subset of a compact set in $W$;
\item for any bounded sequence $(x_n)_{n\in\N} \subseteq V$, then sequence $(Lx_n)_{n\in\N}$ contains a converging subsequence.
\end{enumerate}
\end{proposition}
\begin{proof}
TODO
\end{proof}
\begin{corollary}
All maps of finite rank are compact.
\end{corollary}
\begin{proof}
Closed balls in $\C^n$ are compact.
\end{proof}

\begin{proposition}
Let $V$ be a normed space. Then $\mathcal{K}(V)$ is a closed two-sided ideal in $\Bounded(V)$.
\end{proposition}

\begin{lemma}
The identity map on $X$ is compact \textup{if and only if} $X$ is finite-dimensional.
\end{lemma}
\begin{proof}
The unit ball is compact iff $X$ is finite-dimensional, by \ref{compactnessUnitBall}.
\end{proof}
\begin{corollary}
Let $T\in\Compact(X,Y)$. If $T$ is injective and $T^{-1}$ bounded, then $X$ is finite-dimensional.
\end{corollary}
\begin{proof}
In this case $\id_X = T^{-1}T$ is compact by TODO ref.
\end{proof}

\subsubsection{Compact operators on Banach spaces}
\begin{proposition}
Let $L\in\Hom(V,W)$ with $V,W$ Banach spaces. Then $L$ is compact \textup{if and only if} the image of any bounded subset of $V$ under $L$ is totally bounded in $W$.
\end{proposition}
TODO proof

\begin{lemma} \label{identityCompactFiniteDimensional}
Let $X$ be a Banach space. Then $\id_X$ is compact \textup{if and only if} $X$ is finite dimensional.
\end{lemma}

\begin{theorem}[Schauder's theorem] \label{SchaudersTheorem}
Let $X,Y$ be Banach spaces and $T\in\Bounded(X,Y)$. Then the following are equivalent:
\begin{enumerate}
\item $T: X\to Y$ is compact;
\item $T^*: Y^* \to X^*$ is compact.
\end{enumerate}
\end{theorem}
TODO: more general setting: $X,Y$ normed for $(1) \Rightarrow (2)$ and $X$ normed, $Y$ Banach for $(2)\implies (1)$?
\begin{proof}
TODO \ref{https://arxiv.org/pdf/1010.1298.pdf} and \url{https://math.stackexchange.com/questions/41432/easy-proof-adjointcompact-compact}
\end{proof}

\subsubsection{Calkin algebra}
Calkin algebra: study of properties invariant under compact pertubation.

\begin{proposition}
Let $X$ be a Banach space. Then $\Compact(X)$ is a closed two-sided ideal in $\Bounded(X)$.
\end{proposition}
\begin{proof}
TODO + $*$-ideal for Hilbert spaces.
\end{proof}
\begin{corollary}
An invertible operator $T$ on $X$ is compact \textup{if and only if} $X$ is finite-dimensional.
\end{corollary}
\begin{proof}
If $T$ is compact, then so is $TT^{-1} = \id_X$, meaning that $X$ is finite-dimensional by \ref{identityCompactFiniteDimensional}. Conversely, all operators on a finite-dimensional Banach space are compact.
\end{proof}

\begin{definition}
Let $X$ be a Banach space. The \udef{Calkin algebra} is the quotient $\Bounded(X)/\Compact(X)$.
\end{definition}
TODO: quotient algebra ($[A][B] = [AB]$)

\begin{proposition}
Let $[T]\in\Bounded(X)/\Compact(X)$. Then the following are equivalent:
\begin{enumerate}
\item $[T]$ is invertible in the Calkin algebra;
\item $\exists S\in\Bounded(X):$ both $\vec{1}-TS$ and $\vec{1}-ST$ are compact;
\item $T$ has closed range and finite-dimensional kernel and cokernel. 
\end{enumerate}
\end{proposition}
\begin{proof}
Point 1. and 2. are easily equivalent: $[S]$ is an inverse of $[T]$ if and only if $[\vec{1}] = [S][T] = [ST]$ and $[\vec{1}] = [T][S] = [TS]$. Then
\[ [\vec{1}] = [ST] \iff [ST - \vec{1}] = [0] \qquad [\vec{1}] = [TS] \iff [TS - \vec{1}] = [0] \]
and $[F]=[0]$ if and only if $F$ is compact.

TODO
\end{proof}

\subsubsection{Fredholm operators}
TODO: Moore-Penrose pseudoinverse??

\begin{definition}
An operator $T\in\Bounded(X,Y)$ between Banach spaces is called a \udef{Fredholm operator} if $T$ has a finite-dimensional kernel and cokernel.

The \udef{Fredholm index} of $T$ is defined as
\[ \Index T \defeq \dim\ker T - \dim\coker T.  \]

We denote the space of Fredholm operators from $X$ to $Y$ as $\Fred(X,Y)$. If $X=Y$, we write $\Fred(X)$.
\end{definition}

\begin{example}
\begin{enumerate}
\item If $X=Y$ is finite-dimensional, then all operators are Fredholm with index $0$.
\item A self-adjoint operator on a Hilbert space with finite kernel is Fredholm with Fredholm index $0$.
\item The left shift $S_l:\ell^2(\N)\to\ell^2(\N): (x_n)_n\mapsto (x_{n+1})_n$ has index $1$.
\item The right shift $S_r = S_l^*$ has index $-1$.
\end{enumerate}
\end{example}

\begin{lemma} \label{FredholmOperatorClosedRange}
A Fredholm operator has closed range.
\end{lemma}

\begin{lemma}
Let $T\in\Bounded(H)$ be a bounded operator on a Hilbert space. Then $\dim\coker T = \dim\ker T^*$.
\end{lemma}
\begin{proof}
TODO (is it correct?) $\ker(T^*) = \im(T)^\perp$.
\end{proof}


\begin{proposition}
Let $S,T\in\Fred(X)$, $\lambda\in\F$ and $K\in\Compact(X)$. Then
\begin{enumerate}
\item $\Index(ST) = \Index(S)+\Index(T)$;
\item $\Index(T+K) = \Index(T)$;
\item $\Index(\lambda T) = \Index(T)$, if $\lambda \neq 0$;
\item $\Index(T) = 0$ \textup{if and only if} $T=K'+L$ for some compact $K'$ and invertible $L$.
\end{enumerate}
Let $T\in\Fred(H)$ for some Hilbert space $H$. Then
\begin{enumerate} \setcounter{enumi}{4}
\item $\Index(T^*) = -\Index(T)$.
\end{enumerate}
\end{proposition}
TODO: prove using next lemma:
\begin{lemma}
Let the commutative diagram
\[ \begin{tikzcd}
0 \rar & X \dar{T} \rar & Y \dar{S} \rar & Z \dar{R} \rar & 0 \\
0 \rar & X \rar & Y \rar & Z \rar & 0
\end{tikzcd} \]
have short exact rows. If any two of $T,S,R$ are Fredholm, then so is the third and
\[ \Index S = \Index T + \Index R. \]
\end{lemma}
\begin{proof}
TODO snake lemma to obtain long exact
\[ 0\to \ker T \to \ker S\to \ker R \to \coker T \to \coker S \to \coker R \to 0. \]
\end{proof}
\begin{corollary} \mbox{}
\begin{enumerate} 
\item Let $T\in\Fred(X)$ and $S\in\Fred(Y)$ be Fredholm, then so is $T\oplus S$ with
\[ \Index(T\oplus S) = \Index(T)+\Index(S). \]
\item Let $T\in\Fred(X,Y)$ and $S\in\Fred(Y,Z)$ be Fredholm, then so is $ST$ with
\[ \Index(ST) = \Index(T)+\Index(S). \]
\item Let $K\in\Compact(X)$ be compact, then $\id_X+K$ is Fredholm with
\[ \Index(\id_X+K) = 0. \]
\end{enumerate}
\end{corollary}


\begin{lemma}[Fredholm alternative] \label{FredholmAlternative}
Let $T$ be a Fredholm operator of index zero. Then either $T$ is bijective, or it is neither injective nor surjective.
\end{lemma}
\begin{proof}
The operator $T$ is injective iff $\dim\ker(T) = 0$ and surjective iff $\dim\coker(T) = 0$.
\end{proof}



\section{Isometries}
In this section we do not assume isometries to be linear.

\subsection{Isometries on $\R$}
\begin{lemma} \label{sumSquaredIntervals}
Let $x,y,z\in\R$. Then
\[ (x-y)^2 + (y-z)^2 - (x-z)^2 = 2(x-y)(z-y). \]
\end{lemma}
Thus also $(y-x)^2 + (z-y)^2 \leq (z-x)^2$ if $x\leq y\leq z$.
\begin{proof}
We calculate
\begin{align*}
(x-y)^2 + (y-z)^2 - (x-z)^2 &= \cancel{x^2} + \cancel{z^2} + 2y^2 + -2xy-2yz -\cancel{x^2} -\cancel{z^2} + 2xz \\
&= 2\big(y^2 + -xy-yz + xz\big) \\
&= 2(x-y)(z-y).
\end{align*}
\end{proof}

\begin{lemma}
All isometries of $\R$ are of the form $f: \R\to\R: x\mapsto ax+b$ with $a = \pm 1$.
\end{lemma}
\begin{proof}
Let $f$ be an isometry. Define, for all $x\neq y\in \R$,
\[ \lambda_{x,y} \defeq \frac{f(x)-f(y)}{x-y}. \]
Then
\[ \lambda_{x,y}^2 = \frac{\big(f(x)-f(y)\big)^2}{(x-y)^2} = \frac{\big|f(x)-f(y)\big|^2}{|x-y|^2} = 1, \]
so $\lambda_{x,y} = \pm 1$ and, in particular, $\lambda_{x,y} = \lambda_{x,y}^{-1}$


Fix $x\in \R$. Since $f(y) = -\lambda_{x,y}y +\lambda_{x,y}x + f(x)$, it is enough to show that $\lambda_{x,z} = \lambda_{x,y}$ for all $y,z\in \R$. In this case $a = -\lambda_{x,y}$ and $b = \lambda_{x,y}x + f(x)$.

First note
\[ \lambda_{x,y} = \frac{f(x)-f(y)}{x-y} = \frac{f(y)-f(x)}{y-x} = \lambda_{y,x}, \]
and calculate
\begin{align*}
f(x) &= \lambda_{x,y}(x-y) + f(y) \\
&= \lambda_{x,y}(x-y) + \lambda_{y,z}(y-z) + f(z) \\
&= \lambda_{x,y}(x-y) + \lambda_{y,z}(y-z) + \lambda_{z,x}(z-x) + f(x),
\end{align*}
so $-\lambda_{y,z}(y-z) = \lambda_{x,y}(x-y) + \lambda_{x,z}(z-x)$. Squaring gives
\[ (y-z)^2 = (x-y)^2 + (z-x)^2 + 2\lambda_{x,y}\lambda_{x,z}(z-x)(x-y) \]
and thus
\[ \lambda_{x,y}\lambda_{x,z} = - \frac{(x-y)^2 + (z-x)^2 - (y-z)^2}{2(z-x)(x-y)} = \frac{(x-y)^2 + (z-x)^2 - (y-z)^2}{2(z-x)(y-x)} = 1, \]
by \ref{sumSquaredIntervals}. So $\lambda_{x,z} = \lambda_{x,y}$.
\end{proof}

\subsection{Affine isometries}

\begin{proposition}
Let $V,W$ be real normed spaces and $f: V\to W$ an isometry. Then $f$ is affine \textup{if and only if} $f\big(\frac{1}{2}x + \frac{1}{2}y\big) = \frac{1}{2}\big(f(x) + f(y)\big)$ for all $x,y\in V$.
\end{proposition}
\begin{proof}
The direction $\Rightarrow$ is immediate from the definition.

For the other direction, observe that \ref{midpointPreservingMapLemma} implies that $f\big(\lambda x + (1-\lambda)y\big) = \lambda f(x) + (1-\lambda)f(y)$ for all $\lambda$ of the form $\frac{k}{2^m}$. The set of all such $\lambda$ is dense in $\R$ and $f$ is continuous by \ref{isometriesUniformlyContinuous}. By \ref{denseSetDeterminesContinuousFunction}, this implies that$f\big(\lambda x + (1-\lambda)y\big) = \lambda f(x) + (1-\lambda)f(y)$ for all $\lambda\in\R$, i.e.\ $f$ is affine.
\end{proof}
\begin{corollary}
Let $V,W$ be real normed spaces and $f: V\to W$ an isometry. If $\cball_W(0,1)$ is strictly convex, then $f$ is affine.
\end{corollary}
\begin{proof}
Since $f$ is isometric, we have
\begin{align*}
\norm{f\Big(\frac{x+y}{2}\Big) - f(x)} &= \norm{\frac{x+y}{2} - x} = \frac{\norm{x-y}}{2} \\
\norm{f\Big(\frac{x+y}{2}\Big) - f(y)} &= \norm{\frac{x+y}{2} - y} = \frac{\norm{x-y}}{2}, 
\end{align*}
so $\frac{2}{\norm{x-y}}\Big(f(x) - f\big(\frac{x+y}{2}\big)\Big)$ and $\frac{2}{\norm{x-y}}\Big(f\big(\frac{x+y}{2}\big) - f(y)\Big)$ are unit vectors and 
\begin{align*}
\norm{\frac{2}{\norm{x-y}}\bigg(f(x) - f\Big(\frac{x+y}{2}\Big)\bigg) + \frac{2}{\norm{x-y}}\bigg(f\Big(\frac{x+y}{2}\Big) - f(y)\bigg)} &= \frac{2}{\norm{x-y}}\norm{f(x) - f(y)} \\
&= 2.
\end{align*}
By \ref{strictConvexityUnitBall}, this implies that $f(x) - f\big(\frac{x+y}{2}\big) = f\big(\frac{x+y}{2}\big) - f(y)$, or $f\big(\frac{x+y}{2}\big) = \frac{f(x) + f(y)}{2}$.
\end{proof}

\begin{theorem}[Mazur-Ulam theorem]
Let $V,W$ be real normed spaces. Then every surjective isometry $f: V\to W$ is affine.
\end{theorem}
\begin{proof}

\end{proof}

\begin{example}
Bijective isometry between complex spaces that is real-affine, but not complex-affine.
\end{example}

\begin{theorem}[Beckman-Quarles]

\end{theorem}

\begin{example}
Counterexamples for $\R$ and $L^2$.
\end{example}

\section{Completions and constructions}

\begin{lemma} \label{embeddingInCompletionLinear}
Let $X$ be a normed vector space with completion $\hat{X}$. Then
\begin{enumerate}
\item there exist unique operations of addition and scalar multiplication on $\hat{X}$ that make $\hat{X}$ a Banach space;
\item the embedding $\hat{}: X \hookrightarrow \hat{X}$ is linear.
\end{enumerate}
\end{lemma}
\begin{proof}

\end{proof}


\begin{proposition}
Let $X$ be a normed vector space with completion $\hat{X}$ and $\sSet{Y, \xi}$ a complete vector space. Let $T: X\to Y$ be a bounded linear operator. Then $T$ has a unique continuous extension $\hat{T}: \hat{X} \to Y$ and
\begin{enumerate}
\item $\hat{T}$ is linear;
\item $\norm{\hat{T}} = \norm{T}$.
\end{enumerate}
\end{proposition}
\begin{proof}
We have that $T$ is uniformly continuous by \ref{uniformContinuityGroupHomomorphism}. Thus the continuous extension $\hat{T}$ exists and is unique by \ref{uniformlyContinuousExtensionToCompletion}.

(1) Take $a,b\in \hat{X}$ and $\lambda \in \F$. Then, by \ref{sequentialLemma} and \ref{sequentialInherenceAdherence}, we can find sequences $\seq{a_n}, \seq{b_n}$ such that $\seq{\hat{a}_n}, \seq{\hat{b}_n}$ converge to $a$ and $b$ in the completion.

For all $x,y\in X$, we have $\widehat{x+\lambda y} = \hat{x} + \lambda \hat{y}$ by \ref{embeddingInCompletionLinear}, so
\[ \hat{T}\big(\hat{x} + \lambda \hat{y}\big) = \hat{T}\big(\widehat{x+\lambda y}\big) = T(x+\lambda y) = T(x) + \lambda T(y) = \hat{T}(\hat{x}) + \lambda \hat{T}(\hat{y}). \]

Now we can compute
\begin{align*}
\hat{T}(a+ \lambda b) &= \lim_{n\to \infty}\hat{T}\big(\hat{a_n} + \lambda \hat{b_n}\big) \\
&= \lim_{n\to \infty}\hat{T}(\hat{a_n}) + \lambda \hat{T}(\hat{b_n}) \\
&= \lim_{n\to \infty}\hat{T}(\hat{a_n}) + \lambda \lim_{n\to \infty}\hat{T}(\hat{b_n}) \\
&= \hat{T}(a) + \lambda \hat{T}(\hat{b}).
\end{align*}
This shows linearity.
\end{proof}


\begin{proposition}
The completions of a space with respect to two different norms are isomorphic \textup{if and only if} the norms are equivalent.
\end{proposition}

TODO move down
\subsection{Tensor products}
TODO Ryan
\url{https://math.stackexchange.com/questions/2712906/does-mathcalb-mathcalh-mathcalh-otimes-mathcalh-in-infinite-dime}
\url{https://math.stackexchange.com/questions/35191/operator-norm-and-tensor-norms?noredirect=1&lq=1}

\subsection{Direct sums}
\subsubsection{Algebraic direct sum}

\subsubsection{Topological direct sum}
For arbitrary direct sums we can generalise: now that we have a concept of limits, we can relax the requirement that all but finitely many terms be zero. Instead we require that the sequence of norms is bounded in some way. This gives a whole family of related concepts of direct sum, named for which sequence space the sequence of norms belongs to.
\begin{definition}
Let $\{V_i\}_{i\in I}$ be an arbitrary family of Banach spaces over a field $\F$ and let $\ell(I,\F)$ be a space of sequences in $\F$ indexed by $I$. Then the \udef{$\ell$-direct sum} is the vector space with as field
\[ \bigoplus_{i\in I}^\ell V_i = \setbuilder{(v_i)_{i\in I}}{\forall i\in I: v_i\in V_i \quad\text{and}\quad (\norm{v_i}_{V_i})_{i\in I}\in \ell(I,\F) }. \]
In particular we have, for all $1\leq p<\infty$, the \udef{$\ell^p$-direct sum}
\[ \bigoplus_{i\in I}^p V_i \defeq \setbuilder{(v_i)_{i\in I}}{\forall i\in I: v_i\in V_i \quad\text{and}\quad \sqrt[p]{\sum_{i\in I}\norm{v_i}_{V_i}^p}<\infty} \]
and the \udef{$\ell^\infty$-direct sum}
\[ \bigoplus_{i\in I}^\infty V_i \defeq \setbuilder{(v_i)_{i\in I}}{\forall i\in I: v_i\in V_i \quad\text{and}\quad \sup_{i\in I}\norm{v_i}_{V_i}<\infty}. \]
\end{definition}

\begin{proposition}
For any sequence space that is a Banach space the direct sum is a Banach space. TODO: in particular algebraic direct sum as $c_{00}$? (one possible norm)? and finite direct sums?
\end{proposition}

\subsubsection{Direct sum of identical spaces}
\begin{proposition}
Let $V$ be a Banach space over $\F$, $I$ an arbitrary index set and $\ell(I,\F)$ a banach sequence space.
\[ \bigoplus_{i\in I}^\ell V \cong \ell\otimes V \]
\end{proposition}

\subsubsection{Internal direct sums}
\begin{proposition} \label{directSumClosedSubspacesBanachSpace}
Let $X$ be a Banach space and $A,B\subseteq X$ subspaces such that $A\cap B = \{0\}$ and $A\oplus^i B$ is closed in $X$. Then $A\oplus^i B$ is a convergence direct sum \textup{if and only if} $A$ and $B$ are closed subspaces of $X$.
\end{proposition}
TODO criteria for $A\oplus^i B$ being closed in $X$: \url{https://arxiv.org/abs/1509.06445}.
\begin{proof}
The direction $\Rightarrow$ follows from \ref{convergenceDirectSumsClosedSubspaces} and the fact that $\closure_X(A) = \closure_{A\oplus^i B}(A)$ by \ref{subspaceAdherence}.

Now assume $A,B$ closed. By \ref{internalConvergenceDirectSumEquivalents} it is enough to show that $P_A: A\oplus^i B \to A: x+y \mapsto x$ is continuous. We first show that $P_A$ is a closed operator, using \ref{closedGraphEquivalence}.

Suppose $\seq{a_n+b_n} \in (A\oplus^i B)^\N$ is a convergent sequence with limit $c\in X$ and $P_A(a_n+b_n) = a_n \to a$. Since $A$ is closed, we have $a\in A$. Then $b_n = (a_n+b_n)- a_n \to c-a$ and $c-a\in B$ because $B$ is closed. Now we have, $P_A(c) = P_A(a+c-a) = a$, so $P_A$ is closed.

Since $A\oplus^i B$ is closed, it is a Banach space and we can apply the closed graph theorem \ref{BanachClosedGraphTheorem}.
\end{proof}



\subsection{Quotients of normed spaces}
\begin{proposition}
Let $V$ be a normed space and $U\subseteq V$ a subspace. Then
\[ \norm{x+U}_{V/U} \defeq \inf\setbuilder{\norm{x+u}}{u\in U} \]
is a seminorm on $V/U$. It is a norm \textup{if and only if} $U$ is closed in $V$.
\end{proposition}
\begin{proof}
For absolute homogeneity, take $\lambda\in\F\setminus\{0\}$. Then $\lambda x+U = \lambda(x+U)$, so
\[ \norm{\lambda x}_{V/U} = \inf\setbuilder{\norm{\lambda x+u}}{u\in U} = \inf\setbuilder{|\lambda|\norm{(x+u)}}{u\in U} = |\lambda| \norm{x}_{V/U}. \]
For subadditivity, we have
\begin{align*}
\norm{x+y}_{V/U} &= \inf\setbuilder{\norm{x+y+u}}{u\in U} \\
&= \inf\setbuilder{\norm{x+y+u+v}}{u\in U, v\in U} \\
&\leq \inf\setbuilder{\norm{x+u}+\norm{y+v}}{u,v\in U} \\
&= \norm{x}_{V/U} + \norm{y}_{V/U}.
\end{align*}

Now $\norm{x}_{V/U} = 0$ iff there exists a sequence $\seq{u_n}$ in $U$ such that $u_n\to x$ in $V$. Also $[x]_U = 0$ is equivalent to $x\in U$. Thus point-separation (i.e. $\norm{x}_{V/U} = 0$ implies $[x]_U = 0$) is equivalent to the statement ``if there exists a sequence $\seq{u_n}$ in $U$ such that $u_n\to x$ in $V$, then $x\in U$'', which is equivalent to the statement that $U$ is closed.
\end{proof}

\begin{proposition}
Let $V$ be a normed space and $U\subseteq V$ a subspace. Then
\begin{enumerate}
\item the quotient map $[\cdot]_U$ is bounded and $\norm{[\cdot]_U}\leq 1$;
\item the topology generated by $\norm{\cdot}_{V/U}$ is the quotient topology on $V/U$, i.e.\ the final topology w.r.t.\ the quotient map $[\cdot]_U$;
\item $[\cdot]_U$ is an open map.
\end{enumerate}
\end{proposition}
\begin{proof}
(1) We have
\[ \norm{[x]_U}_{V/U} = \inf\setbuilder{\norm{x+u}}{u\in U} \leq \inf\setbuilder{\norm{x+u}}{u\in \{0\}} = \norm{x+0} = \norm{x}. \]

(2), (3) TODO Conway p.71
\end{proof}

\begin{proposition} \label{quotientBanachSpace}
Let $V$ be a Banach space and $U\subseteq V$ a closed subspace. Then $V/U$ is a Banach space.
\end{proposition}
\begin{proof}
TODO Conway p.71
\end{proof}

\section{Unbounded operators}
Should be: not-necessarily-bounded operators.
\subsection{Operators bounded below}
TODO: also unbounded operators!
\begin{definition}
Let $T$ be a linear operator. We say $T$ is \udef{bounded below} if
\[ \exists b>0:\forall v\in \dom(T): \quad \norm{Tv}\geq b\norm{v} \]
\end{definition}

\begin{proposition} \label{boundedBelow}
Let $T\in \Lin(V, W)$ be an operator. Then $T$ has a bounded inverse $T^{-1}: \im(T)\to V$ \textup{if and only if} $T$ is bounded below by some constant $b$.

In this case
\[ \displaystyle\norm{T^{-1}} = \left(\inf_{x\neq 0}\frac{\norm{Tx}}{\norm{x}}\right)^{-1} \leq \frac{1}{b}. \]
\end{proposition}
\begin{proof}
First assume $T$ bounded below.
To show $T$ is injective, take $x_1,x_2\in \dom T$ such that $Tx_1 = Tx_2$. Then
\[ 0 = \norm{Tx_1 - Tx_2} = \norm{T(x_1 - x_2)} \geq b\norm{x_1 - x_2} \geq 0. \]
So $\norm{x_1 - x_2} = 0$ and thus $x_1=x_2$.
The existence of $T^{-1}$ is then clear. For boundedness notice that $T^{-1}y \in \dom(T)$, so because $T$ is bounded below,
\[ b\norm{T^{-1}y} \leq \norm{TT^{-1}y} = \norm{y} \quad\implies\quad \norm{T^{-1}y} \leq \frac{1}{b}\norm{y}. \]

This also shows that $\norm{T^{-1}} \leq 1/b$ for all lower bounds $b$. In other words $1/\norm{T^{-1}} \geq \inf_{x\neq 0}\norm{Tx}/\norm{x}$.

Now assume $T^{-1}$ bounded. Then for all $x\in\dom(T)$: $\norm{x} = \norm{T^{-1}Tx} \leq \norm{T^{-1}}\norm{Tx}$, so $T$ is bounded below by $1/\norm{T^{-1}}$.

This also shows that $1/\norm{T^{-1}}$ is a lower bound, so $1/\norm{T^{-1}} \leq \inf_{x\neq 0}\norm{Tx}/\norm{x}$.
\end{proof}



\subsection{Closed operators and graph norm}
\begin{definition}
Let $T:\dom(T)\subseteq X\to Y$ be an operator. Then $T$ is a \udef{closed operator} if $\graph(T)$ is closed in $X\oplus Y$.
\end{definition}
This is not the same as a closed map in the topological sense!

\subsubsection{The graph norm}
Let $L:V\to W$ be a linear map between normed spaces. The graph of $L$
\[ \setbuilder{(v,w)\in V\oplus W}{w = Lv} \]
has a natural norm inherited from the direct sum:
\[ \norm{(v,Lv)} = \norm{v}_V + \norm{Lv}_W. \]
This norm can also be seen as a norm on $V$: the \udef{graph norm} induced by $L$ is defined as
\[ \norm{v}_L := \norm{v}_V + \norm{Lv}_W. \]

\begin{proposition}
Let $L: \sSet{V, \norm{\cdot}_V}\to \sSet{W, \norm{\cdot}_W}$ be a linear map between normed spaces. Then $L: \sSet{V, \norm{\cdot}_L}\to \sSet{W, \norm{\cdot}_W}$ is bounded with norm $K$.
Also
\begin{enumerate}
\item $K \leq 1$;
\item $K < 1$ \textup{if and only if} $L: \sSet{V, \norm{\cdot}_V}\to \sSet{W, \norm{\cdot}_W}$ is bounded.
\end{enumerate}
\end{proposition}
\begin{proof}
Take any $v\in V$. Then
\[ \norm{L(v)}_W \leq \norm{L(v)}_W + \norm{v}_V = \norm{v}_L. \]
This shows the $L$ is bounded and the norm is less than or equal to $1$.

Now we can write
\[ K = \sup_{v\in V\setminus\{0\}}\frac{\norm{L(v)}_W}{\norm{v}_L} = \sup_{v\in V\setminus\{0\}}\frac{\norm{L(v)}_W}{\norm{v}_V + \norm{L(v)}_W} \defeq \sup_{v\in V\setminus\{0\}}K_v, \]
where we have set $K_v \defeq \frac{\norm{L(v)}_W}{\norm{v}_V + \norm{L(v)}_W}$.

First assume $L: \sSet{V, \norm{\cdot}_V}\to \sSet{W, \norm{\cdot}_W}$ is bounded. Then, from $\norm{L_v}_W = K_v \big(\norm{L(v)}_W + \norm{v}_V\big)$, we calculate
\[ K_v\norm{v}_V = \norm{L(v)}_W(1-K_v) \leq \norm{L}\;\norm{v}_V(1-K_v), \]
which implies $K_v \leq \norm{L}(1-K_v)$. This can be written as $K_v \leq \frac{\norm{L}}{1+ \norm{L}}$.
Thus $K = \sup_v K_v \leq \frac{\norm{L}}{1+ \norm{L}} < 1$.

Now assume $L: \sSet{V, \norm{\cdot}_V}\to \sSet{W, \norm{\cdot}_W}$ is unbounded. We write
\[ K_v = \frac{\norm{L(v)}_W}{\norm{v}_V + \norm{L(v)}_W} = \frac{\norm{L(v)}_W + \norm{v}_V - \norm{v}_V}{\norm{v}_V + \norm{L(v)}_W} = 1 - \frac{\norm{v}_V}{\norm{v}_V + \norm{L(v)}_W}. \]
We can find a sequence $\seq{v_n}$ of unit vectors such that $\norm{L(v_n)}_W \to \infty$. Then $K_{v_n} = 1 - \frac{1}{1+\norm{L(v_n)}_W} \to 1$. Thus
\[ K = \sup_{v\in V}K_v \geq \sup_{v\in \seq{v_n}}K_v \geq \limsup_{n}K_{v_n} \geq \lim_{n}K_{v_n} = 1, \]
so $K = 1$.
\end{proof}


\begin{lemma} \label{graphNormConvergenceLemma}
Let $T: X\not\to Y$ be an operator between normed spaces and $\seq{x_n}$ a sequence in $\dom(T)$. Then the following are equivalent:
\begin{enumerate}
\item $x_n \overset{\norm{\cdot}_T}{\longrightarrow} x$;
\item $(x_n, Tx_n) \overset{\norm{\cdot}_{X\oplus Y}}{\longrightarrow} (x, Tx)$;
\item $x_n\overset{\norm{\cdot}_X}{\longrightarrow} x$ and $Tx_n\overset{\norm{\cdot}_Y}{\longrightarrow} Tx$.
\end{enumerate}
\end{lemma}
\begin{proof}
We have the equivalences
\begin{align*}
x_n \overset{\norm{\cdot}_T}{\longrightarrow} x &\iff \norm{x_n - x}_T \longrightarrow 0 \\
&\iff \norm{x_n - x}_X + \norm{Tx_n - Tx}_Y \longrightarrow 0 \\
&\iff \norm{(x_n - x, Tx_n - Tx)}_{X\oplus Y} \longrightarrow 0 \\
&\iff \norm{(x_n, Tx_n) - (x, Tx)}_{X\oplus Y} \longrightarrow 0 \\
&\iff (x_n, Tx_n) \overset{\norm{\cdot}_{X\oplus Y}}{\longrightarrow} (x, Tx).
\end{align*}
Now if $x_n\overset{\norm{\cdot}_X}{\longrightarrow} x$ and $Tx_n\overset{\norm{\cdot}_Y}{\longrightarrow} Tx$, then $\norm{x_n - x}_X + \norm{Tx_n - Tx}_Y \longrightarrow 0$. 

Conversely, from
\[ 0 \leq \norm{x_n - x}_X\leq \norm{x_n - x}_X + \norm{Tx_n - Tx}_Y, \]
we get $x_n\overset{\norm{\cdot}_X}{\longrightarrow} x$ by the squeeze theorem (TODO ref). We similarly get $Tx_n\overset{\norm{\cdot}_Y}{\longrightarrow} Tx$.
\end{proof}
\begin{corollary}
The graph norm is strong than then original norm. Both norms are equivalent on $\dom(T)$ \textup{if and only if} $T$ is bounded.
\end{corollary}
\begin{corollary}
Let $T: X\not\to Y$ be an operator between normed spaces. Then the topology induced by the graph norm is equal to the initial topology w.r.t. $\{\id_X: X\to \sSet{X,\norm{\cdot}_X}, T\}$.
\end{corollary}

\subsubsection{Closed operators}

\begin{proposition} \label{boundedBelowClosedRange}
Let $T\in \Lin(X, Y)$ be a closed operator between Banach spaces that is bounded below. Then $\im(T)$ is closed.
\end{proposition}
\begin{proof}
Let $T$ be bounded below by $b$ and let $\seq{Tx_n}$ be a Cauchy sequence in $\im(T)$. Then $\norm{x_m - x_n} \leq \frac{1}{b}\norm{T(x_m - x_n)}$, so $\seq{x_n}$ is also Cauchy by \ref{CauchyCriterion}.

So we can find $x\in X,y\in Y$ such that $x_n\to x$ and $Tx_n\to y$. By closedness of $T$, we have $Tx = y$ and thus $y\in\im(T)$.
\end{proof}

\begin{proposition}
Let $X,Y$ be Banach spaces and $S,T\in \Lin(X,Y)$ with $\dom(S) = \dom(T)$. If $S$ is a closed operator and there exist $\alpha,\beta,\gamma\in \R^+$ such that $0 < \gamma \leq 1$ and $\beta < 1/\gamma$ and
\[ \norm{(S-T)u} \leq \alpha \norm{u} + \beta\norm{Su}^\gamma{u}^{1-\gamma} \qquad\text{for all $u\in \dom(S) = \dom(T)$,} \]
then $T$ is also closed.
\end{proposition}
\begin{proof}
TODO Jeribi.
\end{proof}

\subsubsection{Closable operators}
\begin{definition}
A linear operator is called \udef{closable} if it has closed extension.
\end{definition}

\begin{proposition} \label{closableCriterion}
A linear operator $T$ is closable \textup{if and only if} for all sequences $\seq{x_n}\subset\dom(T)$
\[ \left(x_n\to 0 \land T(x_n)\to v\right) \quad\implies\quad v = 0. \]
\end{proposition}
\begin{proof}
TODO
\end{proof}

\begin{lemma}
A closable operator $T$ has a minimal closed extension $\overline{T}$, which is given by the closure of the graph of $T$.
\end{lemma}
\begin{proof}
TODO
\end{proof}

\begin{lemma} \label{domImClosureOperator}
Let $T$ be a closable operator. Then
\begin{enumerate}
\item $\dom(T)$ is dense in $\dom(\overline{T})$;
\item $\im(T)$ is dense in $\im(\overline{T})$.
\end{enumerate}
\end{lemma}
\begin{proof}
We have $(x,\overline{T}x)\in\graph(\overline{T})$ iff there exists a sequence $\seq{x_n}$ in $\dom(T)$ such that $\seq{x_n,Tx_n}\overset{\norm{\cdot}_{X\oplus Y}}{\longrightarrow} (x,\overline{T}x)$. So we can conclude using \ref{graphNormConvergenceLemma}.
\end{proof}

\begin{lemma}
Let $X,Y$ be normed spaces and $T$ a closable operator such that $\overline{T}$ is injective. Then $\overline{T}^{\,-1} = \overline{T^{-1}}$.
\end{lemma}
\begin{proof}
TODO
\end{proof}

\subsubsection{Domain and core}
\begin{definition}
Let $T: X\not\to Y$ be a closed operator between normed spaces and $D\subseteq \dom(T)$ a subspace. We call $D$ a \udef{core} or \udef{essential domain} for $T$ if $\setbuilder{(x,Tx)}{x\in D}$ is dense in $\graph(T)\subseteq X\oplus Y$.
\end{definition}

\begin{proposition} \label{operatorCoreCriterion}
Let $T: X\not\to Y$ be a closed operator between normed spaces and $D\subseteq \dom(T)$ a subspace. Then $D$ is a core of $T$ \textup{if and only if} $D$ is dense in $\dom(T)$ w.r.t. the graph norm $\norm{\cdot}_T$ of $T$.
\end{proposition}
Note that the norm is bounded by the graph norm, so the graph norm topology is finer than the norm topology by \ref{normComparison}. Thus $\closure_{\norm{\cdot}_T}(D) \subseteq \closure_{\norm{\cdot}}(D)$ and it is not enough for $D$ to be norm dense in $\dom(T)$.
\begin{proof}
Immediate by \ref{graphNormConvergenceLemma}.
\end{proof}






\chapter{Differentiation}
\url{file:///C:/Users/user/Downloads/978-1-4614-3894-6.pdf}
\url{file:///C:/Users/user/Downloads/2011_Bookmatter_TheRicciFlowInRiemannianGeomet.pdf}

\section{Functions with real domain}
\begin{definition}
Let $\sSet{V,\xi}$ be a topological vector space, $f: U\subseteq \R \to V$ a function and $x\in U$. We call $f$ \udef{differentiable} at $x$ if the function
\[ (U - x)\to V: h \mapsto \frac{f(x+h) - f(x)}{h} \]
is continuous at $0$. This limit is called the \udef{derivative} of $f$ at $x$ and is denoted by $f'(x)$. The partial function $f': U\not\to V: x\mapsto f'(x)$ is called the \udef{derivative} of $f$. It is also denoted $\od{f(x)}{x}$.
\end{definition}

\begin{lemma} \label{differentiabilityImpliesContinuity}
Let $\sSet{V,\xi}$ be a convergence vector space, $f: U\subseteq \R \to V$ a function and $x\in U$. If $f$ is differentiable at $x$, then it is continuous at $x$.
\end{lemma}
\begin{proof}
Let $\seq{x_i}_{i\in I}$ be a net in $U$ that converges to $x$. Then $\seq{x_i - x}_{i\in I}$ is a net in $U-x$ that converges to $0$. Then
\[ \frac{f\big(x + (x_i - x)\big) - f(x)}{x_i - x} = \frac{f(x_i) - f(x)}{x_i - x} \to f'(x). \]
By continuity of the scalar multiplication, we have
\[ f(x_i) - f(x) = \frac{f(x_i) - f(x)}{x_i - x}(x_i - x) \to f'(x)\cdot 0 = 0. \]
By continuity of the addition, this implies $f(x_i) \to f(x)$.
\end{proof}

\begin{lemma} \label{derivativeOfConstructions}
Let $\sSet{V,\xi}, \sSet{W,\zeta}$ be convergence vector spaces, $T\in \contLin(V, W)$ a continuous linear function $f,g: U\subseteq \R \to V$ functions and $x\in U$. Suppose $f$ and $g$ are differentiable at $x$, then
\begin{enumerate}
\item $f+g$ is differentiable at $x$ and $(f+ g)'(x) = f'(x)+ g'(x)$;
\item $T\circ f$ is differentiable at $x$ and $(T\circ f)'(x) = T\big(f'(x)\big)$.
\end{enumerate}
\end{lemma}
In particular, combining (1) and (2) gives $(f+\lambda g)' = f'+\lambda g'$.
\begin{proof}
(1) We calculate
\begin{align*}
\lim_{h\to 0} \frac{(f+g)(x+h) - (f+g)(x)}{h} &= \lim_{h\to 0} \frac{f(x+h) - f(x)}{h} + \frac{g(x+h) - g(x)}{h} \\
&= \lim_{h\to 0} \frac{f(x+h) - f(x)}{h} + \lim_{h\to 0}\frac{g(x+h) - g(x)}{h} \\
&= f'(x) + g'(x).
\end{align*}

(2) We calculate
\begin{align*}
\lim_{h\to 0} \frac{(T\circ f)(x+h) - (T\circ f)(x)}{h} &= \lim_{h\to 0} T\Big(\frac{f(x+h)-f(x)}{h}\Big) \\
&= T\Big(\lim_{h\to 0} \frac{f(x+h)-f(x)}{h}\Big) \\
&= T\big(f'(x)\big).
\end{align*}
\end{proof}


\begin{proposition}[Mean value theorem for vector-valued functions] \label{meanValueTheoremVectorFunctions}
Let $X$ be a normed space. Let $a<b\in \R$ and $f: \interval{a,b}\to X$ be a continuous real function that is differentiable on $\interval[o]{a,b}$. Then there exists $c\in \interval[o]{a,b}$ such that
\[ \frac{\norm{f(b)-f(a)}}{b-a} \leq \norm{f'(c)}. \]
\end{proposition}
TODO: straightforward generalisation to seminorms of the form $|h|$, where $h$ is a linear functions. Is this worthwhile?
\begin{proof}
The claim is trivially true if $f(b) = f(a)$. We now assume $f(b) \neq f(a)$.

Let $\omega: X\to \F$ be the functional $\omega_{f(b)-f(a)}$ defined in \ref{existenceBoundedFunctionalOfSameNorm} which sends $f(b)-f(a)$ to $\norm{f(b)-f(a)}$ and has norm $1$. 
Set $g \defeq \omega \circ f: \interval{a,b}\to \F$.
Now we calculate, applying the scalar mean value theorem \ref{meanValueTheorem} to $g$ (from which we obtain $c$) and using \ref{derivativeOfConstructions},
\begin{align*}
\frac{\norm{f(b)-f(a)}}{b-a} &= \Big|\frac{\norm{f(b)-f(a)}}{b-a}\Big| \\
&= \Big|\frac{\omega\big(f(b)-f(a)\big)}{b-a}\Big| \\
&= \Big|\frac{(\omega\circ f)(b)-(\omega \circ f)(a)}{b-a}\Big| \\
&= \Big|\frac{g(b)- g(a)}{b-a}\Big| \\
&\leq \big|g'(c)\big| \\
&= \big|(\omega \circ f)'(c)\big| \\
&= \big|\omega\big(f'(c)\big)\big| \\
&\leq \norm{\omega}\,\norm{f'(c)} \\
&= \norm{f'(c)}.
\end{align*}
\end{proof}
TODO: we have used the mean value theorem for scalared-valued functions $g: \interval{a,b}\to \F$, not the real mean valued theorem. We need to prove this version first, mayby like in the following proof, although it's very redundant. Or some generalised version?

TODO: in the special case of Hilbert spaces we have the following:
\begin{proof}
The claim is trivially true if $f(b) = f(a)$. We now assume $f(b) \neq f(a)$.

Consider the function $g(t) \defeq \inner{f(b)-f(a), f(t)}$. Since $g$ is real-valued, there exists $c\in \interval[o]{a,b}$ such that $g'(c) = \frac{g(b)-g(a)}{b-a}$. Then $g(b)-g(a) = \norm{f(b)-f(a)}^2$ and $g'(c) = \inner{f(b)-f(a), f'(t)}$ (TODO ref). By the Cauchy-Schwarz inequality \ref{CauchySchwarz}, we have
\[ \frac{\norm{f(b)-f(a)}^2}{b-a} = \left|\frac{\norm{f(b)-f(a)}^2}{b-a}\right| = \left|\frac{g(b)-g(a)}{b-a}\right| = |g'(c)| = |\inner{f(b)-f(a), f'(t)}| \leq \norm{f(b)-f(a)} \norm{f'(t)}. \]
Dividing by $\norm{f(b)-f(a)}$ yields the result.
\end{proof}

\begin{proposition} \label{derivativeOfUniformLimit}
Let $X$ be a Banach space, $a,b\in \R$ and $\seq{f_n: \interval{a,b} \to X}_{n\in\N}$ a sequence of differentiable functions. Suppose
\begin{itemize}
\item $\seq{f_n'}$ is a uniform Cauchy sequence;
\item there exists $c\in \interval{a,b}$ such that $\seq{f_n(c)}$ is a Cauchy sequence;
\end{itemize}
then $\seq{f_n}$ converges uniformly to a differentiable function $f: \interval{a,b}\to X$ and $f' = g$.
\end{proposition}
\begin{proof}
Define the functions
\[ g_{x,n}: \R\to X: h\mapsto \frac{f_n(x+h) - f_n(x)}{h}. \]
We first show that $\seq{g_{x,n}}_{n\in \N}$ is a uniform Cauchy sequence. Take arbitrary $\epsilon > 0$. Since $\seq{f_n'}$ is uniform Cauchy, there exists $N\in \N$ such that for all $m,n\geq N$ and all $t\in \interval{a,b}$, we have $\norm{f_n'(t) - f_m'(t)} \leq \epsilon$, by \ref{metricCauchySequence}. By \ref{derivativeOfConstructions}, the function $f_n - f_m$ is differentiable with $(f_n - f_m)' = f_n' - f_m'$, so we can use the mean value theorem \ref{meanValueTheoremVectorFunctions} to calculate, for arbitrary $t\in \interval{a,b}$,
\begin{align*}
\norm{g_{x,n}(h) - g_{x,m}(h)} &= \frac{\norm{f_n(x+h) - f_n(x) - \big(f_m(x+h) - f_m(x)\big)}}{|h|} \\
&= \frac{\norm{\big(f_n - f_m\big)(x) - \big(f_n - f_m\big)(x+h)}}{|h|} \\
&\leq \norm{(f_n - f_m)'(t)} \\
&= \norm{f_n'(t) - f_m'(t)} \leq \epsilon.
\end{align*}
This implies that $\seq{g_{x,n}}_{n\in \N}$ is a uniform Cauchy sequence by \ref{metricCauchySequence}.

Next we show that $\seq{f_n}$ is a uniform Cauchy sequence. Take arbitrary $\epsilon > 0$. Now we can find $N_1\in \N$ such that $\norm{g_{x,n}(t) - g_{x,m}(t)} \leq \frac{\epsilon}{2(b-a)}$ for all $m,n\geq N_1$ and $t\in \interval{a,b}$, by \ref{metricCauchySequence}. We can also find $N_2 \in \N$ such that $\norm{f_n(c) - f_m(c)} \leq \frac{\epsilon}{2}$, also by \ref{metricCauchySequence}. Set $N\defeq \max\{N_1, N_2\}$.
Take arbitrary $m,n\geq N$ and $x\in \interval{a,b}$. We calculate
\begin{align*}
\norm{f_n(x) - f_m(x)} &\leq \norm{f_n(x) - f_n(c) - f_m(x) + f_m(c)} + \norm{f_n(c) - f_m(c)} \\
&\leq \norm{f_n(x) - f_n\big(x + (c-x)\big) - f_m(x) + f_m\big(x + (c-x)\big)} + \frac{\epsilon}{2} \\
&\leq \norm{(c-x)g_{x,n}(c-x) - (c-x)g_{x,m}(c-x)} + \frac{\epsilon}{2} \\
&= |c-x|\norm{g_{x,n}(c-x) - g_{x,m}(c-x)} + \frac{\epsilon}{2} \\
&\leq |c-x|\frac{\epsilon}{2(b-a)} + \frac{\epsilon}{2} \leq \frac{\epsilon}{2}  + \frac{\epsilon}{2}  = \epsilon.
\end{align*}
We conclude that $\seq{f_n}$ is a uniform Cauchy sequence by \ref{metricCauchySequence}.

By \ref{supmetricComplete} and the fact that $X$ is complete, there exists a function $f: \interval{a,b}\to X$ such that $f_n \to f$.

By continuity of addition and scalar multiplication (and the fact that $f_n\to f$), we have $g_{x,n}(h) \to \frac{f(x+h) - f(x)}{h}$ as $n\to \infty$. Set $g_{x}: \R\to X: h\mapsto \frac{f(x+h) - f(x)}{h}$, so $g_{x,n} \to g_x$ pointwise. By \ref{uniformCauchyPointwiseConvergentUniformConvergent}, $g_{x,n} \to g_x$ uniformly.

By definition of the derivative, we have $g_{x,n}(h) \to f_n'(x)$ as $h\to 0$. If $f$ is differentiable, then its derivative at $x$ is given by $\lim_{h\to 0}g_x(h)$.

Thus, using \ref{swapLimitsUniformConvergenceMetricSpaces}, we calculate,
\begin{align*}
\lim_{n\to \infty} f_n'(x) &= \lim_{n\to \infty} \lim_{h\to 0}g_{x,n}(h) \\
&= \lim_{h\to 0} \lim_{n\to \infty} g_{x,n}(h) \\
&= \lim_{h\to 0} g_{x}(h) \\
&= f'(x).
\end{align*}
\end{proof}
TODO: if we add the assumption that the $f'_n$ are continuous, then we have the following proof (TODO: extend to vector case)
\begin{proof}
By \ref{weakSecondTheoremCalculus}, we have
\[ f_n(x) = f_n(c) + \int_c^x f'_n(t)\diff{t}. \]
Now set
\begin{align*}
f(x) \defeq& \lim_{n\to \infty} \Big(f_n(c) + \int_c^x f'_n(t)\diff{t}\Big) \\
=& f(c) + \lim_{n\to \infty}\int_c^x f'_n(t)\diff{t} \\
=& f(c) + \int_c^x g(t)\diff{t},
\end{align*}
where the existence of the limit and its value follow from \ref{interchangeLimitIntegralUniformLimit}.

Since $g$ is continuous (TODO ref), we have $f' = g$ by \ref{firstFundamentalTheoremCalculus}.

Finally, we just need to show that the convergence of $f_n\to f$ is uniform. We use \ref{metricUniformConvergence}. Take arbitrary $\epsilon >0$. Let $N\in \N$ be such that $|f(c) - f_n(c)| \leq \epsilon / 2$ and $|g(x) - f'_n(x)| \leq \frac{\epsilon}{2(b-a)}$ for all $x\in \interval{a,b}$ and $n\geq N$. Then take arbitrary $x\in \interval{a,b}$ and calculate
\begin{align*}
|f(x) - f_n(x)| &= \bigg|\Big(f(c)+\int_c^x g(t) \diff{t}\Big) - \Big(f_n(c)+\int_c^x f_n'(t) \diff{t}\Big)\bigg| \\
&\leq \big|f(c) - f_n(c)\big| + \Big|\int_c^x \big(g(t)- f_n'(t)\big)\diff{t}\Big| \\
&\leq \frac{\epsilon}{2} + \frac{\epsilon}{2(b-a)}\int_a^b\diff{t} \\
&= \frac{\epsilon}{2} + \frac{\epsilon}{2(b-a)}(b-a) = \frac{\epsilon}{2} + \frac{\epsilon}{2} = \epsilon.
\end{align*}
By \ref{metricUniformConvergence} this concludes the proof. 
\end{proof}

\begin{example}
Let $f_n: \interval{0,2\pi} \to \R: x\mapsto \frac{\sin(nx)}{n}$. Then $\seq{f_n}$ converges uniformly to $0$, but $f_n'(x) = \cos(nx)$, which does not converge, even pointwise.
\end{example}


\section{Derivatives of functions between normed groups}
\begin{definition}
Let $G, H$ be normed groups, $f:G\to H$ a function and $x_0\in G$. We call $f$ \udef{differentiable} if there exists a continuous homomorphism $A_{x_0}$ such that
\[ \lim_{x\to 1}\frac{\norm{f(xx_0)f(x_0)^{-1}A_{x_0}(x)^{-1}}}{\norm{x}} = 0. \]
We call $A_{x_0}$ a \udef{derivative} of $f$ at $x_0$.
\end{definition}

\begin{proposition}
Let $G, H$ be normed groups, $f:G\to H$ a function and $x_0\in G$. There exists at most one derivative of $f$ at $x_0$.
\end{proposition}
\begin{proof}
TODO
\end{proof}

\section{Directional derivatives}

\section{For real normed vector spaces}
TODO: directional / Gateaux derivative for locally convex TVSs?
\subsection{Directional derivatives}
\begin{definition}
Let $V,W$ be normed vector spaces and $f:U\subseteq V\to W$ a function defined on an open subset $U$. For $a,u\in V$, we call
\[ \partial_u f|_a \defeq \lim_{t\to 0} \frac{f(a+tu) - f(a)}{t} \]
the \udef{directional derivative} of $f$ at $a$ in the direction $u$,if it exists.

\begin{itemize}
\item If $V= \R^n$, then we define $\pd{f}{x^i}f \defeq \partial_{\vec{e}_i}f$, where $\mathcal{E} = \seq{\vec{e}_i}_{i=1}^n$ is the standard basis of $\R^n$. These directional derivatives are called the \udef{partial derivatives} w.r.t. the basis $\mathcal{E}$.
\item If $V = \R$, then there is, up to scalar multiplication, only one direction $u$. We denote the directional derivative $f'(a) \defeq \partial_u f|_a$.
\end{itemize}
\end{definition}
For a given function $f:V\to W$, the directional derivative is a partial function of both a direction and a point:
\[ (V\times V) \not\to W:\quad (u,a) \mapsto \partial_u f(a)  \]

Partial application in the first argument gives a function
\[ \partial_u f:\; V\not\to W:\; a\mapsto \partial_u f(a) \defeq \partial_u f|_a \]
that is also referred to as the \udef{directional derivative} of $f$ in the direction $u$.

\begin{lemma}
Let $f,g: V\to W$, $u\in V$ and $\lambda\in\F$, then
\begin{enumerate}
\item $\partial_u(f+g) = \partial_uf + \partial_u g$;
\item $\partial_u(fg) = (\partial_uf)g + f(\partial_u g)$;
\item $\partial_u(\lambda f) = \lambda \partial_uf$.
\end{enumerate}
\end{lemma}

\begin{proposition} \label{derivativeBilinearForm}
Let $B: V_1 \oplus V_2 \to W$ be a bilinear form. Then, for $(x,y),(a,b)\in V_1\oplus V_2$
\[ \partial_{(x,y)}B|_{(a,b)} = B(x,b) + B(a,y). \]
\end{proposition}
\begin{proof}
We calculate
\begin{align*}
\partial_{(x,y)}B|_{(a,b)} &= \lim_{t\to 0} \frac{B(a+tx, b+ty) - B(a,b)}{t} \\
&= \lim_{t\to 0} \frac{1}{t} (B(a,b) + tB(a,y) + tB(x,b) + t^2B(x,y) - B(a,b)) \\
&=B(x,b) + B(a,y) + \lim_{t\to 0} tB(x,y) \\
&= B(x,b) + B(a,y).
\end{align*}
\end{proof}

\subsubsection{Partial derivatives}
TODO notation $D^\alpha$ for multiindex $\alpha$. Also $|\alpha| = \sum_i \alpha_i$.

\subsubsection{Gateaux derivative}
\begin{definition}
Let $f:V\to W$ be a function between normed spaces. If $\partial_u f|_a$ exists for all $u\in V$, then we call the partial application of the directional derivative in the second argument
\[ \diff{_af}: V\not\to W: u\mapsto \diff{_af}(u) \defeq \partial_u f|_a = \lim_{t\to 0} \frac{f(a+tu) - f(a)}{t} \]
the \udef{Gateaux differential} of $f$ at the point $a$.

If $\diff{_af}: V\not\to W$ is a bounded linear map, we will refer to it as the \udef{Gateaux derivative}.
\end{definition}
The Gateaux differential is homogeneous even if it is not linear:
\begin{lemma}
Let $f:V\to W$ be a function between normed spaces and $a,u\in V$. If $\partial_u f$ is defined at $a$, then
\[ \diff{_a f}(\lambda u) = \partial_{\lambda u}f(a) = \lambda\partial_u f(a) = \lambda \diff{_a f}(u) \qquad \forall \lambda\in\F. \]
\end{lemma}
\begin{proof}
$\partial_{\lambda u}f(a) = \lim_{t\to 0} \frac{f(a+t\lambda u) - f(a)}{t} = \lim_{t\lambda\to 0} \frac{f(a+t\lambda u) - f(a)}{t \lambda / \lambda} = \lambda\partial_u f(a)$.
\end{proof}

TODO mean value theorem?

\begin{example}
The function
\[ f: \R^2\to \R: (x,y) \mapsto \begin{cases}
\frac{x^2y}{x^2+y^2} & (x,y)\neq (0,0) \\0 & (x,y) = (0,0)
\end{cases} \]
has a Gateaux differential that is defined everywhere, but is non-linear.

TODO??
\end{example}

\begin{proposition}[Chain rule for Gateaux differential]
Let $U,V,W$ be normed spaces and $f: U\to V$, $g: V\to W$ be functions. Suppose the Gateaux differential of $f$ at $u\in U$ exists and the Gateaux differential of $g$ at $f(u)$ exists, then the Gateaux differential of $g\circ f$ at $u$ exists and
\[ \diff_{u}\big(g\circ f\big) = \big(\diff{_{f(u)}}g\big) \circ \big(\diff{_u}f\big). \]
If both $\diff{_u}f$ and $\diff{_{f(u)}}g$ are Gateaux derivatives, then $\diff_{u}\big(g\circ f\big)$ is a Gateaux derivative.
\end{proposition}
\begin{proof}
TODO!
\end{proof}

\subsection{Hadamard derivative}

\subsection{Fréchet derivative}
\begin{definition}
If a function has a (bounded linear) Gateaux derivative at $a$ and the limit in the definition of the derivative
\[ \diff{_af}: V\not\to W: u\mapsto \diff{_af}(u) \defeq \partial_u f|_a = \lim_{t\to 0} \frac{f(a+tu) - f(a)}{t} \]
is uniform in all $u$ on the $S(\vec{0},1)$, then we say the function is \udef{(Fréchet) differentiable} at $a$ and has \udef{Fréchet derivative} $\diff{_af}$.

We may also write $\diff{f}$, leaving the $a$ implicit.
\end{definition}

\begin{proposition} \label{FrechetDerivativeAsymptotics}
Let $V,W$ be normed vector spaces and $f:U\subseteq V\to W$ a function defined on an open subset $U$. Let $a\in V$.

Then $f$ is Fréchet differentiable at $a$ \textup{if and only if} there exists a bounded linear map $A: V\to W$ such that $f(a+x)$ can be written as
\[ f(a+x) = f(a) + A(x) + o\big(\norm{x}\big) \qquad \text{as} \qquad x\to 0. \]
In this case $A = \diff{_af}$.
\end{proposition}
\begin{proof}
First assume $f$ is Fréchet differentiable at $a$. Then
\begin{multline*}
\forall \varepsilon>0:\exists \delta>0: \; \forall u\in S(\vec{0},1): \forall t\in\R: \; t< \delta \implies \varepsilon > \\ \norm{\frac{f(a+tu) - f(a)}{t} - \diff{_af}(u)} = \frac{\norm{f(a+tu) - f(a)- \diff{_af}(tu)}}{|t|} = \frac{\norm{f(a+tu) - f(a)- \diff{_af}(tu)}}{\norm{tu}}.
\end{multline*}

Now each vector $x$ in $V$ can be written as $tu$ for some $t\in\R$ and $u\in S(\vec{0},1)$, so this can be written as
\[ \forall \varepsilon>0:\exists \delta>0: \; \forall x\in V: \; \norm{x}< \delta \implies  \varepsilon > \frac{\norm{f(a+x) - f(a)- \diff{_af}(x)}}{\norm{x}} \]
which is exactly the statement $f(a+x) = f(a) + \diff{_af}(x) + o(x)$ as $x\to 0$.

The logic can be reversed to obtain the equivalence.
\end{proof}

\begin{proposition}
If a function is Fréchet differentiable at a point $a$, then it is continuous at $a$.
\end{proposition}
\begin{proof}
Assume $f$ is has Fréchet derivative $A$. Then
\[ 0 = \lim_{x\to a} \norm{f(x) - f(a) - \diff{_af}(x-a)} = \norm{\lim_{x\to a}f(x) - f(a) - \diff{_af}(\lim_{x\to a} x-a)} = \norm{\lim_{x\to a}f(x) - f(a)}. \]
\end{proof}

\begin{lemma}
The Fréchet derivative is the same for equivalent norms.
\end{lemma}

\begin{proposition}[Chain rule for Fréchet derivative] \label{FrechetChainRule}
Let $U,V,W$ be normed spaces and $f: U\to V$, $g: V\to W$ be functions. Suppose $f$ is Fréchet differentiable at $u\in U$ and $g$ is Fréchet differentiable at $f(u)$, then $g\circ f$ is Fréchet differentiable at $u$ and
\[ \diff_{u}\big(g\circ f\big) = \big(\diff{_{f(u)}}g\big) \circ \big(\diff{_u}f\big). \]
\end{proposition}
\begin{proof}
Take $x\in U$. Then
\begin{align*}
(g\circ f)(u+x) &= g\Big(f(u) + \big(\diff{_uf}\big)(x) + o\big(\norm{x}\big)\Big) \\
&= (g\circ f)(u) + \big(\diff{_f(u)}\big)\Big(\big(\diff{_uf}\big)(x) + o\big(\norm{x}\big)\Big) + o\big(\norm{x}\big) \\
&= (g\circ f)(u) + \Big(\big(\diff{_f(u)}\big)\circ \big(\diff{_uf}\big)\Big)(x) + \big(\diff{_f(u)}\big)\big(o\big(\norm{x}\big)\big) + o\big(\norm{x}\big).
\end{align*}
We just need to observe that $\big(\diff{_f(u)}\big)\big(o\big(\norm{x}\big)\big)$ is $o\big(\norm{x}\big)$ as $x\to 0$, which is immediate since $\diff{_f(u)}$ is a bounded linear function.
\end{proof}

\subsubsection{Link with Gateaux derivative}
\url{https://link.springer.com/content/pdf/bbm%3A978-3-642-16286-2%2F1.pdf}
\url{http://www.m-hikari.com/ams/ams-password-2008/ams-password17-20-2008/behmardiAMS17-20-2008.pdf}
\begin{proposition}
If a function between subsets of normed spaces is Fréchet differentiable, it is also Gateaux differentiable and the Fréchet derivative is equal to the Gateaux derivative.
\end{proposition}
\begin{proof}
Let $A$ be the Fréchet derivative of $f: U\subseteq V\to W$. Then for all $u\in V$
\begin{align*}
0 &= \lim_{t\to 0} \frac{\norm{f(a+tu) - f(a) - A(tu)}}{\norm{tu}} = \lim_{t\to 0} \frac{\norm{(f(a+tu) - f(a))/t - A(u)}}{\norm{u}} \\
&= \frac{\norm{\lim_{t\to 0}(f(a+tu) - f(a))/t - A(u)}}{\norm{u}} = \frac{\norm{\diff{_af}(u) - A(u)}}{\norm{u}}. 
\end{align*}
\end{proof}
For this reason we will also denote the Fréchet derivative of $f$ at $a$ as $\diff{_a f}$. We will sometimes also write $f'(a)$.

\begin{example}
TODO!

There are functions that have a Gateaux derivative, but not a Fréchet derivative at certain points. For example
\[ f: \R^2\to \R: (x,y) \mapsto \begin{cases}
\frac{xy}{x^2+y^2} & (x,y)\neq (0,0) \\0 & (x,y) = (0,0)
\end{cases} \]
which has $\partial_{\vec{u}}f(\vec{0}) = 0$ for all $\vec{u}\in \R^2$ and thus the Gateaux derivative at zero is $\diff{f} = 0$.

Composing $f$ with $t\mapsto (t,t^2)$ yields the function $t\mapsto \begin{cases}
t^{-2} & t\neq 0 \\ 0 & t=0
\end{cases}$, which is not continuous at $0$. So $f$ is not continuous at zero and a fortiori is not Fréchet differentiable.
\end{example}

\begin{proposition}
If there exists a basis $\beta$ of $V$ such that the partial derivatives of $f:U\subseteq V\to W$ w.r.t. $\beta$ exist and are continuous in $a\in V$, then $f$ is Fréchet differentiable in $a$.
\end{proposition}
\begin{proof}

\end{proof}
TODO for finite dimensions! Expand to criterion for Gateaux to Fréchet.
\begin{example}

\end{example}

\subsubsection{The Jacobian}
\begin{definition}
Let $f:U\subseteq\R^m\to\R^n$ be a function. Then $A_{\diff{f}}$ is a matrix with
\[ [A_{\diff{f}}]_{ij} = [\diff{f}\vec{e}_j]_i = \left[\pd{f}{x^j}\right]_i. \]
This matrix is called the \udef{Jacobian} $J_f$.
\end{definition}


\subsection{Differentiation in a convergence algebra}

\begin{proposition}[Leibniz rule] \label{LeibnizRuleDerivativeAlgebra}
Let $A$ be a normed algebra and $a,b\in (\R \to A)$ elements that have derivatives. Then
\[ (ab)' = a'b + ab'. \]
\end{proposition}
\begin{proof}
We calculate
\begin{align*}
0 &= 0\cdot a'(t)b'(t) = \lim_{\epsilon \to 0} \epsilon a'(t)b'(t) \\
&= \lim_{\epsilon \to 0} \epsilon \frac{a(t+\epsilon) - a(t)}{\epsilon}\frac{b(t+\epsilon) - b(t)}{\epsilon} \\
&= \lim_{\epsilon \to 0}\frac{a(t+\epsilon)b(t+\epsilon) - a(t+\epsilon)b(t) - a(t)b(t+\epsilon) + a(t)b(t)}{\epsilon} + \frac{a(t)b(t)}{\epsilon} - \frac{a(t)b(t)}{\epsilon} \\
&= \lim_{\epsilon \to 0} \frac{a(t+\epsilon)b(t+\epsilon) - a(t)b(t)}{\epsilon} - \frac{a(t+\epsilon) - a(t)}{\epsilon}b(t) - a(t)\frac{b(t+\epsilon) - b(t)}{\epsilon} \\
&= (ab)' - a'b - ab'.
\end{align*}
\end{proof}

\begin{proposition} \label{derivativeIdempotent}
Let $A$ be an algebra and $p\in A$ such that $p^2 = p$ and $p'$ exists. Then
\begin{enumerate}
\item $p' = pp'+ p'p$;
\item $pp'p = 0$;
\item $(p')^2 = p'pp' + p(p')^2p$;
\item $p^{\prime\prime} = 2(p')^2 + pp^{\prime\prime} + p^{\prime\prime}p$;
\item $pp^{\prime\prime}p = -2p(p')^2p$.
\end{enumerate}
\end{proposition}
\begin{proof}
(1) We calculate $p' = (p^2)' = pp'+ p'p$.

(2) Multiply (1) by $p$ on the left and right.

(3) We calculate $(p')^2 = (pp'+ p'p)(pp'+ p'p) = pp'pp' + pp'p'p + p'ppp' + p'pp'p = 0p + pp'p'p + p'pp' + p'0$.

(4) Take derivative of (1).

(5) Multiply (4) by $p$ on the left and right.
\end{proof}
\begin{corollary}
Let $\Tr$ be a trace functional on $A$ and $p\in A$ as before. Then $\Tr(p') = 0$.
\end{corollary}
\begin{proof}
$\Tr(p') = \Tr(pp'+ p'p) = \Tr(p^2p')+ \Tr(p'p^2) = \Tr(pp'p) + \Tr(pp'p) = 2\Tr(0) = 0$.
\end{proof}
\begin{proposition}
Let $p_0,p_1$ be differentiable idempotents such that $p_0p_1 = 0 = p_1p_0$. Then $p_0'p_1 = -p_0p_1'$.
\end{proposition}
\begin{proof}
We have $0 = p_0p_1$, so $0 = 0' = p_0'p_1 + p_0p_1'$.
\end{proof}
\begin{corollary}
Let $p_0,p_1$ be differentiable idempotents such that $p_0p_1 = 0 = p_1p_0$. Then
\begin{enumerate}
\item $p_1p_0'p_0 = -p_1p_1'p_0$;
\item $p_1p_0'p_1 = 0$;
\item $p_1(p_0')^2p_1 = p_1p_1'p_0p_1'p_1$;
\item $p_0(p_0')^2p_1 = 0$;
\item $p_1p^{\prime\prime}_0p_1 = 2p_1(p_0')^2p_1$.
\end{enumerate}
If in addition $p_2$ is a differentiable idempotent such that $p_0p_2 = 0 p_2p_0$ and $p_1p_2 = 0 p_2p_1$, then
\begin{enumerate} \setcounter{enumi}{5}
\item $p_1p_0'p_2 = 0$.
\end{enumerate}
\end{corollary}
\begin{proof}
(1) We have
\[ p_1p_0'p_0 = p_1(p_1p_0')p_0 = -p_1(p_1'p_0)p_0 = -p_1p_1'p_0. \]

(2) We have $p_1p_0'p_1 = -(p_1'p_0)p_1 = -p_1'(p_0p_1) = 0$.

(3) We have $p_1(p_0')^2p_1 = (p_1p_1p_0')(p_0'p_1p_1) = (p_1p_1'p_0)(p_0p_1'p_1)$.

(4) We have $p_0(p_0')^2p_1 = (p_0p_0')(p_0'p_1) = -(p_0p_0')(p_0p_1') = -(p_0p_0'p_0)p_1' = 0$.

(5) We have, using \ref{derivativeIdempotent}, $p_1p^{\prime\prime}_0p_1 = p_1(2(p'_0)^2 + p_0p_0^{\prime\prime} + p_0^{\prime\prime}p_0)p_1 = 2p_1(p_0')^2p_1$.

(6) We have $(p_1p_0')p_2 = - (p_1'p_0)p_2 = - p_1'(p_0p_2) = 0$.
\end{proof}
\begin{corollary} \label{derivativeIdempotentOffDiagonal}
Let $p_0,p_1$ be differentiable idempotents such that $p_0p_1 = 0 = p_1p_0$ and $p_0 + p_1 = 1$. Then
\begin{enumerate}
\item $p_0' = p_0p_0'p_1 + p_1p_0'p_0$;
\item $p_0p_0' = p_0'p_1$ and $p_0'p_0 = p_1p_0'$.
\end{enumerate}
\end{corollary}
\begin{proof}
(1) We have
\[ p_0' = (p_0 + p_1)p_0'(p_0 + p_1) = \cancel{p_0p_0'p_0} + p_0p_0'p_1 + p_1p_0'p_0 + \cancel{p_1p_0'p_1}. \]

(2) We have, using point (1),
\[ p_0p_0' = p_0(p_0p_0'p_1) + p_0(p_1p_0'p_0) = p_0p_0'p_1 = (p_0p_0'p_1)p_1 + (p_1p_0'p_0)p_1 = p_0'p_1. \]
The other equation is similar.
\end{proof}


\begin{proposition}
Let $A$ be a convergence algebra and $a: U\subseteq\C \to A$.

If $a$ is differentiable and $a(t)^{-1}$ exists for all $t\in \R$, then
\[ \od{a^{-1}}{t} = -a^{-1}a'a^{-1}. \]
\end{proposition}
\begin{proof}
We have
\begin{align*}
\od{}{t}a^{-1} &= \lim_{h\to 0}\frac{a(t+h)^{-1} - a(t)^{-1}}{h} \\
&= \lim_{h\to 0} -\frac{a(t)^{-1}a(t+h)a(t+h)^{-1} - a(t)^{-1}a(t)a(t+h)^{-1}}{h} \\
&= \lim_{h\to 0} -\frac{a(t)^{-1}\Big(a(t+h) - a(t)\Big)a(t+h)^{-1}}{h} \\
&= -a(t)^{-1}\left(\lim_{h\to 0}\frac{\big(a(t+h) - a(t)\big)a(t+h)^{-1}}{h}\right)\Big(\lim_{h\to 0}a(t+h)^{-1}\Big) \\
&= -a(t)^{-1}a'a^{-1}.
\end{align*}
\end{proof}

\subsubsection{Derivative of determinant}
\begin{proposition} \label{DerivativeDeterminantAtIdentity}
Let $\F$ be a field and $A\in \F^{n\times n}$. Then $\diff{_{\mathbb{1}_n}\det} = \Tr$, where the derivative is a Fréchet derivative.
\end{proposition}
In other words, the Fréchet derivative of the determinant function $\det: \F^{n\times n}\to \F$ at $\mathbb{1}_{n}$ is the trace function $\Tr:\F^{n\times n}\to \F$.
\begin{proof}
We use \ref{FrechetDerivativeAsymptotics} to show that it is the Fréchet derivative. To that end, we expand using \ref{expansionDeterminantAroundIdentity}:
\begin{align*}
\det(\mathbb{1}_n + X) &= \det(\mathbb{1}_n + \frac{\norm{X}}{\norm{X}}X) \\
&= 1 + \norm{X}\Tr\Big(\frac{X}{\norm{X}}\Big) + {\norm{X}}^2 P({\norm{X}}) \\
&= \det(\mathbb{1}_n) + \Tr(X) + {\norm{X}}^2 P({\norm{X}}),
\end{align*}
so we just need to show that ${\norm{X}}^2 P({\norm{X}})$ is $o(X)$ as $X\to 0$. For $X$ such that $\norm{X} \leq 1$, we use the bound in \ref{expansionDeterminantAroundIdentity} (and the fact that $\norm{X/\norm{X}} = 1$) to calculate
\begin{align*}
0\leq \frac{{\norm{X}}^2 P({\norm{X}})}{\norm{X}} &= {\norm{X}} P({\norm{X}}) \\
&\leq {\norm{X}} P(1) \\
&\leq \norm{X}\big(1 + n + n!2^n\big).
\end{align*}
The last term converges to $0$ as $X\to 0$, so ${\norm{X}}^2 P({\norm{X}})$ is $o(X)$ as $X\to 0$ by the squeeze theorem \ref{squeezeTheorem}.
\end{proof}

\begin{proposition}[Jacobi's formula] \label{JacobisFormula}
Let $U\subseteq \R$ be an open set and $A: U\to \F^{n\times n}$ a differentiable function. Then
\[ \od{}{t}\Big|_{t=t_0}\det\big(A(t)\big) = \Tr\Big(\adj\big(A(t_0)\big)A'(t_0)\Big). \]
If $A(t_0)$ is invertible, then
\[ \od{}{t}\Big|_{t=t_0}\det\big(A(t)\big) = \det\big(A(t_0)\big)\Tr\Big(A^{-1}(t_0)A'(t_0)\Big). \]
\end{proposition}
\begin{proof}
We first prove the second assertion, assuming $A(t_0)$ is invertible. Using \ref{DerivativeDeterminantAtIdentity} and the chain rule \ref{FrechetChainRule}, we calculate
\begin{align*}
\dod{}{t}\Big|_{t=t_0}\det\big(A(t)\big) &= \dod{}{t}\Big|_{t=t_0}\det\big(A(t_0)A(t_0)^{-1}A(t)\big) \\
&= \det\big(A(t_0)\big)\dod{}{t}\Big|_{t=t_0}\det\big(A(t_0)^{-1}A(t)\big) \\
&= \det\big(A(t_0)\big)\big(\diff{_{\mathbb{1}_n}\det}\big)\Big(A(t_0)^{-1}\dod{}{t}\Big|_{t=t_0}A'(t)\Big) \\
&= \det\big(A(t_0)\big)\Tr\Big(A(t_0)^{-1}A'(t_0)\Big).
\end{align*}
For the first assertion, first assume $A(t_0)$ is invertible. Then, by \ref{inverseAdjunctDeterminant},
\begin{align*}
\od{}{t}\Big|_{t=t_0}\det\big(A(t)\big) &= \det\big(A(t_0)\big)\Tr\big(A^{-1}(t_0)A'(t_0)\big) \\
&= \Tr\Big(\det\big(A(t_0)\big)A^{-1}(t_0)A'(t_0)\Big) \\
&= \Tr\Big(\adj\big(A(t_0)\big)A'(t_0)\Big).
\end{align*}
Now suppose $A(t_0)$ is not invertible. Since the invertible elements are dense in the space of all matrices, by \ref{finiteDimensionsInvertiblesDense}, we can find a sequence $\seq{B_n}$ of invertible matrices that converges to $A(t_0)$ by \ref{existenceConvergentSequenceDenseSubset}. TODO: finish argument!
\end{proof}
\begin{corollary}
Let $B\in \F^{n\times n}$. Then $\det(e^{B}) = e^{\Tr(B)}$.
\end{corollary}
\begin{proof}
Setting $A(t) = e^(t B)$ in the Jacobi formula gives $\od{}{t}\det(e^{tB}) = \det(e^{tB})Tr(e^{-tB}Be^{tB}) = \det(e^{tB})Tr(B)$. Solving this differential equation yields $\det(e^{tB}) = e^{t\Tr(B)}$.
\end{proof}

\section{Analytic functions}
TODO: multiindex notation
\begin{definition}
Let $M$ be a convergence module over a ring $R$ and $n\in\N$. A function $f: R^n\to M$ is called \udef{analytic} if
\[ f(x) = \sum_{I\in\N^n}c_I(x-x_0)^I \]
where $c_I\in M^n$ and $x_0\in R^n$.
\end{definition}

\subsection{Taylor expansion}
Radius of convergence

\subsection{Properties of analytic functions}
\begin{proposition}
Let $f$ be an analytic function. Then
\begin{enumerate}
\item $f$ is continuous;
\item $f$ is differentiable.
\end{enumerate}
\end{proposition}

\section{Classification of spaces}
\begin{definition}
Let $X,Y$ be subsets of normed vector spaces and $X$ be open. We call a function $f: X\to Y$
\begin{itemize}
\item \udef{smooth} at $x_0\in V$ if all derivatives of $f$ at $x_0$ exist;
\item \udef{analytic} at $x_0\in V$ if the Taylor series of $f$ at $x_0$ exists and has non-zero radius of convergence.
\end{itemize}
\end{definition}
\begin{lemma}
Let $f: X\to Y$ be a smooth function. Then all derivatives are continuous.
\end{lemma}

\begin{definition}
Let $X,Y$ be subsets of normed vector spaces and $X$ be open.
\begin{itemize}
\item $\cont^r(X,Y)$ is the space of functions in $(X \to Y)$ whose first $r$ derivatives exist and are continuous;
\item $\cont^\infty(X,Y)$ is the space of functions in $(X \to Y)$ that are smooth at all points in $X$;
\item $\cont^\omega(X,Y)$ is the space of functions in $(X \to Y)$ that are analytic at all points in $X$.
\end{itemize}
If $Y = \C$, we write $\cont^r(X), \cont^\infty(X)$ and $\cont^\omega(X)$. We can also use subscripts $_0$ and $_c$ to denote the extra conditions of vanishing at infinity and having compact support.
\end{definition}







\chapter{Banach algebras}
In this part we set $\F \in \{\R, \C\}$. Usually operator algebras are assumed to be complex. We will attempt to give results for real algebras where possible.
\begin{definition}
A \udef{normed algebra} is an associative algebra $A$ over $\F$ with norm $\norm{\cdot}$ such that $(\F, A,+, \norm{\cdot})$ is a normed space and we have \udef{submultiplicativity}, i.e.
\[ \forall x,y\in A: \quad \norm{xy}\leq\norm{x}\norm{y}. \]
We say $A$ is \udef{unital} if there exists a unit element $\vec{1}\in A$ such that
\[ \forall x\in A: \vec{1}\cdot x = x = x\cdot \vec{1} \qquad \text{and} \qquad \norm{\vec{1}} = 1. \]
\end{definition}
TODO: which results also hold for normed algebras?
\begin{definition}
A \udef{Banach algebra} is a normed algebra that is also a Banach space.
\end{definition}

\begin{proposition}
Let $X,Y$ be normed spaces. Then $\Bounded(X,Y)$ is a unital normed algebra.

The algebra $\Bounded(X,Y)$ is a Banach algebra \textup{if and only if} $Y$ is a Banach space.
\end{proposition}
\begin{proof}
We have $\Bounded(X,Y)\subseteq \Lin(X,Y)$. which is an algebra by \ref{linearMapsAlgebra}. Closure under multiplication follows from \ref{operatorNormIsNorm} and \ref{existenceOperatorNorm}. Submultiplicativity is also given by \ref{operatorNormIsNorm}.

The algebra is unital because the identity operator is bounded.

The condition for $\Bounded(X,Y)$ to be a Banach algebra is given by \ref{boundedOperatorsFormBanachSpace}.
\end{proof}

\begin{lemma} \label{multiplicationContinuous}
Let $A$ be a Banach algebra. The multiplication map $\cdot: A\times A \to A: (x,y)\mapsto xy$ is continuous.
\end{lemma}
\begin{proof}
Because $A\times A$ is a metric space, we can combine \ref{sequentialContinuity} and \ref{convergenceFiniteProductTopology} to conclude that the multiplication map is continuous iff $x_ny_n \to xy$ whenever $x_n \to x$ and $y_n \to y$.

Assume $x_n \to x$ and $y_n \to y$. Then
\begin{align*}
\norm{x_ny_n - xy} &= \norm{x_ny_n - xy_n + xy_n - xy} \leq \norm{(x_n-x)y_n}+ \norm{x(y_n-y)}\\ 
&\leq \norm{x_n-x}\cdot\norm{y_n}+ \norm{x}\cdot\norm{y_n-y} = \norm{x_n-x}\cdot\norm{y_n-y+y}+ \norm{x}\cdot\norm{y_n-y}\\
&\leq \norm{x_n-x}\cdot(\norm{y_n-y} + \norm{y})+ \norm{x}\cdot\norm{y_n-y} \to 0
\end{align*}
\end{proof}
As a consequence multiplication by a fixed factor, $x\mapsto cx$ or $x\mapsto xc$ for some $c$, is also continuous, by \ref{productInclusionsContinuous}. This is also immediate from the boundedness of multiplication $\norm{xy}\leq\norm{x}\norm{y}$ and \ref{boundedLinearMaps}.

\begin{lemma}
Let $A$ be a Banach algebra and $D\subset A$ a subset. Suppose $a\in A$ commutes with all elements of $D$, then $a$ commutes with the closure $\overline{D}$.
\end{lemma}
\begin{proof}
Take an arbitrary element $d\in \overline{D}$. Take an arbitrary $\epsilon >0$. Then we can find an $x\in D$ such that $\norm{x-d}\leq \epsilon$. Then, using that $a$ and $x$ commute,
\begin{align*}
\norm{ad - da} &= \norm{a(d+x-x) - (d+x-x)} \\
&= \norm{a(d-x) - (d-x)a} \leq 2\epsilon \norm{a}.
\end{align*}
Because we can choose $\epsilon$ arbitrarily small, $\norm{ad - da}$ must be zero.
\end{proof}

\begin{proposition} \label{smallestBanachAlgebra}
Let $A$ be a Banach algebra and $S\subset A$ a subset. Then
\[ \mathcal{B}(S) \defeq \overline{\Span}\setbuilder{s_1\cdot s_2 \cdot \ldots \cdot s_k}{k\geq 1, s_1,\ldots, s_k \in S} \]
is the smallest Banach subalgebra in $A$ that contains $S$.
\end{proposition}

\section{Unitisation}
\begin{definition}
Let $A$ be a Banach algebra. Then the \udef{unitisation} of $A$ is the algebra $A^\dagger = A\oplus \F$ with multiplication
\[ (x,\lambda)\cdot (y,\mu) = (xy+\lambda y + \mu x, \lambda\mu) \]
and a norm that extends the norm $\norm{\cdot}$ on $A$ to a norm on $A^\dagger$. In other words, there is an isometric embedding
\[ A \hookrightarrow A^\dagger: x\mapsto (x,0). \]
\end{definition}
TODO: is $A^\dagger$ necessarily complete?
\begin{lemma}
For any Banach algebra $A$, $A^\dagger$ is a unital Banach algebra with unit $\vec{1} = (0,1)$.
\end{lemma}
\begin{proof}
TODO: is $A^\dagger$ necessarily complete?
\end{proof}
It is possible to use multiple norms for the unitisation.
\begin{proposition} \label{normsOfUnitisation}
Let $A$ be a Banach algebra. Of the possible norms for $A^\dagger$, the $1$-norm
\[ \norm{(x,\lambda)}_1 = \norm{x}+|\lambda| \]
is minimal and the operator norm
\[ \norm{(x,\lambda)}_{op} = \sup\setbuilder{\norm{xa + \lambda a}}{a\in A \land \norm{a}\leq 1} \]
is maximal. All possible norms are equivalent.
\end{proposition}
\begin{proof}
TODO: prove the operator norm is actually a norm and isometric.
\end{proof}

\begin{definition}
We define
\[ \tilde{A} \defeq \begin{cases}
A & \text{if $A$ unital} \\
A^\dagger & \text{if $A$ non-unital.}
\end{cases} \]
If a Banach algebra $A$ is unital, we can identify $\F$ with $\F\cdot \vec{1} \subseteq A$.
\end{definition}

Alternatively we could define $\tilde{A}$ as the smallest unital Banach algebra containing $A$.

\begin{lemma} \label{algebraIdealInUnitisation}
Let $A$ be a Banach algebra. Then $A$ is a maximal ideal of $A^\dagger$.
\end{lemma}

\begin{lemma}
Let $A$ be a Banach algebra. We have the split exact sequence
\[ \begin{tikzcd}
0 \rar & A \rar[hook, "\iota"] & A^\dagger \rar[shift left, "\pi_2"] & \lar[hook, shift left, "\lambda"] \F \rar & 0.
\end{tikzcd} \]
\end{lemma}

\begin{lemma} \label{unitalProjectionsAlgebraHomomorphisms}
Let $A$ be a Banach algebra. Then
\begin{enumerate}
\item $\proj_2: A^\dagger \to \F$ is a unital algebra homomorphism;
\item $\proj_1: \setbuilder{(a,0)}{a\in A}\subseteq A^\dagger \to A$ is an algebra homomorphism.
\end{enumerate}
\end{lemma}
\begin{proof}
(1) Linearity and unitality are immediate. For multiplicativity, take $(a,\lambda), (b, \mu)\in A^\dagger$. Then
\[ \proj_2\big((a,\lambda)(b, \mu)\big) = \proj_2\big(ab+\lambda b + \mu a, \lambda\mu\big) = \lambda\mu = \proj_2(a,\lambda)\proj_2(b,\mu). \]

(2) Linearity and unitality are immediate. For multiplicativity, take $(a,0), (b, 0)\in A^\dagger$. Then
\[ \proj_1\big((a,0)(b, 0)\big) = \proj_1\big(ab+0 b + 0 a, 0\big) = ab = \proj_1(a,0)\proj_2(b,0). \]
\end{proof}

\begin{lemma}
Let $A,B$ be Banach algebras. Every algebra homomorphism $\Psi:A\to B$ extends uniquely to a unital homomorphism $\Psi^\dagger: A^\dagger \to B^\dagger$:
\[ \Psi^\dagger: A^\dagger \to B^\dagger: (a,\lambda) \mapsto (\Psi(a),\lambda). \]
\end{lemma}
\begin{proof}
We want $\Psi^\dagger((a,0)) = (\Psi(a),0)$ for all $a\in A$. Because $\Psi$ is unital, we have $\Psi^\dagger((\vec{0},1)) = (\vec{0},1)$. So
\[ \Psi^\dagger((a,\lambda)) = \Psi^\dagger((a,0))+\lambda \Psi^\dagger((\vec{0},1)) = (\Psi(a),0) + \lambda(\vec{0},1) = (\Psi(a),\lambda). \]
\end{proof}
\begin{corollary} \label{projectionOnACommutes}
Let $\pi_1: A^\dagger \to A$ be the projection on the first component: $\pi_1(a,\alpha) = a$.

The unital extension $\Psi^\dagger$ commutes with $\pi_2$:
\[ \pi_2\circ\Psi^\dagger = \Psi^\dagger \circ \pi_2 = \Psi\circ \pi_2. \]
Restricted to $A$, this is equal to $\Psi$.
\end{corollary}

\begin{definition}
As before we set, for $\Psi: A \to B$ an algebra homomorphism
\[ \tilde{\Psi} = \begin{cases}
\Psi & \text{if $A$ unital} \\
\Psi^\dagger & \text{if $A$ non-unital.}
\end{cases} \]
Thus $\tilde{\Psi}$ is a function on $\tilde{A}$.
\end{definition}

\begin{lemma} \label{DaggerMorphismProperties}
Let $A,B$ be Banach algebras and $\Psi:A\to B$ and algebra homomorphism. Then
\begin{enumerate}
\item $\im(\Psi^\dagger) = (\im\Psi)^\dagger$;
\item $\ker(\Psi^\dagger) = \ker(\Psi)\oplus\{0\}$;
\item $\Psi^\dagger$ is injective \textup{if and only if} $\Psi$ is injective;
\item $\Psi^\dagger$ is surjective \textup{if and only if} $\Psi$ is surjective;
\item $\norm{\Psi^\dagger} = \max\{\norm{\Psi},1\}$;
\item $\Psi^\dagger$ is isometric \textup{if and only if} $\Psi$ is isometric.
\end{enumerate}
\end{lemma}
\begin{proof}
The third point follows from the second and \ref{injectivityKernelTriviality}.
\end{proof}

\begin{definition}
Let $A$ be a Banach algebra. We define the \udef{scalar mapping} to be
\[ s = \lambda\circ \pi: A^\dagger \to A^\dagger: (a,\lambda) \mapsto (0,\lambda). \]
\end{definition}
Notice that $\pi\circ s = \pi$.

\subsection{Approximate units}
\begin{definition}
Let $A$ be a Banach algebra. A net $(e_\lambda)_{\lambda\in\Lambda}$ is an \udef{approximate unit} if
\begin{enumerate}
\item $\norm{e_\lambda}\leq 1$ for all $\lambda$;
\item $a = \lim_{\lambda\to \infty} e_\lambda \cdot a = \lim_{\lambda\to \infty} a \cdot e_\lambda$.
\end{enumerate}
We call $(e)_\lambda$ is an \udef{increasing approximate unit} if $\lambda_0 \leq \lambda_1$ implies $0\leq e_{\lambda_0} \leq e_{\lambda_1}$.
\end{definition}
\begin{lemma}
If $A$ is unital, any approximate unit in $A$ converges to $\vec{1}$.
\end{lemma}
\begin{proof}
We have $\vec{1} = \lim_{\lambda\to\infty}e_\lambda\cdot \vec{1} = \lim_{\lambda\to\infty}e_\lambda$.
\end{proof}

\section{Neumann series}
\begin{proposition}[Neumann series] \label{NeumannSeries}
Let $A$ be a unital Banach algebra and $x\in A$. 
If $\norm{x}<1$, then $\vec{1}-x$ is invertible with inverse
\[ (\vec{1}-x)^{-1} = \sum_{n=0}^\infty x^n \qquad\text{and}\qquad \norm{(\vec{1} - x)^{-1}} \leq \frac{1}{1-\norm{x}}. \]
Equivalently, if $\norm{\vec{1}-x}< 1$, then $x$ is invertible with inverse
\[ x^{-1} = \sum_{n=0}^\infty(\vec{1}-x)^n. \]
\end{proposition}
\begin{proof}
Since $\norm{x^n}\leq \norm{x}^n$ for all $n\geq 1$ and $\sum \norm{x}^n$ is a convergent geometric series, the series $\sum x^n$ is convergent by \ref{absoluteConvergenceImpliesConvergence}.

Also
\[ \norm{(\vec{1} - x)^{-1}} = \norm{\sum_{i=0}^\infty x^i} \leq \sum_{i=0}^\infty \norm{x}^i = \frac{1}{1-\norm{x}} \]
by the geometric series.
\end{proof}
We can in fact weaken the requirement of $\norm{x}<1$ to $\exists k\in\N: \norm{x^k}<1$:
\begin{corollary} \label{NeumannSeriesEventuallyContractive}
Let $A$ be a unital Banach algebra and $x\in A$ such that $\norm{x^k}<1$ for some $k>0$. Then $\vec{1} - x$ is invertible and $(\vec{1} - x)^{-1} = \sum_{i=0}^\infty x^i$.
\end{corollary}
\begin{proof}
We know that the Neumann series $\sum_{i=0}^\infty(x^k)^i$ converges. So
\[ \sum_{i=0}^\infty x^i = (\vec{1} + x + x^2 +\ldots + x^{k-1})\sum_{i=0}^\infty(x^k)^i \]
converges.

To show this convergent sequence acturally gives the correct inverse, we calculate
\begin{align*}
(\vec{1}-x)(\vec{1} + x + x^2 +\ldots + x^{k-1})(\vec{1} - x^k)^{-1} &= \Big(\vec{1} + x + x^2 +\ldots + x^{k-1} - x - x^2 -\ldots - x^{k}\Big)(\vec{1} - x^k)^{-1} \\
&= (\vec{1} - x^k)(\vec{1} - x^k)^{-1} = \vec{1}.
\end{align*}
This shows that $\sum_{i=0}^\infty x^i$ is the correct right inverse. To show it is also a left inverse, we expand $(\vec{1} - x^k)^{-1}(\vec{1} + x + x^2 +\ldots + x^{k-1})(\vec{1}-x)$.
\end{proof}


\begin{lemma}
Let $A$ be a unital Banach algebra and $a,b\in A$ with $\norm{a} < 1$. Then $\sum_{n=0}^\infty a^nb$ is the unique fixed point of $x\mapsto ax+b$.
\end{lemma}
\begin{proof}
The function $x\mapsto ax+b$ is a contraction if and only if $\norm{x}<1$. So it has a unique fixed point (TODO). Starting the fixed point iteration at $b$ yields the series:
\begin{align*}
b &\mapsto  ab+b \\
ab+b &\mapsto a^2b + ab + b \\
&\hdots.
\end{align*}
\end{proof}
This gives an alternate proof of the convergence of the Neumann series.

\subsection{The set of invertible elements}
\begin{proposition} \label{openSetInvertibles}
Let $x\in\GL(A)$ and $y\in A$ such that $\norm{y} < \norm{x^{-1}}^{-1}$, then
\begin{enumerate}
\item $(x-y)^{-1} = x^{-1}\sum_{i=0}^\infty(x^{-1}y)^i$ for all $y\in A$ such that $\norm{y}\leq \norm{x^{-1}}^{-1}$;
\item $\ball(x,\norm{x^{-1}}^{-1})\subset \GL(A)$;
\item the invertible elements $\GL(A)$ form an open subset of $A$.
\end{enumerate}
\end{proposition}
\begin{proof}
(1) From $\norm{x^{-1}y} \leq \norm{x^{-1}}\,\norm{y} < \norm{x^{-1}}\,\norm{x^{-1}}^{-1} = 1$, we have that $(\vec{1} - x^{-1}y)$ is invertible with a Neumann series expansion. We then have
\[ x^{1}\sum_{i=0}^\infty (x^{-1}y)^i = x^{-1}(\vec{1} - x^{-1}y)^{-1} = (x-y)^{-1}. \]

(2) Any element in  $\ball(x,\norm{x^{-1}}^{-1})$ is of the form $x-z$, where $\norm{z} < \norm{x^{-1}}^{-1}$.

(3) This follows from (2) by \ref{interior}.
\end{proof}
TODO: this also works if $x$ is closed, bijective linear operator on a Banach space (i.e.\ not necessarily bounded).

\begin{proposition} \label{inverseMapContinuous}
The map $^{-1}: \GL(A)\to\GL(A): x\mapsto x^{-1}$ is continuous.
\end{proposition}
\begin{proof}
Take a convergent sequence $(x_n)\subset\GL(A)$ with limit $x$. We wish to prove $(x_n^{-1})$ converges to $x^{-1}$, because then the map is continuous by \ref{sequentialContinuity}. We can choose an $n_0$ such that $\forall n\geq n_0: x_n \in B(x,\norm{x^{-1}}^{-1})$. From now on we consider only the tails $(x_n)_{n=n_0}^\infty$ and $(x_n^{-1})_{n=n_0}^\infty$, which have the same limits. Then
\[ \norm{x^{-1}}\cdot\norm{x-x_n} < \norm{x^{-1}}\cdot\norm{x^{-1}}^{-1} = 1. \]
Also
\[ \norm{\vec{1} - x^{-1}x_n} = \norm{x^{-1}(x-x_n)} \leq \norm{x^{-1}}\cdot\norm{x-x_n} < 1. \]
We calculate, using the inequalities to apply the Neumann series formula and geometric series formula:
\begin{align*}
\norm{x_n^{-1} - x^{-1}} &= \norm{(x_n^{-1}x - \vec{1})x^{-1}} = \norm{((x^{-1}x_n)^{-1} - \vec{1})x^{-1}} \\
&= \norm{\left(\sum_{k=0}^\infty[\vec{1} - x^{-1}x_n]^k - \vec{1}\right)x^{-1}} = \norm{\left(\sum_{k=1}^\infty[\vec{1} - x^{-1}x_n]^k\right)x^{-1}} \\
&\leq \sum_{k=1}^\infty\norm{\vec{1} - x^{-1}x_n}^k\cdot\norm{x^{-1}} = \sum_{k=1}^\infty\norm{x^{-1}(x - x_n)}^k\cdot\norm{x^{-1}} \\
&\leq \norm{x^{-1}}\sum_{k=1}^\infty\norm{x - x_n}^k\cdot\norm{x^{-1}}^{k} = \norm{x^{-1}}\sum_{k=0}^\infty\norm{x - x_n}^k\cdot\norm{x^{-1}}^{k} - \norm{x^{-1}} \\
&= \frac{\norm{x^{-1}}}{1-\norm{x - x_n}\cdot\norm{x^{-1}}}-\norm{x^{-1}} = \frac{\norm{x - x_n}\cdot\norm{x^{-1}}^2}{1-\norm{x - x_n}\cdot\norm{x^{-1}}}.
\end{align*}
As the right-hand side converges to $0$, so must the left-hand side. Thus $(x_n^{-1})$ converges to $x^{-1}$.
\end{proof}

\begin{lemma} \label{finiteDimensionsInvertiblesDense}
Let $A$ be a finite-dimensional unital Banach algebra. Then $\GL(A)$ is dense in $A$.
\end{lemma}
\begin{proof}
TODO: any set of eigenvectors with different eigenvalues is linearly independent. Since there are only finitely many linearly independent vectors, there are only finitely many eigenvalues. Let $\epsilon$ be the lowest absolute value of an eigenvalue of $a$, excluding $0$. Then $\mu \vec{1} - a$ is invertible for all $\mu\in ball_\F(0,\epsilon)$.
\end{proof}

\section{Quotient algebras}
\begin{proposition}
Let $A$ be a Banach algebra and $J\subset A$ a closed (two-sided) ideal. Then $A/J$ is a Banach algebra.
\end{proposition}
\begin{proof}
We know that $A/J$ is a Banach space by \ref{quotientBanachSpace} and an algebra by (TODO ref). We just need to check that the quotient norm is submultiplicative.

Take $a,b\in A$ and $\epsilon>0$. Then there exist $x,y\in J$ such that $\norm{a+J} + \epsilon > \norm{a+x}$ and $\norm{b+J} + \epsilon > \norm{b+y}$. Then
\begin{align*}
\big(\norm{a+J} + \epsilon\big)\big(\norm{b+J} + \epsilon\big) &> \norm{a+x}\;\norm{b+y} \\
&\geq \norm{(a+x)(b+y)} = \norm{ab + (ay+xb+xy)} \geq \norm{ab + J}.
\end{align*}
Taking $\epsilon\to 0$, gives $\norm{a+J}\;\norm{b+J} \geq \norm{ab + J}$.
\end{proof}

\begin{proposition}
Let $A$ be a unital Banach algebra and $J\subseteq A$ a proper ideal. Then $\norm{\vec{1}}_{A/J} = 1$.
\end{proposition}
\begin{proof}
Since $0\in J$, we have $\norm{\vec{1}}_{A/J} \leq 1$ and it is enough to show that $\norm{\vec{1}+z} \geq 1$ for all $z\in J$. Suppose, towards a contradiction, that $\norm{\vec{1}+z} < 1$, so $z\in \ball(\vec{1},1)$. This means that $z$ is invertible by \ref{openSetInvertibles} and thus that $J$ is not proper by \ref{properIdealNoUnit}.
\end{proof}
\begin{corollary}
Let $A$ be a unital Banach algebra and $J$ a proper ideal. Then
\begin{enumerate}
\item $\vec{1} \notin \overline{J}$;
\item if $J$ is maximal, then it is closed.
\end{enumerate}
\end{corollary}
\begin{proof}
(1) We have $\vec{1}\notin J$ by \ref{properIdealNoUnit}. There does not exist a sequence in $J$ that converges to $\vec{1}$ because $1 = \norm{\vec{1}}_{A/J} = \inf_{z\in J}\norm{\vec{1}-z}$.

(2) Let $J\subseteq A$ be a maximal ideal in $A$. It is enough to show that the closure $\overline{J}$ is also an ideal. Since $\vec{1}\notin \overline{J}$ this ideal is proper.

The fact that $\overline{J}$ is an ideal follows straight from the continuity of addition and multiplication.
\end{proof}

\begin{proposition} \label{commutativeBanachAlgebraIdeals}
Let $A$ be a commutative unital Banach algebra and $\mathcal{J}$ is a maximal ideal. Then 
\begin{enumerate}
\item if $A$ is complex, then $A/\mathcal{J} \cong \C$;
\item if $A$ is real, then $A/\mathcal{J} \cong \R$ or $A/\mathcal{J} \cong \C$.
\end{enumerate}
\end{proposition}
\begin{proof}
(1) If $A$ is commutative, $A/\mathcal{J}$ is a field by TODO ref. It is also a unital Banach algebra (TODO), so $A/\mathcal{J} \cong \C$ by the Gelfand-Mazur theorem, \ref{GelfandMazur}.

(2) TODO
\end{proof}

\section{Finite elements}
elements of the socle. \url{https://link.springer.com/content/pdf/10.1023/A:1009717500980.pdf}

have finite spectrum 

\url{http://matwbn.icm.edu.pl/ksiazki/sm/sm104/sm10431.pdf}

\section{Real and complex Banach algebras}
TODO: define $A_\R$ and $A_\C$.

\begin{proposition} \label{preservationAlgebraicPropertiesComplexificationRealification}
$\GL(A) = \GL(A_\C)\cap A$ etc.
\end{proposition}

\section{The spectrum}
TODO: remove unital requirement.
\begin{definition}
Let $A$ be a complex Banach algebra. The \udef{spectrum} of an element $x\in A$ is defined as
\[ \spec(x) = \spec_A(x) \defeq \setbuilder{\lambda\in\C}{\lambda\cdot \vec{1} - x \in \tilde{A} \;\text{is not invertible}}. \]
If $A$ is a real Banach algebra, then the spectrum of $x\in A$ is defined as
\[ \spec_A(x) \defeq \spec_{A_\C}(x) = \setbuilder{\lambda\in\C}{\lambda\cdot \vec{1} - x \in \widetilde{A_\C} \;\text{is not invertible}}.  \]
The \udef{resolvent set} of an element $x\in A$ is
\[ \res(x) = \C\setminus\spec(x) \]
and its \udef{resolvent map} is
\[ R_x: \res(x) \to A : \lambda\mapsto (\lambda\cdot\vec{1}  - x)^{-1}. \]
The \udef{spectral radius} of $x\in A$ is
\[ \spr(x) = \sup\setbuilder{|\lambda|}{\lambda\in\spec(x)}. \]
\end{definition}
As we will later show that the spectrum is compact (\ref{spectrumCompact}), we may equivalently write
\[ \spr(x) = \max\setbuilder{|\lambda|}{\lambda\in\spec(x)}. \]

\begin{lemma}
Let $A$ be a non-unital Banach algebra. Then $0\in\spec_A(a)$ for all $a\in A$.
\end{lemma}
\begin{proof}
Because $A\subset A^\dagger$ as an ideal, $(a,0)\in A^\dagger$ is not invertible.
\end{proof}

\begin{lemma}
Let $A$ be a real Banach algebra. Then for all $a\in A$ and $\mu_1,\mu_2\in \R$:
\begin{enumerate}
\item $\spec(a) = \overline{\spec(a)}$;
\item $\mu_1 + \mu_2 i \in \spec(a)$ \textup{if and only if} $(a-\mu_1)^2+\mu_2^2$ is not invertible in $\tilde{A}$.
\end{enumerate}
\end{lemma}
\begin{proof}
(1) Assume $\lambda \notin \spec(a)$, so $(\lambda-a)^{-1}$ exists. Then
\[ \vec{1} = \overline{\vec{1}} = \overline{(\lambda-a)}\overline{(\lambda-a)^{-1}} = (\overline{\lambda}-a)\overline{(\lambda-a)^{-1}}, \]
so $\overline{\lambda}-a$ is invertible and $\overline{\lambda}\notin \spec(a)$. The converse is identical, using $\overline{\lambda}$.

(2) By (1), $(\mu_1 + \mu_2 i)\vec{1}- a$ is invertible if and only if $(\mu_1 - \mu_2 i)\vec{1}-a$ is invertible. Because $(\mu_1 + \mu_2 i)\vec{1}-a$ and $(\mu_1 - \mu_2 i)\vec{1}-a$ commute, this is equivalent to saying
\[ \big((\mu_1 + \mu_2 i)-a\big)\big((\mu_1 - \mu_2 i)-a\big) = (\mu_1-a)^2 + \mu_2^2 \]
is invertible in $\widetilde{A_\C}$, by \ref{productInvertibility} and thus also in $A$ by \ref{preservationAlgebraicPropertiesComplexificationRealification}.
\end{proof}

\begin{proposition}
Let $B$ be a complex Banach algebra and $A = B_\R$, then for all $a\in A$
\[ \spec_A(a) = \spec_B(a) \cup \overline{\spec_B(a)}. \]
\end{proposition}
\begin{proof}
TODO
\end{proof}

\begin{proposition} \label{spectrumCompact}
For any $x\in A$, the spectrum $\spec(x)$ is a compact subset of $\setbuilder{\lambda\in\C}{|\lambda|\leq \norm{x}}$.

In particular, $\spr(x) \leq \norm{x}$.
\end{proposition}
\begin{proof}
Let $\lambda\in \C$ be such that $|\lambda|>\norm{x}$, then
\[ 1 > \frac{\norm{x}}{|\lambda|} = \frac{\lambda - (\lambda - \norm{x})}{|\lambda|} = \norm{\vec{1} - \left(\vec{1} - \frac{x}{\lambda}\right)}. \]
By \ref{NeumannSeries}, $\vec{1} - x/\lambda$ is invertible and thus so is $\lambda-x$.

It is then enough to show that $\spec(x)$ is closed. By \ref{openSetInvertibles}, $\GL(A)$ is open and the set of non-invertibles $A\setminus \GL(A)$ is closed. Consider $f: \C \to A: \lambda \mapsto \lambda - x$. Then $\spec(x) = f^{-1}[A\setminus \GL(A)]$ is the preimage of a closed set under a continuous map, and hence is closed.
\end{proof}

\begin{lemma}[Polynomial spectral mapping] \label{polynomialSpectralMapping}
Let $A$ be a Banach algebra and $p$ a complex polynomial. Then
\[ p^{\imf}\big(\spec(x)\big) \subseteq \sigma\big(p(x)\big). \]
\end{lemma}
\begin{proof}
Take $\lambda\in\spec(x)$ so $p(\lambda)\in p^{\imf}\big(\spec(x)\big)$. Then $y\mapsto p(\lambda)-p(y)$ is a polynomial with zero at $\lambda$, so we can factorise it as $(\lambda - y)q(y)$ for some other polynomial $q$ by the fundamental theorem of algebra (TODO ref).

Now suppose, towards a contradiction, that $p(\lambda)\notin \sigma\big(p(x)\big)$. Then $p(\lambda) - p(x) = (\lambda - x)q(x) = q(x)(\lambda - x)$ has an inverse, so $(\lambda - x)$ is invertible by \ref{productInvertibility}. This contradicts $\lambda\in\spec(x)$.
\end{proof}

\begin{proposition}
Let $A$ be a unital Banach algebra and $x,y\in A$. Then $\vec{1} - xy$ is invertible \textup{if and only if} $\vec{1} - yx$ is invertible.
\end{proposition}
\begin{proof}
Assume $\vec{1} - xy$ invertible. Then the inverse of $\vec{1} - yx$ is
\[ y(\vec{1} - xy)^{-1}x + \vec{1}. \]
\end{proof}
\begin{corollary}
Let $A$ be a unital Banach algebra and $x,y\in A$. Then
\[ \spec(xy)\cup\{0\} = \spec(yx)\cup\{0\}. \]
\end{corollary}
\begin{proof}
Assuming $\lambda \neq 0$, we have $\lambda\in\spec(xy) \iff \frac{xy}{\lambda} - \vec{1}$ is invertible.
\end{proof}
It is important to include $0$: there are cases when $0\in \spec(xy)$, but $0\notin \spec(yx)$.

\begin{lemma} \label{spectrumOfImage}
Let $A,B$ be unital Banach algebras and $\Psi: A\to B$ a unital algebra homomorphism. Then for all $x\in A$: $\spec(\Psi(x)) \subseteq \spec(x)$ and hence $\spr(\Psi(x)) \leq \spr(x)$.
\end{lemma}
\begin{proof}
By contraposition: Assume $\lambda\notin\spec(x)$, then $x-\lambda$ has an inverse, call it $a$. Then $(\Psi(x) - \lambda)$ has an inverse by
\[ (\Psi(x) - \lambda)\Psi(a) = \Psi(x-\lambda)\Psi(a) = \Psi((x-\lambda)a) = \Psi(\vec{1}) = \vec{1},\]
meaning $\lambda \notin \spec(\Psi(x))$.
\end{proof}

In general if $B$ is a subalgebra of a Banach algebra $A$, then for any $x\in B$, $\spec_B(x) \supseteq \spec_A(x)$.

\begin{proposition}
Let $A$ be a unital Banach algebra and suppose that $S\subset A$ is a set of pairwise commuting elements. Then there exists a unital commutative Banach subalgebra $C$ such that $S\subset C\subset A$ and
\[ \spec_A(s) = \spec_C(s) \qquad \text{for all $s\in S$.} \]
\end{proposition}
\begin{proof}
TODO
\end{proof}


\subsection{Resolvents and pseudoresolvents}

\begin{proposition} \label{secondNeumannSeries}
Let $A$ be a Banach algebra, $x\in A$ and $|\lambda| > \inf_{n\to \infty}\norm{x^n}^{1/n}$, then
\begin{enumerate}
\item $\lambda\in\res(x)$;
\item $R_x(\lambda) = \sum_{n=0}^\infty\frac{x^n}{\lambda^{n+1}}$;
\item $\norm{R_x(\lambda)} \leq \frac{1}{|\lambda|-\norm{x}}$.
\end{enumerate}
\end{proposition}
\begin{proof}
Take arbitrary $\epsilon > 0$. We can find an $n\in\N$ such that $|\lambda| > \norm{x^n}^{1/n}$, so $1 > \norm{\left(\frac{x}{\lambda}\right)^n}$. By \ref{NeumannSeriesEventuallyContractive}, we have that $(\vec{1} - \frac{x}{\lambda})$ is invertible and
\[ R_x(\lambda) = \lambda^{-1} \left(\vec{1} - \frac{x}{\lambda}\right)^{-1} = \lambda \sum_{n=0}^\infty\left(\frac{x}{\lambda}\right)^n = \sum_{n=0}^\infty\frac{x^n}{\lambda^{n+1}}. \]
Finally $\norm{R_x(\lambda)} \leq \sum_{n=0}^\infty\frac{\norm{x}^n}{|\lambda|^{n+1}} = \frac{1}{|\lambda|(1-\frac{\norm{x}}{\lambda})} = \frac{1}{|\lambda|-\norm{x}}$.
\end{proof}

\begin{lemma} \label{BanachAlgebraResolventMultiplication}
Let $A$ be a unital Banach algebra, $a\in A$ and $\lambda\in\\res(a)$. Then
\[ aR_a(\lambda) = \lambda R_a(\lambda) - \vec{1}. \]
\end{lemma}
\begin{proof}
We have $\id_X = (\lambda \id_X - T)R_T(\lambda) = \lambda R_T(\lambda) - TR_T(\lambda)$.
\end{proof}

\subsubsection{Pseudoresolvents and first resolvent identity}
\begin{definition}
Let $A$ be a Banach algebra. A function $\mathcal{R}:\Lambda \subseteq \C \to A$ is called a \udef{pseudoresolvent} if, for all $\lambda,\mu\in\Lambda$
\[ \mathcal{R}(\lambda) - \mathcal{R}(\mu) = (\mu-\lambda)\mathcal{R}(\lambda)\mathcal{R}(\mu). \]
This equation is known as the (first) \udef{resolvent identity}.
\end{definition}

Note that if a pseudoresolvent $\mathcal{R}$ is zero anywhere, it is identically zero.

\begin{lemma}
Let $\mathcal{R}:\Lambda \subseteq \C \to A$ be a pseudoresolvent on a Banach algebra $a$ and $\lambda,\mu\in\Lambda$. Then $\mathcal{R}(\lambda)\mathcal{R}(\mu) = \mathcal{R}(\mu)\mathcal{R}(\lambda)$.
\end{lemma}
\begin{proof}
If $\lambda = \mu$, then the result is immediate. If $\lambda \neq \mu$, then
\[ \mathcal{R}(\lambda)\mathcal{R}(\mu) = (\mu-\lambda)^{-1}\big(\mathcal{R}(\lambda) - \mathcal{R}(\mu)\big) = (\lambda - \mu)^{-1}\big(\mathcal{R}(\mu) - \mathcal{R}(\lambda)\big) = \mathcal{R}(\mu)\mathcal{R}(\lambda). \]
\end{proof}

\begin{proposition} \label{firstNeumannSeries}
Let $\mathcal{R}:\Lambda \subseteq \C \to A$ be a pseudoresolvent and $\lambda_0,\lambda\in\Lambda$ such that $|\lambda-\lambda_0|\,\norm{\mathcal{R}(\lambda_0)} < 1$. Then
\[ \mathcal{R}(\lambda) = \sum_{n=0}^\infty(\lambda_0 - \lambda)^n \mathcal{R}(\lambda_0)^{n+1} \qquad\text{and}\qquad \norm{\mathcal{R}(\lambda)} \leq \frac{1}{\norm{\mathcal{R}(\lambda_0)}^{-1} - |\lambda_0-\lambda|}. \]
In particular $\mathcal{R}$ is analytic and can be analytically continued to $\Lambda \cup \ball(\lambda_0, \norm{\mathcal{R}(\lambda_0)}^{-1})$. The analytic continuation still satisfies the resolvent identity.
\end{proposition}
\begin{proof}
By assumption we have $(\lambda - \lambda_0)\mathcal{R}(\lambda_0)$ is a contraction, so $(\id_X - (\lambda - \lambda_0)\mathcal{R}(\lambda_0))^{-1}$ exists and has a Neumann series expansion by \ref{NeumannSeries}. From the resolvent identity, we get
\[ \mathcal{R}(\lambda)\big(\id_X - (\lambda_0 - \lambda)\mathcal{R}(\lambda_0)\big) = \mathcal{R}(\lambda_0), \]
so, using the Neumann series expansion,
\begin{align*}
\mathcal{R}(\lambda) &= \big(\id_X - (\lambda_0 - \lambda)\mathcal{R}(\lambda_0)\big)^{-1}\mathcal{R}(\lambda_0) \\
&= \sum_{n=0}^\infty(\lambda_0 - \lambda)^n \mathcal{R}(\lambda_0)^{n+1}.
\end{align*}
This series converges in norm for all $\lambda\in \C$ such that $|\lambda-\lambda_0| < \norm{\mathcal{R}(\lambda_0)}^{-1}$. Running the equalities in reverse gives the resolvent identity.

The norm estimate is also given by \ref{NeumannSeries}:
\begin{align*}
\norm{\mathcal{R}(\lambda)} &\leq \norm{\big(\id_X - (\lambda_0 - \lambda)\mathcal{R}(\lambda_0)\big)^{-1}}\norm{\mathcal{R}(\lambda_0)} \\
&\leq \frac{1}{1 - |\lambda_0-\lambda|\,\norm{\mathcal{R}(\lambda_0)}}\norm{\mathcal{R}(\lambda_0)} \\
&= \frac{1}{\norm{\mathcal{R}(\lambda_0)}^{-1} - |\lambda_0-\lambda|}.
\end{align*}
\end{proof}
\begin{corollary} \label{derivativePseudoresolvent}
Let $\mathcal{R}:\Lambda \subseteq \C \to A$ be a pseudoresolvent. Then
\begin{enumerate}
\item $\mathcal{R}'(\lambda) = -\mathcal{R}(\lambda)^2$ for all $\lambda\in\Lambda$;
\item $\mathcal{R}^{(n)}(\lambda) = n!(-1)^n \mathcal{R}(\lambda)^{n+1}$ for all $n\in \N$.
\end{enumerate}
In particular the map $\mathcal{R}$ is holomorphic on its domain of definition.
\end{corollary}
\begin{proof}
We calculate
\begin{align*}
\mathcal{R}'(\lambda) &= \lim_{\mu\to\lambda} \frac{\mathcal{R}(\mu) - \mathcal{R}(\lambda)}{\mu-\lambda} \\
&= \lim_{\mu\to\lambda} \frac{\mathcal{R}(\mu) - \mathcal{R}(\lambda)}{\mu-\lambda} \\
&= \lim_{\mu\to\lambda} -\mathcal{R}(\lambda)\mathcal{R}(\mu) = -\mathcal{R}(\lambda)\lim_{\mu\to\lambda} \mathcal{R}(\mu) = -\mathcal{R}(\lambda)^2.
\end{align*}
For the last equality we have used the fact that $\mathcal{R}$ is continuous, which follows from its analyticity.
\end{proof}

\begin{proposition} \label{firstResolventIdentity}
Let $A$ be a Banach algebra and $x\in A$. Then the resolvent map
\[ R_x: \res(x)\to A: \lambda \mapsto (\lambda\cdot\vec{1} - x)^{-1} \]
is a pseudoresolvent.
\end{proposition}
\begin{proof}
We first note that $R_x(\lambda), R_x(\mu)$ commute for any $\lambda,\mu\in\spec(x)$, by \ref{commutationInverse}.

We then calculate
\begin{align*}
R_x(\lambda) - R_x(\mu) &= R_x(\lambda)(\mu - x)R_x(\mu) - R_x(\lambda)(\lambda - x)R_x(\mu) \\
&= \mu R_x(\lambda)R_x(\mu) - R_x(\lambda)xR_x(\mu) - \lambda R_x(\lambda)R_x(\mu) + R_x(\lambda)xR_x(\mu) \\
&= \mu R_x(\lambda)R_x(\mu) - \cancel{R_x(\lambda)xR_x(\mu)} - \lambda R_x(\lambda)R_x(\mu) + \cancel{R_x(\lambda)xR_x(\mu)} \\
&= (\mu - \lambda)R_x(\lambda)R_x(\mu).
\end{align*}
\end{proof}

\subsubsection{Second resolvent identity}
\begin{proposition}[Second resolvent identity] \label{secondResolventIdentity}
Let $A$ be a Banach algebra and $x,y\in A$. Then for all $\lambda \in \res(x)\cap \res(y)$ we have
\[ R_x(\lambda) - R_y(\lambda) = R_x(\lambda)\big(x-y\big)R_y(\lambda). \]
\end{proposition}
\begin{proof}
We have
\begin{align*}
R_x(\lambda)\big(x-y\big)R_y(\lambda) &= R_x(\lambda)\big(\lambda\vec{1}-y - (\lambda\vec{1} - x)\big)R_y(\lambda) \\
&= R_x(\lambda)\cancel{(\lambda\vec{1}-y)R_y(\lambda)} - \cancel{R_x(\lambda)(\lambda\vec{1} - x)}R_y(\lambda) \\
&= R_x(\lambda) - R_y(\lambda).
\end{align*}
\end{proof}
We can obtain the first resolvent identity from the second by setting $y = (\lambda-\mu)\vec{1} + x$. Then $R_{(\lambda-\mu)\vec{1} + x}(\lambda) = R_x(\mu)$, so
\begin{align*}
R_x(\lambda) - R_x(\mu) &= R_x(\lambda) - R_{(\lambda-\mu)\vec{1} + x}(\lambda) \\
&= R_x(\lambda)(x - (\lambda-\mu)\vec{1} + x)R_{(\lambda-\mu)\vec{1} + x}(\lambda) \\
&= (\lambda - \mu)R_x(\lambda)R_{(\lambda-\mu)\vec{1} + x}(\lambda) \\
&= (\lambda - \mu)R_x(\lambda)R_x(\mu).
\end{align*}

\begin{corollary}
Let $x,y\in A$ and $\lambda\in \res(x)\cap \res(y)$ be such that $\norm{R_x(\lambda)(y-x)}<1$. Then 
\[ R_y(\lambda) = \sum_{n=0}^\infty \big(R_x(\lambda)(y-x)\big)^nR_x(\lambda) \quad\text{and}\quad \norm{R_y(\lambda)} \leq \frac{1}{\norm{R_x(\lambda)}^{-1} - \norm{y-x}}. \]
\end{corollary}
\begin{proof}
We have
\[ R_x(\lambda) = R_y(\lambda) + R_x(\lambda)(x-y)R_y(\lambda) = \big(\vec{1} + R_x(\lambda)(x-y)\big)R_y(\lambda) = \big(\vec{1} - R_x(\lambda)(y-x)\big)R_y(\lambda). \]
Because $R_x(\lambda)(y-x)$ was assumed a contraction, $\vec{1} + R_x(\lambda)(x-y)$ has an inverse given by its Neumann series, \ref{NeumannSeries}, so
\begin{align*}
R_y(\lambda) &= \big(\vec{1} - R_x(\lambda)(y-x)\big)^{-1} R_x(\lambda) \\
&= \sum_{n=0}^\infty \big(R_x(\lambda)(y-x)\big)^n R_x(\lambda).
\end{align*}
The norm estimate is also given by \ref{NeumannSeries}:
\begin{align*}
\norm{R_y(\lambda)} &\leq \norm{\big(\vec{1} - R_x(\lambda)(y-x)\big)^{-1}}\norm{R_x(\lambda)} \\
&\leq \frac{1}{1 - \norm{R_x(\lambda)(y-x)}}\norm{R_x(\lambda)} \\
&\leq \frac{1}{1 - \norm{R_x}\,\norm{(\lambda)(y-x)}}\norm{R_x(\lambda)} \\
&= \frac{1}{\norm{R_x(\lambda)}^{-1} - \norm{(\lambda)(y-x)}}.
\end{align*}
\end{proof}

\subsubsection{Properties of the spectrum}

\begin{proposition}
Let $A$ be a Banach algebra and $x\in A$. Then $\spec(x)\neq \emptyset$.
\end{proposition}
\begin{proof}
Assume, towards a contradiction, that $\res(x) = \C$. Then the resolvent norm $\lambda\mapsto \norm{R_x(\lambda)}$ is an entire function by \ref{derivativePseudoresolvent}. By \ref{secondNeumannSeries} we have $\lim_{|\lambda|\to\infty}\norm{R_x(\lambda)} = 0$. By Liouville's theorem \ref{liouvilleTheoremAnalysis}, we have that $\norm{R_x(\lambda)}$ is identically zero.

Now we have
\[ 1 = \norm{\vec{1}} = \norm{R_x(\lambda)(\lambda-x)} \leq \norm{R_x(\lambda)}\,\norm{\lambda - x} = 0. \]
This is a contradiction.
\end{proof}
\begin{corollary}[Gelfand-Mazur] \label{GelfandMazur}
Let $A$ be a unital complex Banach algebra. If every non-zero element is invertible, then $A=\C\cdot \vec{1}$.
\end{corollary}
\begin{proof}
Suppose $x\in A\setminus (\C\cdot\vec{1})$. Then $\spec(x) = \emptyset$, contradicting the theorem.
\end{proof}
In other words, $\C$ is the only normed complex division algebra.


\begin{proposition}[Spectral radius formula] \label{spectralRadiusFormula}
Let $A$ be a Banach algebra and $x\in A$. Then
\[ \spr(x) = \lim_{n\to\infty}\norm{x^n}^{1/n} = \inf_{n\in\N}\norm{x^n}^{1/n}. \]
\end{proposition}
TODO: sometimes Fekete's lemma \ref{FeketesLemma} is used in the proof. Does this help us?

TODO: fill out references!!
\begin{proof}
The contraposition of (1) in \ref{secondNeumannSeries} gives that $\lambda\in\spec(x)$ implies $|\lambda| \leq \inf_{n\to \infty}\norm{x^n}^{1/n}$. Thus
\[ \spr(x) \leq \inf_{n\in\N}\norm{x^n}^{1/n} \leq \liminf_{n\in\N}\norm{x^n}^{1/n} \leq \limsup_{n\in\N}\norm{x^n}^{1/n}. \]
The result follows if we can prove $\limsup_{n\to\infty}\norm{x^n}^{1/n}\leq \spr(x)$.

Consider the function $zR_x\big(z^{-1}\big)$, which is holomorphic on $\ball(0,\spr(x)^{-1})\setminus\{0\}$ by \ref{derivativePseudoresolvent}. Take an arbitrary continuous linear functional $f\in \dual{A}$. Then $f\big(zR_x(z^{-1})\big)$ is holomorphic (TODO ref).

For all $z\in \ball(0,\norm{x}^{-1})\setminus\{0\}\subseteq \ball(0,\spr(x)^{-1})\setminus\{0\}$, we have the series expansion
\[ f\big(zR_x(z^{-1})\big) = f\Big(z\sum_{n=0}^\infty \frac{x^n}{z^{-n-1}}\Big) = f\Big(\sum_{n = 0}^\infty (zx)^n\Big) = \sum_{n = 0}^\infty f\big((zx)^n\big), \]
by \ref{secondNeumannSeries}. By TODO ref, this series expansion must also hold on the larger disk $\ball(0,\spr(x)^{-1})$, which means that $f\big((zx)^n\big) \to 0$ by TODO ref.

Since $f\in A^*$ was arbitrary, the sequence $\seq{(zx)^n}$ is weakly convergent and so norm-bounded (with, say, bound $C$) by \ref{weaklyConvergentSequenceNormBounded} for all $z\in \ball(0,\spr(x)^{-1})$. Thus
\[ |z|\limsup_{n\to\infty}\norm{x^n}^{1/n} = \limsup_{n\to\infty}\norm{(zx)^n}^{1/n} \leq \limsup_{n\to\infty}C^{1/n} = \lim_{n\to\infty} C^{1/n} = 1, \]
and so $\limsup_{n\to\infty}\norm{x^n}^{1/n} \leq |z|^{-1}$. Since $z\in \ball(0,\spr(x)^{-1})$ was picked arbitrarily, we have $\limsup_{n\to\infty}\norm{x^n}^{1/n} \spr(x)$.
\end{proof}



\subsection{Quasinilpotent operators}
\begin{definition}
Let $A$ be a Banach algebra and $x\in A$. If $\spec(x) = \{0\}$, then $x$ is called \udef{quasinilpotent}
\end{definition}
\url{https://www.jstor.org/stable/2042882?seq=1}
\url{https://www.researchgate.net/profile/Zbigniew-Slodkowski/publication/265547661_A_note_on_quasinilpotent_elements_of_a_Banach_algebra/links/5e7e8f94458515efa0b0fe83/A-note-on-quasinilpotent-elements-of-a-Banach-algebra.pdf?origin=publication_detail}

\url{https://www.cambridge.org/core/services/aop-cambridge-core/content/view/AC3CBD3000D16515D0BD83C07B703186/S0013091500015352a.pdf/finite_dimensionality_nilpotents_and_quasinilpotents_in_banach_algebras.pdf}

\url{https://www.cambridge.org/core/services/aop-cambridge-core/content/view/C8F26DDF45A29D689C726A29D8F0BC2A/S0017089500008429a.pdf/algebraic-ideals-of-semiprime-banach-algebras.pdf}

\begin{proposition} \label{nilpotentQuasinilpotent}
Every nilpotent element is quasinilpotent. The converse holds for finite elements in semisimple Banach algebras (TODO correct version of finite).
\end{proposition}
\begin{proof}
Let $x$ be a nilpotent element in a (unital) Banach algebra $A$.
By the spectral radius formula \ref{spectralRadiusFormula}, we have
\[ \spr(x) = \lim_{n\to\infty}\norm{x^n}^{1/n} = 0. \]
This implies $\spec(x) = \{0\}$.

Now assume $x$ a finite quasimilpotent element. Then $\dim(xAx) = n$ and so $x^2, \ldots x^{n+2}$ a linearly dependent and thus there exists a polynomial $p$ of degree at most $n+2$ such that $p(x) = 0$. We can factorise $p(x) = x^kq(x)$ where $q$ is some polynomial such that $q(0) \neq 0$ and $k\in \N$. Then by spectral mapping, we have that $\spec(q(x)) = q(\spec(x)) = q(\{0\}) \neq \{0\}$. Thus $q(x)$ is invertible and we have
\[ x^k = x^kq(x)q(x)^{-1} = 0\cdot q(x)^{-1} = 0. \]
This means $x$ is nilpotent.
\end{proof}

\subsection{Characters}
\begin{definition}
Let $A$ be a Banach algebra. A \udef{character} on $A$ is a non-zero algebra homomorphism $A\to\C$.

The \udef{character space} (or \udef{(Gelfand) spectrum}) $\hat{A}$ is the set of characters on $A$, equipped with the pointwise convergence.
\end{definition}
In other words, a character on $A$ is a non-zero multiplicative linear functional $A\to \C$.
In particular, if $A$ is a real algebra, a character is still complex valued, but now  an $\R$-linear functional on $A$. 

\begin{lemma} \label{unitalCharacterExtension}
Let $A$ be a Banach algebra and $\varphi\in \hat{A}$. Set $\tilde{\varphi}: A^\dagger \to \C: (a,\lambda) \mapsto \varphi(a)+\lambda$. Then $\tilde{\varphi} \in \widehat{A^\dagger}$.
\end{lemma}

If $A$ is a real algebra, then we set
\[ \hat{A} = \setbuilder{\varphi|_A}{\varphi\in \widehat{A_\C}}. \]

\begin{proposition} \label{charactersUnital}
Let $A$ be a Banach algebra and $\varphi$ a character on $A$, then $\varphi$ is continuous and
\begin{enumerate}
\item $\varphi(\vec{1}) = 1$ if $A$ is unital;
\item $\norm{\varphi}\leq 1$;
\item $\norm{\varphi} = 1$ if $A$ contains an approximate unit.
\end{enumerate}
\end{proposition}
\begin{proof}
(1) We prove that $\varphi$ is unital if $A$ is unital: As $\varphi \neq 0$, we have $\varphi(x)\neq 0$ for some $x\in A$. Then $\varphi(x) = \varphi(x\cdot\vec{1}) = \varphi(x)\varphi(\vec{1})$, so $\varphi(\vec{1}) = 1$.

(2) If we can show $\norm{\tilde{\varphi}} \leq 1$, then $\norm{\varphi}\leq 1$ follows by \ref{DaggerMorphismProperties}. To this end suppose that for some $x\in \tilde{A}$, $|\tilde{\varphi}(x)|>\norm{x}$. Then $x-\tilde{\varphi}(x)$ is invertible by \ref{spectrumCompact}. Thus
\begin{align*}
1 = \tilde{\varphi}(\vec{1}) &= \tilde{\varphi}\big((x-\tilde{\varphi}(x))^{-1}(x-\tilde{\varphi}(x))\big) \\
&= \tilde{\varphi}(x-\tilde{\varphi}(x))^{-1}\tilde{\varphi}(x-\tilde{\varphi}(x)) \\
&= \tilde{\varphi}(x-\tilde{\varphi}(x))^{-1}\big(\tilde{\varphi}(x)-\tilde{\varphi}(x)\big) \\
&= \tilde{\varphi}(x-\tilde{\varphi}(x))^{-1}\cdot 0 = 0,
\end{align*}
which is a contradiction. Then $\norm{\tilde{\varphi}} \leq 1$ and thus $\norm{\varphi} \leq 1$.

(3) By \ref{boundedLinearMaps}, $\varphi$ is continuous. Let $\seq{e_\lambda}_{\lambda\in\Lambda}$ be an approximate unit.
Then, for all $x\in A$, we have
\[ \varphi(x) = \varphi(\lim_\lambda x\cdot e_\lambda) = \lim_\lambda\varphi(x\cdot e_\lambda) = \lim_\lambda \varphi(x)\cdot \varphi(e_\lambda). \]
Since $\varphi\neq 0$, we can take $x$ such that $\varphi(x)\neq 0$. Then
\[ 1 = \varphi(x)^{-1}\varphi(x) = \varphi(x)^{-1}\cdot\big(\lim_\lambda \varphi(x)\cdot \varphi(e_\lambda)\big) = \lim_\lambda \varphi(x)^{-1}\varphi(x)\cdot \varphi(e_\lambda) = \lim_\lambda \varphi(e_\lambda). \]
This implies $\sup_{\lambda}|\varphi(e_\lambda)| \geq 1$. Because $\norm{e_\lambda}\leq 1$ for all $\lambda\in\Lambda$, we have
\[ 1 \leq \sup_{\lambda}|\varphi(e_\lambda)| \leq \sup_{\lambda}\frac{|\varphi(e_\lambda)|}{\norm{e_\lambda}} \leq \norm{\varphi}. \]
The other inequality is given by (2).
\end{proof}

\begin{lemma}
Let $A$ be a real Banach algebra. Let $\varphi$ be a character on $A$. Then $\varphi$ is continuous \textup{if and only if} $\im(\varphi)\subseteq \R$.
\end{lemma}
\begin{proof}
TODO
\end{proof}

\begin{proposition} \label{characterSpaceLocallyCompact}
Let $A$ be a commutative Banach algebra. Then the character space $\hat{A}$
\begin{enumerate}
\item is locally compact and Hausdorff;
\item is compact if and only if $A$ unital.
\end{enumerate}
\end{proposition}
\begin{proof}
(1) The character space is Hausdorff by \ref{weakTopologyLCTVS}. The unit ball in the dual $\dual{A}$ is weak-$*$-compact by the Banach-Alaoglu theorem \ref{alaogluTheorem}. The set of all algebra homomorphisms $\hat{A}\cup \{\underline{0}\}$ is a closed subset of $(A\to \C)$ (TODO ref), so it is weak-$*$-compact by \ref{compactClosedSets}.

Now $\hat{A} = \big(\hat{A}\cup \{\underline{0}\}\big)\setminus \{\underline{0}\}$ is locally closed by \ref{locallyClosedEquivalents} (using the fact that $\{\underline{0}\}$ is closed by \ref{FrechetCharacterisation}). Thus it is locally compact by \ref{locallyCompactSubspace}.

(2) TODO
\end{proof}

\begin{proposition} \label{commutativeSameSpectrum}
Let $A$ be  a  unital  Banach  algebra,  and  suppose  that $S\subseteq A$ is a subset  of  pairwise commuting elements.  Then there exists a unital commutative Banach subalgebra $C\subseteq A$ with $S\subseteq C$ such that
\[ \forall s\in S: \quad \spec_A(s) = \spec_C(s). \]
\end{proposition}
\begin{proof}
TODO
\end{proof}

\begin{proposition} \label{characterMaximalIdealsComplex}
Let $A$ be a complex unital commutative Banach algebra. Then we have a bijection
\[ \ker: \hat{A} \twoheadrightarrowtail \{\text{maximal ideals in $A$}\}: \varphi \mapsto \ker(\varphi).  \]
\end{proposition}
\begin{proof}
First we verify that for each character $\varphi$ the kernel is a maximal ideal. Indeed applying \ref{splittingMap} to $\varphi$ we get an isomorphism $A/\ker\varphi \cong \im\varphi = \C$, meaning $\ker(\varphi)$ has codimension 1 and thus is a maximal proper subspace. By \ref{kernelIsIdeal}, $\ker(\varphi)$ is an ideal.

To prove $\ker$ is injective: let $\ker(\varphi) = \ker(\psi)$. Take some $a\in A$, which we can uniquely write as $\lambda+x$, with $x\in\ker(\varphi) = \ker(\psi)$, as $A = \Span(\vec{1})\oplus \ker(\varphi)$. Then
\[ \varphi(a) = \varphi(\lambda\cdot\vec{1} + x) = \lambda\varphi(\vec{1}) + 0 = \lambda = \lambda\psi(\vec{1}) + 0 = \psi(\lambda\cdot\vec{1} + x) = \psi(a), \]
so $\varphi = \psi$.

For surjectivity, take a maximal ideal $\mathcal{J}$.
By \ref{commutativeBanachAlgebraIdeals}, $A/\mathcal{J}\cong \C$, so the quotient map $A\to A/\mathcal{J}\cong \C$ can be seen as a character with kernel $\mathcal{J}$.
\end{proof}

\begin{example}
We know that $A$ is a maximal ideal in $A^\dagger$ by \ref{algebraIdealInUnitisation}. It is the kernel of the character $\proj_2: A^\dagger \to \C: (x,\lambda) \mapsto \lambda$. We take this character as the basepoint of $\widehat{A^\dagger}$.
\end{example}

\begin{lemma} \label{compactificationOfCharacterSpaceIsCharacterSpaceOfUnitisation}
Let $A$ be a complex commutative Banach algebra. Then
\[ \left(\begin{smallmatrix}
\widetilde{(-)} \\ \proj_2
\end{smallmatrix}\right): \hat{A}^\dagger \to \widehat{A^\dagger}: \varphi \mapsto \begin{cases}
\tilde{\varphi} & (\varphi \in \hat{A}) \\
\proj_2 & (\varphi = \infty)
\end{cases} \]
is a homeomorphism.
\end{lemma}
TODO: clean up proof
\begin{proof}
The function $\widetilde{(-)}: \hat{A} \to \widehat{A^\dagger}: \varphi \to \varphi^\dagger$ is well-defined by \ref{unitalCharacterExtension}.

We first show that $\left(\begin{smallmatrix}
\widetilde{(-)} \\ \proj_2
\end{smallmatrix}\right)$ is a bijection. For injectivity, take $\varphi_1 \neq \varphi_2\in \hat{A}^\dagger$. Suppose $\varphi_1, \varphi_2\in \hat{A}$, then clearly $\widetilde{\varphi_1} \neq \widetilde{\varphi_2}$. Now suppose $\varphi_2 = \infty$, then $\left(\begin{smallmatrix}
\widetilde{(-)} \\ \proj_2
\end{smallmatrix}\right)(\varphi_2) = \widetilde{\constant{0}} \neq \widetilde{\varphi_1}$, since $\constant{0}\notin \hat{A}$.

For surjectivity, take $\varphi\in \widehat{A^\dagger}$. Then $\ker(\varphi)$ is a maximal ideal in $A^\dagger$ by \ref{characterMaximalIdealsComplex}. Suppose $\varphi \neq \proj_2$, then $\ker(\varphi) \neq A$, so $\varphi|_A$ is a non-zero algebra homomorphism and thus $\varphi|_A\in \hat{A}$.

Finally it is enough to show continuity of $\left(\begin{smallmatrix}
\widetilde{(-)} \\ \proj_2
\end{smallmatrix}\right)$ by \ref{compactToHausdorffHomeomorphism}. We start by showing the continuity of $\widetilde{(-)}: \hat{A} \to \widehat{A^\dagger}: \varphi \to \varphi^\dagger$. Take arbitrary $(a,\lambda)\in A^\dagger$. Then \[ \evalMap_{(a,\lambda)}|_{\widehat{A^\dagger}}\circ \widetilde{(-)} = \evalMap_a|_{\hat{A}} + \lambda, \]
which is clearly continuous, so $\widetilde{(-)}: \hat{A} \to \widehat{A^\dagger}$ is continuous by \ref{characteristicPropertyInitialFinalConvergence}.

We use \ref{universalPropertyAlexandroffCompactification} to show the continuity of $\left(\begin{smallmatrix}
\widetilde{(-)} \\ \proj_2
\end{smallmatrix}\right)$. Take a closed subset $C\subseteq \widehat{A^\dagger}\setminus \{\proj_2\}$, then $\widetilde{(-)}^{\preimf}(C)$ is a closed subset of $\hat{A}$. It is also a closed subset of $\hat{A}\cup\{\constant{0}\}$. Indeed suppose, towards a contradiction, that $F\in \powerfilters(\hat{A}\cup\{\constant{0}\})$ converges pointwise to $\varphi \notin \widetilde{(-)}^{\preimf}(C)$. Then $\varphi = \constant{0}$, since $\widetilde{(-)}^{\preimf}(C)$ is a closed subset of $\hat{A}$, and for all $a\in A$ we have $\upset\evalMap_a^{\imf\imf}(F) \to 0$. Then, for all $\lambda \in \C$, we have $\evalMap_{(a,\lambda)}\Big(\widetilde{(-)}^{\imf\imf}(F)\Big) \to \lambda$ and thus $\widetilde{(-)}^{\imf\imf}(F) \to \proj_2$. Since $\widetilde{(-)}^\imf\Big(\widetilde{(-)}^\preimf(C)\Big)\subseteq C$, this means $\proj_2\in C$, which is a contradiction.

Thus $\widetilde{(-)}^{\preimf}(C)$ is compact in $\hat{A}\cup \{\constant{0}\}$ by \ref{compactClosedSets} and so compact in $\hat{A}$ by \ref{compactSetCompactSubspace}.
\end{proof}

TODO characters in real Banach algebra.


\subsubsection{The Gelfand transform}
\begin{definition}
Let $A$ be a unital commutative Banach algebra. The \udef{Gelfand transform} of $A$ is the map
\[ \evalMap_{-}|_{\hat{A}} : A\to \cont(\hat{A}): x\mapsto \evalMap_x \]
where $\evalMap_x(\varphi) = \varphi(x)$ for all $x\in A, \varphi\in\hat{A}$.
\end{definition}
Note that $\evalMap_{-}|_{\hat{A}}$ does not mean $\big(\evalMap_{-}\big)|_{\hat{A}}$.


Note that $\evalMap_{-}|_{\hat{A}}$ is well-defined, in the sense that $\evalMap_{x} \in \cont(\hat{A})$, because we have equipped $\hat{A}$ with the weak-$*$ topology, which makes each $\evalMap_{x}$ continuous.

\begin{lemma} \label{GelfandTransformHomomorphism}
Let $A$ be a commutative Banach algebra. Then the Gelfand transform $\evalMap_{-} : A\to \cont(\hat{A})$ is an algebra homomorphism.
\end{lemma}
\begin{proof}
We need to show that $\evalMap_{-}$ is both linear and multiplicative. First note $\evalMap_{x}(\lambda \varphi + \psi) = \lambda \varphi(x) + \psi(x) = \lambda\evalMap_{x}(\varphi) + \evalMap_{x}(\psi)$ and then $\evalMap_{x}(\varphi\psi) = \varphi(x)\psi(x) = \evalMap_{x}(\varphi)\evalMap_{x}(\psi)$.
\end{proof}

\begin{proposition} \label{spectrumFromSpectrum}
Let $A$ be a unital complex commutative Banach algebra and $x\in A$. Then
\[ \spec(x) = \setbuilder{\varphi(x)}{\varphi\in\hat{A}} = \evalMap_x^{\imf}(\hat{A}). \]
\end{proposition}
\begin{proof}
Suppose $\lambda = \varphi(x)$ for some $\varphi\in\hat{A}$. Then $\varphi(x) = \lambda \varphi(\vec{1}) = \varphi(\lambda\cdot \vec{1})$, since $\varphi$ is unital, by \ref{charactersUnital}.

Thus $x-\lambda\cdot \vec{1}\in\ker(\varphi)$, which is a proper ideal (since $\varphi \neq \constant{0}$). So $x-\lambda\cdot \vec{1}\notin\GL(A)$ by \ref{nonInvertibleGeneratedIdeals} and $\lambda \in\spec(x)$.

Suppose $\lambda \in \spec(x)$. Because $x-\lambda\cdot \vec{1}$ is non-invertible, the ideal generated by it is proper, by \ref{nonInvertibleGeneratedIdeals}, and $x-\lambda\cdot \vec{1}$ lies in a maximal ideal, by \ref{idealLatticeCoatomic}. By \ref{characterMaximalIdealsComplex}, this means $x-\lambda\cdot \vec{1} \in \ker(\varphi)$ for some $\varphi\in\hat{A}$ and then $\lambda = \varphi(x)$.
\end{proof}
\begin{corollary}
Let $A$ be a unital complex commutative Banach algebra and $x\in A$. Then
\[ \norm{\evalMap_{x}} = \spr(x) \leq \norm{x} \]
\end{corollary}
\begin{proof}
For all $x\in A$:
\[ \norm{\evalMap_x} = \sup_{\varphi\in\hat{A}}\left( \frac{|\varphi(x)|}{\norm{\varphi}} \right) = \sup_{\varphi\in\hat{A}}(|\varphi(x)|) = \spr(x) \leq \norm{x} \]
where we have used that $\norm{\varphi} = 1$ by \ref{charactersUnital}, $\spec(x) = \setbuilder{|\varphi(x)|}{\varphi\in\hat{A}}$ by \ref{spectrumFromSpectrum} and the inequality is from \ref{spectrumCompact}.
\end{proof}
\begin{corollary}
Let $A$ be a unital complex commutative Banach algebra. The Gelfand transform is a unital, norm-contractive Banach algebra homomorphism.
\end{corollary}
\begin{proof}
Algebra homomorphism is given by \ref{GelfandTransformHomomorphism}. Norm-contractiveness (and thus continuity) follows from the previous corollary.

To see that $\evalMap_{-}$ is unital, note that $\evalMap_{\vec{1}}(\varphi) = 1$ by for all $x\in A$ and $\varphi\in \hat{A}$ by \ref{charactersUnital}. Thus $\evalMap_{\vec{1}} = \constant{1}$, which is the unit of $\cont(\hat{A})$.
\end{proof}

\subsection{Holomorphic functional calculus}
ISem.

\url{https://noncommutativeanalysis.wordpress.com/2014/01/02/advanced-analysis-notes-18-the-holomorphic-functional-calculus-i/}.

\url{https://noncommutativeanalysis.wordpress.com/2014/01/05/advanced-analysis-notes-19-the-holomorphic-functional-calculus-ii-definition-and-basic-properties/#more-2773}.

Works for all elements, not just normal ones.

\begin{example}
Power series are not satisfactory, since a holomorphic function may have different power series expansions at different points. When defining a functional calculus, we need to take the wole of the spectrum of each element into account. We cannot join together different power series at different points in the spectrum.

For example, take $a = \begin{pmatrix}
2 & 0 \\ 0 & 0
\end{pmatrix}$ and $f(z) = (1-z)^{-1}$. Then $f(z)$ is holomorphic and
\begin{itemize}
\item $f(z) = \sum_{n\in\N}z^n$ around $0$;
\item $f(z) = \sum_{n\in\N}-(2 - z)^n$ around $2$.
\end{itemize}
Since $\spec(a) = \{0,2\}$, we somehow need to combine these two series. Plugging $a$ into either yields a non-convergent series.
\end{example}

\subsubsection{Analyticity}
\begin{definition}
Let $U\subseteq \C$ be an open set, $X$ a Banach space and $f: U\to X$ a function. Then
\begin{itemize}
\item $f$ is called \udef{weakly analytic} if $\rho\circ f: U\to \C$ is analytic for all $\rho\in \dual{X}$;
\item $f$ is called \udef{strongly analytic} if, for all $z_0 \in U$, the limit
\[ \od{f}{z}\Big|_{z_0} = \lim_{z\to z_0} \frac{f(z) - f(z_0)}{z-z_0} \]
exists in the norm convergence.
\end{itemize}
\end{definition}

\begin{lemma}
Let $U\subseteq \C$ be an open set, $X$ a Banach space and $f: U\to X$ a function. If $f$ is strongly analytic, then $f$ is continuous and weakly analytic.
\end{lemma}
\begin{proof}
Suppose $f$ is strongly analytic. Then
\[ \lim_{z\to z_0} f(z) - f(z_0) =  \lim_{z\to z_0}\frac{f(z) - f(z_0)}{z-z_0}\cdot (z-z_0) = \od{f}{z}\Big|_{z_0} \big(\lim_{z\to z_0}z-z_0\big) = \od{f}{z}\Big|_{z_0}\cdot 0 = 0, \]
so $\lim_{z\to z_0} f(z) = f(z_0)$, which means that $f$ is continuous.

Take $\rho\in \dual{X}$. Then
\begin{align*}
\dod{\rho\circ f}{z}\Big|_{z_0} &= \lim_{z\to z_0} \frac{(\rho \circ f)(z) - (\rho \circ f)(z_0)}{z-z_0} \\
&= \lim_{z\to z_0} \rho\Big(\frac{f(z) - f(z_0)}{z-z_0}\Big) \\
&= \rho\Big(\lim_{z\to z_0}\frac{f(z) - f(z_0)}{z-z_0}\Big) \\
&= \rho\Big(\dod{f}{z}\Big|_{z_0}\Big).
\end{align*}.
\end{proof}

\begin{proposition} \label{weakAnalyticityConsequences}
Let $U\subseteq \C$ be an open set, $X$ a Banach space, $f: U\to X$ a weakly analytic function and $\Gamma$ a closed Jordan curve in $U$ whose interior is also in $U$. Then
\begin{enumerate}
\item $f$ is continuous;
\item $\oint_{\Gamma}f(z)\diff{z} = 0$ and $f(w) = \frac{1}{2\pi i}\oint_{\Gamma}\frac{f(z)}{z-w}\diff{z}$ for all $w$ in the interior of $\Gamma$;
\item $f$ is strongly analytic.
\end{enumerate}
\end{proposition}
TODO integrals well-defined because $f$ is uniformly continuous on $\Gamma$.
\begin{proof}
(1) Pick $z_0\in U$ and $r>0$ small enough such that $\ball(z_0, r)\subseteq U$. Take arbitrary $\rho\in\dual{X}$. Since $\rho\circ f$ is analytic, the function
\[ z\mapsto \frac{(\rho\circ f)(z) - (\rho\circ f)(z_0)}{z-z_0} = \rho\Big(\frac{f(z) - f(z_0)}{z-z_0}\Big) \]
is continuous on $\ball{z_0, r}$ and thus bounded on $\ball{z_0, r}$ by the extreme value theorem \ref{extremeValueTheorem}. 

This means that the set
\[ \setbuilder[\Big]{\frac{f(z) - f(z_0)}{z-z_0}}{z\in\ball(z_0, r)} \]
is weakly bounded, and thus bounded by \ref{weaklyBoundedIffBounded}. Thus there exists $M \geq 0$ such that
\[ \norm{f(z) - f(z_0)} \leq M(z-z_0) \]
for all $z\in\ball(z_0,r)$. This implies that $f$ is continuous at $z_0$.

(2) For all $\rho\in\dual{X}$, we have
\[ \rho\Big(\oint_{\Gamma}f\diff{z}\Big) = \oint_\Gamma \rho\circ f \diff{z} = 0, \]
by \ref{boundedOperatorUnderIntegral} and \ref{CauchyTheorem}. By the Hahn-Banach theorem, \ref{locallyConvexDualPair}, we have $\oint_{\Gamma}f\diff{z} = 0$.

Again, take arbitrary $\rho\in\dual{X}$. Then
\begin{align*}
\rho\Big(f(w) - \frac{1}{2\pi i}\oint_{\Gamma}\frac{f(z)}{z-w}\diff{z}\Big) &= (\rho\circ f)(w) - \frac{1}{2\pi i}\oint_{\Gamma}\frac{(\rho \circ f)(z)}{z-w}\diff{z} \\
&= \frac{1}{2\pi i}\oint_{\Gamma}\frac{(\rho \circ f)(z)}{z-w}\diff{z} - \frac{1}{2\pi i}\oint_{\Gamma}\frac{(\rho \circ f)(z)}{z-w}\diff{z} = 0,
\end{align*}
by \ref{boundedOperatorUnderIntegral} and \ref{CauchyIntergralFormula}. By the Hahn-Banach theorem, \ref{locallyConvexDualPair}, we have $f(w) = \frac{1}{2\pi i}\oint_{\Gamma}\frac{f(z)}{z-w}\diff{z}$.

(3) Take $z_0\in U$ and $r>0$ such that $\cball(z_0, r)\subseteq U$. By \ref{continuityExpandedDomain}, we can restict our attention to $\ball(z_0, r)$. Take $z\in \ball(z_0, r)$. Then, using point (2) and the resolvent identity \ref{firstResolventIdentity}, we have
\begin{align*}
\frac{f(z)- f(z_0)}{z-z_0} &= \frac{1}{2\pi i (z-z_0)}\Big(\oint_{|z'- z_0| = r}\frac{f(z')}{z'-z}\diff{z'} - \oint_{|z'- z_0| = r}\frac{f(z')}{z'-z_0}\diff{z'}\Big) \\
&= \frac{1}{2\pi i (z-z_0)}\oint_{|z'- z_0| = r}f(z')\Big(\frac{(z'-z)^{-1} - (z'-z_0)^{-1}}{z-z_0}\Big)\diff{z'} \\
&= \frac{1}{2\pi i (z-z_0)}\oint_{|z'- z_0| = r}f(z')(z'-z)^{-1}(z'-z_0)^{-1}\diff{z'} \\
&= \frac{1}{2\pi i}\oint_{|z'- z_0| = r}f(z')\Big(\frac{1}{(z'-z_0)^2} - \frac{1}{(z'-z_0)^2} + \frac{1}{(z'-z)(z'-z_0)}\Big)\diff{z'} \\
&= \frac{1}{2\pi i}\oint_{|z'- z_0| = r}f(z')\Big(\frac{1}{(z'-z_0)^2} + \frac{(z'-z_0)-(z'-z)}{(z'-z_0)^2(z'-z)}\Big)\diff{z'} \\
&= \frac{1}{2\pi i}\oint_{|z'- z_0| = r}f(z')\Big(\frac{1}{(z'-z_0)^2} + \frac{z-z_0}{(z'-z_0)^2(z'-z)}\Big)\diff{z'} \\
&= \frac{1}{2\pi i}\oint_{|z'- z_0| = r}\frac{f(z')}{(z'-z_0)^2}\diff{z'} + \frac{z-z_0}{2\pi i}\oint_{|z'- z_0| = r}\frac{f(z')}{(z'-z_0)^2(z'-z)}\diff{z'}.
\end{align*}
The first part is independent of $z$. For the second part, the integral is bounded as $z\to z_0$ (since $z'$ stays $r$ away from $z_0$ and $z$ goes to $z_0$). Since the prefactor goes to $0$, this means that the second term goes to zero. Thus the limit $\lim_{z\to z_0}\frac{f(z)-f(z_0)}{z-z_0}$ exists and is equal to $\frac{1}{2\pi i}\oint_{|z'- z_0| = r}\frac{f(z')}{(z'-z_0)^2}\diff{z'}$.
\end{proof}

\subsubsection{Holomorphic functional calculus}

\begin{lemma}
Let $K\subseteq \C$ be a compact set and $U$ an open set containing $K$. Then $K$ lies in the union of interiors of a finite set of simple Jordan curves.
\end{lemma}
\begin{proof}
Essentially by compactness. TODO smooth interpolation of curves.
\end{proof}

\begin{theorem}[Holomorphic functional calculus] 
\label{holomorphicFunctionalCalculus} \label{holomorphicSpectralMapping}
Let $A$ be a unital Banach algebra and $x\in A$. Consider the function
\[ \Phi_x: \holomorphic(\spec(x),\C) \to A: f\mapsto f(x)\defeq \frac{1}{2\pi i}\oint_\Gamma f(z)R_x(z)\diff{z}. \]
Here $\Gamma$ is any finite union of simple Jordan curves that contains $\spec(x)$ such that $f$ is holomorphic in a region that contains $\Gamma$ and its interior. Then
\begin{enumerate}
\item $\Phi_x$ is well-defined: it does not depend on the particular curve $\Gamma$;
\item $\Phi_x$ is an algebra homomorphism;
\item $\Phi_x$ is continuous if $\holomorphic(\spec(x),\C)$ is equipped with continuous convergence;
\item $\Phi_x(\id_\C) = x$ and $\Phi_x(\underline{1}) = \vec{1}$;
\item if $A$ is unital, then $\spec(\Phi_x(f)) = f^\imf\big(\spec(x)\big)$.
\end{enumerate}
\end{theorem}
From points (2) and (3), it follows that $\Phi_x(p) = p(x)$ for any polynomial $p\in \C[X]$.

Note that equipping $\holomorphic(\spec(x),\C)$ with continuous convergence is not the same as uniform convergence, because functions in $\holomorphic(\spec(x),\C)$ may have unbounded domain, even though $\spec(x)$ is compact.
\begin{proof}
(1) TODO: from \ref{weakAnalyticityConsequences}.

(2) Take $f,g \in \holomorphic(\spec(x),\C)$ and $\lambda\in \C$. Then $\spec(x) \subseteq \dom(f)\cap \dom(g)$ and we can find a curve $\Gamma$ in $\dom(f)\cap \dom(g)$. By linearity of the integral, we have
\begin{align*}
\Phi_x\big(f+\lambda g\big) &= \frac{1}{2\pi i}\oint_\Gamma \big(f(z)+\lambda g(z)\big)R_x(z)\diff{z} \\
&= \frac{1}{2\pi i}\oint_\Gamma f(z)R_x(z)\diff{z} + \frac{\lambda}{2\pi i} \oint_\Gamma g(z)R_x(z)\diff{z} \\
&= \Phi_x(f) + \lambda \Phi_x(g).
\end{align*}
To show multiplicativity, take two curves $\Gamma_1, \Gamma_2$ in $\dom(f)\cap \dom(g)$ such that $\Gamma_2$ is in the interior of $\Gamma_1$ and $\spec(x)$ is in the interior of $\Gamma_2$. Then, using the first resolvent identity \ref{firstResolventIdentity}, we have
\begin{align*}
\Phi_x(f)\Phi_x(g) &= \Big(\frac{1}{2\pi i}\Big)^2\oint_{\Gamma_1}f(z)R_x(z)\diff{z}\oint_{\Gamma_2}g(z')R_x(z')\diff{z'} \\
&= \Big(\frac{1}{2\pi i}\Big)^2\oint_{\Gamma_1}\oint_{\Gamma_2}f(z)g(z')R_x(z)R_x(z')\diff{z'}\diff{z} \\
&= \Big(\frac{1}{2\pi i}\Big)^2\oint_{\Gamma_1}\oint_{\Gamma_2}f(z)g(z')\Big(\frac{R_x(z) - R_x(z')}{z'- z}\Big)\diff{z'}\diff{z} \\
&= \Big(\frac{1}{2\pi i}\Big)^2\oint_{\Gamma_1}\oint_{\Gamma_2}f(z)g(z')\frac{R_x(z)}{z'- z}\diff{z'}\diff{z} + \oint_{\Gamma_1}\oint_{\Gamma_2}f(z)g(z')\frac{R_x(z')}{z- z'}\diff{z'}\diff{z} \\
&= \frac{1}{2\pi i}\oint_{\Gamma_2}\Big(\frac{1}{2\pi i}\oint_{\Gamma_1}\frac{f(z)}{z- z'}\diff{z}\Big)g(z')R_x(z')\diff{z'} + \frac{1}{2\pi i}\oint_{\Gamma_1}f(z)R_x(z)\Big(\frac{1}{2\pi i}\oint_{\Gamma_2}\frac{g(z')}{z'- z}\diff{z'}\Big)\diff{z},
\end{align*}
where the order of integration has been swapped in the second integral using Fubini's theorem (TODO ref for vector-valued functions).

We have $\frac{1}{2\pi i}\oint_{\Gamma_1}\frac{f(z)}{z- z'}\diff{z} = f(z')$ for all $z'\in \Gamma_2$ by Cauchy's integral formula \ref{CauchyIntergralFormula}, since all these $z'$ lie inside $\Gamma_1$. We have $\oint_{\Gamma_2}\frac{g(z')}{z'- z}\diff{z'} = 0$ for all $z\in \Gamma_1$ by Cauchy's theorem \ref{CauchyTheorem}, since all these $z$ lie outside $\Gamma_2$.
Thus
\[ \Phi_x(f)\Phi_x(g) = \frac{1}{2\pi i}\oint_{\Gamma_2}f(z')g(z')R_x(z')\diff{z'} = \frac{1}{2\pi i}\oint_{\Gamma_2}(f\cdot g)(z')R_x(z')\diff{z'} = \Phi_x(f\cdot g). \]

(3) By \ref{continuousConvergenceCompactOpen}, \ref{uniformConvergenceOnCompactsIsCompactOpenConvergence}, \ref{spectrumCompact} and \ref{metricUniformConvergence}, the continuous convergence is metric and thus sequential, by \ref{pseudometricSpaceFrechetUrysohn}, so it is enough to check sequential convergence.

TODO: Using uniform metric we can see that the sequence is uniformly bounded and so we can use the bounded convergence theorem (TODO ref).

(4) Take $x\in A$ and let $\Gamma$ be a circle centred at $0$ with radius larger than $\norm{x}$. Then, using \ref{secondNeumannSeries} and (3), we have
\begin{align*}
\Phi_x(\id_{\spec(x)}) &= \frac{1}{2\pi i}\oint_\Gamma zR_x(z)\diff{z} \\
&= \frac{1}{2\pi i}\oint_\Gamma \sum_{n=0}^\infty z\frac{x^n}{z^{n+1}}\diff{z} \\
&= \sum_{n=0}^\infty x^n \frac{1}{2\pi i}\oint_\Gamma  z^{-n}\diff{z} = a,
\end{align*}
where we have used that $\oint_\Gamma  z^{-n}\diff{z} = 2\pi i$ if $n = 1$ and is zero otherwise, by the residue formula \ref{residueFormula}.

Similarly, we calculate
\begin{align*}
\Phi_x(\constant{1}) = \frac{1}{2\pi i}\oint_\Gamma R_x(z)\diff{z} = \sum_{n=0}^\infty x^n \frac{1}{2\pi i}\oint_\Gamma  z^{-n-1}\diff{z} = \vec{1}.
\end{align*}

(5) First take $\lambda\in\spec(x)$. We need to show that $f(\lambda)\in \spec(\Phi_x(f))$, so $f(\lambda)\vec{1} - \Phi_x(f)$ is not invertible. Now $z\mapsto f(\lambda)- f(z)$ is holomorphic and equals $0$ at $z=\lambda$. Then $f(z) - f(\lambda) = (\lambda - z)g(z)$ for some holomorphic $g$ by \ref{holomorphicZeroFactorisationLemma}. Now, by (2) and (4), we have
\[ f(\lambda)\vec{1} - \Phi_x(f) = \Phi_x\big(f(\lambda)\constant{1} - f\big) = \Phi_x\big((\lambda\constant{1} - \id)\cdot g(z)\big) = (\lambda\vec{1} - x)\Phi_x(g). \]
If $f(\lambda)\vec{1} - \Phi_x(f)$ were invertible, then $\lambda\vec{1} - x$ would be invertible with inverse $\big(f(\lambda)\vec{1} - \Phi_x(f)\big)^{-1}\Phi_x(g)$. Since this is not true (by assumption $\lambda\in\spec(x)$), we have that $f(\lambda)\vec{1} - \Phi_x(f)$ is not invertible.

Now suppose $\mu\notin f^\imf\big(\spec(x)\big)$. Then $\lambda - f(z)$ is non-zero on $\spec(x)$, so $\spec(x) \subseteq f^\preimf(\C\setminus\{0\})$. Also $f^\preimf(\C\setminus\{0\})$ is open by \ref{preimageOpenClosed}. The function $(\constant{\lambda} - f)^{-1}$ is holomorphic on $f^\preimf(\C\setminus\{0\})$ and thus an element of $\holomorphic(\spec(x),\C)$. Then $\Phi_x\big((\constant{\lambda} - f)^{-1}\big)$ is the inverse of $\lambda \vec{1} - \Phi_x(f)$, so $\lambda \notin \spec\big(\Phi_x(f)\big)$.
\end{proof}

Alternative proof for (5) in \url{https://noncommutativeanalysis.wordpress.com/2014/01/05/advanced-analysis-notes-19-the-holomorphic-functional-calculus-ii-definition-and-basic-properties/}

\subsubsection{Riesz eigenprojections}
Holomorphic functional calculus applied to
\[ \chi_{S,\delta}: A\to \{0,1\}: x\mapsto \begin{cases}
1 & d(x,S) \leq \delta \\
0 & \text{otherwise}.
\end{cases} \]

TODO: spectral measure with only disconnected parts in $\sigma$-algebra??

TODO: $P_\Delta$ and $E_\Delta \defeq \im P_\Delta$.

\begin{lemma}
$\spec(T|_{E_\Delta}) = \spec(T)\cap\Delta$.
\end{lemma}

\begin{definition}
We call $\dim E_\lambda$ the \udef{algebraic multiplicity} of $\lambda$.
\end{definition}

\subsubsection{Frobenius covariants}
TODO $P_\lambda$ is a Frobenius covariant. \url{https://en.wikipedia.org/wiki/Frobenius_covariant}

TODO cfr. Lagrange polynomial??

\subsubsection{The exponential}
\begin{definition}
Let $A$ be a Banach algebra and $a\in A$. We define the \udef{exponential} of $a$ by holomorphic functional calculus:
\[ e^a \defeq \Phi_a(\exp) = \frac{1}{2\pi i}\oint_\Gamma e^zR_a(z)\diff{z}. \]
We also denote the exponential by $\exp(a)$.

We call the function $\exp: A\to A: a\mapsto e^a$ the \udef{exponential mapping}.
\end{definition}

\begin{proposition}
Let $A$ be a Banach algebra and $a\in A$. Then
\[ e^a = \sum_{i=0}^\infty \frac{a^i}{i!}. \]
\end{proposition}
\begin{proof}
TODO
\end{proof}
Note that $\exp(0) = \vec{1}$.

\begin{lemma} \label{continuityExp}
The exponential mapping is continuous.
\end{lemma}
\begin{proof}
TODO - see Coleman
\end{proof}

\begin{proposition} \label{factorisationCommutingExponentials}
Let $A$ be a unital Banach algebra and $a,b\in A$. If $a$ and $b$ commute, then
\[ \exp(a+b) = \exp(a)\exp(b). \]
\end{proposition}
\begin{proof}
TODO - Coleman
\end{proof}
\begin{corollary}
Let $a\in A$. Then $\exp(a)\in \GL(A)$ and $\exp(a)^{-1} = \exp(-a)$.
\end{corollary}
\begin{proof}
As $a$ and $-a$ commute, we have $\exp(-a)\exp(a) = \exp(0) = \vec{1}$.
\end{proof}

\begin{lemma}
Let $A$ be a Banach algebra and $a\in A$. Then
\[ \exp(a) = \lim_{n\to\infty} \left(\vec{1} + \frac{a}{n}\right)^n. \]
\end{lemma}
\begin{proof}
TODO
\end{proof}

\begin{lemma}
Let $A$ be a Banach algebra and $p\in A$ an idempotent. Then
\[ e^p = \vec{1} + (e-1)p. \]
\end{lemma}
\begin{proof}
We calculate
\[ e^p = \vec{1} + \sum_{k=1}^\infty \frac{p^k}{k!} = \vec{1} + \sum_{k=1}^\infty \frac{p}{k!} = \vec{1} + p\sum_{k=1}^\infty \frac{1}{k!} = \vec{1} + (e-1)p. \]
\end{proof}

\begin{lemma}
Let $A$ be a Banach algebra, $a\in A$ and $b\in \GL(A)$. Then $\exp(bab^{-1}) = b\exp(a)b^{-1}$.
\end{lemma}
\begin{proof}
TODO
\end{proof}

TODO: $\exp(a^*) = \exp(a)^*$ is Banach-$*$-algebra.

TODO: correct setting for this:
\begin{proposition}
$\det(e^a) = e^{\Tr(a)}$.
\end{proposition}


\subsection{Jordan decomposition}
\subsubsection{Eigennilpotent}
\begin{definition}
Let $a$ be a finite element in a semisimple Banach algebra and $\lambda\in \spec(a)$. The \udef{eigennilpotent operator} of $a$ at $\lambda$ is defined as
\[ D_{\lambda} \defeq (a-\lambda)P_{\lambda}. \]
\end{definition}
This definition works because we can find a $\delta < d(\lambda, \spec(a)\setminus\{\lambda\})$.

\begin{lemma}
Let $a$ be a finite element in a semisimple Banach algebra and $\lambda\in \spec(a)$. The eigennilpotent operator $D_\lambda$ is nilpotent.
\end{lemma}
\begin{proof}
By spectral mapping \ref{holomorphicSpectralMapping}, $D_\lambda$ is quasinilpotent. Because $a$ is finite, it is nilpotent by \ref{nilpotentQuasinilpotent}.
\end{proof}



\subsubsection{Jordan vectors}
\begin{definition}
Let $V$ be a finite dimensional vector space and $T$ an operator on $V$. A \udef{Jordan vector} of $T$ belonging to the eigenvalue $\lambda$ is a vector $x\in V$ such that
\[ (\lambda\id_V - T)^kx = 0 \]
for some $k\in \N$. The least such $k$ is called the \udef{degree} of $x$ and is denoted $\deg_J(x)$.
\end{definition}
Eigenvectors are Jordan vectors of degree $1$.

\begin{proposition}
Let $V$ be a finite dimensional vector space, $T$ an operator on $V$ $\lambda\in\spec(T)$ and $x\in V$. Then $x$ is a Jordan vector of $T$ belonging to the eigenvalue $\lambda$ \textup{if and only if} $x\in E_\lambda$.
\end{proposition}
\begin{proof}
Let $x\in E_\lambda$. Then $x = P_\lambda x$ and thus
\[ (\lambda\id_V - T)^kx = (\lambda\id_V - T)^kP_\lambda x = \big((\lambda\id_V - T)P_\lambda\big)^k x = D_\lambda^k x, \]
which is zero for some $k$ because $D_\lambda$ is nilpotent.

Conversely, assume $x$ is a Jordan vector of $T$ belonging to the eigenvalue $\lambda$. We can write $x = x_1+x_2 \in E_{\lambda}\oplus E_{\C\setminus\{\lambda\}}$.
Then (because $E_\lambda$ is reducing for $T-\lambda\id_V$)
\[ 0 = (\lambda\id_V - T)^kx = (\lambda\id_V - T)^kx_1 + (\lambda\id_V - T)^kx_2 \in E_{\lambda}\oplus E_{\C\setminus\{\lambda\}} \]
Thus we have $(\lambda\id_V - T)^kx_1 = 0$ and $(\lambda\id_V - T)^kx_2 = 0$ separately.
Now $T-\lambda\id_V$ is invertible on $E_{\C\setminus\{\lambda\}}$, so $x_2 = 0$ (TODO ref). This means that $x = x_1 \in E_\lambda$.
\end{proof}

\begin{definition}
Let $m = \deg_N(D_\lambda)$. Then we have
\[ \{0\} \subsetneq \ker(\lambda\id_V - T) \subsetneq \ker(\lambda\id_V - T)^2 \subsetneq \ldots \subsetneq \ker(\lambda\id_V - T)^{m-1} \subsetneq \ker(\lambda\id_V - T)^m = V. \]
We define $E^k_\lambda \defeq \ker(\lambda\id_V - T)^k$. In particular
\begin{itemize}
\item $E^1_\lambda$ is the \udef{geometric eigenspace};
\item $E^{m-1}_\lambda$ is the \udef{algebraic eigenspace}.
\end{itemize}
\end{definition}

\begin{lemma}
Let $V$ be a finite dimensional vector space, $T$ an operator on $V$, $\lambda\in\spec(T)$ and $x\in E_\lambda$. Then
\begin{enumerate}
\item $1 \leq \dim\ker(\lambda\id_V - T) \leq \dim E_\lambda$;
\item $1 \leq \deg_J(x) \leq \dim_E\lambda$.
\end{enumerate}
\end{lemma}
The lemma says the geometric multiplicity is smaller than the algebraic multiplicity.
\begin{proof}
Every eigenvector is a Jordan vector, so $\ker(\lambda\id_V - T) \subseteq E_\lambda$.

For all $k\in\N$ smaller then the degree of $x$, $(\lambda\id_V - T)^kx$ is a Jordan vector and thus in $E_\lambda$. TODO all $(\lambda\id_V - T)^kx$ are linearly independent (like in \ref{nilpotentQuasinilpotent})
\end{proof}

\begin{definition}
Let $V$ be a finite dimensional vector space, $T$ an operator on $V$ and $\lambda\in\spec(T)$. The eigenvalue $\lambda$ is called
\begin{itemize}
    \item \udef{simple} if the algebraic multiplicity is $1$;
    \item \udef{semisimple} if every Jordan vector in $E_\lambda$ has degree $1$;
    \item \udef{prime} if the geometric multiplicity is $1$.
\end{itemize}
If all eigenvalues of $T$ are semisimple, then $T$ is called a \udef{diagonal operator}.
\end{definition}

\begin{lemma}
An operator $T$ is diagonal iff $T$ is of the form $\sum_j a_jP_j$, where $a_j\in \F$ and $P_j$ are projectors that commute pairwise.
\end{lemma}

\subsubsection{Characteristic polynomial and equation}
\begin{definition}
Let $V$ be a finite dimensional vector space and $T$ an operator on $V$. The \udef{characteristic polynomial} $p_T(x)$ of $T$ is the polynomial
\[ p_T(x) \defeq \det(x\id_V - T). \]
\end{definition}

\begin{proposition}
Let $V$ be a finite dimensional vector space, $T$ an operator on $V$ and $\spec(T) = \{\lambda_j\}_{j=1}^r$. Then
\[ p_T(x) = \prod_{j=1}^r(x - \lambda_j)^{\dim E_{\lambda_j}}. \]
\end{proposition}
\begin{proof}
TODO
\end{proof}
\begin{corollary}
A number $\lambda\in \C$ is an eigenvalue of $T$ \textup{if and only if} it is a root of $p_T(x)$.
\end{corollary}

\begin{definition}
The equation $p_T(x) = 0$ is the \udef{characteristic equation} of $T$.
\end{definition}

\subsubsection{Spectral representation}
\begin{proposition}
Let $V$ be a finite dimensional complex vector space and $T$ an operator on $V$. There exists a unique decomposition $T = S + D$ such that
\begin{itemize}
\item $S$ is diagonal;
\item $D$ is nilpotent;
\item $SD = DS$.
\end{itemize}
If $\spec(T) = \{\lambda_j\}_{j=1}^r$, this decomposition is given by
\[ T = \sum_{j=1}^r \lambda_r P_{\lambda_r} + \sum_{j=1}^r D_{\lambda_r}. \]
\end{proposition}

\subsubsection{Partial fraction decomposition of the resolvent}
For any operator $T$ on a vector space $V$ with eigenvalue $\lambda_0$, the resolvent $R_T(\lambda)$ has a pole at $\lambda_0$.

\begin{proposition}
Let $T$ be an operator on a finite dimensional vector space $V$ and $\lambda_0\in\spec(T)$. Then the Laurent expansion of $R_T(\lambda)$ around $\lambda_0$ is of the form
\[ R_T(\lambda) = \frac{P_0}{\lambda-\lambda_0} + \sum_{n=1}^{\deg_N(D_0)-1}\frac{D_0^{n}}{(\lambda - \lambda_0)^{n+1}} + \sum_{n=0}^\infty(-1)^n S_0^{n+1}(\lambda - \lambda_0)^n, \]
where $P_0\defeq P_{\lambda_0}, D_0\defeq D_{\lambda_0}$ and $S_0$ is some fixed operator.
\end{proposition}
\begin{proof}
TODO
\end{proof}

\begin{definition}
The holomorphic part of the Laurent expansion of $R_T(\lambda)$ at $\lambda_0$ is called the \udef{reduced resolvent} of $T$ w.r.t. $\lambda_0$:
\[ S_{T,\lambda_0}(\lambda) \defeq \sum_{n=0}^\infty(-1)^n S_0^{n+1}(\lambda - \lambda_0)^n = R_T(\lambda) - \left(\frac{P_0}{\lambda-\lambda_0} + \sum_{n=1}^{\deg_N(D_0)-1}\frac{D_0^{n}}{(\lambda - \lambda_0)^{n+1}}\right). \]
\end{definition}

\begin{proposition}
Let $T$ be an operator on a finite dimensional vector space $V$ and $\lambda_0\in\spec(T)$. Then
\[ R_{T|_{(\id_V-P_0)}}(\lambda) = S_{T,\lambda_0}|_{\id_V-P_0}(\lambda). \]
\end{proposition}

\begin{proposition}
Let $T$ be an operator on a finite dimensional vector space $V$ with $\spec(T) = \{\lambda_j\}_{j=1}^r$. The partial fraction decomposition of $R_T(\lambda)$ is given by
\[ R_T(\lambda) = \sum_{j=1}^r\left(\frac{P_{\lambda_j}}{\lambda - \lambda_j} +\sum_{n=1}^{\deg_N(D_{\lambda_j})-1}\frac{D_{\lambda_j}^n}{(\lambda - \lambda_j)^{n+1}}\right). \]
The partial fraction decomposition of $S_{T,\lambda_k}(\lambda)$ is given by
\[ S_{T,\lambda_k}(\lambda) = \sum_{\substack{j=1 \\ j\neq k}}^r\left(\frac{P_{\lambda_j}}{\lambda - \lambda_j} +\sum_{n=1}^{\deg_N(D_{\lambda_j})-1}\frac{D_{\lambda_j}^n}{(\lambda - \lambda_j)^{n+1}}\right). \]
\end{proposition}
\begin{proof}
The poles of $R_T(\lambda)$ are exactly the eigenvalues of $T$. There are finitely many of them, so we can use partial fraction decomposition, \ref{partialFractionDecomposition}. We just need to show that the holomorphic part is zero. For that we note that $\lim_{\lambda \to \infty} R_T(\lambda) = 0$ and all principal parts tend to $0$ at infinity as well. Thus the holomorphic part also tends to $0$, making it bounded. By Liouville's theorem, \ref{liouvilleTheoremAnalysis}, we get that it is identically zero.
\end{proof}
\begin{corollary}[Sylvester-Lagrange formula]
Let $f$ be a holomorphic function on an open set that contains $\spec(T)$. Then
\[ f(T) = \sum_{j=1}^r\left(f(\lambda_j)P_{\lambda_j} +\sum_{n=1}^{\deg_N(D_{\lambda_j})-1}\frac{f^{(n)}(\lambda_j)D_{\lambda_j}^n}{n!}\right). \] 
\end{corollary}
\begin{proof}
We have
\[ f(T) = \oint_\Gamma f(\lambda)R_T(\lambda)\diff{\lambda} = 2\pi i\sum_{j=1}^r \Res_{\lambda_j}f(\lambda)R_T(\lambda) \]
by the residue theorem (TODO ref for operators).
\end{proof}
\begin{corollary}[Cayley-Hamilton]
Let $p_T(x)$ be the characteristic polynomial of $T$. Then $p_T(T) = 0$.
\end{corollary}
\begin{proof}
Since $p_T(x) = \prod_{j=1}^r(x - \lambda_j)^{\dim E_{\lambda_j}}$ and $\dim E_{\lambda_j} \geq \deg_N(D_{\lambda_j})$, we see that $p_T(\lambda)R_T(\lambda)$ has no poles and is holomorphic, meaning that $oint_\Gamma f(\lambda)R_T(\lambda)\diff{\lambda} = 0$ by Cauchy's theorem (TODO ref for operators).
\end{proof}

\subsubsection{Normal operators}


\begin{proposition}
If $T$ is a normal operator, then $P_\lambda = P^*_\lambda$ and $D_\lambda = D^*_\lambda = 0$.
\end{proposition}
This means normal operators are diagonalisable.
\begin{proof}
TODO
\end{proof}
\begin{corollary}
Let $V$ be a finite dimensional complex vector space and $T$ a normal operator
on $V$ with $\spec(T) = \{\lambda_j\}_{j=1}^r$.
\begin{enumerate}
\item We have the spectral decompositions
\[ T = \sum_{j=1}^r \lambda_r P_{\lambda_r} \qquad\text{and}\qquad T^* = \sum_{j=1}^r \overline{\lambda_r} P_{\lambda_r}. \]
\item We have
\[ R_T(\lambda) = \sum_{j = 1}^r \frac{P_{\lambda_j}}{\lambda - \lambda_j} \qquad \text{and} \qquad S_{T,\lambda_k}(\lambda) = \sum_{\substack{j = 1 \\ j\neq k}}^r \frac{P_{\lambda_j}}{\lambda - \lambda_j} \]
\end{enumerate}
\end{corollary}

\subsubsection{Jordan decomposition}
TODO matrix representation + matrix representation of Lagrange-Sylvester. See Baumgärtel



\section{Tensor products}
\subsection{Algebraic tensor product}
\begin{proposition}
Let $A$ be a Banach algebra, $a\in A$ and $p\in A$ an idempotent. Then
\begin{enumerate}
\item $e^{p\otimes a} = (\vec{1}-p)\otimes \vec{1} + p\otimes e^a$;
\item $e^{a\otimes p} = \vec{1}\otimes (\vec{1}-p) + e^a\otimes p$.
\end{enumerate}
In particular, $e^{\vec{1}\otimes a} = \vec{1}\otimes e^a$ and $e^{a\otimes \vec{1}} = e^a\otimes \vec{1}$.
\end{proposition}
\begin{proof}
We calculate
\begin{align*}
e^{p\otimes a} &= \sum_{k=0}^\infty \frac{(p\otimes a)^k}{!k} \\
&= \sum_{k=0}^\infty \frac{p^k\otimes a^k}{!k} \\
&= \vec{1}\otimes \vec{1} + \sum_{k=1}^\infty \frac{p\otimes a^k}{!k} \\
&= \vec{1}\otimes \vec{1} + p\otimes\left(\sum_{k=1}^\infty \frac{a^k}{!k}\right) \\
&= \vec{1}\otimes \vec{1} + p\otimes\left(\sum_{k=0}^\infty \frac{a^k}{!k}\right) - p\otimes \vec{1} \\
&= (\vec{1} - p)\otimes \vec{1} + p\otimes e^a,
\end{align*}
where we have used the continuity of $p\otimes -$ (which is bounded by $\norm{p}$).
\end{proof}
\begin{corollary}
Let $A$ be a Banach algebra and $a,b\in A$. Then $e^a\otimes e^b = e^{a\otimes \vec{1} + \vec{1}\otimes b}$.
\end{corollary}
\begin{proof}
We calculate
\[ e^a\otimes e^b = (e^a\otimes \vec{1})(\vec{1}\otimes e^b) = e^{a\otimes \vec{1}}e^{\vec{1}\otimes b} = e^{a\otimes \vec{1} + \vec{1}\otimes b}, \]
using \ref{factorisationCommutingExponentials} with the fact that $a\otimes \vec{1}$ and $\vec{1}\otimes b$ commute.
\end{proof}

