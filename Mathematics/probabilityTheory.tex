\url{file:///C:/Users/user/Downloads/Gut2005_Book_ProbabilityAGraduateCourse.pdf}
\url{https://services.math.duke.edu/~rtd/PTE/PTE5_011119.pdf}
TODO: Kolmogorov 0-1 law Gut p21

\chapter{Probability spaces}
\section{Kolmogorov axioms}
\begin{definition}
A measure space $\seq{\Omega, \mathcal{A}, P}$ is called a \udef{probability space} if the measure $P$ is normalised: $P(\Omega) = 1$.
\end{definition}

\begin{lemma}
Let $\seq{\Omega, \mathcal{A}, P}$ be a probability space and $A,B\subseteq \Omega$ measurable sets. Then
\begin{enumerate}
\item $P(A^c)= 1- P(A)$;
\item $P(A) = P(A\setminus B)+P(A\cap B)$
\item $P(A\cup B)+P(A\cap B) = P(A) + P(B)$;
\end{enumerate}
\end{lemma}
\begin{proof}
(1) $\Omega = A\uplus A^c$ is a disjoint union.

(2) $B = (B\setminus A)\uplus (A\cap B)$ is a disjoint union.

(3) Using (2) we get
\[ A\cup B = \Big(A\setminus (A\cap B)\Big) \uplus \Big(B\setminus (A\cap B)\Big) \uplus (A\cap B) = P(A) - P(A\cap B) + P(B)- P(A\cap B)+ P(A\cap B). \]
\end{proof}
\begin{corollary} \mbox{}
\begin{enumerate}
\item $P(A\cup B) \leq P(A) + P(B)$;
\item $A\subset B$ implies $P(B)= P(A) + P(B\setminus A)$;
\item $A\subset B$ implies $P(A) \leq P(B)$.
\end{enumerate}
\end{corollary}

\begin{theorem}[The inclusion-exclusion formula]
Let $\seq{\Omega, \mathcal{A}, P}$ be a probability space and $\seq{A_k}$ a sequence of events. Then
\begin{multline*}
P\left(\bigcup^n_{k=1} A_k\right) = \sum_{k=1}^nP(A_k)\; - \sum_{1\leq i< j \neq n}P(A_i\cap A_j)\; + \sum_{1\leq i<j<k\leq n}P(A_i\cap A_j\cap A_k)\; - \;\ldots \\
+ \;(-1)^{n+1}P(A_1\cap A_2 \cap \ldots \cap A_n).
\end{multline*}
This can also be written as
\[ P\left(\bigcup^n_{k=1} A_k\right) = \sum_{S\subset 1:n}(-1)^{\#(S)+1} P \left(\bigcap_{i\in S}A_i\right). \]
\end{theorem}
\begin{proof}
Set $A = \bigcup^n_{k=1}A_k$ and consider the function
\[ f = \prod_{k=1}^n(\chi_A-\chi_{A_k}) \]
in $(\Omega\to \{0,1\})$. This function is identically zero. Expanding $f=0$ yields the equation
\[ \chi_A = \sum_{k=1}^n\chi_{A_k} - \sum_{1\leq i< j \neq n}\chi_{A_i}\cdot\chi_{A_j} + \sum_{1\leq i<j<k\leq n}\chi_{A_i}\cdot\chi_{A_j}\cdot\chi_{A_k} - \ldots + (-1)^{n+1}\chi_{A_1}\cdot\chi_{A_2}\cdot \ldots \cdot\chi_{A_n}. \]
Integrating both sides of the equation over the measure $P$ gives the result.
\end{proof}
\begin{corollary}[Bonferroni inequalities]
\begin{align*}
P\left(\bigcup^n_{k=1} A_k\right) &\leq \sum_{k=1}^nP(A_k) \\
P\left(\bigcup^n_{k=1} A_k\right) &\geq \sum_{k=1}^nP(A_k) - \sum_{1\leq i< j \neq n}P(A_i\cap A_j) \\
P\left(\bigcup^n_{k=1} A_k\right) &\leq \sum_{k=1}^nP(A_k) - \sum_{1\leq i< j \neq n}P(A_i\cap A_j) + \sum_{1\leq i<j<k\leq n}P(A_i\cap A_j\cap A_k)
\end{align*}
\end{corollary}
\begin{proof}
TODO \url{https://planetmath.org/proofofbonferroniinequalities}
\end{proof}
\begin{corollary}
If the events of the sequence $\seq{A_k}$ are independent, then
\[ P\left(\bigcup^n_{k=1} A_k\right) = 1 - \prod^n_{k=1}(1-P(A_k)). \]
Also
\[ P\left(\bigcup^n_{k=1} A_k\right) \geq 1 - \exp\left(-\sum^n_{k=1}P(A_k)\right). \]
\end{corollary}

\begin{proposition}
Let $\seq{\Omega, \mathcal{A}, \mu}$ be a probability space and $\mathcal{F}$ an algebra that generates the $\sigma$-algebra $\mathcal{A} = \sigma\{\mathcal{F}\}$. For any $A\in\mathcal{A}$ and $\varepsilon > 0$ there exists a set $A_\varepsilon \in \mathcal{F}$ such that
\[ \mu(A\symdiff A_\varepsilon) \leq \varepsilon. \] 
\end{proposition}
\begin{proof}
Let $\varepsilon > 0$ and define
\[ \mathcal{E} = \setbuilder{A\in\mathcal{A}}{\mu(A\symdiff A_\varepsilon) \leq \varepsilon\;\text{for some}\; A_\varepsilon\in\mathcal{F}}. \]
Clearly $\mathcal{F} \subseteq \mathcal{E} \subseteq \mathcal{A}$. So if $\mathcal{E}$ is a $\sigma$-algebra, then it is equal to $\mathcal{A}$ and the proposition is proven.
\begin{itemize}
\item $\Omega \in \mathcal{A}$ because $\Omega \in \mathcal{F}$.
\item Let $A\in \mathcal{E}$. Then $A^c\symdiff (A_\varepsilon)^c = A\symdiff A_\varepsilon < \varepsilon$, so $A^c\in \mathcal{E}$.
\item Let $\seq{A_i}$ be a sequence of sets in $\mathcal{E}$ and set $A = \bigcup_{i= 0}^\infty A_i$. Then
\[ \lim_{n\to\infty}P\left(\bigcup_{i=0}^n A_i\right) = P\left(\lim_{n\to\infty}\bigcup_{i=0}^n A_i\right) = P(A) \]
and there exists an $n_0\in\N$ such that
\[ \varepsilon/2 > P(A) - P\left(\bigcup_{i=0}^{n_0} A_i\right) = P\left(A\setminus \bigcup_{i=0}^{n_0} A_i\right). \]
TODO
\end{itemize}
\end{proof}

\section{Independence}
\begin{definition}
Let $\seq{\Omega, \mathcal{A}, P}$ be a probability space. The events in a set $\{A_i\}$ are called \udef{independent} if for all finite $F\subset \{A_i\}$ we have
\[ P\left(\bigcap_{A_i\in F}A_i\right) = \prod_{A_i\in F}P(A_i). \]
\end{definition}

\begin{lemma}
Let $\seq{\Omega, \mathcal{A}, P}$ be a probability space and $A,B$ independent events. Then $\{A,B^c\}, \{A^c,B\}$ and $\{A^c, B^c\}$ are also independent.
\end{lemma}
\begin{lemma}
Null sets are independent of any event, in particular of themselves.
\end{lemma}
\begin{proof}
Let $A$ be a null set and $B$ any event. Then
\[ 0\leq P(A\cap B) \leq P(A\setminus B) + P(A\cap B) = P(A) = 0, \]
so 
\[ P(A\cap B) = 0 =  P(A)P(B).  \]
\end{proof}

\subsection{Independent collections of events}
\begin{definition}
Let $\seq{\Omega, \mathcal{A}, P}$ be a probability space. Let $\{\mathcal{A}_i\}$ be a countable family of sets of events. The sets of events in this family are called \udef{independent} if (the image of) every section of $(\mathcal{A}_i\mapsto i)$ is independent.
\end{definition}

\begin{proposition}
Let $\{\mathcal{A}_i\}_{i\in I}$ be a countable family of independent sets of events. Then
\begin{enumerate}
\item $\{\mathfrak{D}\{\mathcal{A}_i\}\}$ are independent sets of events;
\item if the $\mathcal{A}_i$ are $\pi$-systems, then $\{\sigma\{\mathcal{A}_i\}\}$ are independent sets of events.
\end{enumerate}
\end{proposition}
\begin{proof}
The second part follows from the first by \ref{generatedDynkinSigma}.

We prove the first part by induction on the cardinality of $I$. For $\#(I) = 1$ any section contains only one set, which is necessarily independent.

For the induction step, let $s: I \to \bigcup \{\mathfrak{D}\{\mathcal{A}_i\}\}$ be a section. Take $i_0\in I$. We need to show that $s[I\setminus \{i_0\}]\cup \{A\}$ is independent for all $A\in \mathfrak{D}\{\mathcal{A}_{i_0}\}$. By the induction hypothesis we may assume that $s[I\setminus \{i_0\}]\cup \{A\}$ is independent for all $A\in \mathcal{A}_{i_0}$.

Let $B\in s[I]$ and define 
\[ \mathcal{E}_B = \setbuilder{A\in \mathfrak{D}\{\mathcal{A}_{i_0}\}}{P(A\cap B) = P(A)P(B)}. \]
TODO
\end{proof}

\subsection{Pair-wise independence}
\begin{definition}
Let $\seq{\Omega, \mathcal{A}, P}$ be a probability space. The events in a set $\{A_k\}_{k\in I}$ are called \udef{pair-wise independent} if for all $i\neq j \in I$ we have
\[ P\left(A_i \cap A_j\right) = P(A_i)\cdot P(A_j). \]
\end{definition}
Clearly independence implies pair-wise independence. The converse is not true.

\begin{example}
Let $\Omega = \{(1, 0, 0), (0, 1, 0), (0, 0, 1), (1, 1, 1)\}$, $\mathcal{A} = \powerset(\Omega)$ and $P = A\mapsto 1/4 \cdot \#(A)$.

Set $A_k = \{\text{the $k^\text{th}$ coordinate equals $1$}\}$ for $k=1,2,3$. Then
\begin{align*}
P(A_k) &= \frac{1}{2} & \forall k \in\{1,2,3\} \\
P(A_i\cap A_j) &= \frac{1}{4} & \forall i\neq j \in\{1,2,3\} \\
P(A_i)P(A_j) &= \frac{1}{4} & \forall i\neq j \in\{1,2,3\} \\
P(A_1\cap A_2 \cap A_3) &= \frac{1}{4} \\
P(A_1)P(A_2)P(A_3) &= \frac{1}{8}.
\end{align*}
The sets $A_1, A_2, A_3$ are pair-wise independent, but not independent.
\end{example}

\section{Conditional probability}
\begin{definition}
Let $\seq{\Omega, \mathcal{A}, P}$ be a probability space, $A$ and $B$ be two events, and suppose that $P(A) > 0$. The \udef{conditional probability} of $B$ given $A$ is defined as
\[ P(B | A) \defeq \frac{P(A\cap B)}{P(A)}. \]
\end{definition}
\begin{lemma}
Let $\seq{\Omega, \mathcal{A}, P}$ be a probability space and $A$ an event with non-zero probability. Then
\[ P(\cdot | A): B\mapsto P(B | A) \]
is a probability measure on the measurable space $\seq{\Omega, \mathcal{A}}$.
\end{lemma}
\begin{lemma}
If $A,B$ are independent events, then $P(B|A) = P(B)$.
\end{lemma}
\begin{proof}
$P(B|A) = \frac{P(A\cap B)}{P(A)} = \frac{P(A)\cdot P(B)}{P(A)} = P(B)$.
\end{proof}

\section{Chain rule and law of total probability}
\begin{theorem}[Law of total probability]
Let $\seq{\Omega, \mathcal{A}, P}$ be a probability space and $\seq{H_i}_{i\in I}$ a (countable) partition of $\Omega$. Then, for any event $A\in \mathcal{A}$
\[ P(A) = \sum_{i\in I}P(A|H_i)\cdot P(H_i). \]
\end{theorem}
\begin{proof}
$A = A\cap \Omega = \biguplus_{i\in I}(A\cap H_i)$ is a disjoint union.
\end{proof}

\section{Bayes' formula}
\begin{theorem}[Bayes' formula]
Let $\seq{\Omega, \mathcal{A}, P}$ be a probability space and $\seq{H_i}_{i\in I}$ a (countable) partition of $\Omega$. Then, for any event $A$ of non-zero probability,
\[ P(H_k|A ) = \frac{P(A|H_k)\cdot P(H_k)}{P(A)} = \frac{P(A|H_k)\cdot P(H_k)}{\sum_{i\in I}P(A|H_i)\cdot P(H_i)}. \]
\end{theorem}
\begin{proof}
$P(H_k|A) = \frac{P(H_k \cap A)}{P(A)} = \frac{P(A|H_k)\cdot P(H_k)}{P(A)}$.
\end{proof}

\section{Sequences of events}
\subsection{Infinitely often events}
\begin{definition}
Let $\sSet{\Omega, \mathcal{A}, P}$ be a probability space and $\seq{A_n}$ be a sequence of events. We say $\omega \in A_n$ \udef{infinitely often} (or i.o.) if $\omega\in \limsup_{n\to\infty}A_n$.

The event $\limsup_{n\to\infty}A_n$ is also denoted $\{A_n \text{i.o.}\}$.
\end{definition}
\subsubsection{Borel-Cantelli lemma}
\begin{proposition}[Borel-Cantelli lemma]
Let $\seq{\Omega, \mathcal{A}, P}$ be a probability space.
\begin{enumerate}
\item If $\seq{A_n}$ is an arbitrary sequence of events, then
\[ \sum_{n=1}^\infty P(A_n) < \infty \implies P(A_n \text{i.o.}) = 0; \]
\item If $\seq{A_n}$ is a sequence of pair-wise independent events, then
\[ \sum_{n=1}^\infty P(A_n) = \infty \implies P(A_n \text{i.o.}) = 1. \]
\end{enumerate}
\end{proposition}
\begin{proof}
(1) We have, for all $k$,
\[ P(A_n \text{i.o.}) = P\left(\bigcap_{n=1}^\infty\bigcup_{m=n}^\infty A_m\right) \leq P\left(\bigcup_{m=k}^\infty A_m\right) \leq \sum_{m=k}^\infty P(A_m), \]
and $\sum_{m=k}^\infty P(A_m) \to 0$ as $k\to \infty$.

(2) TODO
\end{proof}
\begin{corollary}
Let $\sSet{\Omega, \mathcal{A}, P}$ be a probability space and $\seq{A_n}$ be a sequence of pair-wise independent events. Then
\[  P(A_n \text{i.o.}) = \begin{cases}
0 & \sum_{n=1}^\infty P(A_n) < \infty \\
1 & \sum_{n=1}^\infty P(A_n) = \infty.
\end{cases} \]
\end{corollary}

\chapter{Random variables, random vectors and random elements}
\begin{definition}
Let $\sSet{\Omega, \mathcal{A}, P}$ be a probability space and $\sSet{S, d}$ a metric space which we consider as a measurable space $\sSet{X,\mathcal{B}}$, where $\mathcal{B}$ is the Borel $\sigma$-algebra.
\begin{itemize}
\item A measurable function $X:\Omega \to S$ is called a \udef{random element}.
\item If $S$ is a normed vector space, then $X$ is called a \udef{random vector}.
\item If $S = \R$, then $X$ is called a \udef{random variable} (or \udef{r.v.}).
\item If $S = \overline{\R} = [-\infty, +\infty]$, then $X$ is called an \udef{extended random variable}.
\end{itemize}
\end{definition}


\begin{lemma}
Let $X: \sSet{\Omega, \mathcal{A}, P} \to \sSet{S, d}$ be a random element. Then the pushforward measure
\[ \mathbb{P}_X: \mathcal{B}\to [0, +\infty]: B\mapsto P(X^{-1}(B)) = P(\setbuilder{\omega\in \Omega}{X(\omega)\in B}) \]
is a probability measure on $\sSet{V, \mathcal{B}}$.
\end{lemma}
\begin{proof}
The pushforward measure is a measure by \ref{pushforwardMeasure}.
It is normalised because $X^{-1}[V] = \Omega$, so $\mathbb{P}(V) = P(\Omega) = 1$.
\end{proof}

\begin{definition}
The pushforward probability measure $\mathbb{P}_X$ is called the \udef{induced probability measure} or the probability measure \udef{induced} by $X$. The probability space $\sSet{S, \mathcal{B}, \mathbb{P}_X}$ is the \udef{induced probability space}.
\end{definition}

We will often write $P(X\in B)$ for $\mathbb{P}_X(B) = P(X^{-1}(B)) = P(\setbuilder{\omega\in \Omega}{X(\omega)\in B})$

\section{Equivalence relations on random vectors}
\subsection{Almost sure equivalence}
\begin{definition}
Let $X, Y: \sSet{\Omega, \mathcal{A}, P} \to \sSet{S, \mathcal{B}}$ be random elements. We say $X$ and $Y$ are \udef{almost surely (a.s.) equal}, denoted $X\sim Y$, if they differ on at most a null set:
\[ X\sim Y \iff P(\setbuilder{\omega\in \Omega}{X(\omega) \neq Y(\omega)}) = 0 \iff P(\setbuilder{\omega\in \Omega}{X(\omega) = Y(\omega)}) = 1. \]
We also say $X$ and $Y$ are \udef{equivalent} random vectors.
\end{definition}

\subsection{Equivalence in distribution}
\begin{definition}
Let $X, Y: \sSet{\Omega, \mathcal{A}, P} \to \sSet{S, \mathcal{B}}$ be random elements. We say $X$ and $Y$ are \udef{equal in distribution}, denoted $X \overset{d}{=} Y$, if they assign the same probability the each event in $\mathcal{B}$
\[ X \overset{d}{=} Y \iff \forall B\in\mathcal{B}: \; P(X\in B) = P(Y\in B). \]
\end{definition}

\begin{lemma}
Let $X, Y: \sSet{\Omega, \mathcal{A}, P} \to \sSet{S, \mathcal{B}}$ be random elements. If $X$ and $Y$ are a.s. equal, then they are equal in distribution.
\end{lemma}
\begin{proof}
Set $C = \setbuilder{\omega\in \mathcal{A}}{X(\omega)\in B}$, $D = \setbuilder{\omega\in \mathcal{A}}{Y(\omega)\in B}$ and $E = \setbuilder{\omega\in \Omega}{X(\omega)\neq Y(\omega)}$. Clearly $C\cap E$ and $D\cap E$ are measurable null sets, so $P(C\cap E) = 0 = P(D\cap E)$. Also $C\setminus E = D\setminus E$.

We calculate
\[ P(X\in B) = P(C) = P(C\setminus E) +P(C\cap E) = P(D\setminus E) +P(D\cap E) = P(D) = P(Y\in B). \]
\end{proof}
The converse of this lemma is not true.
\begin{example}
Toss a fair coin. The universe set is $\Omega = \{\text{heads}, \text{tails}\}$. Consider the random vectors
\[ X: \omega \mapsto \begin{cases}
1 & \omega = \text{heads} \\ 0 & \omega = \text{tails}
\end{cases} \qquad\text{and}\qquad  Y: \omega \mapsto \begin{cases}
0 & \omega = \text{heads} \\ 1 & \omega = \text{tails}.
\end{cases} \]
Clearly $P(X = 1) = P(X = 0) = P(Y = 1) = P(Y = 0) = 1/2$. Thus we see that $X \overset{d}{=} Y$. But clearly $X$ and $Y$ are not almost surely equal. In fact they are surely unequal.
\end{example}

\section{Distribution functions}
\begin{definition}
Let $X$ be a random variable on a probability space $\sSet{\Omega, \mathcal{A}, P}$. The \udef{distribution function} of $X$ is the function
\[ F_X: \R \to \R: x\mapsto P(X \leq x) = P(\setbuilder{\omega\in \Omega}{X(\omega) \leq x}). \]
\end{definition}

TODO: this is the Riemann-Stieltjes function. Generalise.

\begin{proposition}
Let $X$ be a random variable on a probability space $\sSet{\Omega, \mathcal{A}, P}$ and $F$ the distribution function of $X$. Then
\begin{enumerate}
\item $F$ is monotonically increasing;
\item $\lim_{x\to-\infty} F(x) = 0$ and $\lim_{x\to+\infty} F(x) = 1$; 
\item $F$ is right-continuous at every point.
\end{enumerate}
Conversely, any function $F:\R\to\R$ that satisfies these properties is the distribution function of some random variable.
\end{proposition}
\begin{proof}
(1) Let $x\leq y$. Then $\setbuilder{\omega\in \Omega}{X(\omega) \leq x} \subseteq \setbuilder{\omega\in \Omega}{X(\omega) \leq y}$, so
\[ F(x) =  P(\setbuilder{\omega\in \Omega}{X(\omega) \leq x}) \leq  P(\setbuilder{\omega\in \Omega}{X(\omega) \leq y}) = F(y). \]

(2) Follows from \ref{measures}.

(3) TODO

(Converse) TODO
\end{proof}
\begin{corollary}
Every discontinuity is a jump discontinuity, so all left limits exist. Also there are at most countably many discontinuities.
\end{corollary}
\begin{proof}
By \ref{monotoneDiscontinuities} and \ref{DarbouxFroda}.
\end{proof}

\begin{proposition}
Let $X_1, X_2$ be random variables. Then
\[ F_{X_1+X_2}(u) = \int_{-\infty}^\infty F_{X_1}(u-y)\diff{F_{X_2}(y)}. \]
If both distributions are absolutely continuous, then
\[ f_{X_1+X_2}(u) = \int_{-\infty}^\infty f_{X_1}(u-y)f_{X_2}(y)\diff{y}. \]
\end{proposition}
\begin{proof}
Fubini TODO
\end{proof}

\begin{lemma}
Let $X$ be a random variable. Then $P\{X = x\} = \Delta F_X(x)$.
\end{lemma}

\subsection{Probability density functions}

\subsection{Transformed random variables}

\begin{proposition} \label{transformationRandomVariable}
Let $X:\Omega \to \R$ be a random variable and $g: \R\to\R$ a Borel measurable function.
\begin{enumerate}
\item If $(g, h)$ forms a Galois connection, then $F_{g(X)}(y) = F_X(h(y))$.
\item If $(g, h)$ forms an antitone Galois connection, then $F_{g(X)}(y) = 1-F_X(h(y)) + \Delta F_X(h(y))$.
\item If $g$ is either strictly increasing or strictly decreasing, then
\[ f_{g(X)}(y) = \begin{cases}
f_X(g^{-1}(y))\left|\od{g^{-1}(y)}{y}\right| & y\in \im(g) \\
0 & y\notin \im(g).
\end{cases} \]
\end{enumerate}
\end{proposition}
In particular we can find a Galois connection $(g,h)$ if $g$ is right continuous and increasing.
\begin{proof}
(1) We calculate
\[ F_{g(X)}(y) = P\{g(X) \leq y\} = P\{X \leq h(y) \} = F_X(h(y)). \]
(2) Similarly,
\[ F_{g(X)}(y) = P\{g(X) \leq y\} = P\{X \geq h(y) \} = 1 - P\{X < h(y) \} = 1 - P\{X \leq h(y) \} + P\{X = h(y)\} = 1-F_X(h(y)) + \Delta F_X(h(y)). \]
(3) TODO
\end{proof}


\section{Convergence}
\begin{definition}
Let $\seq{X_n}$ be a sequence of random elements in $(\sSet{\Omega, \mathcal{A}, P} \to \sSet{S,d})$ and $X$ a random element in the same set. We say
\begin{itemize}
\item $\seq{X_n}$ \udef{converges almost surely} to $X$ if
\[ P(\setbuilder{\omega\in\Omega}{X_n(\omega) \to X(\omega)\;\text{as}\; n\to \infty}) = 1. \]
We write $X_n \overset{a.s.}{\longrightarrow} X$.
\end{itemize}
\end{definition}

\begin{lemma}
Suppose $Y,X,X_n$ are random vectors such that $X_n \overset{a.s.}{\longrightarrow} X$, $E[Y]<\infty$ and $|X_n| \leq Y$ for all $n$. Then $E[|X_n -X|] \to 0$ as $n\to \infty$.
\end{lemma}
\begin{proof}
This is just the Lebesgue dominated convergence theorem TODO ref.
\end{proof}

\section{Expected value}
\begin{definition}
Let $X$ be a random  vector on a probability space $\sSet{\Omega, \mathcal{A}, P}$. We define the \udef{exprectated value} of $X$ as
\[ \E{X} \defeq \int_\Omega X(\omega)\diff{P(\omega)}. \]
assuming $X$ is integrable.
\end{definition}



\subsection{Moments}
\subsubsection{Raw and central moments}
\subsubsection{Moment generating function}
\subsubsection{Normalised moments}
\subsubsection{Examples of moments}
\paragraph{Expected value}
\paragraph{Variance and standard deviation}
\paragraph{Skewness}
\paragraph{Kurtosis}

\subsection{Mean and variance}

\begin{proposition}
Let $\sSet{\Omega, \mathcal{A}, P}$ be a probability space and $X,Y:\Omega \to \R$ random variables with finite means $\mu_X,\mu_Y$ and standard deviations $\sigma_X$, $\sigma_Y$. Then
\[ |\E[XY] - \mu_X\mu_Y| \leq \sigma_X\sigma_Y. \]
\end{proposition}
\begin{proof}
This follows from the CSB inequality, \ref{CauchySchwarz}:
\begin{align*}
\sigma_X\sigma_Y &= \sqrt{\E[(X-\mu_X)^2]}\sqrt{\E[(Y-\mu_Y)^2]} \\
&\geq |\E[(X-\mu_X)(Y-\mu_Y)]| \\
&= |\E[XY] + \mu_X\mu_Y -\mu_X\mu_Y -\mu_X\mu_Y| = |\E[XY] - \mu_X\mu_Y|.
\end{align*}
\end{proof}

\subsection{Cumulants}

\subsection{Conditional expectation}

\section{Joint distributions}
\subsection{Marginal distributions}

\section{Independence of random elements}
\begin{definition}
A set of random elements $\{X_i\}_{i\in 1:n}$ is called \udef{independent} if for all sets $\{A_i\}_{i\in 1:n}$ of $n$ Borel measurable sets we have that $\{X_i^{-1}[A_i]\}_{i\in 1:n}$ is a set of independent events. i.e.
\[ P\left(\bigcap_{i=1}^n X_i^{-1}[A_i]\right) = \prod_{i=1}^n P(X_i^{-1}[A_i]). \]
\end{definition}

\begin{proposition}
The random variables $X_1, \ldots X_n$ are independent \textup{if and only if}
\[ F_{X_1,\ldots, X_n}(x_1, \ldots, x_n) = \prod_{i=1}^n F_{X_i}(x_i). \]
\end{proposition}

\begin{proposition}
Let $X_1, \ldots X_n$ be independent random elements and $f_1, \ldots, f_n$ measurable functions. Then $f_1\circ X_1, \ldots, f_n\circ X_n$ are independent.
\end{proposition}
\begin{proof}
Let $A_1, \ldots, A_n$ be Borel measurable sets. Since the $f_i^{-1}[A_i]$ are Borel measurable, we have
\[ P\left(\bigcap_{i=1}^n (f_i\circ X_i)^{-1}[A_i]\right) = P\left(\bigcap_{i=1}^n X_i^{-1}[f^{-1}_i[A_i]]\right) = \prod_{i=1}^n P(X_i^{-1}[f^{-1}_i[A_i]]) = \prod_{i=1}^n P((f_i\circ X_i)^{-1}[A_i]). \]
\end{proof}

\chapter{Distributions}
TODO: uniform distribution

\section{Distributions of discrete random variables}
\subsection{Bernoulli trials}
\subsubsection{Bernoulli distribution}
\subsubsection{Geometric distribution}

\subsection{Iterated Bernoulli trials}
\subsubsection{Binomial distribution}
\subsubsection{Negative binomial or Pascal distribution}
\subsubsection{Hypergeometric distribution}
\subsubsection{Negative hypergeometric distribution}

\subsection{Poisson distribution}
\begin{definition}
Let $\lambda > 0$ be a positive real number. The \udef{Poisson distribution} with parameter $\lambda$ is the distribution of a random variable $X: \sSet{\Omega, \mathcal{A}, P} \to \N$ with probability density
\[ f_\lambda(k) = \begin{cases}
\frac{\lambda^k e^{-\lambda}}{k!} & k\in\N \\
0 & \text{otherwise}
\end{cases}. \]
We write $X \sim \Poisson(\lambda)$.
\end{definition}

\section{Distributions of continuous random variables}
\subsection{Gamma distribution and subfamilies}
\subsubsection{Gamma distribution}
\begin{definition}
Let $\alpha, \beta$ be positive real numbers. The \udef{gamma distribution} with parameters $\alpha, \beta$ is the distribution of a random variable $X: \sSet{\Omega, \mathcal{A}, P} \to \R_+$ with probability density
\[ f_{\alpha,\beta}(x) = \frac{x^{\alpha-1}e^{-\beta x}\beta^\alpha}{\Gamma(\alpha)}, \]
where $\Gamma$ is the Gamma function.
\begin{itemize}
\item We call $\alpha$ the \udef{shape parameter}.
\item We call $\beta$ the \udef{rate parameter}.
\item We call $1/\beta$ the \udef{scale parameter}.
\end{itemize}
We write $X \sim \GammaDist(\alpha,\beta)$.
\end{definition}
TODO lower incomplete gamma function.

\begin{lemma}
Let $\alpha,\beta, k$ be positive real numbers. Let $X \sim \GammaDist(\alpha, \beta)$ be a random variable. Then $kX \sim \GammaDist(\alpha, \beta / k)$.
\end{lemma}

\subsubsection{Erlang distribution}
\begin{definition}
An \udef{Erlang distribution} is a gamma distibution where the shape parameter $\alpha$ is an integer $n$. We wite $\Erlang(n, \beta) \defeq \GammaDist(n, \beta)$.
\end{definition}

\begin{proposition} \label{ErlangCDF}
Let $X \sim \Erlang(n, \beta)$. Then the cumulative distribution function of $X$ is given by
\[ F_{n,\beta}(x) = 1 = \sum_{k=0}^{n-1} \frac{(\beta x)^k}{k!}e^{-\beta x}. \]
\end{proposition}

\subsubsection{Exponential distribution}
\begin{definition}
An \udef{exponential distribution} is an Erlang distribution with shape parameter $n = 1$. Thus $\Exponential(\beta) \defeq \Erlang(1,\beta) = \GammaDist(1, \beta)$.
\end{definition}

\subsubsection{$\chi^2$-distribution}
\begin{definition}
Let $k\in \N^\times$ be strictly positive integer. Then we call a gamma distribution with shape $k/2$ and rate $1$ a \udef{$\chi^2$-distribution} with $k$ \udef{degrees of freedom}. We write $\chi^2_k = \GammaDist(k/2, 1)$.
\end{definition}

\section{Distributions of random vectors}

\chapter{Convergence}
\section{Types of convergence}

\chapter{Stochastic processes}
\url{https://math.stackexchange.com/questions/1309853/proving-galmarinos-test/1596012}

\url{https://link.springer.com/content/pdf/10.1007%2F978-3-319-78768-8.pdf}
\url{https://people.math.harvard.edu/~knill/books/KnillProbability.pdf}

\url{file:///C:/Users/user/Downloads/(Advances%20in%20applied%20mathematics)%20Kirkwood,%20James%20R%20-%20Markov%20Processes-CRC%20Press%20(2015).pdf}
\url{file:///C:/Users/user/Downloads/(De%20Gruyter%20Studies%20in%20Mathematics)%20Kolokoltsov%20V.N.%20-%20Markov%20processes,%20semigroups%20and%20generators-De%20Gruyter%20(2011).pdf}

\section{Processes}
\begin{definition}
Let $\sSet{\Omega, \mathcal{A}, P}$ be a probability space, $\sSet{S,d}$ a metric space and $\sSet{I,\leq}$ a partially ordered index set. A \udef{stochastic process} $X$ is a function
\[ I\times \Omega \to S: (t,\omega) \mapsto X_t(\omega) \]
such that the partial application $X_t$ is a random element for all $t\in I$.
\begin{itemize}
\item A \udef{sample path}, \udef{trajectory} or \udef{realisation} is a partial application
\[ X_-(\omega): t\mapsto X_t(\omega). \]
\item If $I \subseteq \N$, we call the stochastic process a \udef{stochastic sequence}.
\item If $I$ is a subinterval of $\R$, we call the stochastic process a \udef{continuous process}.
\item If $I\subseteq \R^+$, we call the index \udef{time} and the process a \udef{continuous time process}.
\item If $I\subseteq \R^k$, we call the stochastic process a \udef{$k$-parameter} or \udef{multiparameter process}.
\end{itemize}
\end{definition}

\begin{lemma}
Let $\sSet{\Omega, \mathcal{A}, P}$ be a probability space, $\sSet{S,d}$ a metric space, $\sSet{I,\leq}$ a partially ordered index set and $X$ a function $X: I\times \Omega\to S: (t,\omega) \mapsto X_t(\omega)$. The following are equivalent:
\begin{enumerate}
\item $X$ is a stochastic process;
\item $X$ is measurable w.r.t. the $\sigma$-algebra generated by $\bigcup_{\substack{t\in I\\ A\in \mathcal{A}}}\{\{t\}\}\times A$;
\item 
\end{enumerate}

Then $X$ is a stochastic process \textup{if and only if} $X$ is measurable w.r.t. the $\sigma$-algebra $\powerset(I)\otimes \mathcal{A}$.
\end{lemma}
\begin{proof}

\end{proof}

\begin{lemma}
Let $\sSet{\Omega, \mathcal{A}, P}$ be a probability space, $\sSet{S,d}$ a metric space, $\sSet{I,\leq}$ a partially ordered index set and $X$ a function $X: I\times \Omega\to S: (t,\omega) \mapsto X_t(\omega)$.

Then $X$ is a stochastic process \textup{if and only if} $\operatorname{curry}(X): \Omega \to (I\to S)$ is measurable, where $(I\to S)$ is equipped with the $\sigma$-algebra $\bigotimes_{t\in I}\mathcal{B}$ and $\mathcal{B}$ is the Borel-$\sigma$-algebra on $S$.
\end{lemma}
\begin{proof}
TODO!! (is it true??)
\end{proof}

\subsection{Equivalent stochastic processes}
\begin{definition}
Let $\sSet{\Omega, \mathcal{A}, P}$ be a probability space, $\sSet{S,d}$ a metric space and $\sSet{I,\leq}$ a partially ordered index set. Let $X,Y$ be stochastic processes. We call $X$ and $Y$
\begin{itemize}
\item \udef{equivalent} or \udef{indistinguishable} if
\[ P(X_- = Y_-) = 1. \]
\item \udef{stochastically equivalent} or \udef{modifications} of each other if
\[ \forall t\in I: P(X_t = Y_t) = 1.  \]
\end{itemize}
\end{definition}

\begin{lemma}
Equivalence and stochastic equivalence are equivalence relations.
\end{lemma}

\begin{lemma}
Let $\sSet{\Omega, \mathcal{A}, P}$ be a probability space, $\sSet{S,d}$ a metric space, $\sSet{I,\leq}$ a partially ordered index set and $X,Y$ stochastic processes. Then
\begin{enumerate}
\item $X$ and $Y$ are equivalent if and only if
\[ \exists \;\text{null set}\; A\subseteq \Omega: \forall t\in I: \forall \omega\in A^c: \; X_t(\omega) = Y_t(\omega); \]
\item $X$ and $Y$ are stochastically equivalent if and only if
\[ \forall t\in I: \exists \;\text{null set}\; A\subseteq \Omega: \forall \omega\in A^c: \; X_t(\omega) = Y_t(\omega).  \]
\end{enumerate}
In particular equivalence implies stochastic equivalence.
\end{lemma}
The opposite implication does not hold:
\begin{example}
Let $T$ be a random variable that is uniformly distributed over the interval $[0,1]$. Define
\[ X_t = \chi_{\{t=T\}} \qquad\text{and}\qquad Y_t = \omega\mapsto 0. \]
So the sample paths of $Y$ are identically zero and the sample paths of $X$ are zero everywhere except at one point, where it is one.

Now $X$ and $Y$ are stochastically equivalent: for all $t$ we have
\[  P(X_t = Y_t) = P(X_t = 0) = P(T \neq t) = 1. \]

But $X$ and $Y$ are not equivalent: for all $\omega$, the sample paths differ by exactly one point, so the probability of them coinciding is zero.
\end{example}

\begin{proposition}
If the index set $I$ is countable, then stochastic equivalence implies equivalence.
\end{proposition}
\begin{proof}
Let $X,Y$ be stochastically equivalent processes on a countable index set $I$. We calculate
\begin{align*}
P(X_- = Y_-) &= P\left(\bigcap_{i\in I}\{X_i = Y_i\}\right) = 1-P\left(\bigcup_{i\in I}\{X_i \neq Y_i\}\right) \\
&\geq 1 - \sum_{i\in I}P(\{X_i \neq Y_i\}) = 1.
\end{align*}
\end{proof}
So for countable index sets stochastic equivalence and equivalence are equivalent.

\begin{proposition}
Let $X$ be a stochastic process such that all sample paths of $X$ lie in a separable ...
\end{proposition}
\begin{proof}
TODO
\end{proof}
\begin{corollary}
Let $X$ and $Y$ be stochastic processes whose sample paths are almost surely right-continuous (resp. left-continuous). Then $X$ and $Y$ are equivalent \textup{if and only if} they are stochastically equivalent.
\end{corollary}

\subsection{Filtration}
\begin{definition}
Let  $\sSet{\Omega, \mathcal{A}, P}$ be a probability space and $\sSet{I,\leq}$ an ordered index set. A \udef{filtration} is an order-preserving function from $I$ to the lattice of sub-$\sigma$-algebras of $\mathcal{A}$.

If $i$ is mapped to $\mathcal{A}_i$, we call $\sSet{\Omega, \mathcal{A}, \{\mathcal{A}_i\}_{i\in I}, P}$ a \udef{filtered probability space}.

Let $t\in I$. Then we define
\begin{itemize}
\item the \udef{left limit} at $t$ as $\mathcal{A}_{t-} \defeq \bigvee_{s<t}\mathcal{A}_s$;
\item the \udef{right limit} at $t$ as $\mathcal{A}_{t+} \defeq \bigwedge_{t<s}\mathcal{A}_s$;
\item the \udef{limit at infinity} as $\mathcal{A}_{\infty} \defeq \bigvee_{s\in I}\mathcal{A}_s$.
\end{itemize}
\end{definition}
The suprema and infima are taken in the lattice of $\sigma$-algebras on $\Omega$. By \ref{completeLatticeOperationsUnderClosure} we have
\[ \bigwedge\mathcal{E} = \bigcap\mathcal{E} \qquad\text{and}\qquad \bigvee\mathcal{E} = \sigma\left\{\bigcup \mathcal{E}\right\},  \]
where $\mathcal{E}$ is any set of $\sigma$-algebras on $\Omega$.

\begin{lemma}
Let $\sSet{\Omega, \mathcal{A}, \{\mathcal{A}_i\}_{i\in I}, P}$ be a filtered probability space. Then for all $t\in I$
\begin{enumerate}
\item $\mathcal{A}_{t-} \subseteq \mathcal{A}_{t} \subseteq \mathcal{A}_{t+}$;
\item $\mathcal{A}_{t} \subseteq \mathcal{A}_{\infty}$.
\end{enumerate}
\end{lemma}
\begin{proof}
Using the fact that $t\mapsto \mathcal{A}_t$ is order-preserving and \ref{orderPreservingFunctionLatticeOperations}, we have
\[ \mathcal{A}_{t-} = \bigvee\mathcal{A}_{\downset t \setminus\{t\}} \subseteq \mathcal{A}_{\bigvee \downset t \setminus\{t\}} \subseteq \mathcal{A}_{\bigvee \downset t} = \mathcal{A}_t = \mathcal{A}_{\bigwedge \upset t} \subseteq \mathcal{A}_{\bigwedge \upset t \setminus\{t\}} \subseteq \bigwedge \mathcal{A}_{\upset t \setminus\{t\}} = \mathcal{A}_{t+}. \]
\end{proof}

\subsubsection{Adapted processes and natural filtrations}
\begin{definition}
Let $\sSet{\Omega, \mathcal{A}, P}$ be a probability space, $\sSet{I,\leq}$ an ordered index set and $\sSet{S,d}$ a metric space.

\begin{itemize}
\item Given a filtration $\{\mathcal{A}_t\}_{t\in I}$, a stochastic process $X: I\times \Omega \to S$ is \udef{adapted} to the filtration if for all $t\in I$ $X_t$ is measurable w.r.t. $\mathcal{A}_t$.
\item Given a stochastic process $X: I\times \Omega \to S$, the \udef{natural filtration} $\NF(X)$ is the filtration \udef{generated} by $X$:
\[ \mathcal{A}_t \defeq \sigma\setbuilder{X_s^{-1}[B]}{s\leq t, B\in \mathcal{B}(S)}. \]
\end{itemize}

Let $\NF_{I,\Omega}^S$ be the set of natural filtrations generated by stochastic processes in $(I\times\Omega \to S)$.
\end{definition}

\begin{lemma}
Let $\sSet{\Omega, \mathcal{A}, P}$ be a probability space, $\sSet{I,\leq}$ an ordered index set and $\sSet{S,d}$ a metric space. Let $X: I\times \Omega\to S$ be a stochastic process and $\{\mathcal{A}_t\}_{t\in I}$ a filtration. Then
\[ X \;\text{is adapted to}\; \{\mathcal{A}_t\}_{t\in I} \iff \NF(X) \leq \{\mathcal{A}_t\}_{t\in I}. \]
\end{lemma}

\begin{lemma}
Let $\sSet{\Omega, \mathcal{A}, P}$ be a probability space, $\sSet{I,\leq}$ an ordered index set, $\sSet{S,d}$ a metric space and $X: I\times\Omega\to S$ a stochastic process.

For all $t\in I$ we define $\mathcal{A}_i$ as the set of all subsets of $\Omega$ of the form
\[ \bigcap_{j\in J} X_{t_j}^{-1}[B_j] \]
for some (countable) sequence $\seq{t_j}$ in $\downset t$ and $\seq{B_j}$ in $\mathcal{B}(S)$.

Then $\{\mathcal{A}_t\}_{t\in I}$ is the natural filtration $\NF(X)$.
\end{lemma}
\begin{proof}
Clearly $\setbuilder{X_s^{-1}[B]}{s\leq t, B\in \mathcal{B}(S)}_{t\in I} \subseteq \{\mathcal{A}_t\}_{t\in I} \subseteq \NF(X)$. So it is enough to prove that $\mathcal{A}_t$ is a $\sigma$-algebra for all $t\in I$. By the monotone class theorem, \ref{monotoneClassTheorem}, it is in fact enough to show that $\mathcal{A}_t$ is a monotone class for all $t\in I$. Closure under countable (monotone) intersections is clear.


\end{proof}

\begin{proposition}
Let $\sSet{\Omega, \mathcal{A}, P}$ be a probability space, $\sSet{I,\leq}$ an ordered index set and $\sSet{S,d}$ a metric space.

The set $\NF_{I,\Omega}^S$ of natural filtrations forms a sublattice of the lattice of filtrations of $\mathcal{A}$ on $I$.
\end{proposition}
\begin{proof}

\end{proof}

\subsubsection{Usual and natural conditions}
\begin{definition}
Usual conditions, natural conditions
\end{definition}

\subsection{Stopping times}
\begin{definition}
Let $\sSet{\Omega, \mathcal{A}, \{\mathcal{A}_i\}_{i\in I}, P}$ be a filtered probability space, $\sSet{I,\leq}$ an ordered index set and $\overline{I}$ its Dedekind-MacNeille completion. A \udef{stopping time} is a function $\tau: \Omega \to I$ such that $\{\tau \leq t\} \in \mathcal{A}_t$ for all $t\in I$.
\end{definition}

We equip the set of stopping times with pointwise order.

\begin{lemma}
Let $\sSet{\Omega, \mathcal{A}, \{\mathcal{A}_i\}_{i\in I}, P}$ be a filtered probability space and $\sSet{I,\leq}$ an ordered index set. Then
\begin{enumerate}
\item the constant function $\underline{t}$ is a stopping time for all $t\in I$;
\item the set of stopping times is a sublattice of $(\Omega\to I)$.
\end{enumerate}
\end{lemma}
\begin{proof}
(1) For all $i\in I$: we have
\[ \{\underline{t} \leq i\} = \begin{cases}
\Omega & (t\leq i) \\
\emptyset & (t > i)
\end{cases} \]
In both cases $\{\underline{t} \leq i\}$ is an element of each $\sigma$-algebra.

(2)
\end{proof}

\begin{theorem}[Galmarino's test]
Let $\sSet{\Omega, \mathcal{A}, \{\mathcal{A}_i\}_{i\in I}, P}$ be a filtered probability space and $\sSet{I,\leq}$ an ordered index set.

A function $\tau: \Omega\to I$ is a stopping time \textup{if and only if} for all $\omega,\omega'\in \Omega$:
\[ \tau(\omega) = t \land \Big( \forall s\in\downset t: X_s(\omega) = X_s(\omega') \Big) \implies \tau(\omega')=t. \]
\end{theorem}

\subsubsection{Stopped processes}
\begin{definition}
Let $X: I\times \Omega\to S$ be a stochastic process and $\tau:\Omega\to I$ a stopping time. Then the \udef{stopped process} $X^\tau$ is defined by
\end{definition}

\subsection{Measurability requirements}
\subsubsection{Joint measurability}
\begin{definition}
Let $\sSet{\Omega, \mathcal{A}, P}$ be a probability space, $\sSet{S,d}$ a metric space, $\sSet{I,\mathcal{T}, \leq}$ a topological poset and $X$ a stochastic process. We call $X: \Omega\times I\to S$ \udef{jointly measurable} if it is measureable w.r.t. $\mathcal{A}\otimes \mathcal{B}(I)$.
\end{definition}

TODO: order algebra???????

\begin{lemma}
All right-continuous and left-continuous processes are jointly measurable. 
\end{lemma}

\begin{proposition}
If $X$ is a jointly measurable stochastic process and $\tau: \Omega\to I$ a random time, then
\[ X_\tau: \Omega\to S: \omega\mapsto X(\omega)_{\omega} \]
is measurable and thus a random element.
\end{proposition}
\begin{proof}

\end{proof}

\subsubsection{Predictable and optional processes}

\subsubsection{Progressively measurable processes}

\section{Martingales}

\section{Properties and classes of processes}
\subsection{Processes generated by transition probabilities}
\url{https://arxiv.org/pdf/1603.00251.pdf}
\subsubsection{Markov processes}
\subsubsection{Feller processes}
``$C_0$-semigroup''??
\subsubsection{Lévy processes}

\subsection{Processes by distribution}
\subsubsection{Wiener processes}
\subsubsection{Bessel processes}

\subsection{Integer-valued processes}
\subsubsection{Birth-death processes}
\begin{definition}
An integer-valued Markov process is called a \udef{birth-death process}.
\end{definition}

\subsubsection{Counting processes and birth processes}
\begin{definition}
A \udef{counting process} is a stochastic process
\[ N: \sSet{I,\leq}\times \sSet{\Omega, \mathcal{A}, P} \to \N \]
for some probability space $\Omega$ and ordered set $I$ such that for all $s,t\in I$:
\[ \forall s,t\in I: \quad s\leq t \implies N(s)\leq N(t). \]

If the counting process $N$ is a Markov process, then it is called a \udef{birth process}.
\end{definition}

\subsubsection{Poisson processes}
\begin{definition}
A stochastic process
\[ N: \R_+\times \sSet{\Omega, \mathcal{A}, P} \to \Z \]
is called a \udef{Poisson process} if there exists a continuous, increasing function $\Lambda: \R\to \R$ such that
\[ N_t - N_s \sim \Poisson(\Lambda(t) - \Lambda(s)) \]
for all $s\leq t$, independently of $\setbuilder{N_u}{u\leq s}$.

The function $\Lambda$ is called the \udef{cumulative rate}. If $\od{\Lambda(s)}{s}$ exists, it is called the \udef{(instantaneous) rate}.

If $\Lambda$ is of the form $t\mapsto t\lambda$ for some $\lambda \in \R_+$, then we say $N$ is a \udef{homogenous Poisson process}.
\end{definition}

\begin{lemma} \label{PoissonProcessRateTransform}
Let $N_t$ be a Poisson process with cumulative rate $\Lambda$.
\begin{enumerate}
\item Let $\theta: \R_+\to \R$ be a continuous function. Then $N_{\theta(t)}$ is a Poisson process with cumulative rate $\Lambda\circ \theta$, if $\Lambda\circ \theta$ is increasing.
\item Let $c\in \R$. Then $\Lambda + \underline{c}$ is also a cumulative rate function for $N_t$.
\item Let $K$ be a random, integer-valued element. Then $N_t + K$ is also a Poisson process with cumulative rate $\Lambda$.
\end{enumerate}
\end{lemma}
From now on we assume, WLOG, that $\Lambda(0) = 0$.

\begin{lemma}
Let $N$ be a Poisson process with cumulative rate $\Lambda$ such that $N_0 = 0$ and $\Lambda(0) = 0$. Then for each $t\in \R_+$, we have $N_t \sim \Poisson(\Lambda(t))$.
\end{lemma}
\begin{proof}
This follows directly from $N_t = N_t - N_0 \sim \Poisson(\Lambda(t) - \Lambda(0)) = \Poisson(\Lambda(t))$.
\end{proof}

\begin{proposition}
For any continuous, increasing function $\Lambda: \R_+\to \R$, there exists a Poisson processes with cumulative rate $\Lambda$.
\end{proposition}
\begin{proof}
Construct homogenous Poisson process $N_t$ with rate $1$ (TODO ref). Then $N_{\Lambda(t)}$ is a Poisson process with cumulative rate $\Lambda$ by \ref{PoissonProcessRateTransform}.
\end{proof}

\begin{proposition}
Let $N$ be a Poisson process. Then
\begin{enumerate}
\item $N$ is a Markov process;
\item if $N$ is a homogenous Poisson process, then it is a Lévy process.
\end{enumerate}
\end{proposition}
\begin{proof}
TODO
\end{proof}

\begin{proposition}
Let $N$ be a Poisson process. For each $n\in \N$, consider the stopping time
\[ \tau_n: \sSet{\Omega, \mathcal{A}, P} \to \R_+: \omega \mapsto \inf\setbuilder{t}{N_t(\omega) - N_0(\omega) \geq n }. \]
\begin{enumerate}
\item The distribution of $\tau_n$ is given by
\[ F_{\tau_n}(t) = 1- \sum_{k=0}^{n-1}\frac{\Lambda(t)^k}{k!}e^{-\Lambda(t)} = F_{\Erlang(n, 1)}(\Lambda(t)). \]
\item If $N$ is a homogenous Poisson process with rate $\lambda$, then $\tau_n \sim \Erlang(n, \lambda)$. In particular $\tau_1 \sim \Exponential(\lambda)$.
\item If $\Lambda$ is bijective, then $N_{\Lambda^{-1}(t)}$ is a homogenous Poisson process with rate $1$ and stopping times $\Lambda(\tau_n)$.
\end{enumerate}
\end{proposition}
\begin{proof}
(1) We have
\begin{align*}
F_{\tau_n}(t) &= P\{\tau_n \leq t\} = P\{N_t \geq n\} \\
&= \sum_{k=n}^{\infty}P\{N_t = k\} = \sum_{k=n}^{\infty} \frac{\Lambda(t)^k}{k!}e^{-\Lambda(t)} \\
&= (e^{\Lambda(t)} - \sum_{k=0}^{n-1}\frac{\Lambda(t)^k}{k!})e^{-\Lambda(t)} = 1- \sum_{k=0}^{n-1}\frac{\Lambda(t)^k}{k!}e^{-\Lambda(t)}.
\end{align*}
We see this is equal to $F_{\Erlang(n, 1)}(\Lambda(t))$ by comparing with \ref{ErlangCDF}. 

(2) This follows by the substitution $\Lambda(t) = \lambda t$ and comparison with \ref{ErlangCDF}.

(3) We calculate
\[ \inf\setbuilder{t}{N_{\Lambda^{-1}(t)}(\omega) - N_0(\omega) \geq n } = \inf\setbuilder{\Lambda(u)}{N_{u}(\omega) - N_0(\omega) \geq n } = \Lambda(\tau_n), \]
using the substitution $u = \Lambda^{-1}(t)$ and TODO ref inf preserving.
\end{proof}

\begin{proposition}
Let $N$ be a homogenous Poisson process with rate $\lambda$. Then the interarrival times $S_n = \tau_n - \tau_{n-1}$ are i.i.d. random variables with distribution $\Exponential(\lambda)$.
\end{proposition}
\begin{proof}
TODO
\end{proof}

\section{Stochastic integration}
\subsection{Stochastic differential equations}

