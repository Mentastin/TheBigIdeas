
\url{https://www.mat.univie.ac.at/~gerald/ftp/book-fa/fa.pdf}


\chapter{Functionals on vector spaces}

\begin{theorem}[Riesz–Markov–Kakutani representation theorem]
Let $X$ be a locally compact Hausdorff space. For any positive linear functional $\psi$ on $C_c(X)$, there is a unique Radon measure $\mu$ on $X$ such that
\[ \forall f\in C_c(X): \quad \psi(f) = \int_X f(x)\diff{\mu(x)}. \]
\end{theorem}

\begin{definition}
Let $V$ be a vector space over a field $\mathbb{F}$.
\begin{enumerate}
\item A \udef{functional} on $V$ is a map $V\to \F$;
\item A \udef{linear functional} on $V$ is a linear map from $V$ to $\mathbb{F}$.
\end{enumerate}
\end{definition}

\section{Non-linear functionals}
\subsection{Sublinear functionals}
\begin{definition}
Let $V$ be a vector space. A functional $p:V\to \R$ is called \udef{sublinear} if it is
\begin{enumerate}
\item subadditive: $\forall x,y\in V: p(x+y) \leq p(x) + p(y)$;
\item positive homogenous: $\forall x\in V,\lambda\geq 0: p(\lambda x) = \lambda p(x)$.
\end{enumerate}
\end{definition}
Thus norms and seminorms are sublinear.

\subsection{Convex functionals}
\begin{definition}
Let $V$ be a vector space. A functional $p:V\to \R$ is called \udef{convex} if for all $x,y\in V$ and $\lambda\in [0,1]$
\[ p(\lambda x + (1-\lambda)y) \leq \lambda p(x) + (1-\lambda)p(y). \]
\end{definition}
Clearly every sublinear functional is convex.

\begin{lemma}
Let $p: V\to\R$ be convex functional. Then
\[ P: V\to\R: x\mapsto \inf_{t>0} t^{-1}p(tx) \]
is sublinear and $P(x)\leq p(x)$.

Also, if $f:V\to \R$ is a linear functional, then $f\leq p \iff f\leq P$.
\end{lemma}
\begin{proof}
For sublinearity: let $x,y\in V$, then for all $s,t>0$
\[ P(x+y) \leq \frac{s+t}{st}p\left(\frac{st}{s+t}(x+y)\right) = \frac{s+t}{st}p\left(\frac{s}{s+t}(tx)+\frac{t}{s+t}(sy)\right) \leq t^{-1}p(tx) + s^{-1}p(sy). \]
This implies that $P(x+y)\leq P(x)+P(y)$.

For positive homogeneity: let $x\in V,\lambda\geq 0$
\[ P(\lambda x) = \inf_{t>0} t^{-1}p(t\lambda x) = \inf_{t\lambda>0} \lambda (t\lambda)^{-1}p(t\lambda x) = \inf_{t>0} \lambda (t)^{-1}p(tx) = \lambda P(x). \]

Finally we prove that $f\leq p \implies f\leq P$ for linear functionals $f$. For all $t>0$ we have $f(tx) \leq p(tx)$, which implies $f(x) = t^{-1}f(tx) \leq t^{-1}p(tx)$. So $f\leq P$.
\end{proof}

\section{Hahn-Banach extension theorems}
\begin{theorem}[Hahn-Banach majorised by convex functionals] \label{theorem:sublinearHahnBanach}
Let $V$ be a real vector space, $U\subset V$ a subspace and $p$ a convex functional on $V$. Let $f:U\to\R$ be a linear functional that is bounded by $p$:
\[ \forall u\in U: \quad f(u) \leq p(u). \]
Then $f$ has an extension $\tilde{f}: V\to \R$ such that $\tilde{f}$ is a linear functional on $V$ bounded by $p$:
\[ \forall v\in V: \tilde{f}(v) \leq p(v) \qquad \text{and} \qquad \forall u\in U: \tilde{f}(u) = f(u). \]
\end{theorem}
\begin{proof}
As a first step, we want to extend $f$ to a functional $g$ on a space that is one dimension larger than $U$. This means $g$ is of the form
\[ g: U\oplus\Span\{v_1\}\to\R: v + \alpha v_1 \mapsto f(v) + \alpha c \]
for some $v_1\in V\setminus U$.

If we want $g$ to be majorised by $p$, then we need to find a $c$ such that
\[ \forall v\in U: \forall \alpha\in\R: \; g(\alpha v_1 + v) = \alpha c + f(v) \leq p(\alpha v_1 + v) \]
this means that we need
\[ \forall v\in U: \forall \alpha\in\R:\; \frac{-p(v - |\alpha|v_1) + f(v)}{|\alpha|} \leq c \leq \frac{p(v + |\alpha|v_1) - f(v)}{|\alpha|} \]
and we can find such a $c$ if and only if
\[ \forall v\in U: \forall \alpha\in\R:\; -p(v - |\alpha|v_1) + f(v) \leq p(v + |\alpha|v_1) - f(v), \]
which is equivalent to $2f(v) \leq p(v+|\alpha|v_1)+p(v-|\alpha|v_1)$. This follows from
\begin{align*}
f(v) \leq p(v) &= p(\tfrac{1}{2}(v+|\alpha|v_1) + \tfrac{1}{2}(v-|\alpha|v_1)) \\
&\leq \tfrac{1}{2}p(v+|\alpha|v_1) + \tfrac{1}{2}p(v-|\alpha|v_1).
\end{align*}
So we can extend the domain of $f$ by one dimension such that it is still majorised by $p$.

An extension by multiple dimensions is determined by a subset of $V\times \R$. Consider the family of all such subsets that determine a majorised extension of $f$. This is a family of finite character. We apply the Teichmüller-Tukey lemma, \ref{theorem:ZornEquivalents}, to obtain a maximal element.

This maximal element has domain $V$, because if it did not, it could be extended and was not a maximal element.
\end{proof}
Clearly if $V$ has a well-ordered Hamel basis, we do not need choice as we can just take successive $v$s in the basis and find $c$s constructively.
\begin{corollary}[Hahn-Banach majorised by sublinear functionals] \label{theorem:sublinearHahnBanach}
Any majorant $p$ that is sublinear is also convex and can be used in the Hahn-Banach theorem.
\end{corollary}
\begin{corollary}[Hahn-Banach majorised by seminorms] \label{theorem:seminormHahnBanach}
Let $(\mathbb{F},V,+)$ be a real or complex vector space, $U\subset V$ a subspace and $p$ a seminorm on $V$. Let $f:U\to\mathbb{F}$ be a linear functional that is bounded by $p$:
\[ \forall u\in U: \quad |f(u)| \leq p(u). \]
Then $f$ has an extension $\tilde{f}: V\to \R$ such that $\tilde{f}$ is a linear functional on $V$ bounded by $p$:
\[ \forall v\in V: |\tilde{f}(v)| \leq p(v) \qquad \text{and} \qquad \forall u\in U: \tilde{f}(u) = f(u). \]
\end{corollary}
\begin{proof}
For \emph{real} vector fields, we notice that every seminorm is a sublinear function, so we can use \ref{theorem:sublinearHahnBanach} to find an extension $\tilde{f}$. We then just need to check it satisfies $\forall v\in V: |\tilde{f}(v)| \leq p(v)$.
From \ref{theorem:sublinearHahnBanach} we know $\forall v\in V: \tilde{f}(v) \leq p(v)$.
To prove $-\tilde{f}(v) \leq p(v)$, we calculate
\[ -\tilde{f}(v) = \tilde{f}(-v) \leq p(-v) = |-1|p(v) = p(v). \]

For \emph{complex} vector fields, we can write $f= f_1 + if_2$ with $f_1,f_2$ real functionals on $U$, which can also be seen as a real vector space. First take $f_1$. Now $\forall u\in U f_1(u) \leq |f(x)| \leq p(x)$, so we can extend $f_1$ to $\tilde{f}_1$ by \ref{theorem:sublinearHahnBanach}.

Now by complex linearity, $if(u) = f(iu)$ so
\[ i[f_1(u) + if_2(u)] = -f_2(u) + if_1(u) = f_1(iu) + if_2(iu) \implies f_2(u) = -if_1(iu). \]
So we set $\tilde{f}(v) = \tilde{f}_1(v)-i\tilde{f}_1(iv)$. It is easy to show $\tilde{f}$ is $\C$-linear. For boundedness, write $\tilde{f}(v) = |\tilde{f}(v)|e^{i\theta}$ then
\[ |\tilde{f}(v)| = e^{-i\theta}\tilde{f}(v) = \tilde{f}(e^{-i\theta}v) = \tilde{f}_1(e^{-i\theta}v) \leq p(e^{-i\theta}v) = |e^{-i\theta}|p(v) = p(v). \]
\end{proof}

\begin{corollary}
Let $X$ be a normed space and $Z\subset X$ a subspace. Any bounded linear functional in $\tdual{Z}$ can be extended to a bounded linear functional in $\tdual{X}$ with the same norm.
\end{corollary}
\begin{proof}
Let $f:Z\to \mathbb{F}$ be such a functional. Extend $f$ by the previous theorem, \ref{theorem:seminormHahnBanach}, using $p(x) = \norm{f}_Z\norm{x}$.
\end{proof}
\begin{corollary} \label{corollary:existenceBoundedFunctionalOfSameNorm}
Let $X$ be a normed space and $x_0\neq 0$ an element of $X$. Then there exists a bounded linear functional $\omega_{x_0}$ such that
\[ \norm{\omega_{x_0}} = 1 \qquad \text{and} \qquad \omega_{x_0}(x_0)=\norm{x_0}. \]
\end{corollary}
\begin{proof}
Extend the functional $f: \Span\{x_0\}\to \mathbb{F}$ defined by
\[ f(x) = f(ax_0) = a\norm{x_0}. \]
\end{proof}
\begin{corollary}
Let $X$ be a normed space. Then $\forall x\in X:$
\[ \norm{x} = \sup_{\substack{f\in X' \\ f\neq 0}}\frac{|f(x)|}{\norm{f}}. \]
\end{corollary}
\begin{proof}
We calculate
\[ \norm{x} \geq \sup_{\substack{f\in X' \\ f\neq 0}}\frac{|f(x)|}{\norm{f}} \geq \frac{|\omega_{x}(x)|}{\norm{\omega_{x}}} = \frac{\norm{x}}{1} = \norm{x} \]
where the first inequality follows from $|f(x)|\leq \norm{f}\norm{x}$ for all $f\in X', x\in X$.
\end{proof}

TODO: locally convex Hausdorff spaces.

\subsection{Banach limits}
\begin{proposition}
There exists a linear map $L:l^\infty(\N) \to \C$ satisfying
\begin{enumerate}
\item $\displaystyle L(x) = \lim_{n\to \infty}x_n$ if the limit exists;
\item $L((x_{n+1})_{n\in\N}) = L((x_n)_{n\in\N})$;
\item if $\forall n\in\N:x_n\geq 0$, then $L(x) \geq 0$;
\item $\norm{L} = 1$.
\end{enumerate}
Such a linear map is called a \udef{Banach limit}.
\end{proposition}
\begin{proof}
TODO, after Cesàro means.
\end{proof}

\subsection{Hahn-Banach separation}



\section{Algebraic duality}
\subsection{Linear functionals}
\begin{definition}
Let $V$ be a vector space over a field $\mathbb{F}$.

The \udef{(algebraic) dual} of $V$, denoted $V^*$, is the vector space of all linear functionals on $V$.
\[ V^* = \Hom_{\mathbb{F}}(V,\mathbb{F}). \]
\end{definition}

\begin{proposition} \label{prop:dualBasisDimension}
Let $V$ be a vector space. Then $\dim V^* \geq \dim V$ and
\[ \dim V^* = \dim V \iff \text{$V$ is finite-dimensional}. \]
If $V$ is finite-dimensional with a basis $v_1, \ldots, v_n$, then the \udef{dual basis} $\varphi_1, \ldots, \varphi_n$ is the set of linear functionals on $V$ such that
\[ \varphi_j(v_k) = \begin{cases}
1 & (k=j), \\ 0 & (k\neq j)
\end{cases}. \]
This dual basis is indeed a basis of $V^*$.
\end{proposition}
\begin{proof}
We first assume $V$ is finite-dimensional and prove the dual basis is a basis, which proves $\dim V^* = \dim V$. We then assume $V$ is infinite-dimensional and prove $\dim V^* \neq \dim V$.\footnote{Reference: \url{https://mathoverflow.net/questions/13322/slick-proof-a-vector-space-has-the-same-dimension-as-its-dual-if-and-only-if-i}}
\begin{enumerate}
\item Assume $V$ is finite-dimensional. To show the dual basis spans $V^*$, take a linear functional $\varphi$. Now define $a_i = \varphi(v_i)$. It is clear that $\varphi = \sum_{i=1}^n a_i\varphi_i$. To show linear independence, take a combination
\[ b_1\varphi_1 + \ldots +b_n\varphi_n =0. \]
Filling in all basis vectors $v_i$ in turn, gives $b_i=0$ for all $i$.
\item Assume $V$ is infinite-dimensional. At first let us assume $\dim_{\mathbb{F}}V \geq |\mathbb{F}|$. Then we can apply lemma \ref{lemma:vsCardinality} to obtain $\dim_{\mathbb{F}}V = |V|$. Let $\beta$ be a basis for $V$. The elements of $V^*$ correspond bijectively to functions from $\beta$ to $\mathbb{F}$. Thus
\[ |V^*| = |\mathbb{F}^\beta| = |\mathbb{F}|^{|\beta|} > |\beta| = |V|. \]
Now we relax the condition $\dim_{\mathbb{F}}V \geq |\mathbb{F}|$. We first note that every field contains a subfield that is at most denumerable. Take such a field $K\subset \mathbb{F}$. We introduce the new vector space $W = \Span_K(\beta)$. Every functional from $W$ to $K$ extends to a functional from $V$ to $\mathbb{F}$. Hence
\[ \dim_\mathbb{F} V = \dim_K W < \dim_K W^* \leq \dim_{\mathbb{F}} V^* \]
using $\dim_{K}W \geq |K| \geq \aleph_0$.
\end{enumerate}
\end{proof}


\begin{proposition}
Let $f\in\Hom(V,W)$ and $\mathcal{V}, \mathcal{W}$ bases of $V,W$. The
\[ (f^*)^{\mathcal{V}^*}_{\mathcal{W}^*} = ((f)^{\mathcal{W}}_{\mathcal{V}})^\transp. \] \label{prop:transpDual}
\end{proposition}

\subsubsection{Annihilator subspace}
\begin{definition}
Let $U\subset V$ be a subspace. The \udef{annihilator} of $U$, denoted $U^0$, is the set of functionals that are identically zero on $U$:
\[ U^0 = \left\{ \varphi\in V^*\;|\; \forall u\in U:\varphi(u) = 0 \right\}. \]
\end{definition}
\begin{proposition} \label{prop:annihilatorSpace}
Let $U\subset V$ be a subspace and $T\in \Hom(V,W)$.
\begin{enumerate}
\item $U^0$ is a subspace of $\adual{V}$;
\item $\dim \adual{U} + \dim U^0 = \dim \adual{V}$;
\item $\ker T^t = (\im T)^0$
\item $T$ is surjective \textup{if and only if} $T^t$ is injective.
\end{enumerate}
\end{proposition}
\begin{proof}
\mbox{}
\begin{enumerate}
\item Elementary application of subspace criterion, proposition \ref{prop:subspaceCriterion}.
\item Consider the inclusion $\iota: U\hookrightarrow V$. Then the dimension theorem \ref{theorem:dimensionLinearMaps} applied to $\iota'$ gives
\[ \dim \im \iota' + \dim \ker\iota' = \dim V^*. \]
Now $\dim \ker\iota'$ are $\varphi\in V^*$ such that $\varphi \circ \iota = 0$. These are exactly the elements of the annihilator. Any functional on $U$ can be extended to a functional on $V$, so $\iota'$ is surjective and $\dim \im \iota' = \dim U^*$.
\item There are two inclusions. First assume $\varphi \in \ker T'$, so $\forall v\in V$
\[ 0 = (\varphi\circ T)(v) = \varphi(Tv). \]
Thus $\varphi\in(\im T)^0$. The other inclusion uses the same equality.
\item $T\in\Hom(V,W)$ is surjective iff $\im T = W$ iff $(\im T)^0 = \{0\}$ iff $\ker T' = \{0\}$ iff $T'$ is injective.
\end{enumerate}
\end{proof}


\subsection{The transpose of a map}
\begin{definition}
Let $f:V\to W \in \Hom_{\mathbb{F}}(V,W)$. The \udef{dual map}\footnote{The dual map $f^t$ is often denoted $f^*$ or $f'$. We avoid this because it clashes with the notation of the Hilbert adjoint.} or \udef{transpose} $f^t$ is the linear map
\[ f^t:W^* \to V^*: l\mapsto f^t(l) = l\circ f. \]
\end{definition}
\begin{lemma}
Let $f\in \Hom(U,V)$ and $g\in \Hom(V,W)$.
\begin{itemize}
\item $(g\circ f)^t = f^t\circ g^t$;
\item $\id^t_V = \id_{\adual{V}}$;
\item $f$ is an isomorphism \textup{if and only if} $f^t$ is an isomorphism;
\item $(f^t)^{-1} = (f^{-1})^t$ 
\end{itemize}
\end{lemma}
TODO: merge
\begin{lemma}
Let $S,T\in\Hom(V,W)$ and $\alpha\in\mathbb{F}$. Then
\begin{enumerate}
\item $(S+T)^t = S^t+T^t$;
\item $(\alpha T)^t = \alpha T^t$
\item if $T$ is invertible, then $T^t$ is invertible and
\[ (T^t)^{-1} = (T^{-1})^t. \]
\end{enumerate}
\end{lemma}

\begin{proposition}
Let $U\subset V$ be a subspace and $T\in \Hom(V,W)$, where $V,W$ are \emph{finite-dimensional}.
\begin{enumerate}
\item $\dim\ker T^t = \dim \ker T + \dim W - \dim V$;
\item $\dim\im T^t = \dim \im T$;
\item $\im T^t = (\ker T)^0$
\item $T$ is injective \textup{if and only if} $T^t$ is surjective.
\end{enumerate}
\end{proposition}
\begin{proof}
\mbox{}
\begin{enumerate}
\item Using $\dim \adual{V} = \dim V$, we have
\begin{align*}
\dim \ker T^t &= \dim(\im T)^0 = \dim W-\dim \im T \\
&= \dim W - (\dim V - \dim \ker T) = \dim \ker T + \dim W - \dim V
\end{align*}
where the equalities come from proposition \ref{prop:annihilatorSpace} and the dimension theorem for linear maps, theorem \ref{theorem:dimensionLinearMaps}.
\item Still using these results, we can calculate
\begin{align*}
\dim \im T^t &= \dim \adual{W} - \dim \ker T^t = \dim \adual{W} - \dim (\im T)^0 \\
&= \dim \adual{(\im T)} = \dim \im T.
\end{align*}
\item Take $\varphi = T^t(\psi) \in \im T^t$ where $\psi \in \adual{W}$. If $v\in \ker T$, then
\[ \varphi(v) = \left(T^t(\psi)\right)v = (\psi\circ T)(v) = \psi(Tv) = \psi(0) = 0. \]
Hence $\varphi \in (\ker T)^0$ and $\im T^t\subset (\ker T)^0$. We prove the equality by showing the dimensions are the same. Indeed:
\[ \dim \im T^t = \dim \im T = \dim V - \dim \ker T = \dim(\ker T)^0. \]
\item $T\in\Hom(V,W)$ is injective iff $\ker T = \{0\}$ iff $(\ker T)^0 = \adual{V}$ iff $\im T^t = \adual{V}$ iff $T^t$ is surjective.
\end{enumerate}
\end{proof}
\subsection{Bidual spaces}
\begin{definition}
Let $V$ be a vector space. The \udef{bidual space} is the dual of the dual $\abidual{V} = \adual{(\adual{V})}$.
\end{definition}
\begin{definition}
Let $V$ be a vector space over $\mathbb{F}$ and $v\in V$. The \udef{evaluation map} $\evalMap: V\to \abidual{V}: v\mapsto \evalMap_v$ is given by
\[ \evalMap_v: \adual{V} \to \mathbb{F}: l\mapsto l(v). \]
\end{definition}

\begin{lemma}
Let $V$ be a vector space. The evaluation map $\evalMap: V\to \abidual{V}: v\mapsto \evalMap_v$ is linear:
\[ \forall v,w\in V, a\in\mathbb{F}: \quad \evalMap_{av + w} = a\evalMap_v + \evalMap_w. \]
\end{lemma}
\begin{lemma}
Let $V$ be vector space over $\mathbb{F}$. The evaluation map is injective.
\end{lemma}
\begin{proof}
Assume $\evalMap_v = \evalMap_w$ for some $v,w\in V$. Then
\[ 0 = \evalMap_v - \evalMap_w  = \evalMap_{v-w}. \]
So $\forall l\in \adual{V}: \evalMap_{v-w}(l) = l(v-w) = 0$. Now define the sublinear functional by
\[ p(x) = \begin{cases}
\alpha & x = \alpha(v-w) \\
0 & \text{else}.
\end{cases} \]
Then the functional $f$ defined on $\Span\{v-w\}$ by $f(\alpha(v-w)) = \alpha$ is bounded by $p$ and can be extended to a functional on all $V$ by the Hahn-Banach theorem \ref{theorem:sublinearHahnBanach} if $v-w\neq 0$. Then $f(v-w) \neq 0$, which contradicts our assumptions. Thus $v=w$.
\end{proof}

\begin{proposition}
The mapping $\evalMap: V\to \abidual{V}: v\mapsto \evalMap_v$ is an isomorphism \textup{if and only if} $V$ is finite-dimensional.
\end{proposition}
\begin{proof}
Assume $V$ finite dimensional. As the evaluation map is injective, it is an isomorphism by \ref{prop:invertibleFiniteDim}.
The other direction is a dimensional argument by proposition \ref{prop:dualBasisDimension}.
\end{proof}

\subsection{Considerations of naturality}
TODO
Dual basis not natural, determined by inner product.

$V$ canonically embeddable in $\abidual{V}$.



\section{Topological duality}
\begin{definition}
Let $X$ be a normed space. Define
\[ \tdual{X} = \{  \omega \;|\; \omega:X\to \mathbb{F} \;\text{is a continuous map}\} \]
with the norm
\[ \norm{\omega} = \sup\{|\omega(x)|\;|\; x\in X, \norm{x}\leq 1\}. \]
Then $(\tdual{X},\norm{\cdot})$ is a normed space. We call $\tdual{X}$ the \udef{continuous dual} or \udef{topological dual} of $X$.
\end{definition}
\begin{lemma}
The topological dual $\tdual{X}$ is a subspace of the algebraic dual $\adual{X}$. If $X$ is finite-dimensional, then $\tdual{X}=\adual{X}$.
\end{lemma}
\begin{lemma} Let $X$ be a normed space and
let $x\in X$ $\omega\in \tdual{X}$ be a bounded linear functional. Then
\begin{align*}
\norm{\omega} &= \sup\setbuilder{|\omega(v)|}{\norm{v}=1 } \\
&= \sup\setbuilder{\frac{|\omega(v)|}{\norm{v}}}{v\neq 0} \\
&= \inf\setbuilder{c>0} {|\omega(v)|\leq c\norm{v}\forall v\in X}
\end{align*}
and
\begin{align*}
\norm{x} &= \sup\setbuilder{|\varphi(x)|}{ \norm{\varphi}=1} \qquad\qquad\quad\\ %TODO: fragile spacing!
&= \sup\setbuilder{\frac{|\varphi(x)|}{\norm{\varphi}}}{\varphi\neq 0}.
\end{align*}
\end{lemma}
\begin{proof}
We prove the third equality. Let $\alpha$ be the infimum. Let $\epsilon>0$, then by the definition $|\omega[(\norm{x}+\epsilon)^{-1}x]|\leq \norm{\omega}$. Hence $|\omega(x)|\leq \norm{\omega}(\norm{x}+\epsilon)$. Letting $\epsilon\to 0$ gives $|\omega(x)|\leq \norm{\omega}\norm{x}$ for all $x$. So $\alpha\leq \norm{\omega}$. On the other hand, $|\omega(x)|\leq c$ for all $x$ with $\norm{x}=1$. Hence $\norm{\omega}\leq \alpha$.
\end{proof}

\begin{proposition}
The continuous dual of $l^p(J)$ is $l^q(J)$ where $1<p,q<\infty$ satisfy $\frac{1}{p}+\frac{1}{q}$.
Also, the continuous dual of $l^1$ is $l^\infty$.
\end{proposition}

\subsection{The (topological) transpose of a map}
\begin{definition}
Let $T\in\Bounded(V,W)$. The dual map $T^t: \tdual{W}\to \tdual{V}$ is called the \udef{adjoint} or the \udef{transpose} of $T$.
\end{definition}
The notation $T^t$ is consistent for maps on both the algebraic and topological duals: if $T$ is bounded, $T^t:\adual{W}\to \adual{V}$ restricts to $T^t|_{\tdual{W}} = T^t:\tdual{W}\to \tdual{V}$.

\begin{proposition}
Let $T\in\Bounded(V,W)$. Then the transpose $T^t$ is a bounded operator in $\Bounded(W,V)$ with $\norm{T^t} = \norm{T}$.
\end{proposition}
\begin{proof}
The operator $T^t$ is linear since $\forall f_1,f_2\in \tdual{W}, \forall a\in\mathbb{F}, \forall x\in V:$
\[ (T^t(af_1 + f_2))(x) = (af_1 + f_2)(Tx) = af_1(Tx) + f_2(Tx) = a(T^tf_1)(x) + (T^tf_2)(x). \]
For the equality of norms, we prove two inequalities. First $\forall x\in V, f\in \tdual{W}$
\[ |f(Tx)|\leq \norm{f}\norm{Tx}\leq \norm{f}\norm{x}\norm{T} \implies \frac{|f(Tx)|}{\norm{x}} \leq \norm{f}\norm{T}. \]
taking the supremum over $x\in V$, we get $\norm{T^tf} = \norm{f\circ T}\leq \norm{f}\norm{T}$ and taking the supremum over $f\in \tdual{W}$ gives $\norm{T^t}\leq \norm{T}$. This shows that $T^t$ is bounded.

For the other inequality, we use corollary \ref{corollary:existenceBoundedFunctionalOfSameNorm} to the Hahn-Banach theorem: for every $x\in V$, there exists a bounded functional $\omega_x$ such that $\norm{\omega_x}=1$ and $\omega_x(x) = \norm{x}$. Then we can calculate:
\begin{align*}
\norm{Tx} = \omega_{Tx}(Tx) = (T^t\omega_{Tx})(x) \leq \norm{T^t\omega_{Tx}}\norm{x} \leq \norm{T^t}\norm{\omega_{Tx}}\norm{x} = \norm{T^t}\norm{x}
\end{align*}
So $\norm{T}\leq\norm{T^t}$. Combining gives $\norm{T^t}=\norm{T}$.
\end{proof}
\begin{corollary}
The map $T\mapsto T^t$ is an isometric isomorphism in $(\Bounded(X,Y)\to \Bounded(\tdual{Y}, \tdual{X}))$.
\end{corollary}

\begin{lemma}
Let $S,T\in\Bounded(V,W)$ and $\alpha\in\mathbb{F}$. Then
\begin{enumerate}
\item $(S+T)^t = S^t+T^t$;
\item $(\alpha T)^t = \alpha T^t$
\item if $T$ is invertible, then $T^t$ is invertible and
\[ (T^t)^{-1} = (T^{-1})^t. \]
\end{enumerate}
Let $T\in\Bounded(U,V)$ and $S\in\Bounded(V,W)$. Then
\begin{enumerate}
\setcounter{enumi}{3}
\item $(ST)^t = T^tS^t$
\end{enumerate}
\end{lemma}

\subsection{Bidual spaces}
Just like for algebraic duality, we can define a topological bidual space (or second dual space) $\tbidual{V}$.

\begin{proposition}
Let $V$ be a normed space. 
For each $v\in V$
\[ \evalMap_v: \tdual{V} \to \mathbb{F}: \omega \mapsto \omega(v) \]
is bounded and thus an element of $\tbidual{V}$.

The evaluation map $\evalMap: V \to \tbidual{V}$ is
\begin{enumerate}
\item isometric (and thus injective): $\norm{\evalMap_v} = \norm{v}$;
\item bounded with norm $\norm{\evalMap} = 1$.
\end{enumerate}
\end{proposition}
\begin{proof}
Let $v\in V$. Then
\[ \norm{\evalMap_v} = \sup\setbuilder{\norm{\evalMap_v(\omega)}}{\norm{\omega}=1} = \sup\setbuilder{\norm{\omega(v)}}{\norm{\omega}=1} \leq \sup\setbuilder{\norm{v}\;\norm{\omega}}{\norm{\omega}=1} = \norm{v}. \]

(1) Setting $\omega = \inner{v/\norm{v}, \cdot}$, we get
\[ \norm{\evalMap_v} \leq |\evalMap_v(\omega)| = |\inner{v/\norm{v}, v}| = \norm{v}. \]
Together with the calculation above, this gives $\norm{\evalMap_v} = \norm{v}$.

(2) $\norm{\evalMap} = \sup\setbuilder{\norm{\evalMap_v}}{\norm{v}=1} = \sup\setbuilder{\norm{v}}{\norm{v}=1} = 1$.
\end{proof}

\begin{lemma}
Let $V$ be normed space over $\mathbb{F}$ and $v\in V$. For each $v\in V$
\[ \evalMap_v: \tdual{V} \to \mathbb{F}: \omega \mapsto \omega(v) \]
is bounded with norm $\norm{v}$ and thus $\evalMap\in \tbidual{V}$ with $\norm{\evalMap} = 1$.
\end{lemma}

\subsubsection{Reflexive spaces}
\begin{definition}
A normed space $V$ is \udef{reflexive} if the evaluation map $\evalMap:V\to \tbidual{V}$ is surjective:
\[ \im\evalMap = \tbidual{V}. \]
\end{definition}
If $V$ is reflexive, then $\tbidual{V}$ is isometrically isomorphic to $V$. The converse is not necessarily true.

\begin{lemma}
Every finite-dimensional space is reflexive.
\end{lemma}

\begin{proposition}
A separable normed space $X$ with a non-separable dual space $\tdual{X}$ cannot be reflexive. 
\end{proposition}
\begin{proof}
TODO
\end{proof}
Thus $l^1$ is not reflexive.

\begin{proposition}
If the dual space $\tdual{X}$ of a  normed space $X$ is separable, then $X$ itself is separable. 
\end{proposition}
\begin{proof}
TODO
\end{proof}








\chapter{Topological vector spaces}
\url{file:///C:/Users/user/Downloads/Francois%20Treves%20-%20Topological%20Vector%20Spaces,%20Distributions%20and%20Kernels-Academic%20Press%20(1967).pdf}

Define TVS.

\begin{lemma} \label{lemma:closureSum}
Let $V$ be a TVS and $A,B$ subsets of $V$. Then
\[ \overline{A+B} \subseteq \overline{A} + \overline{B} \]
\end{lemma}
\begin{proof}
From the continuity of $+$ and \ref{prop:continuity}.
\end{proof}

\section{General duality theory}
\subsection{Paired spaces}
\begin{definition}
A \udef{pairing} is a triple $(V,W, b)$ where $V,W$ are vector spaces over $\mathbb{F}$ and $b: V\times W\to \mathbb{F}$ is a bilinear form. Often we will write the pairing as just $(V,W)$.

We say $W$ \udef{distinguishes} points of $V$ if
\[ \forall v\in V: \exists w\in W: b(v,w) \neq 0. \]

A \udef{dual system}, \udef{dual pair} or \udef{duality} over a field $\mathbb{F}$ is a pairing $(V,W,b)$ such that $V$ distinguishes points of $W$ and $W$ distinguishes points of $V$.
\end{definition}

\begin{lemma}
Let $(V,W, b)$ be a pairing. The curried map $w\mapsto b(\cdot, w)$ is injective \textup{if and only if} $V$ distinguishes points of $W$.
\end{lemma}
In this case $W$ is isomorphic with a space of linear functionals (the image of the curried function), so we can also say a dual system is a pair $(V,W)$ where $W$ is a space of linear functionals on $V$ that distinguishes points of $V$.

\begin{example}
\begin{itemize}
\item Let $V$ be a vector space. Then $(V,V^*, b)$ with $b:V\times V^*: (v,f)\mapsto f(v)$ is a dual pair.
\item Let $V$ be a locally convex Hausdorff space. Hahn-Banach implies $(V,V')$ is a dual pair.
\end{itemize}
\end{example}

\subsection{Weak topologies}
\begin{definition}
Let $(X,Y,b)$ be paired vector spaces. Then for each $y\in Y$, the map
\[ p_y: X\to \R_{\geq 0} x\mapsto |b(x,y)| \]
determines a seminorm on $X$.

The weakest topology on $X$ for which the seminorms $\{p_y\;|\;y\in Y\}$ are continuous is called the \udef{weak topology} $\sigma(X,Y)$ on $X$ for the pair $(X,Y)$.
\end{definition}

\begin{proposition}
Let $(X,Y,b)$ be a pairing. The following are equivalent:
\begin{enumerate}
\item $X$ distinguishes points of $Y$;
\item the map $Y\to X^*: y\mapsto y^*$ is injective, where $y^*$ is defined by
\[ y^*: X\to \mathbb{F}: x\mapsto b(x,y); \]
\item $\sigma(Y,X)$ is Hausdorff.
\end{enumerate}
\end{proposition}
\begin{proof}
TODO
\end{proof}

\subsubsection{Weak-$*$ topology}

\begin{proposition} \label{prop:weak*continuousFunctional}
Let $X$ be a Banach space and let $X'$ have the weak-$*$ topology. Then a linear functional $\theta: X'\to \C$ is continuous \textup{if and only if}
\[ \exists x\in X: \forall \omega\in X': \quad \theta(\omega) = \omega(x). \]
\end{proposition}
\begin{proof}
TODO 9.2 in lecture notes.
\end{proof}

\subsection{Mackey topology}

\begin{theorem}[Mackey-Arens]
\end{theorem}

\section{Ordered topological vector spaces}
\subsection{Ordered vector spaces}
TODO link ordered groups.
\begin{definition}
Let $(\R, V, +)$ be a real vector space and $\precsim$ a preorder on the set $V$. Then $\precsim$ is a \udef{vector preorder} if it is compatible with the vector space structure as follows: $\forall x,y,z\in V, \lambda\in\R$
\begin{enumerate}
\item $x\leq y$ implies $x+z \leq y+z$;
\item if $\lambda\geq 0$, then $y\leq x$ implies $\lambda y\leq \lambda x$.
\end{enumerate}
We call $(\R, V, +, \precsim)$ a \udef{preordered vector space}. 
\end{definition}
\begin{definition}
An \udef{ordered vector space} is a real vector space with a compatible partial order. Such a partial order is called a \udef{vector partial order}.
\end{definition}

TODO:move?'Subsets of vector spaces'?:

A subset $C$ of a vector space $V$ is called a \udef{cone} if for all real $r>0$, $rC \subseteq C$. A cone is called pointed if it contains the origin.
\begin{lemma} \label{lemma:convexityAdditiveClosure}
A cone $C$ is convex if and only if $C + C \subseteq C$. 
\end{lemma}
\begin{proof}
Assume $C$ convex. Take $v,w\in C$, then $v/2 + w/2\in C$ by convexity and so $v+w = 2(v/2+w/2)\in C$.

Assume $C$ closed under addition. Take $v,w\in C$ and $\lambda\in[0,1]$. Then $(1-\lambda)v$ and $\lambda w$ are elements of $C$ and so the convex combination $(1-\lambda)v + \lambda w$ is too.
\end{proof}

\section{Operators on topological vector spaces}
\subsection{Compact operators}
\begin{definition}
A linear operator $T:X\to Y$ between TVSs is \udef{compact} if it maps a neighbourhood of the origin to a precompact set, i.e. 
\[ \exists U \in \neighbourhoods(0): \;  \text{$\overline{T[U]}$ is compact.} \]
The set of compact linear operators in $(X\to Y)$ is denoted $\Compact(X,Y)$.
\end{definition}

\begin{proposition}
Let $X$ be a normed space and $Y$ a TVS and $T:X\to Y$ a linear operator. Then the following are equivalent:
\begin{enumerate}
\item $T$ is a compact operator;
\item there exists a neighbourhood $U \subset X$ of the origin and a compact set $V\subset Y$ such that $T[U] \subset V$;
\item the image of the unit ball of $X$, $T[B(\vec{0},1)]$, is precompact in $Y$;
\item the image of any bounded set in $X$ is precompact in $Y$.
\end{enumerate}
If $Y$ is a normed space, these are also equivalent to
\begin{enumerate} \setcounter{enumi}{4}
\item for any bounded sequence $(x_{n})_{n\in \mathbb{N}}$ in $X$, the sequence $(Tx_{n})_{n\in \mathbb{N} }$ contains a converging subsequence.
\end{enumerate}
\end{proposition}
\begin{proof}
TODO
\end{proof}


\begin{lemma}
Let $X,Y$ be TVSs.
\begin{enumerate}
\item Then $\Compact(X, Y)$ is a vector space.
\item If $X,Y$ are normed spaces, then $\Compact(X, Y)$ is a subspace of $\Bounded(X, Y)$.
\end{enumerate}
\end{lemma}
\begin{proof}
(1) Let $K,K':X\to Y$ be compact operators. Then, by \ref{lemma:closureSum},
\[ \overline{K[B(0, 1)]+K'[B(0, 1)]} \subseteq \overline{K[B(0, 1)]}+\overline{K'[B(0, 1)]}, \qquad \overline{K[\lambda B(0, 1)]} = \lambda\overline{K[B(0, 1)]}. \]

(2) Let $K\in\Compact(X, Y)$. Then the image of the unit ball is precompact, meaning it is bounded. So $K$ is bounded by \ref{prop:operatorNorm}.
\end{proof}

\begin{lemma}
Let $T:V\to W$ be a bounded operator. If $W$ has the Heine-Borel property, then $T$ is compact.
\end{lemma}
\begin{proof}
The set $T[B(\vec{0},1)]$ is bounded because $T$ is. By the Heine-Borel (TODO ref) property of $W$, $\overline{B(\vec{0},1)}$ is compact.
\end{proof}
\begin{corollary}
Bounded operators with as image a finite dimensional normed space are compact.
\end{corollary}
\begin{corollary}
The identity on a normed space $X$ is compact \textup{if and only if} $X$ is finite-dimensional.
\end{corollary}
\begin{proof}
TODO ref. 
\end{proof}

\section{Continuity}
\url{https://en.wikipedia.org/wiki/Bilinear_map#Continuity_and_separate_continuity}


\chapter{Banach spaces}
\begin{definition}
\begin{itemize}
\item A \udef{Banach space} is a normed vector space that is complete as a metric space.
\item A \udef{Hilbert space} is an inner product space that is complete as a metric space.
\end{itemize}
\end{definition}

A finite-dimensional normed / inner product space is automatically a Banach / Hilbert space by proposition \ref{prop:finiteDimComplete}.

The space $\Bounded(V,W)$ is a Banach space.

TODO: quotient of Banach spaces.

\section{Function spaces}
\subsection{The spaces $\mathcal{L}^p(X,\diff{\mu})$}
\subsection{The spaces $L^p(X,\diff{\mu})$}
\begin{theorem}[Riesz-Fisher]
The space $L^p(X,\diff{\mu})$ is complete.
\end{theorem}

For $L^\infty$: essential supremum.

\subsubsection{Locally integrable spaces}
\begin{definition}
Let $(\Omega, \mathcal{A}, \mu)$ be a measure space. The \udef{locally $L^p$} space is the space
\[ L^p_\text{loc}(\Omega) \defeq \setbuilder{f \in (\Omega\to\C)}{\text{$f\in L^p(K)$ for all compact $K\subset \Omega$}}. \]
The functions in $L^1_\text{loc}(\Omega)$ are called \udef{locally integrable} on $\Omega$.
\end{definition}
TODO: deal with equivalence classes??

\subsection{Sequence spaces}
TODO:  $L^p(A,\mu)$ with $\mu$ counting measure.

Let $J$ be a countable index set and $x:J\to \mathbb{F}$ a sequence indexed by $J$. We define
\[ \norm{x}_p := \left(\sum_{j\in J}|x(j)|^p\right)^{1/p} \qquad\text{and}\qquad \norm{x}_\infty = \sup_{j\in J}|x(j)|. \]
So $\norm{\cdot}_1$ is the standard norm on $\mathbb{F}^n$. For general sequences there is no guarantee that these norms do not diverge.
\begin{definition}
Let $J$ be an index set, $D$ a directed set and $p\geq 1$,
\begin{align*}
\ell^p(J) &= \setbuilder{x:J\to \F}{\norm{x}_p < +\infty},\\
\ell^\infty(J) &= \setbuilder{x:J\to \F}{\norm{x}_\infty < +\infty},\\
c_0(D) &= \setbuilder{x:D\to \F}{\lim_{n\to\infty}|x(n)| = 0}, \\
c_{00}(D) &= \setbuilder{x:D\to \F}{\setbuilder{n\in D}{x(n)\neq 0}\;\text{has finite cardinality}}.
\end{align*}
unless specified we equip $c_0$ and $c_{00}$ with the norm $\norm{\cdot}_\infty$.
\end{definition}

\begin{lemma}
$c_{00}$ is dense in $\ell^p$ if it is equipped with the norm $\norm{\cdot}_p$ and dense in $c_0$ if it is equipped with the norm $\norm{\cdot}_\infty$.
\end{lemma}

Let $1<p,q<\infty$ satisfy $\frac{1}{p}+\frac{1}{q}$. We have the inequalities
\begin{align*}
\norm{xy}_1 &\leq \norm{x}_p\norm{y}_q\qquad\text{(Hölder inequality)} \\
\norm{x+y}_p &\leq \norm{x}_p+\norm{y}_p\qquad\text{(Minkowski inequality)}
\end{align*}
which follow from the general cases (TODO ref) by applying the counting measure.

\section{Series in Banach spaces}
TODO
\url{https://link.springer.com/content/pdf/10.1007%2F978-0-8176-4687-5_3.pdf}
\begin{definition}
Let $\seq{x_n}$ be a sequence in a Banach space $X$. As for series of scalars, we say a series $\sum_{n=1}^\infty x_n$ is
\begin{itemize}
\item \udef{unconditionally convergent} if $\sum_{n=1}^\infty x_{\sigma(n)}$ converges for every permutation $\sigma$ of $\N$;
\item \udef{absolutely convergent} if $\sum_{n=1}^\infty \norm{x_n} < \infty$.
\end{itemize}
\end{definition}

\begin{proposition} \label{prop:absoluteUnconditionalConvergenceBanach}
Let $\seq{x_n}$ be a sequence in a Banach space $X$. If $\sum_{n=1}^\infty$ converges absolutely, then it converges unconditionally.
\end{proposition}
\begin{proof}
Assume absolute convergence, so $\sum\norm{x_i}<\infty$. Then (for $m< n$)
\[ \norm{\sum_{i=1}^n x_i - \sum_{i=1}^m x_i} = \norm{\sum_{i=m+1}^n x_i} \leq \sum_{i=m+1}^n\norm{x_i} = \sum_{i=1}^n \norm{x_i} - \sum_{i=1}^m \norm{x_i}, \]
and because $\sum\norm{x_i}$ converges, it is a Cauchy sequence and by the inequality so is $\sum x_i$. By completeness this sequence is convergent.

By (TODO ref) $\sum\norm{x_{\sigma(i)}}$ converges for any permutation $\sigma$ of $\N$. We can then repeat the argument to show $\sum x_{\sigma(i)}$ is also convergent and thus unconditionally convergent.
\end{proof}

\subsection{Fourier series}
TODO Sacks 7.1

\section{Completions and constructions}

\begin{proposition}
The completions of a space with respect to two different norms are isomorphic \textup{if and only if} the norms are equivalent.
\end{proposition}

TODO move down
\subsection{Tensor products}
TODO Ryan
\url{https://math.stackexchange.com/questions/2712906/does-mathcalb-mathcalh-mathcalh-otimes-mathcalh-in-infinite-dime}
\url{https://math.stackexchange.com/questions/35191/operator-norm-and-tensor-norms?noredirect=1&lq=1}

\subsection{Direct sums}

For arbitrary direct sums we can generalise: now that we have a concept of limits, we can relax the requirement that all but finitely many terms be zero. Instead we require that the sequence of norms is bounded in some way. This gives a whole family of related concepts of direct sum, named for which sequence space the sequence of norms belongs to.
\begin{definition}
Let $\{V_i\}_{i\in I}$ be an arbitrary family of Banach spaces over a field $\F$ and let $\ell(I,\F)$ be a space of sequences in $\F$ indexed by $I$. Then the \udef{$\ell$-direct sum} is the vector space with as field
\[ \bigoplus_{i\in I}^\ell V_i = \setbuilder{(v_i)_{i\in I}}{\forall i\in I: v_i\in V_i \quad\text{and}\quad (\norm{v_i}_{V_i})_{i\in I}\in \ell(I,\F) }. \]
In particular we have, for all $1\leq p<\infty$, the \udef{$\ell^p$-direct sum}
\[ \bigoplus_{i\in I}^p V_i \defeq \setbuilder{(v_i)_{i\in I}}{\forall i\in I: v_i\in V_i \quad\text{and}\quad \sqrt[p]{\sum_{i\in I}\norm{v_i}_{V_i}^p}<\infty} \]
and the \udef{$\ell^\infty$-direct sum}
\[ \bigoplus_{i\in I}^\infty V_i \defeq \setbuilder{(v_i)_{i\in I}}{\forall i\in I: v_i\in V_i \quad\text{and}\quad \sup_{i\in I}\norm{v_i}_{V_i}<\infty}. \]
\end{definition}

\begin{proposition}
For any sequence space that is a Banach space the direct sum is a Banach space. TODO: in particular algebraic direct sum as $c_{00}$? (one possible norm)? and finite direct sums?
\end{proposition}

\subsubsection{Direct sum of identical spaces}
\begin{proposition}
Let $V$ be a Banach space over $\F$, $I$ an arbitrary index set and $\ell(I,\F)$ a banach sequence space.
\[ \bigoplus_{i\in I}^\ell V \cong \ell\otimes V \]
\end{proposition}


\section{Operators on Banach spaces}
\begin{proposition}[Bounded linear extension] \label{prop:BLT}
Let $T:\dom(T)\subseteq X\to Y$ be a bounded operator between normed spaces. Then $T$ has a unique extension
\[ \widetilde{T}:\overline{\dom(T)}\to Y \]
where $\widetilde{T}$ is a bounded operator with $\norm*{\widetilde{T}} = \norm{T}$.
\end{proposition}
\begin{proof}
Normed vector spaces have the unique extension property because they are Hausdorff, \ref{prop:uniqueExtensionHausdorff}. We just need to show the norm stays the same:

Clearly $\norm*{\tilde{T}} \geq \norm{T}$. For the converse take any $x\in X$. As $\overline{\dom(T)} = X$, there exists a sequence $\seq{x_i}\subset \dom(T)$ that converges to $x$. Then
\[ \norm*{\tilde{T}(x)}_Y = \norm{T\left(\lim_{i\to\infty}x_i\right)}_Y = \lim_{i\to\infty}\norm{T(x_i)}_Y \leq \lim_{i\to\infty}\norm{T}\;\norm{x_i}_X = \norm{T}\;\norm{x}_X. \]
\end{proof}

\section{Bounded operators}
\begin{proposition}
Let $V,W$ be normed spaces. The vector space $\Bounded(V,W)$ with the operator norm is a Banach space \textup{if and only if} $W$ is a Banach space.
\end{proposition}
\begin{corollary}
Let $V$ be a normed space. The continuous dual $X'$ is a Banach space.
\end{corollary}
\begin{corollary}
Topologically reflexive spaces are Banach spaces.
\end{corollary}

\begin{proposition} \label{prop:boundedBelowClosedRange}
Let $T$ be a bounded operator with $\dom(T)$ a Banach space that is bounded below. Then the range $\im T$ is closed.
\end{proposition}
\begin{proof}
Let $y\in \overline{\im T}$ and take a sequence $(Tx_n)$ converging to $y$. Because $T$ is bounded below
\[ \norm{x_m-x_n} \leq \frac{1}{b}\norm{T(x_m-x_n)} = \frac{1}{b}\norm{Tx_m-Tx_n} \]
and by proposition \ref{prop:CauchyCriterion} $(x_n)$ is Cauchy. By completeness this sequence has a limit $x$. By boundedness $\lim_n Tx_n = Tx$, meaning $y$ is in $\im T$.
\end{proof}

\subsection{Contractions}
A linear operator $T$ on a normed space is a contraction if and only if it is bounded and $\norm{T}<1$. 

\subsubsection{Neumann series}
\begin{lemma}
Let $T$ be a bounded linear operator on a normed space $X$ with $\norm{T}<1$. Then the series $\sum^\infty_{i=1}T^i(b)$ converges for all $b\in X$ and is the unique fixed point of $F(x) = T(x)+b$.
\end{lemma}
\begin{proof}
The function $F$ is a contraction if and only if $\norm{T}<1$. So it has a unique fixed point. Starting the fixed point iteration at $b$ yields the series:
\begin{align*}
F(b) &= Tb + b \\
F(Tb+b) &= T^2b + Tb + b \\
&\hdots.
\end{align*}
Alternatively we could have used the inequality $\norm{T^nb} \leq \norm{T}^n\norm{b}$, the convergence of the geometric series and \ref{prop:absoluteUnconditionalConvergenceBanach} to prove convergence. Proving it is a fixed point is then elementary.
\end{proof}
\begin{corollary}[Neumann series] \label{corollary:NeumannSeries}
Let $T$ be a bounded linear operator with $\norm{T}<1$. Then
\[ (\id - T)^{-1} = \sum_{i=1}^\infty T^i \]
with uniform convergence. Also
\[ \norm{(\id - T)^{-1}} \leq \frac{1}{1-\norm{T}}. \]
\end{corollary}
\begin{proof}
Let $x\in X$. Then set $(\id - T)^{-1}x = y$. This is equivalent to $x = y-Ty$ and means $y$ is the fixed point of $y\mapsto Ty+x$. So $y = \sum_{i=1}^\infty T^ix$.

The convergence is uniform by TODO ref.

Finally we have
\[ \norm{(\id - T)^{-1}} = \norm{\sum_{i=1}^\infty T^i} \leq \sum_{i=1}^\infty \norm{T^i} = \frac{1}{1-\norm{T}} \]
by the geometric series.
\end{proof}
TODO ref: uniform convergence if $\sum_i \norm{T_i} < \infty$??

\subsection{The uniform boundedness principle}
TODO: if a family of bounded operators on a Banach space is pointwise bounded, then it is uniformly bounded.
\begin{theorem}[Uniform boundedness principle]
Let $\mathcal{F}\subset \Bounded(X,Y)$ be a family of bounded operators where $X$ is a Banach space and $Y$ a normed space, such that
\[ \sup\setbuilder{\norm{Tx}}{T\in\mathcal{F}} < \infty \qquad \text{for all $x\in X$}. \]
Then $\sup\setbuilder{\norm{T}}{T\in\mathcal{F}} < \infty$.
\end{theorem}
\begin{proof}
The proof is an application of the Baire category theorem. Define the closed subsets $K_n$ as
\[ K_n = \setbuilder{x\in X}{\forall T\in\mathcal{F}: \norm{Tx}\leq n}. \]
These are closed because the functional $f_T: X\to \R: x\mapsto \norm{Tx}$ is bounded and
\[ K_n = \bigcap_{T\in\mathcal{F}}f_T^{-1}[\,[0,n]\,]. \]
By assumption, $X=\bigcup_{n\in\N} K_n$. As $X$ is a Banach space, and thus a complete metric space, we can apply the Baire category theorem, \ref{theorem:BaireCategory}, to conclude that there is a $K_n$ with non-empty interior (by contraposition of the Baire condition). Take $x_0\in K_n^\circ$, then $-x_0+K_n^\circ \subset K_{n2}$. So $\vec{0}\in (K_{2n})^\circ$ and we can find a $\rho$ such that $B(\vec{0},\rho)\subset K_{2n}$. By proposition \ref{prop:operatorNorm} we have $\norm{T}\leq 2n/\rho$ for all $T\in\mathcal{F}$.
\end{proof}
\begin{corollary}[Banach-Steinhaus]
Let $X$ be a Banach space and $Y$ a normed space. Let $T_n: X\to Y$ be a sequence of bounded operators. If $T_n$ converges pointwise to $T:X\to Y: Tx = \lim_n T_n x$, then $\sup_n\norm{T_n} <\infty$ and thus $T$ is bounded.
\end{corollary}
\begin{proof}
Any convergent sequence in a normed space is bounded, so we can apply the uniform boundedness principle.
\end{proof}

\subsection{Open mapping and closed graph theorems}

\begin{proposition} \label{prop:openUnitBall}
Let $X,Y$ be Banach spaces and $T:X\to Y$ a surjective bounded operator.  Then the image of the open unit ball $B(\vec{0},1)\subset X$ contains an open ball about $\vec{0}\in Y$.
\end{proposition}
\begin{proof}
We first prove $0\in \overline{T[B(\vec{0},r)]}^\circ$ for every $r>0$: (TODO: make computations lemma.)
\begin{itemize}
\item Using $X = \bigcup_{n=1}^\infty B(\vec{0},n)$, we see by surjectivity
\[ Y = T[X] = T\left[\bigcup_{n=1}^\infty B(\vec{0},n)\right] = \bigcup_{n=1}^\infty T[B(\vec{0},n)]. \]
Because $Y$ has the Baire property (theorem \ref{theorem:BaireCategory}) and $Y$ is both open and non-empty, it may not be meagre, by lemma \ref{lemma:BaireEquivalents}. So for some $n\in\N$, $T[B(\vec{0},n)]$ is non-rare, meaning that $\overline{T[B(\vec{0},n)]}$ has non-empty interior.
\item Because
\[ \overline{T[B(\vec{0},n)]} = \overline{2nT[B(\vec{0},1/2)]} = 2n\overline{T[B(\vec{0},1/2)]}, \]
$\overline{T[B(\vec{0},1/2)]}$ must have non-empty interior. Let $B(y_0,\epsilon)\subset \overline{T[B(\vec{0},1/2)]}$.
\item Note $B(0,\epsilon) = y_0 - B(y_0,\epsilon) \subset \overline{T[B(\vec{0},1)]}$ and thus $B(0,r\epsilon) \subset \overline{T[B(\vec{0},r)]}$.
\end{itemize}
We then prove $\overline{T[B(\vec{0},1/2)]} \subset T[B(\vec{0}, 1)]$, proving the proposition.
\begin{itemize}
\item Choose some $y_0\in \overline{T[B(\vec{0},1/2)]}$. Then every neighbourhood $B(y_0,\epsilon/4)$ intersects $T[B(\vec{0},1/2)]$.
\item Then
\[ B(y_0,\epsilon/4) = y_0 - B(\vec{0},\epsilon/4) \subset y_0 - \overline{T[B(\vec{0},1/4)]}, \]
so $y_0 - \overline{T[B(\vec{0},1/4)]}$ intersects $T[B(\vec{0},1/2)]$. Take a $y_1 \in \overline{T[B(\vec{0},1/4)]}$ such that $y_0-y_1$ is in this intersection. Then we have an $x_0\in B(\vec{0},1/2)$ such that $T(x_0) = y_0-y_1$.
\item We can continue recursively choosing $y_{n+1}\in \overline{T[B(\vec{0}, 2^{-(n+1)})]}$ and $x_n \in B(\vec{0}, 2^{-n})$ such that $y_n-y_{n+1} = T(x_n)$.
\item Consider the sequence $\sum_{k=0}^nx_k$. It is a Cauchy sequence in $X$. Call its limit $x$. Then $x\in B(\vec{0},1)$.
\item Because $\norm{y_n}\leq 2^{-n}\norm{T}$, $(y_n)$ converges to zero. Then
\[ \left( T\left(\sum^n_{k=1}x_k\right) \right)_{n\in\N} = \left( y_0-y_{n+1} \right)_{n\in\N} \]
converges to $y_0$. Thus $T(x) = y_0 \in T[B(\vec{0},1)]$.
\end{itemize}
\end{proof}

\begin{proposition} \label{prop:zeroInInteriorOfImageImpliesOpen}
Let $X,Y$ be normed spaces and $T: X\to Y$ a linear map. If $\vec{0}$ lies in the interior of $T[B(\vec{0},r)]$ for some $r>0$, then $T$ is open.
\end{proposition}
\begin{proof}
TODO: make computations lemma.
Given the assumption, $0$ lies in the interior of $T[B(\vec{0},\epsilon)]$ for all $\epsilon>0$.
Because $T[B(x,\epsilon)] = T(x) + T[B(\vec{0},\epsilon)]$, $T(x)$ lies in the interior of $T[B(x,\epsilon)]$, for all $x\in X$.
Thus for all neighbourhoods $U(x)\subset X$, $T(x)\subset T[U]^\circ$ and so $T[U] \subset T[U]^\circ$, so $T[U]$ is open.
\end{proof}

\begin{theorem}[Open mapping]
Let $X,Y$ be Banach spaces and $T:X\to Y$ a surjective bounded operator. Then $T$ is an open map.
\end{theorem}
\begin{proof}
This is the consequence of propositions \ref{prop:openUnitBall} and \ref{prop:zeroInInteriorOfImageImpliesOpen}.
\end{proof}
\begin{corollary}[Bounded inverse theorem] \label{corollary:boundedInverse}
Let $X,Y$ be Banach spaces. If $T:X\to Y$ is a bounded and bijective linear map, then $T^{-1}$ is bounded as well.
\end{corollary}


\begin{proposition}
Let $T: \dom(T)\subset X\to Y$ be a bounded linear operator. Then
\begin{enumerate}
\item if $\dom(T)$ is a closed subset of $X$, then $T$ has closed graph;
\item if $T$ has closed graph and $Y$ is complete, then $\dom(T)$ is a closed subset of $X$.
\end{enumerate}
\end{proposition}
\begin{proof}
We use proposition \ref{prop:closedGraphEquivalence} twice: First assume $(x_n)$ and $(Tx_n)$ converge to $x$ and $y$, respectively. Then $x\in\dom(T)$ by closure and $y = Tx$ by continuity.

Now assume $T$ has closed graph and $Y$ is complete. Take $x\in\overline{\dom(T)}$ and $(x_n)\subset \dom(T)$ converging to $x$. Since $T$ is bounded:
\[ \norm{Tx_n - Tx_m} = \norm{T(x_n-x_m)} \leq \norm{T}\norm{x_n-x_m}, \]
so $(Tx_n)$ is Cauchy by \ref{prop:CauchyCriterion} and thus by completeness has a limit, say $y$. Then $Tx=y$ by continuity. Since $T$ has closed graph, $x\in\dom(T)$. So $\overline{\dom(T)}\subseteq \dom(T)$ and $\dom(T)$ is closed. 
\end{proof}

\begin{theorem}[Closed graph theorem] \label{theorem:closedGraphTheorem}
Let $X,Y$ be Banach spaces and $T: X\to Y$ a linear operator. Then $T$ is bounded \textup{if and only if} $T$ has closed graph.
\end{theorem}
\begin{proof}
Assume the graph of $T$ is closed. Then the graph, being a closed subset of a Banach space, is a Banach space (TODO: reference). Then the restriction of the bounded map $X\oplus Y \to X: (x,y)\mapsto x$ to the graph of $T$ is bijective. So by corollary \ref{corollary:boundedInverse} the inverse is bounded, so $T$ is bounded.
\end{proof}
Notice that it is important that the domain of $T$ be the whole of $X$.


\subsection{Compact operators}
\begin{proposition}
Let $L\in\Hom(V,W)$ with $V,W$ Banach spaces. Then $L$ is compact \textup{if and only if} the image of any bounded subset of $V$ under $L$ is totally bounded in $W$.
\end{proposition}
TODO proof

\section{Unbounded operators}




\chapter{Hilbert spaces}

\section{Examples}
\subsection{The $\ell^2$ spaces}
Sequence spaces $\ell^p$ Hilbert iff $p=2$. (TODO: other sequence spaces?)

\subsection{Direct sum}
Let $(V_i)_{i\in I}$ be a family of Hilbert spaces. By considering them as Banach spaces we can take the $\ell^2$-direct sum. (TODO: other sequence spaces?)
\begin{proposition}
Let $(V_i)_{i\in I}$ be a family of Hilbert spaces. The $\ell^2$-direct sum is a Hilbert space.
\end{proposition}
This gives the conventional interpretation of the \udef{Hilbert space direct sum}: it is the $\ell^2$-direct sum of the summands as Banach spaces.


\section{Projectors and minimisation problems}
Every subspace is a convex, non-empty subset.
\begin{theorem}[Hilbert projection theorem]
Let $\mathcal{H}$ be a Hilbert space, $K$ a closed, convex, non-empty subset of $\mathcal{H}$.
\begin{enumerate}
\item There exists a unique element of $K$ of least norm. I.e. there exists a unique $k_0\in K$ such that
\[ \norm{k_0} = \inf\setbuilder{\norm{k}}{k\in K}. \]
I.e. $\min\setbuilder{\norm{k}}{k\in K}$ exists.
\item For any $h\in\mathcal{H}$ there exists a unique point $k_0$ in $K$ such that
\[ \norm{h-k_0} = \inf\{\norm{h-k}\;|\; k\in K\}. \]
We use this to define the distance $d(h,K) \defeq \norm{h-k_0}$.
\item If $K$ is a (closed) subspace, then $k_0$ is also the unique point in $K$ such that $(h-k_0)\perp K$.
\end{enumerate}
\end{theorem}
The idea for the first part of the proof is to take a sequence $\seq{\norm{k_i}}\to \inf\setbuilder{\norm{k}}{k\in K}$. By the parallelogram law $\seq{k_i}$ is Cauchy and by completeness it has a limit $k_0$.
\begin{proof}
(1) We can find a sequence $\seq{k_i}$ in $K$ such that $\norm{k_i}$ converges to $d = \inf\setbuilder{\norm{k}}{k\in K}$ by \ref{prop:sequenceToSupInf}. By the parallelogram law
\begin{align*}
\norm{k_i-k_j}^2 &= 2\norm{k_i}^2 + 2\norm{k_j}^2 - 4\norm{\frac{1}{2}(k_i+k_j)}^2 \\
&\leq 2\norm{k_i}^2 + 2\norm{k_j}^2 - 4d^2
\end{align*}
the sequence $\seq{k_i}$ is Cauchy. So it converges to some $k_0$ in $K$ because $K$ is a closed subset of a complete space.

To prove uniqueness, take another $k_0'\in K$ such that $\norm{k_0'}=d$. By convexity $\tfrac{1}{2}(k_0 +k_0')\in K$, hence
\[ d\leq \norm{\tfrac{1}{2}(k_0+k_0')}\leq \tfrac{1}{2}(\norm{k_0}+\norm{k_0'}) = d. \]
So $\norm{\tfrac{1}{2}(k_0+k_0')} = d$. The parallelogram law gives
\[ d^2 = \norm{\frac{k_0+k_0'}{2}}^2 = d^2- \norm{\frac{k_0-k_0'}{2}}^2; \]
hence $\norm{k_0 - k_0'}^2 = 0$ and thus $h_0=k_0$.

(2) The element $k_0$ considered in point 1. is the point closest to a particular choice for $h$, namely $h=0$. For other $h$ consider the set $K-h$, which is again closed and convex.

(3) For all $k\in K$ and $a\in \mathbb{F}$, we have
\[ \norm{h-k_0}\leq \norm{h-k_0+ak} \]
and thus, by lemma \ref{lemma:orthogonality}, $(h-k_0)\perp k$, meaning $(h-k_0)\perp K$.

For the converse (i.e. uniqueness), suppose $f_0\in K$ such that $(h-f_0)\perp K$. Then for all $f\in K$ we have $(h-f_0)\perp (f_0 -f)$ so that
\begin{align*}
\norm{h-f}^2 &= \norm{(h-f_0) + (f_0-f)}^2 \\
&= \norm{h-f_0}^2 + \norm{f_0 - f}^2 \geq \norm{h-f_0}^2.
\end{align*}
So $\norm{h-f_0}=\inf\{\norm{h-k}\;|\; k\in K\} = d(h,K)$ and thus $f_0=k_0$.
\end{proof}
\begin{corollary}
Let $\mathcal{H}$ be a Hilbert space and $K$ a closed vector subspace. Then $\mathcal{H} = K^\perp \oplus K$.
\end{corollary}
\begin{proof}
We need to prove every vector $x\in \mathcal{H}$ has a unique decomposition of the form
\[ x = y+z \qquad y\in K,\; z\in K^\perp. \]

Such a decomposition exists: we can take $y=k_0$ and $z = x-k_0$. We have already proved uniqueness. We can also give another argument for uniqueness: assume another such decomposition $x=y'+z'$. Then $y-y'= z-z'$ where the left side is in $K$ and the right in $K^\perp$. The only element in $K\cap K^\perp$ is $0$, so $y=y'$ and $z=z'$.
\end{proof}
The ability to make such decompositions in general is unique to Hilbert spaces, see theorem \ref{theorem:criterionHilbertSpace}.

\subsection{Orthogonal projection and decomposition}
\begin{definition}
Let $\mathcal{H}$ be a Hilbert space. Given a subspace $K$ and an element $x \in \mathcal{H}$, we call the unique element $y\in K$ of the decomposition $K\oplus K^\perp$ the \udef{orthogonal projection} of $x$ on $K$. It is denoted $P_K(x)$. This defines a function $P_K:\mathcal{H}\to K$ called the \udef{orthogonal projection} on $K$.
\end{definition}

\begin{proposition}
Let $P$ be the orthogonal projection on a closed subspace $K$. Then
\begin{enumerate}
\item $P$ is a linear operator on $\mathcal{H}$;
\item $\norm{Px}\leq \norm{x}$ for all $x\in\mathcal{H}$;
\item $P^2 = P$;
\item $\ker P = K^\perp$ and $\im P = K$;
\item $\id_\mathcal{H} - P$ is the orthogonal projection of $\mathcal{H}$ onto $K^\perp$.
\end{enumerate}
\end{proposition}
\begin{proof}
These are mostly direct results of the decomposition. In particular 5. follows if we know $K^\perp$ is closed, which it is by proposition \ref{prop:orthogonalComplementClosed}.
\end{proof}
\begin{corollary} \label{corollary:HilbertClosedSpaceOrthogonalDecomposition}
Let $\mathcal{H}$ ba a Hilbert space and $K$ a closed subspace, then $\mathcal{H} = K\oplus K^\perp$.
\end{corollary}
\begin{proof}
Let $P$ be the orthogonal projection on $K$. Then by \ref{prop:directSumKernelImageIdempotent}
\[ \mathcal{H} = \im P \oplus \ker P = K\oplus K^\perp. \]
\end{proof}
\begin{corollary} \label{corollary:doubleComplementClosure}
Let $\mathcal{H}$ be a Hilbert space.
\begin{enumerate}
\item If $K$ is a subspace, then $(K^\perp)^\perp = \overline{K}$ is the closure of $K$.
\item If $A$ is a subset, then $(A^\perp)^\perp$ is the closed linear span of $A$.
\end{enumerate}
\end{corollary}
\begin{proof}
(1) Assume $K$ is closed. Then using $0=(I-P_K)x\;\; \Leftrightarrow \;\; x=P_Kx$, we see
\[ (K^\perp)^\perp = \ker(I-P_K) = \im P_K = K. \]
Then, if $K$ is not closed, $(K^\perp)^\perp = (\overline{K}^\perp)^\perp = \overline{K}$, by proposition \ref{prop:orthogonalComplementClosed}.

(2) Using \ref{prop:OrthogonalComplementProperties} we calculate $(A^\perp)^\perp = (\Span(A)^\perp)^\perp = \overline{\Span(A)}$.
\end{proof}
\begin{corollary} \label{corollary:denseZeroComplement}
Let $A$ be a subset of a Hilbert space $\mathcal{H}$. Then $\Span(A)$ is dense in $\mathcal{H}$ \textup{if and only if} $A^\perp = \{0\}$.
\end{corollary}
\begin{proof}
The subspace $\Span(A)$ is dense in $\mathcal{H}$ iff $\overline{\Span(A)} = \mathcal{H}$ iff $(\Span(A)^\perp)^\perp = (A^\perp)^\perp = \mathcal{H}$ iff $A^\perp = \{0\}$.

In the last step we have used that $A^\perp$ is closed so that $((A^\perp)^\perp)^\perp = \overline{A^\perp} = A^\perp$, see \ref{prop:orthogonalComplementClosed}.
\end{proof}

\subsubsection{Existence of orthonormal bases}
\begin{corollary}
Let $D$ be an orthonormal subset of a Hilbert space $\mathcal{H}$, then $D$ is an ortonormal basis \textup{if and only if} it is maximal.
\end{corollary}
\begin{proof}
This is a restatement of the previous corollary in the language of \ref{lemma:characterisationMaximalOrthonormalSet}.
\end{proof}
\begin{corollary}
Every Hilbert space has an orthonormal basis.
\end{corollary}
\begin{proof}
Every inner product space has a maximal orthonormal set by \ref{prop:exitenceMaximalOrthonormalSet}. This maximal orthonormal set is an orthonormal set by the proposition.
\end{proof}
\begin{corollary} \label{lemma:HilbertOnBasisMaximal}
An orthonormal subset of a Hilbert space is an orthonormal basis \textup{if and only if} it is maximal.
\end{corollary}

\begin{lemma}
Let $\mathcal{H}$ be a Hilbert space and $K$ a closed subspace. Let $\{e_i\}_{i\in I}$ be an orthonormal basis of $K$. Then
\[ P_K(x) = \sum_{i\in I} \inner{e_i,x}e_i. \]
\end{lemma}
\begin{proof}
We can extend $\{e_i\}_{i\in I}$ to an orthonormal basis $\{e_i\}_{i\in J}$ of $\mathcal{H}$. Then
\[ x = \sum_{i\in J}\inner{e_i,x}e_i = \sum_{i\in I}\inner{e_i,x}e_i + \sum_{i\notin I}\inner{e_i,x}e_i, \]
which is clearly a decomposition in $K\oplus K^\perp$. This is unique, so we have found $P_K(x)$.
\end{proof}

\subsubsection{When are inner product spaces complete?}
Notice that some of the results obtained for Hilbert spaces have one direction that is generally true for inner product spaces: in any inner product space we have
\begin{itemize}
\item $\overline{K}\subset (K^\perp)^\perp$;
\item $\Span(A)$ dense in $\mathcal{H}$ implies $A^\perp = \{0\}$;
\item if $D$ is an orthonormal basis, then it is maximal.
\end{itemize}
See \ref{prop:orthogonalComplementClosed}, \ref{corollary:orthogonalComplementClosed} and \ref{lemma:characterisationMaximalOrthonormalSet}.

The converses are only true for Hilbert spaces.
\begin{theorem} \label{theorem:criterionHilbertSpace}
Let $H$ be an inner product space. If any of the following hold, $H$ is a Hilbert space:
\begin{enumerate}
\item For any orthonormal set $D$,
\[ \text{$D$ is maximal} \quad\implies\quad \text{$D$ is an orthonormal basis.} \]
\item For any subset $A$, $A^\perp = \{0\}$ implies $\Span(A)$ is dense in $H$.
\item For any subspace $K$, we have $(K^\perp)^\perp = \overline{K}$.
\item For all closed subspaces $K$ we can decompose $H = K\oplus K^\perp$.
\end{enumerate}
\end{theorem}
\begin{proof}
We prove the first statement implies $H$ is a Hilbert space. The other three imply the first and thus that $H$ is a Hilbert space.
\begin{enumerate}
\item We prove the contrapositive: assume $H$ is not complete, we wish to show that 1. does not hold, i.e. there exists a maximal orthonormal subset of $H$ that is not an orthonormal basis.

Let $\mathcal{H}$ be the completion of $H$ and take a unit vector $v\in \mathcal{H}\setminus H$. Now working in the completion, we have the decomposition $\Span\{v\}\oplus \Span\{v\}^\perp$. Consider the subspace $\Span\{v\} + H = \Span\{v\}\oplus(H\cap \Span\{v\}^\perp)$. We can extend $\{v\}$ to a maximal orthonormal set $\{v\}\cup D$ by \ref{prop:exitenceMaximalOrthonormalSet}.

We claim $D$ is the orthonormal set we want:

Firstly it is maximal.
Assume, towards a contradiction, that $D$ is not maximal in $H$, so there exists an orthonormal set $D'\supsetneq D$. Take $w\in D'\setminus D$ and let $w'$ be the normalisation of $w - \inner{v,w}v$. Then $w' \perp v$ and $w' \perp D$, so $\{v\}\cup D\cup\{w'\}$ is an orthonormal set in $\Span\{v\} + H$, which contradicts the maximality of $\{v\}\cup D$.

Secondly it cannot be total. Indeed if $\closure_H(\Span(D)) = H\cap\overline{\Span(D)}$ were equal to $H$, then $H \subseteq \overline{\Span(D)}$ and thus $\mathcal{H} = \overline{H} \subseteq \overline{\Span(D)} \subseteq \mathcal{H}$, meaning $\overline{\Span(D)} = \mathcal{H}$. But $v\notin \overline{\Span(D)}$, so $\overline{\Span(D)} \neq \mathcal{H}$.

\item 2. clearly implies 1. We can also adapt the proof above to show 2. implies $H$ is a Hilbert space:
Assume $H$ is not complete and let $\mathcal{H}$ be the completion of $H$. There exists a $v\in \mathcal{H}\setminus H$. All orthogonal complements are taken in the completion.
The set
\[ U \defeq H\cap\{v\}^\perp \]
is not dense in $\mathcal{H}$ for the same reason $D$ was not total above. We claim that the orthogonal complement of $U$ in $H$ is $\{0\}$:
\[ U^\perp\cap H = \{0\}. \]
First we claim $U$ is dense in $\{v\}^\perp$: take a $w\in \{v\}^\perp$ and let $(x_n)_{n\in\N}\subseteq H$ converge to $w$ (this is possible because $w\in\mathcal{H}$ and $H$ is dense in $\mathcal{H}$). Fix some $x\in H$ such that $\inner{x,v}\neq 0$, then we have the following sequence in $U$ that converges to $w$:
\[ n\mapsto x_n - \inner{x_n,v}\frac{x}{\inner{x,v}}. \]
Then because $U$ is dense in $\{v\}^\perp$,
\[ U^\perp\cap H = \overline{U}^\perp\cap H = (\{v\}^\perp)^\perp \cap H = \Span\{v\}\cap H = \{0\}. \]
\item Assume 3. Let $D$ be a maximal orthonormal set. Then
\[ \overline{\Span(D)} = (\Span(D)^\perp)^\perp = (D^\perp)^\perp = \{0\}^\perp = H, \]
so $D$ is an orthonormal basis.
\item Assume 4. Let $D$ be a maximal orthonormal set. Then $D^\perp$ is a closed subspace, so
\[ H  = D^\perp \oplus (D^\perp)^\perp = \{0\} \oplus (D^\perp)^\perp = (\Span(D)^\perp)^\perp = \overline{\Span(D)}. \]
\end{enumerate}
\end{proof}

\subsubsection{Orthogonal decomposition}
\begin{theorem}
 A Banach space such all of its closed subspaces are complemented is isomorphic to a Hilbert space.
\end{theorem}
\begin{proof}
TODO Lindestrauss and Tzafriri in 1971. Only real??
\end{proof}

\begin{proposition} \label{prop:directSumOrthogonalClosed}
Let $\mathcal{H}$ be a Hilbert space and let $\{V_i\}_{i\in I}$ be a family of closed, (pairwise) orthogonal subspaces. Then
\[ \bigoplus_{i\in I}V_i \qquad \text{is a closed subspace of $\mathcal{H}$.} \]
\end{proposition}
\begin{proof}
Let $(v_n)$ be a Cauchy sequence in $\bigoplus_{i\in I}V_i$ which converges to $w$. Let $v_{i,n}$ be the component of $v_n$ in $V_i$. By orthogonality we have
\[ \norm{v_n-v_m}^2 = \sum_{i\in I}\norm{v_{i,n}-v_{i,m}}^2. \]
Then
\[ \norm{v_{i,n}-v_{i,m}} \leq \norm{v_n-v_m} \]
which implies $(v_{i,n})_n$ is a Cauchy sequence in the closed space $V_i$ which therefore converges to $w_i\in V_i$. Now there are only a finite number of $i$ for which there exist non-zero $v_{i,n}$ (TODO proof!!!!). So then
\[ \lim_n v_n = \lim_n \sum_{i\in I}v_{i,n} = \sum_{i\in I}w_i \in \bigoplus_{i\in I}V_i \]
where the interchange of limits and last equality follow because the sums are finite.
\end{proof}

\begin{lemma} \label{lemma:cancellationOminus}
Let $\mathcal{H}$ be a Hilbert space and $A\supseteq B \supseteq C$ subspaces with $B$ closed. Then
\[ (A\ominus B)\oplus (B\ominus C) = A\ominus C.\]
\end{lemma}
\begin{proof}
Take $v\in(A\ominus B)\oplus (B\ominus C)$. Then either $\{v\}\perp C$ or $\{v\}\perp B$, but this implies $\{v\}\perp C$, so $v\in A\ominus C$.

Take $v\in A\ominus C$. We can uniquely write $v = v_1 + v_2 \in (A\ominus B)\oplus B = A$. We just need to show that $v_2\in B\ominus C$. Indeed assume $\inner{c,v_2}\neq 0$ for some $c\in C$. Then
\[ \inner{c, v} = \inner{c, v_1+v_2} = \inner{c,v_1}+\inner{c,v_2} = \inner{c,v_2} \neq 0, \]
so $v\notin A\ominus C$, a contradiction.
\end{proof}

\subsection{Projection and minimisation in finite-dimensional spaces}

\begin{lemma}
Let $K$ be a subspace of $\F^n$ spanned by the orthonormal basis $\{\vec{u}_i\}_{i=1}^k$. Then
\[ P_K = QQ^* \qquad\text{where}\qquad Q = \begin{bmatrix}
\vec{u}_1 & \vec{u}_2 & \hdots & \vec{u}_k
\end{bmatrix}. \]
\end{lemma}
\begin{proof}
$P_K(\vec{x}) = \sum_{i=1}^k\vec{u}_i\inner{\vec{u}_i,\vec{x}} = \sum_{i=1}^k\vec{u}_i \vec{u}_i^*\vec{x} = \left(\sum_{i=1}^k\vec{u}_i \vec{u}_i^*\right)\vec{x} = QQ^*\vec{x}$.
\end{proof}
\begin{corollary}
For any matrix $A$ with QR factorisation $A=QR$, we have
\[ P_{\Col(A)} = QQ^*. \]
\end{corollary}
In general $P_{\Col(A)} = A(A^*A)^{-1}A^*$.

\begin{proposition}[Normal equations]
Let $\{\vec{v}_i\}_{i=1}^k$ be linearly independent set of vectors in $\F^n$. Set $K = \Span\{\vec{v}_i\}_{i=1}^k$. Then for all $\vec{x}\in \F^n$
\[ P_K(\vec{x}) = \sum_{i=1}^k c_i \vec{v}_i, \]
where $\begin{bmatrix}
c_1 & c_2 & \hdots & c_k
\end{bmatrix}^\transp$ is the solution of
\[ \begin{bmatrix}
\inner{\vec{v}_1,\vec{v}_1} & \inner{\vec{v}_1,\vec{v}_2} & \hdots & \inner{\vec{v}_1,\vec{v}_k} \\
\inner{\vec{v}_2,\vec{v}_1} & \inner{\vec{v}_2,\vec{v}_2} & \hdots & \inner{\vec{v}_2,\vec{v}_k} \\
\vdots & \vdots & \ddots & \vdots \\
\inner{\vec{v}_k,\vec{v}_1} & \inner{\vec{v}_k,\vec{v}_2} & \hdots & \inner{\vec{v}_k,\vec{v}_k} \\
\end{bmatrix}\begin{bmatrix}
c_1 \\ c_2 \\ \vdots \\ c_k
\end{bmatrix} = \begin{bmatrix}
\inner{\vec{v}_1,\vec{x}} \\ \inner{\vec{v}_2,\vec{x}} \\ \vdots \\ \inner{\vec{v}_k,\vec{x}}
\end{bmatrix}. \]
This system of linear equations is consistent, yielding a unique solution.
\end{proposition}
The equations in this proposition are known as \udef{normal equations} and the matrix
\[ G(\vec{v}_1, \ldots, \vec{v}_k) \defeq \begin{bmatrix}
\vec{v}_1^* \\ \vec{v}_2^* \\ \vdots \\ \vec{v}_k^*
\end{bmatrix}\begin{bmatrix}
\vec{v}_1 & \vec{v}_2 & \hdots & \vec{v}_k
\end{bmatrix} = \begin{bmatrix}
\inner{\vec{v}_1,\vec{v}_1} & \inner{\vec{v}_1,\vec{v}_2} & \hdots & \inner{\vec{v}_1,\vec{v}_k} \\
\inner{\vec{v}_2,\vec{v}_1} & \inner{\vec{v}_2,\vec{v}_2} & \hdots & \inner{\vec{v}_2,\vec{v}_k} \\
\vdots & \vdots & \ddots & \vdots \\
\inner{\vec{v}_k,\vec{v}_1} & \inner{\vec{v}_k,\vec{v}_2} & \hdots & \inner{\vec{v}_k,\vec{v}_k} \\
\end{bmatrix} \]
is known as the \udef{Gram matrix} or \udef{Grammian}.
\begin{proof}
TODO
\end{proof}

\begin{proposition}
Let $A\in\F^{m\times n}$, $\vec{b}\in\F^m$ and $\vec{x}_0\in\F^n$. Then
\[ \min_{\vec{x}\in\F^n}\norm{\vec{b}-A \vec{x}} = \norm{\vec{b} - A \vec{x}_0} \]
if and only if
\[ A^*A \vec{x}_0 = A^* \vec{b}. \]
\end{proposition}
We regard $\vec{x}_0$ as the ``best approximate solution'' to the (not necessarily consistent) system $A \vec{x} = \vec{b}$.
\begin{proof}
TODO
\end{proof}

\subsection{Riesz representation}
\begin{theorem}[Riesz-Fréchet representation theorem] \label{theorem:rieszRepresentation}
Let $\mathcal{H}$ be a Hilbert space. For every continuous linear functional $\omega\in \mathcal{H}'$, there exists a unique $v_\omega\in\mathcal{H}$ such that
\[ \omega(x) = \inner{v_\omega, x} \qquad \forall x\in\mathcal{H}. \]
Moreover, $\norm{v_\omega}_\mathcal{H} = \norm{\omega}_{\mathcal{H}'}$.
\end{theorem}  
The idea of the proof is as follows: consider $\mathcal{H} = \ker\omega \oplus U$ where $U\cong\im\omega = \F$, so $\dim U = 1$. Between $1$-dimensional spaces there can only be one linear map, up to rescaling. This map can be written in the form $x\mapsto \inner{v,x}$ for some $v\in U$: the rescaling can be incorporated into $v$.

Now we want extend this form of $\omega|_U$ to the whole of $\mathcal{H}$. This works exactly if $v\in(\ker\omega)^\perp$. So we need $U=(\ker\omega)^\perp$ which is true if and only if $\mathcal{H} = \ker\omega\oplus U = \ker\omega\oplus (\ker\omega)^\perp$, which only works in general if $\ker\omega$ is closed and $\mathcal{H}$ is a Hilbert space. Now $\ker\omega$ is closed if and only if it is continuous, by \ref{prop:continuousMapCriterion}.

With this idea we give a full proof:
\begin{proof}
If $\ker\omega = \mathcal{H}$, we can take $v_\omega = 0$.

Assume $\ker\omega\neq \mathcal{H}$, then $(\ker\omega)^\perp\neq \{0\}$ by \ref{corollary:denseZeroComplement}, because $\ker\omega$ is closed (\ref{prop:continuousMapCriterion}). So we can take a non-zero $u\in (\ker\omega)^\perp$. We can choose it such that $\omega(u) = 1$, by rescaling. Now let $h\in\mathcal{H}$. We can write $h = (h - \omega(h)u)+\omega(h)u\in\ker\omega\oplus (\ker\omega)^\perp$, because $\omega(h - \omega(h)u) = 0$. So
\[ 0 = \inner{u,h - \omega(h)u} = \inner{u,h} - \omega(u)\norm{u}^2. \]
If $v_\omega = \norm{u}^{-2}u$, then $\omega(h) = \inner{v_\omega, h}$ for all $h\in\mathcal{H}$.

For uniqueness: assume we can find two vectors $v_\omega,v_\omega'$ such that for all $h\in\mathcal{H}$ we have $\omega(h) = \inner{v_\omega, h} = \inner{v_\omega', h}$. Then $v_\omega - v_\omega'\perp \mathcal{H}$, so $v_\omega - v_\omega'= 0$.
\end{proof}
Together with lemma \ref{lemma:innerBoundedFunctionals} this gives:
\begin{corollary} \label{corollary:RieszIsometry}
The map $C_\mathcal{H}:\mathcal{H}\to \tdual{\mathcal{H}}: v\mapsto \inner{v,\cdot}$ is a bijective anti-linear isometry.
\end{corollary}
\begin{corollary}
Every Hilbert space is reflexive.
\end{corollary}
\begin{proof}
TODO
\end{proof}
\begin{corollary}
Every bounded functional defined on a closed subspace of $\mathcal{H}$ can be extended to a functional on $\mathcal{H}$ with the same norm.
\end{corollary}
\begin{proof}
The functional on the closed subspace, say $K$, can be represented as $x\mapsto \inner{v,x}_K$ for some $v\in K$. The extended functional is then simply given by $x\mapsto \inner{v,x}_\mathcal{H}$.
\end{proof}

\begin{proposition}[Representation of sesquilinear forms] \label{prop:sesquilinearRepresentation}
Let $\mathcal{H}_1,\mathcal{H}_2$ be Hilbert spaces over $\mathbb{F}$ and $h:\mathcal{H}_1,\mathcal{H}_2\to\mathbb{F}$ a bounded sesquilinear form. Then there exists a unique bounded operator $S:\mathcal{H}_1 \to \mathcal{H}_2$ such that
\[ h(x,y) = \inner{Sx,y}. \]
This operator has the property $\norm{S} = \norm{h}$.
\end{proposition}
\begin{proof}
For fixed $x$, $y\mapsto h(x,y)$ is a bounded linear functional, so by the Riesz representation theorem \ref{theorem:rieszRepresentation} this can be represented by a unique $v_x$. Let $S$ be the function $x\mapsto v_x$. Then $h(x,y) = \inner{Sx,y}$.

To prove this function $S$ is linear, take arbitrary $x_1,x_2\in \mathcal{H}_1;y\in \mathcal{H}_2$ and $\lambda \in \mathbb{F}$. Then
\begin{align*}
\inner{S(\lambda x_1+ x_2),y} &= h(\lambda x_1+ x_2, y) = \overline{\lambda} h(x_1,y)+h(v,y_2) \\
&= \overline{\lambda} \inner{Sx_1, y} + \inner{Sx_2, y} = \inner{\lambda Sx_1 + Sx_2,y},
\end{align*}
so $S$ is linear by lemma \ref{lemma:elementaryOrthogonality}.

The equality of norms follows from
\begin{align*}
\norm{h} = \sup_{\substack{x\neq 0 \\ y\neq 0}}\frac{|\inner{Sx,y}|}{\norm{x}\norm{y}} &\geq \sup_{\substack{x\neq 0 \\ Sx\neq 0}}\frac{|\inner{Sx,Sx}|}{\norm{x}\norm{Sx}} = \sup_{x\neq 0}\frac{\norm{Sx}}{\norm{x}} = \norm{S} \\
&\leq \sup_{\substack{x\neq 0 \\ y\neq 0}}\frac{\norm{Sx}\norm{y}}{\norm{x}\norm{y}} = \sup_{x\neq 0}\frac{\norm{Sx}}{\norm{x}} = \norm{S}
\end{align*}
where the second inequality is Cauchy-Schwarz.
\end{proof}

\section{Orthonormal bases}

Hamel basis / Schauder basis / Hilbert basis

Every Hilbert basis is Schauder basis if $V$ is separable.

Hamel basis too big in Banach space??

Necessity of completeness for existence of complete orthonormal system, i.e. orthonormal system $\{a_i\}_{i\in I}$ (so $a_i \cdot a_j = \delta_{ij}$) with
\[ v = \sum_{i\in I}(a_i \cdot v)a_i \]
for all $v$. This is equivalent with
\[ v \cdot w = \sum_{i\in I}(v\cdot a_i)(a_i \cdot w) \]
for all $v,w$.


\begin{theorem}[Riesz-Fischer]
Let $\{e_i\}_{i\in I}$ be an orthonormal basis of a Hilbert space $H$ and $\alpha: I\to \C$ a net. Then
\[ \sum_{i\in I}\alpha_i e_i \]
converges \textup{if and only if} $\sum_{i\in I}|\alpha_i|^2 < \infty$. 
\end{theorem}
\begin{proof}
If $\sum_{i\in I}\alpha_i e_i$ converges, then $\sum_{i\in I}|\alpha_i|^2$ is bounded by the Bessel inequality \ref{corollary:BesselInequality}.

By monotone convergence, $\sum_{i\in I}|\alpha_i|^2 < \infty$ is equivalent to saying the sum converges. By (ref TODO) $\alpha$ has finite support. So $\sum_{i\in I}\alpha_i e_i$ can be expressed as the series
\[ \sum_{k\in \N}\alpha_{i_k} e_{i_k}. \]
By completeness it is enough to show that $\seq{s_n} = \seq{\sum_{k=0}^n\alpha_{i_k} e_{i_k}}$ is Cauchy. Let $n < m$, then
\[ \norm{s_n - s_m}^2 = \norm{\sum_{k=m+1}^n\alpha_{i_k} e_{i_k}}^2 = \sum_{k=m+1}^n\norm{\alpha_{i_k} e_{i_k}}^2 = \sum_{k=m+1}^n |\alpha_{i_k}|^2 = \sum_{k=0}^n|\alpha_{i_k}|^2 -\sum_{k=0}^m|\alpha_{i_k}|^2.  \]
Since $\seq{\sum_{k=0}^n |\alpha_{i_k}|^2}$ is convergent, it is Cauchy and thus so is $\seq{s_n}$.
\end{proof}
\begin{corollary}
Let $\mathcal{H}$ be a Hilbert space and $D$ be an orthonormal basis of $\mathcal{H}$. Then $\mathcal{H}$ is isometrically isomorphic to $\ell^2(D)$.
\end{corollary}
\begin{corollary}
Hilbert spaces whose orthonormal bases have the same cardinality are isometrically isomorphic.
\end{corollary}

??
\begin{lemma}
Let $(\Omega,\mathcal{A}, \mu)$ be a measure space. Then $L^2(\Omega, \mu)$ is separable \textup{if and only if} $\mu$ is $\sigma$-finite.
\end{lemma}

\begin{lemma}
Let $\{\phi_n(x)\}^\infty_{n=0}$ be an orthonormal basis of $L^2(\Omega, \mu)$ and $\{\psi_n(x)\}^\infty_{n=0}$ be an orthonormal basis of $L^2(\Lambda, \nu)$, then $\{\phi_n(x)\psi_m(y)\}^\infty_{n,m=0}$ is an orthonormal basis of $L^2(\Omega\times\Lambda, \mu\times\nu)$.
\end{lemma}
\begin{proof}
The set $\{\phi_n(x)\psi_m(y)\}^\infty_{n,m=0}$ is orthonormal:
\[ \iint_{\Omega\times\Lambda} \phi_n(x)\psi_m(y)\overline{\phi_{n'}(x)\psi_{m'}(y)}\diff{\mu(x)}\diff{\nu(y)} = \int_\Omega\phi_n(x)\overline{\phi_{n'}(x)}\diff{\mu(x)} \cdot \int_\Lambda\psi_m(y)\overline{\psi_{m'}(y)}\diff{\nu(y)} = \delta_{n,n'}\delta_{m,m'}, \]
using Fubini's theorem and the Hölder inequality (TODO refs).

To show $D = \{\phi_n(x)\psi_m(y)\}^\infty_{n,m=0}$ is an orthonormal basis, we verify point 5. of \ref{prop:totalONBParsevalEquivalence}: if $f\perp D$, then $f = 0$.

If $f\perp D$, then for all $m,n\in \N$
\[ 0 = \inner{f, \phi_n\psi_m} = \iint_{\Omega\times\Lambda}f(x,y)\overline{\phi_n(x)\psi_m(y)}\diff{\mu(x)}\diff{\nu(y)} = \int_\Omega \left(\int_\Lambda f(x,y)\overline{\psi_m(y)}\diff{\nu(y)} \right)\overline{\phi_n(x)}\diff{\mu(x)}.  \]
Using point 5. of \ref{prop:totalONBParsevalEquivalence} in $L^2(\Omega,\mu)$, we see that for all $m$ the function $x\mapsto\int_\Lambda f(x,y)\overline{\psi_m(y)}\diff{\nu(y)}$ is $0$ as an element of $L^2(\Omega, \mu)$, i.e. it is $0$ a.e. as a function of $x$. Let
\[ E_m = \setbuilder{x\in\Omega}{ \int_\Lambda f(x,y)\overline{\psi_m(y)}\diff{\nu(y)} \neq 0} \]
and set $E = \bigcup_{m\in\N}E_m$.
Then
\[ \mu(E) =  \mu\left(\bigcup_{m\in \N}E_m\right) \leq \sum_{m\in\N}\mu(E_m) = 0. \]

For $x\notin E$, we have $\int_\Lambda f(x,y)\overline{\psi_m(y)}\diff{\nu(y)} = 0$, so by the same logic $f(x,y) = 0$ for almost all $y$. 

Now $|f|^2$ is integrable and
\[ \iint_{\Omega\times \Lambda}|f(x,y)|^2\diff{\mu(x)}\diff(\nu(y)) = \int_{\Omega\setminus E}\int_\Lambda |f(x,y)|^2\diff{\mu(x)}\diff(\nu(y)) = 0, \]
so $f=0$ in $L^2(\Omega\times\Lambda, \mu\times\nu)$.
\end{proof}


\section{Adjoints of operators}
\begin{definition}
Let $H,K$ be Hilbert spaces and $T: H\not\to K$ an operator. An \udef{adjoint} of $T$ is an operator $S: K\not\to H$ such that
\[ \inner{w,Tv}_K = \inner{S w,v}_H \quad \forall v\in \dom(T),\; \forall w\in \dom(S). \]
\end{definition}

\begin{theorem}[Hellinger-Toeplitz]
Let $T: H\to K$ be an operator between Hilbert spaces (which is defined everywhere), then $T$ has an adjoint that is defined everywhere \textup{if and only if} it is bounded.
\end{theorem}
\begin{proof}
The ``if'' will be shown below by explicit construction. For the ``only if'', take such an operator $T$.

First we show $T$ has closed graph, by using proposition \ref{prop:closedGraphEquivalence}: assume $(x_n)$ converges to $x$ and $(Tx_n)$ converges to $y$. Then
\[ \inner{z, Tx} = \inner{Sz,x} = \lim_n\inner{Sz, x_n} = \lim_n\inner{z, Tx_n} = \inner{z, y} \]
where we have used the boundedness of $x\mapsto\inner{z,x}$. By the non-degeneracy of the inner product, $Tx = y$. So the graph of $T$ is closed. Similarly the graph of $S$ is closed. Applying the closed graph theorem \ref{theorem:closedGraphTheorem}, yields the boundedness of $T$ and $S$.
\end{proof}
\begin{corollary}
Everywhere-defined symmetric operators are bounded.
\end{corollary}

\begin{example}
The adjoint of the left-shift operator
\[ S_L: \ell^2(\N) \to \ell^2(\N): (x_n)_{n\in\N} \mapsto (x_{n+1})_{n\in\N} \]
is the right-shift operator
\[ S_R: \ell^2(\N) \to \ell^2(\N): (x_n)_{n\in\N} \mapsto \left(\begin{cases}
x_{n-1} & (n\geq 1) \\ 0 &(n=0)
\end{cases}\right)_{n\in \N}. \]
\end{example}

\subsection{Unbounded operators}
\begin{lemma}
Let $T: H\not\to K$ be a densely defined operator between Hilbert spaces. Let $S_1, S_2$ be adjoints of $T$ then for all $x\in \dom(S_1)\cap\dom(S_2)$ we have $S_1(x) = S_2(x)$.
\end{lemma}
\begin{proof}
For all $u\in \dom(T)$ we have
\[ \inner{S_1(x) - S_2(x), u}_H = \inner{S_1(x), u}_H - \inner{S_2(x), u}_H = \inner{x, Tu}_K - \inner{x, Tu}_K = 0. \]
So $\dom(T) \subset (\{S_1(x) - S_2(x)\})^\perp$ and in fact $H = \overline{\dom(T)} \subset (\{S_1(x) - S_2(x)\})^\perp$ because orthogonal complements are closed and $T$ is densely defined. So $S_1(x) - S_2(x) = 0$.
\end{proof}

\begin{definition}
Let $T: H\not\to K$ be a densely defined operator between Hilbert spaces. We define the adjoint $T^*$ as
\[ T^* \defeq \bigcup\setbuilder{\graph(S)}{\text{$S\in (K\not\to H)$ is an adjoint of $T$}}. \]
\begin{itemize}
\item If $T^* = T$, we say $T$ is \udef{self-adjoint}.
\item If $T^* = -T$, we say $T$ is \udef{skew-adjoint}.
\end{itemize}
\end{definition}

\begin{lemma}
Let $T: H\not\to K$ be a densely defined operator between Hilbert spaces. Then
\[ \dom(T^*) = \setbuilder{x\in K}{\text{$u\mapsto \inner{x, Tu}$ is a bounded functional}}. \]
\end{lemma}
\begin{proof}
$\boxed{\subseteq}$ If $\omega: u\mapsto \inner{x, Tu}$ is bounded, then it has a Riesz vector $x^*$ such that $\omega = u\mapsto \inner{x^*, u}$. The anti-linear operator with domain $\Span\{x\}$ that maps $x$ to $x^*$ is then an adjoint.

$\boxed{\supseteq}$ If $x\in\dom(T^*)$, then, using the Cauchy-Schwarz inequality,
\[ |\inner{x,Tu}| = |\inner{T^*x,u}| \leq \norm{T^*x}\;\norm{u}, \]
so the functional $u\mapsto \inner{x, Tu}$ is bounded.
\end{proof}
\begin{corollary}
The domain $\dom(T^*)$ is a vector space and in particular contains $0$.
\end{corollary}

\begin{proposition}
Let $T: H\not\to K$ be a densely defined operator between Hilbert spaces. Then
\[ \graph(T^*) = \left( \begin{pmatrix}
0 & -\id \\ \id & 0
\end{pmatrix}\graph(T) \right)^\perp. \]
\end{proposition}
\begin{proof}
Take $(y, T^{*}y)$ in $\graph(T^*)$. Then for all $x\in\dom(T)$:
\[ 0 = \inner{y, Tx}_K - \inner{T^*y, x}_H = \inner{y, Tx}_K + \inner{T^*y, -x}_H = \inner{(y, T^*y), (Tx,-x)}_{K\oplus H}. \]
So $\graph(T^*) \perp (Tx,-x) = \begin{pmatrix}
0 & -\id \\ \id & 0
\end{pmatrix} (x,Tx)$.

Clearly then $\graph(T^*) \subseteq \left( \begin{pmatrix}
0 & -\id \\ \id & 0
\end{pmatrix}\graph(T) \right)^\perp$.
For the other inclusion we just need to remark that each singleton subset of $\left( \begin{pmatrix}
0 & -\id \\ \id & 0
\end{pmatrix}\graph(T) \right)^\perp$ is an adjoint.
\end{proof}
\begin{corollary}
Let $T: H\not\to K$ be a densely defined operator between Hilbert spaces. Then $T^*$ is a closed operator.
\end{corollary}
\begin{corollary}
Let $T: H\not\to K$ be a densely defined and closable operator between Hilbert spaces. Then $T^*$ is densely defined and $\overline{T} = T^{**}$.
\end{corollary}

\begin{proposition}
Let $T: H\not\to K$ be a densely defined operator between Hilbert spaces. Then
\begin{enumerate}
\item $\ker(T) = \im(T^*)^\perp$;
\item $\ker(T^*) = \im(T)^\perp$.
\end{enumerate}
\end{proposition}
\begin{proof}
First take $v\in \ker(T^*)$, then $T^*(v) = 0$ which implies
\[ \forall x \in\dom(T): \inner{T^*(v), x} = 0 \;\implies\; \forall x \in\dom(T): \inner{v, T(x)} = 0 \;\implies\; v\perp \im(T).  \]
Next take $v\perp \im(T)$
\end{proof}
TODO: link with previous?

\begin{lemma}
Let $T: H\not\to K$ be a densely defined operator between Hilbert spaces. Assume $T$ injective and $\im(T)$ dense in $K$. Then $T^*$ is also injective and
\[ (T^*)^{-1} = (T^{-1})^*. \]
\end{lemma}

\begin{proposition}
Let $T: H\not\to K$ be a densely defined and closable operator between Hilbert spaces. Then $T^*$ is densely defined and $\overline{T} = T^{**}$.
\end{proposition}

\subsection{Bounded operators}
\begin{proposition}
Let $T\in\Bounded(H,K)$ with $H,K$ Hilbert spaces. Then
\[ T^* = C_H^{-1}T^tC_K: K\to H, \]
where $C_K$ is the Riesz isometry from \ref{corollary:RieszIsometry}.
is the unique adjoint of $T$ with $\dom(S) = K$.
\end{proposition}

\begin{lemma}
Let $T\in\Bounded(H,K)$. Then the adjoint $T^*$ is a bounded operator in $\Bounded(K,H)$ with $\norm{T^*} = \norm{T}$.
\end{lemma}
\begin{proof}
The function $(w,v)\mapsto \inner{w,Tv}_K$ is sesquilinear. By proposition \ref{prop:sesquilinearRepresentation} the function $T^*$ must be the unique $S$ from the proposition, which is linear and bounded.

This can also be proved by a direct calculation using $(T^*)^* = T$ from \ref{lemma:HilbertAdjointLemma}.
\end{proof}

\begin{lemma} \label{lemma:HilbertAdjointLemma}
Let $S,T\in\Bounded(H,K)$ and $\lambda \in \mathbb{F}$.
\begin{enumerate}
\item $(T^*)^* = T$;
\item $(S+T)^* = S^* + T^*$;
\item $(\lambda T)^* = \bar{\lambda}T^*$;
\item $\id_V^* = \id_V$.
\end{enumerate}
Let $T\in\Bounded(H_1,H_2), S\in\Bounded(H_2,H_3)$
\begin{enumerate}
\setcounter{enumi}{4}
\item $(ST)^* = T^*S^*$.
\end{enumerate}
\end{lemma}
\begin{proof}
The proofs are elementary manipulations. For example, to prove 1., we take arbitrary $v\in H$ and $w\in K$, Then
\[ \inner{w,Tv} = \inner{T^*w,v} = \overline{\inner{v,T^*w}} = \overline{\inner{(T^*)^*v,w}} = \inner{w, (T^*)^*v}. \]
By lemma \ref{lemma:elementaryOrthogonality} we have $Tv = (T^*)^*v$ for all $v\in V$. 
\end{proof}
\begin{lemma}
The adjoint defines a map $*:\Bounded(H,K)\to \Bounded(K,H)$ that is anti-linear and continuous in the weak and uniform operator topologies. It is continuous in the strong operator topology \textup{if and only if} finite dimensional.
\end{lemma}
\begin{proof}
By the proposition the adjoint map is anti-linear. It is also bounded with norm $1$. Then by corollary \ref{corollary:boundedAntiLinearMaps} it must be bounded.

TODO
\end{proof}

\begin{proposition}
Let $H,K$ be Hilbert spaces and $T:H\to K$ a bijective bounded linear operator with bounded inverse. Then $(T^*)^{-1}$ exists and
\[ (T^*)^{-1} = (T^{-1})^*. \]
\end{proposition}
\begin{proof}
We prove $(T^{-1})^*$ is both a left- and a right-inverse of $T^*$: $\forall x\in H, y\in K$
\begin{align*}
\inner{T^*(T^{-1})^*x,y} &= \inner{x,T^{-1}Ty} = \inner{x,y} \\
\inner{x,(T^{-1})^*T^*y} &= \inner{TT^{-1}x,y} = \inner{x,y}
\end{align*}
So, by lemma \ref{lemma:elementaryOrthogonality}, $T^*(T^{-1})^* = \id_H$ and $(T^{-1})^*T^* = \id_K$.
\end{proof}

\begin{proposition}
Let $T\in\Bounded(H,K)$. Then
\[ \ker T = (\im T^*)^\perp \qquad \text{and thus} \qquad \overline{\im(T)} \subseteq \ker(T^*)^\perp. \]
\end{proposition}
\begin{proof}
\[ x\in \ker T \iff Tx = 0 \iff \forall y\in K: \inner{y, Tx}=0 \iff \forall y\in K: \inner{T^*y, x}=0 \iff x\perp T^*[K]. \]
\end{proof}
In particular $\im(T)$ is closed iff it is equal to $\ker(T^*)^\perp$. This is sometimes known as the closed range theorem. This is, e.g., the case when $T$ is bounded below, see \ref{prop:boundedBelowClosedRange}.

\begin{proposition}
Let $T\in \Bounded(H,K)$ with $H,K$ Hilbert spaces. Then
\begin{enumerate}
\item $\norm{T^*T}= \norm{T}^2 = \norm{TT^*}$;
\item $T$ is an isometry \textup{if and only if} $T^*T = \id_H$;
\item $T$ is unitary \textup{if and only if} $T^*T = \id_H$ and $TT^* = \id_K$, i.e. $T^{-1} = T^*$.
\end{enumerate}
\end{proposition}
\begin{proof}
(1) For $\norm{T^*T}= \norm{T}^2$ first observe that
\[ \norm{T^*T} \leq \norm{T^*}\cdot\norm{T} = \norm{T}^2. \]
Conversely, $\forall x\in H$:
\[ \norm{T(x)}^2 = \inner{Tx,Tx} = \inner{T^*Tx,x} \leq \norm{T^*Tx}\cdot \norm{x} \leq \norm{T^*T}\cdot\norm{x}^2. \]
The other equality follows by applying the first to $T^*$ and using $\norm{T^*}=\norm{T}$.

(2) For all $v,w\in H$ we have
\[ \inner{Tv,Tw} = \inner{T^*Tv,w}. \]
The left-hand side is equal to $\inner{v,w}$ iff $T$ is an isometry. The right-hand side is equal to $\inner{v,w}$ iff $T^*T = \id_H$, by \ref{lemma:equalityOfMapsInnerProductSpaces}.

(3) If $T$ is invertible, it must have a left and right inverse. By lemma \ref{lemma:leftRightInverse} they must be the same.
\end{proof}



\subsection{Friedrichs extension}
\begin{proposition}
Let $T: H\not\to K$ be a densely defined, positive, symmetric operator between Hilbert spaces. Then $T$ has positive self-adjoint extension.
\end{proposition}
\begin{proof}

\end{proof}


\section{Dirac notation}
\url{https://core.ac.uk/download/pdf/25263496.pdf}
\url{https://michael-herbst.com/talks/2014.07.22_Mathematical_Concept_Dirac_Notation.pdf}
\url{http://galaxy.cs.lamar.edu/~rafaelm/webdis.pdf}
\url{https://plato.stanford.edu/entries/qt-nvd/}
\url{file:///C:/Users/user/Downloads/Abdus%20Salam,%20E.P.%20Wigner%20(Ed.)%20-%20Aspects%20of%20Quantum%20Theory%20-%20Dedicated%20to%20Dirac%E2%80%99s%2070th%20Birthday-Cambridge%20University%20Press%20(1972).pdf}
\url{https://aip.scitation.org/doi/pdf/10.1063/1.1705001}

\section{Bounded operators on Hilbert spaces}
\subsection{Properties to do with the adjoint}
\subsubsection{Normal operators}
\begin{definition}
A bounded linear operator $T$ one a Hilbert space $H$ is \udef{normal} if
\[ TT^* = T^*T. \]
\end{definition}
Self-adjoint and unitary operators are normal, but the converse is not true.

TODO 3.10 Self-Adjoint, Unitary and Normal Operators from Kreyszig.

\begin{lemma}
If $T$ is a normal operator, then $\ker T = \ker T^* = (\im T)^\perp$.
\end{lemma}
\begin{proof}
\[ \norm{Tx}^2 = \inner{Tx,Tx} = \inner{T^*Tx, x} = \inner{TT^*x, x} = \inner{T^*x, T^*x} = \norm{T^*x}^2. \]
\end{proof}
\begin{lemma}
If $\forall x\in H: \norm{Tx} = \norm{T^*x}$, then $T$ is normal.
\end{lemma}
\begin{proof}
By polarisation $\inner{Tx, Ty} = \inner{T^*x, T^* y}$ for all $x,y\in H$.
\end{proof}

\begin{lemma} \label{lemma:normalSpectralRadiusEqualsNorm} %cited in: positivity C^*
For normal elements the spectral radius equals the norm.
\end{lemma}

\begin{lemma}
A normal operator on a Hilbert space is invertible \textup{if and only if} it is bounded below.
\end{lemma}

\subsubsection{Self-adjoint operators}
\begin{definition}
Let $H$ be a Hilbert space.

A bounded operator $T\in\Bounded(H)$ is called \udef{self-adjoint} if $T=T^*$.
\end{definition}
\begin{proposition}
Let $T\in\Bounded(H)$ be self-adjoint. Then
\[ \norm{T} = \sup\setbuilder{|\inner{\varphi, T\varphi}|}{\norm{\varphi}\leq 1}. \]
\end{proposition}

\subsubsection{Orthogonal projections}
\url{https://planetmath.org/latticeofprojections}

\begin{proposition}
Let $P$ be a bounded operator $P$ on a Hilbert space $\mathcal{H}$. Then the following are equivalent:
\begin{enumerate}
\item $P$ is an orthogonal projection onto a closed subspace of $\mathcal{H}$;
\item $P^2 = P$ and $P=P^*$;
\item $P^2 = P$ and $\norm{P}\leq 1$.
\end{enumerate}
\end{proposition}
\begin{proof}
Suppose first that $P$ is the orthogonal projection operator onto a closed subspace $K$. Clearly $P^2 = P$. Let $x,y\in\mathcal{H}$ and write $x= x_1+x_2, y = y_1+y_2$ where $x_1,y_1\in K$ and $x_2,y_2\in K^\perp$. Then
\[ \inner{Px, y} = \inner{x_1, y_1+y_2} = \inner{x_1, y_1} + \inner{x_1,y_2} = \inner{x_1,y_1} = \inner{x_1+x_2, y_2} = \inner{x,Py}. \]
So $P = P^*$.

Suppose conversely that $P=P^*$ and $P^2 = P$. Define $K=\im P$, then $K$ is closed because $x\in K$ iff $Px=x$ and thus for any converging sequence $(x_n)_n\subset K$: $\lim x_n = \lim Px_n = P\left(\lim x_n\right)$, so the limit is in $K$. For orthogonality we need $\forall x\in\mathcal{H}: x-Px \in K^\perp$. This follows because $\forall x,y\in \mathcal{H}$:
\[ \inner{Py,x-Px} = \inner{y,P(x-Px)} = 0. \]
\end{proof}

\begin{lemma} \label{lemma:commutingProjectors}
The following are equivalent:
\begin{enumerate}
\item $PQ= QP$;
\item $PQ$ is a projection;
\item $QP$ is a projection;
\item $P+Q-PQ$ is a projection.
\end{enumerate}
If these conditions hold, then $PQ[\mathcal{H}] = P[\mathcal{H}] \cap Q[\mathcal{H}]$. (TODO converse? + integrate in previous prop)
\end{lemma}
\begin{proof}
Points 1., 2., 3. are equivalent by the equation $(PQ)^* = Q^*P^* = QP$, and the fact that 1. implies $(PQ)^2 = PQPQ = PPQQ = PQ$.

To prove 4., assume 1. and calculate
\begin{align*}
(P+Q-PQ)^* &= P+Q-(PQ)^* = P+Q-Q^*P^* =P+Q-QP = P+Q-PQ \\
(P+Q-PQ)^2 &= P^2 + PQ -P^2Q + QP+Q^2 - QPQ - PQP -PQP +PQPQ \\
&= P + Q + 3PQ - 4PQ= P+Q-PQ.
\end{align*}


Finally assume 4., then $(P+Q-PQ)^* = P+Q-QP = P+Q-PQ$. This implies $PQ=QP$.
\end{proof}

\begin{proposition}
Let $P,Q$ be orthogonal projections onto subspaces $P[\mathcal{H}]$ and $Q[\mathcal{H}]$ of $\mathcal{H}$.
\begin{enumerate}
\item The following are equivalent to $P[\mathcal{H}] \perp Q[\mathcal{H}]$:
\begin{enumerate}
\item $QP = 0$;
\item $PQ = 0$;
\item $Q+P$ is an orthogonal projection.
\end{enumerate}
\item The following are equivalent to $P[\mathcal{H}] \subset Q[\mathcal{H}]$:
\begin{enumerate}
\item $QP = P$;
\item $PQ = P$;
\item $Q-P$ is an orthogonal projection;
\item $P\leq Q$;
\item $\norm{Px} \leq \norm{Qx}$ for all $x \in \mathcal{H}$.
\end{enumerate}
\end{enumerate}
\end{proposition}
\begin{proof}
(1) This follows from the following statements:

$\boxed{(a)\Leftrightarrow (b)}$ By \ref{lemma:commutingProjectors}.

$\boxed{(b)\Leftrightarrow (c)}$ We know $(P+Q)^* = P^*+Q^* =P+Q$ and we can write
\[ (P+Q)^2 = P^2 + Q^2 + PQ + QP = P+Q+ PQ+QP,  \]
So clearly (a) or (b) imply (c). Conversely, assume $PQ + QP = 0$, implying $PQ=-QP$. By left- and right-multiplication by $P$ this implies both
\[ PPQ = PQ = -PQP \qquad \text{and} \qquad PQP = -QPP = -QP. \]
So $PQ = -PQP = QP$, meaning $PQ = 1/2(PQ+QP) = 0$.

(2) We prove the following:

$\boxed{(a)\Leftrightarrow (b)}$ By \ref{lemma:commutingProjectors}.

$\boxed{(a,b)\Rightarrow (c)}$ Obviously $(Q-P)^*= Q-P$. Also
\[ (Q-P)^2 = Q+P-PQ-QP= Q+P-2P = Q-P. \]

$\boxed{(c)\Rightarrow (a,b)}$ Now from
\[ Q-P = (Q-P)^2 = Q+P-PQ-QP \]
we obtain $2P = PQ+QP$. The result then follows if we can show that $PQ=QP$. This follows by multiplying the equality on the left and on the right by $P$ to obtain $QP = 2P-PQP$ and $PQ = 2P-PQP$, respectively. 

$\boxed{(c)\Rightarrow (d)}$ Is immediate as all projections are positive.

$\boxed{(d)\Rightarrow (c)}$ TODO (use (?) $\sigma(a+b)\subseteq\sigma(a)+\sigma(b)$ and $\sigma(ab)\subseteq\sigma(a)\sigma(b)$ in unital Banach algebras(TODO!, from Gelfand spectrum))

$\boxed{(d)\Leftrightarrow (e)}$ By the equivalence
\[ \norm{Px} \leq \norm{Qx} \iff \inner{Px,Px} \leq \inner{Qx,Qx} \iff \inner{Px,x}\leq \inner{Qx,x} \iff \inner{(Q-P)x,x}\geq 0. \]
\end{proof}


\subsubsection{Isometries}
\paragraph{Wandering spaces and unilateral shifts}
\begin{definition}
Let $\mathcal{H}$ be a Hilbert space, $\mathcal{V}\subseteq \mathcal{H}$ a closed subspace and $T:\mathcal{H}\to \mathcal{H}$ a linear map. Then $\mathcal{V}$ is called a \udef{wandering space} for $T$ if $T^p[\mathcal{V}]\perp T^q[\mathcal{V}]$ for every $p\neq q\in\N$.
\end{definition}
\begin{lemma}
Let $\mathcal{H}$ be a Hilbert space, $\mathcal{V}\subseteq \mathcal{H}$ a closed subspace and $T:\mathcal{H}\to \mathcal{H}$ a linear map.
If $T$ is an isometry, it is enough to suppose that $T^n[\mathcal{V}]\perp \mathcal{V}$ for all $n\in\N$, for $\mathcal{V}$ to be a wandering space.
\end{lemma}

\begin{definition}
An isometry $T$ on a Hilbert space $\mathcal{H}$ is called a \udef{unilateral shift} if there is a closed subspace $\mathcal{V}\subseteq \mathcal{H}$ that is wandering for $T$ such that
\[ \mathcal{H} = \bigoplus_{n=0}^\infty T^n[\mathcal{V}]. \]
We call the subspace $\mathcal{V}$ \udef{generating} for $T$ and $\dim(\mathcal{V})$ the \udef{multiplicity} of $T$.
\end{definition}
\begin{lemma} \label{lemma:WoldLemma}
Let $T$ be an isometry on $\mathcal{H}$. Then
\begin{enumerate}
\item $\mathcal{V} = T[\mathcal{H}]^\perp$ is a wandering subspace for $T$;
\item if $T$ is a unilateral shift, it is generated by $\mathcal{V} = T[\mathcal{H}]^\perp$.
\end{enumerate}
\end{lemma}
\begin{proof}
(1) For all $n\geq 1$ we have
\[ T^{n}[\mathcal{V}] \subset T^{n}[\mathcal{H}] \subset T[\mathcal{H}] \perp \mathcal{V} \]

(2) Assume $T$ a unilateral shift with generating subspace $\mathcal{V}$. We calculate
\[ T[\mathcal{H}] = T\left[\bigoplus_{n=0}^\infty T^n[\mathcal{V}]\right] = \bigoplus_{n=1}^\infty T^n[\mathcal{V}] = \bigoplus_{n=0}^\infty T^n[\mathcal{V}] \ominus \mathcal{V} = \mathcal{H}\ominus \mathcal{V} = \mathcal{V}^\perp, \]
so $\mathcal{V} = T[\mathcal{H}]^\perp$.
\end{proof}

A unilateral shift is determined up to unitary equivalence by its multiplicity:
\begin{lemma}
Let $T: \mathcal{H}\to\mathcal{H}$ and $T':\mathcal{H}'\to\mathcal{H}'$ be unilateral shifts generated by $\mathcal{V}$ and $\mathcal{V}'$ such that $\dim(\mathcal{V}) = \dim(\mathcal{V}')$. Then there exists an unitary $U:\mathcal{H}'\to\mathcal{H}$ such that
\[ T' = U^*TU \]
\end{lemma}
\begin{proof}
Choose an isometric isomorphism $u:\mathcal{V}'\to\mathcal{V}$. Then any $x\in\mathcal{H}'$ can be written as $x = \sum_{n=0}^\infty T^n(x_n)$. Then define
\[ Ux = \sum_{n=0}^\infty T^n(ux_n). \]
\end{proof}

\begin{theorem}[Wold decomposition]
Let $\mathcal{H}$ be a Hilbert space and $T\in\Bounded(\mathcal{H})$ an isometry. Then $\mathcal{H}$ decomposes into an orthogonal sum $\mathcal{H} = \mathcal{H}_0\oplus \mathcal{H}_1$such that $\mathcal{H}_0, \mathcal{H}_1$ reduce $T$ and
\[ T|_{\mathcal{H}_0}\;\text{is unitary} \quad\text{and}\quad T|_{\mathcal{H}_1}\;\text{is a unilateral shift}. \]
This decomposition is uniquely determined and given by
\[ \mathcal{H}_0 = \bigcap_{n=0}^\infty T^n[\mathcal{H}] \qquad\text{and}\qquad \mathcal{H}_1 = \bigoplus_{n=0}^\infty T^n[\mathcal{V}] \qquad\text{where}\qquad \mathcal{V} = T[\mathcal{H}]^\perp. \]
\end{theorem}
\begin{proof}
The subspace $\mathcal{V} = T[\mathcal{H}]^\perp$ is wandering by \ref{lemma:WoldLemma}. Then $T$ is a unilateral shift in the subspace
\[ \mathcal{H}_1 = \bigoplus_{n=0}^\infty T^n[\mathcal{V}]. \]
Now $v\in\mathcal{H}_1^\perp$ if and only if it is perpendicular to $\bigoplus_{i=0}^n T^i[\mathcal{V}]$ for all $n$ and we have
\begin{align*}
\bigoplus_{i=0}^n T^i[\mathcal{V}] &= \bigoplus_{i=0}^n T^i[\mathcal{H}\ominus T[\mathcal{H}]] = \bigoplus_{i=0}^n T^i[\mathcal{H}]\ominus T^{i+1}[\mathcal{H}] \\
&= (\mathcal{H}\ominus T[\mathcal{H}])\oplus(T[\mathcal{H}]\ominus T^2[\mathcal{H}])\oplus \ldots \oplus (T^n[\mathcal{H}]\ominus T^{n+1}[\mathcal{H}])  = \mathcal{H} \ominus T^{n+1}[\mathcal{H}] 
\end{align*}
using \ref{prop:ominusUnderIsometry} and \ref{lemma:cancellationOminus}, which is applicable because $T^i[\mathcal{V}]$ is closed by \ref{lemma:isometryClosed}. So $\mathcal{H}_0\subseteq T^n[\mathcal{H}]$ for all $n$.

Finally $T|_{\mathcal{H}_0}$ is unitary because it is an isometry and surjective on $\mathcal{H}_0$.
\end{proof}

\subsubsection{Unitaries}
\paragraph{Bilateral shifts}


\subsection{Finite-rank operators}
\begin{lemma} \label{lemma:finiteRankSingularValues}
Let $V$ be an inner product space and $T\in\Hom(V)$. Then $T$ is a finite-rank operator \textup{if and only if} $T$ can be written in the form
\[ T = \sum_{i=1}^N \lambda_i \ketbra{v_i}{w_i}, \]
where $(v_i)_{i=1}^N$ and $(w_i)_{i=1}^N$ are orthonormal sets of vectors and $(\lambda_i)_{i=1}^N$ are positive (non-zero) numbers.
\end{lemma}
The numbers $(\lambda_i)_{i=1}^N$ in this decomposition are uniquely determined by the operator and called the \udef{singular values} of the operator.
\begin{proof}
Because $\im(T)$ is finite-dimensional, we can find an orthonormal basis $(v_i)_{i=1}^N$ for it. Then $T$ can be written as $T(x) = \sum_{i=1}^N c_i(x)v_i$ for some linear functionals $c_i$. By \ref{theorem:rieszRepresentation} these functionals can be uniquely written in the form $\lambda_i\bra{w_i}$ where $w_i$ is a unit vector and $\lambda_i$ is positive (it is the norm of the Riesz vector). This gives the claimed form of $T$. We just need to show that $(w_i)_{i=1}^N$ is an orthogonal set and the values of $(\lambda_i)_{i=1}^N$ do not depend on the chosen basis $(v_i)_{i=1}^N$.

For \undline{orthogonality} of $(w_i)_{i=1}^N$: let $i\neq j$, then orthogonality of $(v_i)_{i=1}^N$ implies $c_i(w_j) = 0$, which in turn implies $\inner{w_i,w_j} = 0$.

For \undline{uniqueness} of $(\lambda_i)_{i=1}^N$: we claim it is equal to $L = \setbuilder{\sqrt{|\norm{T(v)}}}{v\in\im(T)\land\norm{v}=1}$, which is independent of the choice of $(v_i)_{i=1}^N$. TODO!!!!
\end{proof}
\begin{corollary}
Every finite rank operator on a Hilbert space is a finite sum of rank-1 operators.
\end{corollary}

\subsection{Compact operators}
\begin{proposition}
Let $T\in\Bounded(H)$. Then the following are equivalent:
\begin{enumerate}
\item $T$ is compact;
\item $T^*$ is compact;
\item there exists a sequence $(T_n)_{n\in\N}$ of finite rank operators such that $\norm{T-T_n}\to 0$.
\end{enumerate}
\end{proposition}
This is false in Banach spaces.
\begin{proof}
TODO
\end{proof}
\begin{corollary}
Any compact operator $T$ on a Hilbert space $\mathcal{H}$ can be written in the form
\[ T = \sum_{i=1}^\infty \lambda_i \ketbra{v_i}{w_i}, \]
where $(v_i)_{i=1}^\infty$ and $(w_i)_{i=1}^\infty$ are orthonormal sets and $(\lambda_i)_{i=1}^\infty$ is a sequence of positive numbers with $\lim_{i\to\infty}\lambda_i = 0$.
\end{corollary}
As in \ref{lemma:finiteRankSingularValues} for finite-rank operators we call $(\lambda_i)_{i=1}^\infty$ the \udef{singular values} of $T$. They are uniquely determined by the operator.
\begin{proof}

\end{proof}


\begin{proposition}
Let $H$ be a Hilbert space with orthonormal basis $(e_i)_{i\in I}$. If $T\in\Bounded(H)$ and
\[ \sum_{i\in I}\norm{Te_i}^2  < \infty, \]
then $T$ is a compact operator.
\end{proposition}
\begin{proof}
TODO + weaken $T\in\Bounded(H)$?
\end{proof}
\begin{corollary}
An integral operator defined by a square integrable kernel $K\in L^2(A\times A, \mu)$ is compact.
\end{corollary}


\subsubsection{The real spectral theorem}
\subsubsection{The complex spectral theorem}

\subsection{Positive operators}

Every proper subspace $U$ of a normed vector space $V$ has empty interior.
A nice consequence of this is that any closed proper subspace is necessarily nowhere dense. So if V is a Banach space, the Baire category theorem implies that V cannot be a countable union of closed proper subspaces. In particular, an infinite dimensional Banach space cannot be a countable union of finite dimensional subspaces. This means, for example, that a vector space of countable dimension (e.g. the space of polynomials) cannot be equipped with a complete norm.

\section{Unbounded operators}

\section{Dilation theory}
\subsection{Dilations, $N$-dilations and power dilations}
\begin{definition}
Let $\mathcal{H} \subseteq \mathcal{H}'$ be Hilbert spaces and let $P_\mathcal{H}$ be the projector on $\mathcal{H}$. If a pair of linear maps $S: \mathcal{H}'\to\mathcal{H}'$ and $T: \mathcal{H}\to \mathcal{H}$ satisfy the relation
\[ T = P_\mathcal{H} S |_\mathcal{H} \]
then $T$ is called a \udef{compression} of $S$ and $S$ a \udef{dilation} of $T$. This is abbreviated $T\prec U$.

Let $N\in\N$. If $T^k = P_\mathcal{H} S^k |_\mathcal{H}$ for all $k\leq N$, then $S$ is called an \udef{$N$-dilation}. If this holds for all $k\in\N$, then $S$ is called a \udef{power dilation}.
\end{definition}


\begin{lemma}
Let $S:\mathcal{H}'\to\mathcal{H}'$ be an $N$-dilation of $T: \mathcal{H}\to \mathcal{H}$ and $p$ a polynomial of degree at most $N$. Then
\[ p(T) = P_\mathcal{H}p(S)|_\mathcal{H}. \]
\end{lemma}

Let $\mathcal{H}$ be a Hilbert space. We call $T\in\Bounded(\mathcal{H})$ a \udef{contraction} if $\norm{T}\leq 1$.
\begin{lemma}
Let $\mathcal{H}$ be a Hilbert space. Every contraction $T$ on $\mathcal{H}$ is compression of a unitary $U$ on $\mathcal{H}^2 = \mathcal{H}\oplus \mathcal{H}$.
\end{lemma}
\begin{proof}
From $\norm{T}\leq 1$ (and the fact that $T^*T$ is normal), we have that $\vec{1}-T^*T\geq 0$ by spectral mapping. We can define $D_T = \sqrt{\vec{1}-T^*T}$. Then
\[ U = \begin{pmatrix}
T & D_{T^*} \\ D_T & -T^*
\end{pmatrix} \]
is unitary and a dilation of $T$: $T=P_\mathcal{H}U|_\mathcal{H}$.
\end{proof}
\begin{lemma}
Let $\mathcal{H}$ be a Hilbert space. Every contraction $T$ on $\mathcal{H}$ is compression of a unitary $U$ on $\mathcal{H}^{N+1}$.
\end{lemma}
\begin{proof}
Let $U'$ be a unitary dilation of $T$ on $\mathcal{H}^2$. Set $C_1 = U'_{-,1}$ and $C_2 = U'_{-,2}$. Then
\[ U = \begin{pmatrix}
C_1 & \mathbb{0}^{2\times N-1} & C_2 \\
\mathbb{0}^{N-1\times 1} & \mathbb{1}^{N-1\times N-1} & \mathbb{0}^{N-1\times 1}
\end{pmatrix} \]
is the requisite dilation by
\[ \begin{pmatrix}
C_1^* & \mathbb{0} \\
\mathbb{0} & \mathbb{1} \\
C_2^* & \mathbb{0}
\end{pmatrix}\begin{pmatrix}
C_1 & \mathbb{0} & C_2 \\
\mathbb{0} & \mathbb{1} & \mathbb{0}
\end{pmatrix} = \begin{pmatrix}
C_1^*C_1 & \mathbb{0} & C_1^*C_2 \\
\mathbb{0} & \mathbb{1} & \mathbb{0} \\
C_2^*C_1 & \mathbb{0} & C_2^*C_2
\end{pmatrix} = \mathbb{1}^{N+1\times N+1} \]
and TODO
\end{proof}


\begin{proposition}[von Neumann's inequality]
Let $T$ be a contraction on some Hilbert space $\mathcal{H}$. Then, for every polynomial $p\in\C[z]$,
\[ \norm{p(T)}\leq \sup_{|z|=1}|p(z)|. \]
\end{proposition}
\begin{proof}
Suppose the degree of $p$ is $N$. Let $U$ be a unitary $N$-dilation of $T$. Then
\[ \norm{p(T)} = \norm{P_\mathcal{H}p(U)|_\mathcal{H}}\leq \norm{p(U)} = \sup_{z\in\sigma(U)}|p(z)| \leq \sup_{|z|=1}|p(z)| \]
since the spectrum of $U$ is contained in the unit circle.
\end{proof}

\section{Constructions}
\subsection{Direct sum}
\subsection{Tensor product}
\url{https://web.ma.utexas.edu/mp_arc/c/14/14-2.pdf}




\chapter{Spectral theory}
\section{Invariant subspaces}
\begin{definition}
Let $L\in \Hom(V)$ be an endomorphism. A subspace $U$ of $V$ is \udef{invariant} under $L$ if $T|_U$ is an endomorphism on $U$. In other words, $u\in U$ implies $Tu\in U$.
\end{definition}
Clearly this definition only works for endomorphisms, not for linear maps in general. This is true for the rest of the theory about eigenvalues and eigenvectors.
\begin{example}
Let $L\in \Hom(V)$. The following are invariant under $L$:
\begin{itemize}
\item $\{0\}$;
\item $\ker L$;
\item $\im L$.
\end{itemize}
\end{example}
\section{The spectrum}
TODO: consistency $\lambda \id - L$, not $L-\lambda \id$.
TODO: everything is now in $\C$.

\begin{definition}
Let $L: \dom(L)\subset V \to V$ be an operator on a complex vector space $V$.

For $\lambda\in\C$ the \udef{resolvent} $R_\lambda(L)$ is defined as
\[ R_\lambda(L) \defeq (\lambda \id_V - L)^{-1}: \im(\lambda \id_V - L)\to\dom(L), \]
if this inverse exists (i.e. if $\lambda \id_V - L$ is injective).

The \udef{resolvent set} $\rho(L)$ is the set
\[ \rho(L) \defeq \setbuilder{\lambda\in \C}{\text{$R_\lambda(L)$ exists, has domain $V$ and is bounded}}. \]
\end{definition}

\begin{lemma}[Resolvent identity]
Let $T$ be a linear operator and $\lambda,\mu\in\C$ such that $R_\lambda(T), R_\mu(T)$ exist. Then $R_\lambda(T)$ and $R_\mu(T)$ commute and
\[ R_\lambda(T) - R_\mu(T) = (\mu-\lambda)R_\lambda(T)R_\mu(T). \]
\end{lemma}
\begin{proof}
The commutativity of the resolvents follows from \ref{lemma:commutationInverse}.

We calculate
\begin{align*}
R_\lambda(T) - R_\mu(T) &= R_\lambda(T)R_\mu(T)(\mu\id - T) - R_\mu(T)R_\lambda(T)(\lambda\id - T) \\
&= \mu R_\lambda(T)R_\mu(T) - R_\lambda(T)R_\mu(T) T - \lambda R_\mu(T)R_\lambda(T) + R_\mu(T)R_\lambda(T) T \\
&= (\mu - \lambda)R_\lambda(T)R_\mu(T).
\end{align*}
\end{proof}

\begin{definition}
Let $L: \dom(L)\subset V \to V$ be an operator on a complex vector space $V$.
\begin{itemize}
\item The \udef{spectrum} of $L$ is the complement of the resolvent set: $\sigma(L) \defeq \C\setminus\rho(L)$.
\item The \udef{point spectrum} or \udef{discrete spectrum} $\sigma_\text{p}(L)$ contains the values of $\lambda$ where $\lambda \id_V - L$ fails to be injective. These values are called the \udef{eigenvalues} of $L$.
\item The \udef{continuous spectrum} $\sigma_\text{c}(L)$ is the set of all values of $\lambda$ such that $\lambda \id_V - L$ is injective, $\overline{\im(\lambda \id_V - L)} = V$, but $\im(\lambda \id_V - L) \neq V$.
\item The \udef{residual spectrum} $\sigma_\text{r}(L)$ is the set of all values of $\lambda$ such that $\lambda \id_V - L$ is injective, but $\overline{\im(\lambda \id_V - L)} \neq V$.
\end{itemize}
The sets $\sigma_\text{p}(T), \sigma_\text{c}(T)$ and $\sigma_\text{r}(T)$ are disjoint.
\end{definition}
In finite dimensions we know that
\[ \text{$\lambda \id_V - L$ is surjective} \quad\iff\quad \text{$\lambda \id_V - L$ is injective.} \]
So in this case there can only ever be a point spectrum.

\begin{proposition}
Let $X$ be a Banach space and $T$ a closed linear operator on $X$. Then $\lambda \in \sigma(T)$ \textup{if and only if} $\lambda \id_X - T: \dom(T) \to V$ is not bijective.
\end{proposition}
\begin{proof}
If $\lambda \id_X - T$ is not bijective, then clearly $\lambda \in \sigma(T)$.

Conversely, assume $\lambda \id_X - T$ is bijective. Then $(\lambda \id_X - T)^{-1}: X\to \dom(T)$ is closed by \ref{prop:algebraClosedOperators} and has as domain a Banach space, so it is bounded by the closed graph theorem \ref{theorem:closedGraphTheorem}.
\end{proof}
\begin{corollary}
Let $T$ a closed linear operator on a Banach space. Then
\[ \sigma(T) = \sigma_\text{p}(T) \cup \sigma_\text{c}(T) \cup \sigma_\text{r}(T). \]
\end{corollary}

\begin{proposition}
Let $T$ be a bounded operator on a Banach space $X$. For $|\lambda|>\norm{T}$ the resolvent $R_\lambda(T)$ is bounded and given by
\[ R_\lambda(T) = (\lambda \id_X - T)^{-1} = \sum_{n=0}^\infty\frac{T^n}{\lambda^{n+1}} \]
with uniform convergence. The norm is bounded by
\[ \norm{R_\lambda(T)} = \norm{(\lambda \id_X - T)^{-1}} \leq \frac{1}{|\lambda|-\norm{T}}. \]
\end{proposition}
\begin{proof}
The operator $T/\lambda$ is a contraction so the Neumann series \ref{corollary:NeumannSeries} gives
\[ \left(\id - \frac{T}{\lambda}\right)^{-1} = \sum_{n=0}^\infty \left(\frac{T}{\lambda}\right)^n.  \]
Now $(\lambda \id_X - L)^{-1} = \frac{1}{\lambda}\left(\id - \frac{T}{\lambda}\right)^{-1} = \sum_{n=0}^\infty \frac{T^n}{\lambda^{n+1}}$. The Neumann series also gives us the bound on the norm.
\end{proof}
\begin{corollary}
Let $T$ be a bounded operator on a Banach space. Then $\sigma(T)\subset [-\norm{T}, \norm{T}]$.
\end{corollary}

\begin{proposition}
Let $T$ be a closed linear operator on a Banach space such that $0\in\rho(T)$. Let $S$ be a bounded operator with $\norm{S} < \norm{T^{-1}}^{-1}$, then $0\in\rho(T+S)$.
\end{proposition}
\begin{proof}
Since $\norm{T^{-1}S} \leq \norm{T^{-1}}\;\norm{S} < 1$, it follows from the Neumann series \ref{corollary:NeumannSeries} that $\id + T^{-1}S$ has a bounded inverse so that $(\id + T^{-1}S)^{-1}T^{-1}$ exists and is bounded. Then $(\id + T^{-1}S)^{-1}T^{-1} = (T+S)^{-1} = T^{-1}(\id + ST^{-1})$.
\end{proof}
\begin{corollary}
Let $T$ be a closed linear operator on a Banach space. Then $\sigma(T)$ is closed and $\rho(T)$ is open.
\end{corollary}
\begin{proof}
Let $\lambda \in \rho$ such that $(\lambda\id - T)^{-1}$ is bounded. For all $\epsilon \in B(0, 1/\norm{()\lambda\id - T)^{-1}})$ we have that $(\lambda\id - T) + \epsilon\id = (\lambda +\epsilon)\id -T$ has bounded inverse, so $\lambda + \epsilon \in \rho(T)$.
\end{proof}
\begin{corollary}
Let $T$ be a bounded linear operator on a Banach space. Then $\sigma(T)$ is compact.
\end{corollary}

\begin{lemma}
Let $L$ be an operator on a vector space $V$. If $\lambda \id_V - T$ is not bounded from below, then $\lambda \in \sigma(T)$.
\end{lemma}
\begin{proof}
If $\lambda \notin \sigma(T)$, then $R_\lambda(L)$ is bijective and bounded. By lemma \ref{lemma:boundedBelowBounded}, $\lambda \id_V - T$ is bounded below.
\end{proof}


\begin{lemma}
Let $T:X\to X$ be an operator on a Banach space and $\lambda\in\sigma_\text{c}$, then $R_\lambda(T)$ is unbounded.
\end{lemma}
\begin{proof}
If $R_\lambda(T)$ is bounded, $\lambda \id_V - T$ then is bounded below by lemma \ref{lemma:boundedBelowBounded} and has closed range by proposition \ref{prop:boundedBelowClosedRange}.
\end{proof}

TOreDO:
\begin{proposition}
Let $T \in \Bounded(H)$ for some Hilbert space $H$. Then $\sigma(T) \neq \emptyset$.
\end{proposition}
\begin{proof}
Let $x,y\in H$ and define
\[ f(\lambda) = \inner{x,R_\lambda(T)y}. \]
If $\sigma(T) = \emptyset$, then $f$ is an entire function. Now
\[ \norm{R_\lambda(T)} \leq \frac{1}{|\lambda| - \norm{T}} \to 0 \quad\text{as}\quad |\lambda| \to \infty. \]
By Liouville's theorem (TODO ref) we must have $f\equiv 0$. Because the $x,y$ we arbitrary we must have $R_\lambda(T)y = 0$ for all $y\in H$, such that $R_\lambda(T)$ is not injective, which is impossible as it is an inverse.
\end{proof}

\subsection{The point spectrum: eigenvalue and eigenvectors}
In this section we study invariant subspaces with dimension $1$, i.e. subspaces $U= \Span\{v\}$ such that
\[ Lv = \lambda v. \]
\begin{definition}
Suppose $L\in \Hom_{\mathbb{F}}(V)$.
\begin{itemize}
\item  A scalar $\lambda\in \mathbb{F}$ is called an \udef{eigenvalue} of $L$ if there exists a $v\in V$ such that $v\neq 0$ and $Lv = \lambda v$.
\item Such a vector $v$ is called an \udef{eigenvector}.
\item The set of all eigenvectors associated with an eigenvalue $\lambda$ is called the \udef{eigenspace} $E_\lambda(L)$. Because
\[ E_\lambda(L) = \ker(L-\lambda \id_V) \]
it is indeed a vector space.

The dimension of $E_\lambda(L)$ is the \udef{geometric multiplicity} of $\lambda$.
\end{itemize}
\end{definition}
\begin{proposition}
Let $L\in \Hom_\mathbb{F}(V)$ and $\lambda\in \mathbb{F}$, then
\[ \text{$\lambda$ is an eigenvalue of $L$} \qquad \iff \qquad \text{$\lambda$ is in the point spectrum $\sigma_p(L)$.} \]
\end{proposition}
\begin{proof}
The equation $Lv = \lambda v$ is equivalent to $(L-\lambda \id_V)v = 0$.
\end{proof}

\begin{proposition}
Let $L\in\Hom(V)$ be an operator on some vector space. Suppose $\lambda_1, \ldots, \lambda_m$ are distinct eigenvalues of $L$ and $v_1,\ldots, v_m$ are corresponding eigenvectors. Then $\{v_1,\ldots, v_m\}$ is linearly independent.
\end{proposition}
\begin{proof}
The proof goes by contradiction. Assume $\{v_1,\ldots, v_m\}$ is linearly dependent. Let $k$ be the smallest positive integer such that
\[ v_k \in \Span\{v_1,\ldots, v_{k-1}\}. \]
So there exists a nontrivial linear combination
\[ v_k = a_1v_1+\ldots +a_{k-1}v_{k-1}. \]
Applying $L$ to both sides gives
\[ \lambda_kv_k = a_1\lambda_kv_1+\ldots +a_{k-1}\lambda_kv_{k-1}. \]
Multipliying the previous combination by $\lambda_k$ and subtracting both equations gives
\[ 0= a_1(\lambda_k-\lambda_1)v_1 +\ldots + a_{k-1}(\lambda_k - \lambda_{k-1})v_{k-1}. \]
By assumption of linear independence of $\{v_1,\ldots, v_{k-1}\}$ this combination must be trivial, however none of the $(\lambda_k-\lambda_i)$ can be zero, so all the $a_i$ must be zero. This is a contradiction with the assumption of linear dependence.
\end{proof}
\begin{corollary}
For each operator on $V$, the set of distinct eigenvalues has at most cardinality $\dim V$.
\end{corollary}
\begin{corollary}
Let $L\in\Hom(V)$. Suppose $\lambda_1, \ldots, \lambda_m$ are distinct eigenvalues of $L$. Then
\[ E_{\lambda_1}(L) \oplus \ldots \oplus E_{\lambda_m}(L) \]
is a direct sum. Furthermore, the sum of geometric multiplicities is less than or equal to the dimension of $V$:
\[ \dim E_{\lambda_1}(L) + \ldots + \dim E_{\lambda_m}(L) \leq \dim V. \]
\end{corollary}

\subsubsection{In finite-dimensional spaces}
\begin{definition}
Let $L\in\Hom(V)$ with $V$ finite-dimensional. The \udef{characteristic polynomial} $p_L(x)$ of $L$. Is the polynomial
\[ p_L(x) \defeq \det(x\id_V - L). \]
\end{definition}
The characteristic polynomial is also sometimes defined as $\det(L - x\id_V)$. This differs by a sign $(-1)^{\dim(V)}$.
\begin{lemma}
For any $L\in\Hom(V)$ with $V$ finite-dimensional, the characteristic polynomial is a monic polynomial.
\end{lemma}
\begin{proposition}
Let $L\in\Hom(V)$ with $V$ finite-dimensional. Then the eigenvalues of $L$ are the solutions of the equation
\[ p_L(x) = 0. \]
This is called the \udef{characteristic equation} of $L$.
\end{proposition}

\begin{definition}
Let $L\in\Hom(V)$ with $V$ finite-dimensional and $\lambda$ an eigenvalue of $L$. The multiplicity of $\lambda$ as a root of $p_L(x)$ is the \udef{algebraic multiplicity} of $\lambda$.
\end{definition}
\begin{lemma}
Let $L\in\Hom(V)$ with $V$ finite-dimensional and $\lambda$ an eigenvalue of $L$.

The geometric multiplicity of $\lambda$ is less than or equal to the algebraic multiplicity of $\lambda$.
\end{lemma}
\begin{proof}
Set $k=\dim E_\lambda$. Take a basis of $E_\lambda(L)$ and extend it to a basis $\beta$ of $V$. With respect to this basis the matrix of $L$ is of the form
\[ (L)_\beta^\beta =  \begin{pmatrix}
\lambda \mathbb{1}_k & B \\ 0 & C
\end{pmatrix} \]
for some matrices $B,C$. Then 
\[ p_L(x) = p_{\lambda \id_{E_\lambda}}(x)p_C(x) = (\lambda - x)^kp_C(x), \]
so the algebraic multiplicity of $\lambda$ is at least the geometric multiplicity $k$. It may be greater if $\lambda$ is also an eigenvector of $C$, but in this case the eigenvector is a linear combination of the eigenvectors already chosen for $\beta$.
\end{proof}

\begin{definition}
Let $L\in\Hom(V)$ with $V$ finite-dimensional. The operator $L$ is called \udef{diagonalisable} if $V$ has a basis of eigenvectors.
\end{definition}
\begin{proposition}
Let $L\in\Hom(V)$ with $V$ finite-dimensional. Let $\lambda_1,\ldots, \lambda_m$ denote the distinct eigenvalues of $L$. The following are equivalent:
\begin{enumerate}
\item $L$ is diagonalisable;
\item there exist $1$-dimensional subspaces $U_1,\ldots, U_n$ of $V$, each invariant under $L$, such that
\[ V = U_1\oplus \ldots \oplus U_n; \]
\item $V = E_{\lambda_1}(L) \oplus \ldots \oplus E_{\lambda_m}(L);$
\item $\dim V = \dim E_{\lambda_1}(L) + \ldots + \dim E_{\lambda_m}(L);$
\item for each $\lambda_i$ the geometric multiplicity is equal to the algebraic multiplicity and the sum of algebraic multiplicities is $\dim(V)$.
\end{enumerate}
\end{proposition}
In the case of complex vector spaces, the sum of algebraic multiplicities is always $\dim(V)$ by the fundamental theorem of algebra.
\begin{corollary}
If $L\in\Hom(V)$ has $\dim V$ distinct eigenvalues, then $L$ is diagonalisable.
\end{corollary}
So an operator may fail to be diagonalisible for two reasons. 

\subsection{Approximate spectrum}
\begin{definition}
The set of all $\lambda$ such that $T-\lambda \id_V$ is not bounded from below is called the \udef{approximate point spectrum} $\sigma_\text{ap}$.

If $\lambda\in\sigma_\text{ap}(T)$, then $\lambda$ is an \udef{approximate eigenvalue} of $T$.
\end{definition}
\begin{lemma}
Let $T$ be an operator on a vector space $V$. Then $\lambda \in \sigma_\text{ap}(T)$ \textup{if and only if} there exists a sequence of unit vectors $(e_n)_{n\in\N}$ for which
\[ \lim_{n\to\infty}\norm{Te_n - \lambda e_n} = 0. \]
\end{lemma}
\begin{proof}
Assume there is such a sequence $(e_n)_{n\in\N}$. Then for all $\epsilon>0$, we can find a unit  vector $e_k$ such that $\norm{(T - \lambda \id_V)e_n} \leq \epsilon = \epsilon \norm{e_n}$. This is clearly not bounded below.

This other direction is just an inversion of this argument.
\end{proof}

\begin{lemma}
Let $T$ be an operator. Then $\sigma_\text{p}(T)\cup\sigma_\text{c}(T)\subset\sigma_\text{ap}(T)$.
\end{lemma}
\begin{proof}
If $T-\lambda \id_V$ is bounded below, then $T-\lambda \id_V$ is injective by \ref{prop:boundedBelow} and $\lambda\notin\sigma_\text{p}(T)$. By proposition \ref{prop:boundedBelowClosedRange} the range $\im(T-\lambda \id_V)$ is closed, so it cannot be a proper dense subset of $X$ and $\lambda\notin\sigma_\text{c}(T)$.
\end{proof}
\subsection{Compression spectrum}
\begin{definition}
The set of $\lambda$ for which $T-\lambda I$ does not have dense range is the \udef{compression spectrum} $\sigma_\text{cp}(T)$ of $T$.
\end{definition}
Then $\sigma_\text{r}(T) = \sigma_\text{cp}(T)\setminus\sigma_\text{p}(T)$.

\subsection{The essential spectrum}
TODO \url{https://en.wikipedia.org/wiki/Spectrum_(functional_analysis)#Classification_of_points_in_the_spectrum}

\section{Spectral properties of operators on Hilbert spaces}

\begin{proposition}
Let $T$ be a closed, densly defined operator on a Hilbert space.
\begin{enumerate}
\item If $\lambda\in\rho(T)$, then $\overline{\lambda}\in\rho(T^*)$.
\item If $\lambda\in\sigma_\text{r}(T)$, then $\overline{\lambda}\in\sigma_\text{p}(T^*)$.
\item If $\lambda\in\sigma_\text{p}(T)$, then $\overline{\lambda}\in\sigma_\text{r}(T^*)\cup\sigma_\text{p}(T^*)$.
\end{enumerate}
\end{proposition}
\begin{proof}
TODO
\end{proof}

\begin{proposition}
Let $T$ be a densely defined self-adjoint operator (TODO: closed necessary??). Then
\begin{enumerate}
\item $\sigma(T) \subset \R$;
\item $\sigma_r(T) = \emptyset$;
\item let $\lambda_1,\lambda_2 \in \sigma_\text{p}(T)$ and $\lambda_1\neq \lambda_2$, then 
\[ \Null(\lambda_1\id - T) \perp \Null(\lambda_2 \id - T). \]
\end{enumerate}
\end{proposition}
\begin{proof}
TODO
\end{proof}

\begin{proposition}
Let $T$ be a unitary operator. Then
\begin{enumerate}
\item $\sigma_\text{r}(T) = \emptyset$;
\item $\sigma(T) \subset \setbuilder{\lambda\in\C}{|\lambda| = 1}$.
\end{enumerate}
\end{proposition}
TODO: move to more general place??

\section{Multiplication operators}
\begin{definition}
Let $(\Omega, \mathcal{A}, \mu)$ be a measure space. A \udef{multiplication operator} is an operator of the form
\[ T: L^p(\Omega, \mu) \to L^p(\Omega, \mu): u(x) \mapsto a(x)u(x) \]
for some $a\in L^\infty(\Omega,\mu)$
\end{definition}

\begin{proposition}
Let $T: L^p(\Omega, \mu) \to L^p(\Omega, \mu): u \mapsto a\cdot u$ be a multiplication operator. Then
\[ \norm{T} = \norm{a}_{L^\infty}. \]
\end{proposition}
\begin{proof}
From the inequality $\norm{Tu}_{L^p}\leq \norm{a}_{L^\infty}\norm{u}_{L^p}$ we get $\norm{T} \leq \norm{a}_{L^\infty}$.

TODO
\end{proof}

\begin{lemma}
Let $T: L^2(\Omega, \mu) \to L^2(\Omega, \mu): u \mapsto a\cdot u$ be a multiplication operator with $a\in L^\infty(\Omega,\mu)$. Then $T^*$ is the multiplication operator
\[ T^*: L^2(\Omega, \mu) \to L^2(\Omega, \mu): u \mapsto \overline{a}\cdot u. \]
\end{lemma}
\begin{proof}
From 
\[ \inner{Tu,v} = \int_\Omega a\cdot u \cdot \overline{v}\diff{\mu} = \int_\Omega u \cdot \overline{\overline{a}\cdot v}\diff{\mu} \]
it follows that $T^*v = \overline{a}\cdot v$.
\end{proof}
\begin{corollary}
Then
\begin{enumerate}
\item $T$ is self-adjoint if $a$ is real-valued;
\item $T$ is skew-adjoint if $a$ is purely imaginary;
\item $T$ is unitary if $|a(x)| \equiv 1$.
\end{enumerate}
\end{corollary}

Let $E_\lambda$ be the level set
\[ E_\lambda = \setbuilder{x\in\Omega}{a(x) = \lambda} \]

\begin{proposition}
Let $T: L^2(\Omega, \mu) \to L^2(\Omega, \mu): u\mapsto a\cdot u$ be a multiplication operator with $a\in \cont(\Omega)$. Then
\begin{enumerate}
\item $\sigma_\text{p}(T) = \setbuilder{\lambda\in \im(a)}{\mu(E_\lambda)>0}$;
\item $\sigma_\text{c}(T) = \setbuilder{\lambda\in \overline{\im(a)}}{\mu(E_\lambda) = 0}$;
\item $\sigma_\text{r}(T) = \emptyset$;
\item $\rho(T) = \C\setminus \overline{\im(T)}$.
\end{enumerate}
\end{proposition}
\begin{proof}
TODO
\end{proof}

\section{The spectral theorem}
\url{https://link.springer.com/content/pdf/10.1007%2F978-1-4614-7116-5.pdf}

\url{http://individual.utoronto.ca/jordanbell/notes/SVD.pdf}
\url{https://digitalcommons.mtu.edu/cgi/viewcontent.cgi?article=2133&context=etdr}



\chapter{Types of operators}
\section{Fredholm operators}
\begin{definition}
An operator $T\in\Bounded(X,Y)$ between Banach spaces is called a \udef{Fredholm operator} if $T$ has a finite-dimensional kernel and cokernel.

The \udef{Fredholm index} of $T$ is defined as
\[ \Index T \defeq \dim\ker T - \dim\coker T.  \]

We denote the space of Fredholm operators from $X$ to $Y$ as $\Fred(X,Y)$. If $X=Y$, we write $\Fred(X)$.
\end{definition}

\begin{example}
\begin{enumerate}
\item If $X=Y$ is finite-dimensional, then all operators are Fredholm with index $0$.
\item The left shift $S_l:\ell^2(\N)\to\ell^2(\N): (x_n)_n\mapsto (x_{n+1})_n$ has index $1$.
\item The right shift $S_r = S_l^*$ has index $-1$.
\end{enumerate}
\end{example}

\begin{lemma}
A Fredholm operator has closed range.
\end{lemma}

\begin{lemma}
Let $T\in\Bounded(H)$ be a bounded operator on a Hilbert space. Then $\dim\coker T = \dim\ker T^*$.
\end{lemma}
\begin{proof}
TODO (is it correct?) $\ker(T^*) = \im(T)^\perp$.
\end{proof}

\begin{proposition}
Let $X$ be a Banach space. Then $\Compact(X)$ is a closed two-sided ideal in $\Bounded(X)$.
\end{proposition}
\begin{definition}
Let $X$ be a Banach space. The \udef{Calkin algebra} is the quotient $\Bounded(X)/\Compact(X)$.
\end{definition}
TODO: quotient algebra ($[A][B] = [AB]$)

\begin{proposition}
Let $[T]\in\Bounded(X)/\Compact(X)$. Then the following are equivalent:
\begin{enumerate}
\item $[T]$ is invertible in the Calkin algebra;
\item $\exists S\in\Bounded(X):$ both $\vec{1}-TS$ and $\vec{1}-ST$ are compact;
\item $T$ has closed range and finite-dimensional kernel and cokernel. 
\end{enumerate}
\end{proposition}
\begin{proof}
Point 1. and 2. are easily equivalent: $[S]$ is an inverse of $[T]$ if and only if $[\vec{1}] = [S][T] = [ST]$ and $[\vec{1}] = [T][S] = [TS]$. Then
\[ [\vec{1}] = [ST] \iff [ST - \vec{1}] = [0] \qquad [\vec{1}] = [TS] \iff [TS - \vec{1}] = [0] \]
and $[F]=[0]$ if and only if $F$ is compact.

TODO
\end{proof}

\begin{proposition}
Let $S,T\in\Fred(X)$, $\lambda\in\F$ and $K\in\Compact(X)$. Then
\begin{enumerate}
\item $\Index(ST) = \Index(S)+\Index(T)$;
\item $\Index(T+K) = \Index(T)$;
\item $\Index(\lambda T) = \Index(T)$, if $\lambda \neq 0$;
\item $\Index(T) = 0$ \textup{if and only if} $T=K'+L$ for some compact $K'$ and invertible $L$.
\end{enumerate}
Let $T\in\Fred(H)$ for some Hilbert space $H$. Then
\begin{enumerate} \setcounter{enumi}{4}
\item $\Index(T^*) = -\Index(T)$.
\end{enumerate}
\end{proposition}
TODO: integrate with corollary??

\begin{lemma}
Let the commutative diagram
\[ \begin{tikzcd}
0 \rar & X \dar{T} \rar & Y \dar{S} \rar & Z \dar{R} \rar & 0 \\
0 \rar & X \rar & Y \rar & Z \rar & 0
\end{tikzcd} \]
have short exact rows. If any two of $T,S,R$ are Fredholm, then so is the third and
\[ \Index S = \Index T + \Index R. \]
\end{lemma}
\begin{proof}
TODO snake lemma to obtain long exact
\[ 0\to \ker T \to \ker S\to \ker R \to \coker T \to \coker S \to \coker R \to 0. \]
\end{proof}
\begin{corollary} \mbox{}
\begin{enumerate} 
\item Let $T\in\Fred(X)$ and $S\in\Fred(Y)$ be Fredholm, then so is $T\oplus S$ with
\[ \Index(T\oplus S) = \Index(T)+\Index(S). \]
\item Let $T\in\Fred(X,Y)$ and $S\in\Fred(Y,Z)$ be Fredholm, then so is $ST$ with
\[ \Index(ST) = \Index(T)+\Index(S). \]
\item Let $K\in\Compact(X)$ be compact, then $\id_X+K$ is Fredholm with
\[ \Index(\id_X+K) = 0. \]
\end{enumerate}
\end{corollary}

\subsection{Fredholm alternative}

\section{Integral operators and transforms}
\begin{definition}
Let $(\Omega, \mathcal{A}, \mu)$ be a measure space. Then an \udef{integral operator} or \udef{integral transform} is a map of the form
\[ T: U\subset (\Omega\to\C) \to (\Omega\to\C): f \mapsto \int_\Omega K(x,y)f(y) \diff{\mu(y)} \]
where $K\in (\Omega\times \Omega \to \C)$ is the \udef{kernel} or \udef{nucleus} of $T$.

The kernel is called
\begin{itemize}
\item \udef{symmetric} if $K(x,y) = \overline{K(y,x)}$;
\item \udef{Volterra} if $\Omega = \R$ and $K(x,y) = 0$ for $y>x$;
\item \udef{convolutional} if $\Omega$ is a group and $K(x,y) = F(x-y)$ for some function $F$;
\item \udef{Hilbert-Schmidt} if $K\in L^2(\Omega\times \Omega)$, i.e.
\[ \int_{\Omega\times \Omega}|K(x,y)|^2\diff{x}\diff{y} < \infty; \]
\item \udef{singular} if $K(x,y)$ is unbounded on $\Omega\times \Omega$.
\end{itemize}
\end{definition}

\begin{lemma}
Hilbert-Schmidt integral operators are compact operators on $L^2(\Omega\times \Omega)$.
\end{lemma}
\begin{proof}
A Hilbert-Schmidt integral operator $T$ maps $L^2(\Omega)$ to $L^2(\Omega)$ functions:
\begin{align*}
\norm{Tu}^2_{L^2} &= \int_\Omega \left|\int_{\Omega} K(x,y)u(y)\diff{\mu(y)}\right|^2\diff{\mu(x)} \\
&\leq \int_\Omega \left(\int_{\Omega} |K(x,y)|^2\diff{\mu(y)}\right) \bigg( |u(y)|^2\diff{\mu(y)}\bigg)\diff{\mu(x)} \\
&= \left(\int_\Omega \int_{\Omega} |K(x,y)|^2\diff{\mu(y)}\diff{\mu(x)}\right) \bigg( |u(y)|^2\diff{\mu(y)}\bigg) < \infty
\end{align*}
where we have used the Cauchy-Schwarz inequality. This also immediately shows Hilbert-Schmidt integral operators are bounded.

TODO Compact
\end{proof}

\begin{proposition}
Let $T$ be an integral operator with kernel $K(x,y)$, then $T^*$ is the integral operator with kernel $\overline{K(y,x)}$.
\end{proposition}
\begin{proof}
TODO
\end{proof}

\begin{proposition}
Let $A$ be a Borel set and $K:A\times A\to \C$ a measurable function such that the integral operator with kernel $K$ is bounded. Then the adjoint of the integral operator is again an integral operator with kernel $K^*(x,y) = \overline{K(y,x)}$.
\end{proposition}

\begin{proposition}
Let $T$ be a Volterra integral operator. Then $\sigma(T) = \sigma_\text{c}(T) = \{0\}$.
\end{proposition}
\begin{proof}
TODO
\end{proof}

\subsection{Integral equations}
\begin{definition}
Let $(\Omega, \mathcal{A}, \mu)$ be a measure space. An \udef{integral equation} is an equation containing an unknown function on $\Omega$ and an integral over $\Omega$.

An integral equation is 
\begin{itemize}
\item \udef{of the first kind} if it is of the form
\[ \int_\Omega K(x,y)u(y)\diff{\mu(y)} = f(x) \qquad x\in \Omega \]
where $f$ is a given function and $u$ is the unknown function;
\item \udef{of the second kind} if it is of the form
\[ \lambda u(x) - \int_\Omega K(x,y)u(y)\diff{\mu(y)} = f(x) \qquad x\in \Omega \]
where $f$ is a given function, $\lambda$ is a scalar and $u$ is the unknown function.
\end{itemize}
\end{definition}

\begin{proposition}
Let
\[ \lambda u(x) - \int_\Omega K(x,y)u(y)\diff{\mu(y)} = f(x)\]
be an integral equation of the second kind. This integral equation has a unique solution $u$ if
\[ |\lambda| > \sup_{x\in \Omega} \int_{\Omega}|K(x,y)|\diff{\mu(y)}. \]
\end{proposition}
\begin{proof}
Let the map $T$ be defined by
\[ T(u) = x\mapsto \frac{1}{\lambda}\left(\int_\Omega K(x,y)u(y)\diff{\mu(y)} + f(x)\right) \]
so that solutions of the integral equation are exactly the fixed points of $T$. Then
\[ \norm{Tu-Tv}_\infty = \sup_{x\in\Omega} \frac{1}{|\lambda|} \left|\int_\Omega K(x,y)(u(y)- v(y))\diff{\mu(y)}\right| \leq \frac{1}{|\lambda|} \sup_{x\in \Omega} \int_{\Omega}|K(x,y)|\diff{\mu(y)} \cdot \norm{u-v}_\infty. \]
So $T$ is a contraction if $|\lambda| > \sup_{x\in \Omega} \int_{\Omega}|K(x,y)|\diff{\mu(y)}$. The result follows from \ref{prop:contractionFixedPoint}.
\end{proof}

\section{Convolution operators}