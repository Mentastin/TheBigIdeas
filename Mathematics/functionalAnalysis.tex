\input{functionalAnalysis/banachSpaces}

\chapter{Convex analysis}

\section{Extrema of functions on convex sets}
\begin{definition}
Let $\sSet{V,\xi}$ be a convergence vector space, $A\subseteq V$ a subset and $a\in A$. A continuous linear functional $f\in \dual{V}$ is said to \udef{support} $A$ at $a$ if $f(a)$ is a maximum of $f^\imf(A)$.
\begin{itemize}
\item If $a\in A$ is such that there exists $f\in \dual{V}$ that supports $A$ at $a$, then $a$ is called a \udef{support point} of $A$.
\item If $A$ is supported at $a$ by $f$ and $f^{\imf}(A) \neq \{f(a)\}$, then $f$ is said to \udef{properly support} $A$ at $a$.
\end{itemize}
\end{definition}
Note that $f$ attains a maximum iff $-f$ attains a minimum, so we can equivalently define support points using minimisers.

\begin{lemma} \label{supportPointsNotInCore}
Let $\sSet{V,\xi}$ be a convergence vector space, $A\subseteq V$ a subset and $a\in A$. If $a$ is a proper support point, then $a\notin \inh_\mathfrak{a}(A)$.
\end{lemma}
\begin{proof}
Suppose, towards a contradiction, that $a\in \inh_\mathfrak{a}(A)$. Let $f$ be the functional that supports $A$ at $a$. Since the support is proper, $f$ is not constant and thus there exists $x\in V$ such that $f(x) \neq f(a)$.

Now since $a\in \inh_\xi(A)$, there exists, by \ref{constructionsInAlgebraicConvergence}, an $\epsilon >0$ such that $a+\epsilon(x-a)\in C$ and $a-\epsilon (x-a)\in C$. Since $a$ is a support point, we have $f(a) \geq f(a) + \epsilon \big(f(x) - f(a)\big)$, so $f(a) \geq f(x)$, and $f(a) \geq f(a) - \epsilon \big(f(x) - f(a)\big)$, so $f(a)\leq f(x)$. Thus $f(a) = f(x)$, which is a contradiction.
\end{proof}

\begin{proposition} \label{properSupportConvexSets}
Let $\sSet{V,\xi}$ be a real topological convergence vector space and $C\subseteq V$ a convex subset with non-empty interior. If $x$ is a boundary point that belongs to $C$, then $C$ is properly supported at $x$.
\end{proposition}
\begin{proof}
Since the interior of $C$ is a nonempty open convex (by \ref{inherenceAdherenceConvex}) set and $\{x\}$ is convex, we can apply \ref{separatingFunctionalOrderedImage} to obtain a continuous functional such that $f(x)$ is a strict upper bound of $f^\imf\big(\interior_\xi(C)\big)$.

Then $f(x)$ is also an upper bound of $\closure_\R\Big(f^\imf\big(\interior_\xi(C)\big)\Big)$ and we have
\[ \closure_\R\Big(f^\imf\big(\interior_\xi(C)\big)\Big) \supseteq f^\imf\big(\closure_\xi\circ\interior_\xi(C)\big) = f^\imf\big(\closure_\xi(C)\big) \supseteq f^\imf(C), \]
by \ref{adherenceInherenceContinuity} and \ref{adherenceInherenceClosureConvexSets}.
Thus $f$ supports $C$ at $x$.

The support is proper because the upper bound was strict, so $f(y) < f(x)$ for all $y\in \interior_\xi(C)$, which was assumed non-empty.
\end{proof}

\begin{theorem}[Bishop-Phelps]
Aliprantis / Border p.284, 285
\end{theorem}

\begin{theorem}[BrÃ¸ndsted-Rockafellar]
Aliprantis / Border p.287
\end{theorem}

\section{Subgradients and subdifferentials}
\begin{definition}
Let $\sSet{X,Y,\pair{\cdot,\cdot}}$ be a pairing, $f: C\subseteq Y\to \R$ a convex function and $y\in Y$. An element $x\in X$ such that
\[ \forall y'\in C: \qquad f(y') \geq f(y) + \pair{x, y'-y}  \]
is called a \udef{subgradient} of $f$ at $y$. The set of all subgradients at $y$ is called the \udef{subdifferential} of $f$ at $y$ and is denoted $\subdiff{f}(y)$.
\end{definition}

\begin{lemma}
Let $\sSet{X,Y,\pair{\cdot,\cdot}}$ be a pairing, $f: C\subseteq Y\to \R$ a convex functional and $y\in C$. Then $f(y) = \min\big(\im(f)\big)$ \textup{if and only if} $0\in \subdiff{f}(y)$.
\end{lemma}
\begin{proof}
We have $f(y) = \min\big(\im(f)\big)$ iff $f(y')\geq f(y)$ for all $y'\in C$, which is equivalent to saying $0\in X$ is a subgradient.
\end{proof}

\begin{lemma} \label{subgradientEpigraphSupport}
Let $\sSet{X,Y,\pair{\cdot,\cdot}}$ be a pairing, $C\subseteq Y$ a convex set and $f: C\to \R$ a convex functional and $y\in Y$. Then
\begin{enumerate}
\item $x\in X$ is a subgradient of $f$ at $y$ \textup{if and only if} $\pair{x, \cdot}\circ \proj_1 - \proj_2$ supports $\epigraph(f)$ at $\big(y, f(y)\big)$;
\item if $g$ supports $\epigraph(f)$ at $\big(y, f(y)\big)$ and either
\begin{enumerate}
\item $g(0,1)\neq 0$, or
\item $y\in \inh_\mathfrak{a}(C)$ and $g$ is a proper support,
\end{enumerate}
then there exists $x\in X$ such that $\pair{x,\cdot} = g(\cdot,0)$ and $g(0,-1)^{-1}x$ is a subgradient of $f$ at $y$. 
\end{enumerate}
\end{lemma}
\begin{proof}
(1) Pick arbitrary $y'\in C$. Then
\begin{align*}
f(y') \geq f(y) + \pair{x, y'-y} &\iff \pair{x,y} - f(y) \geq \pair{x, y'} - f(y') \\
&\iff \big(\pair{x, \cdot}\circ \proj_1 - \proj_2\big)\big(y, f(y)\big) \geq \big(\pair{x, \cdot}\circ \proj_1 - \proj_2\big)\big(y', f(y')\big).
\end{align*}

(2) Since $g(\cdot, 0) = g\circ(\id, \underline{0})$ is a continuous linear functional, the existence of $x\in X$ such that $\pair{x,\cdot} = g(\cdot, 0)$ is given by \ref{functionalContinuityWeakTopology}.

Now we have $g(y',r) = g(y,0) + g(0,r)$, so
\begin{align*}
g(0,-1)^{-1}\cdot g(y',r) &= g(0,-1)^{-1}\cdot \big(g(y',0) + g(0,r)\big) \\
&= g(0,-1)^{-1}\pair{x, y'} + g(0,-1)^{-1}g(0,1)r \\
&= g(0,-1)^{-1}\pair{x, y'} - r \\
&= \big(\pair{g(0,-1)^{-1}x, \cdot}\circ\proj_1 - \proj_2\big)(y',r).
\end{align*}
So $g(0,-1)^{-1}\cdot g = \pair{g(0,-1)^{-1}x, \cdot}\circ\proj_1 - \proj_2$. If $g(0,-1)^{-1} \geq 0$, then $g(0,-1)^{-1}\cdot g$ supports $\epigraph(f)$ at $\big(y, f(y)\big)$, so $g(0,-1)^{-1}x$ is a subgradient of $f$ at $y$, by point (1).

We now just need to prove that $g(0,-1)^{-1} \geq 0$, or, equivalently, $g(0,1) \leq 0$.
Now consider the function $r\mapsto g(y,r) = g(y,0)+rg(1,0)$. For all $r\geq f(y)$, we have $g(y,r) \leq f(y)$. Considering very large and positive $r$, this is clearly only possible if $g(1,0)\leq 0$.

Finally we prove hypothesis $(a)$ from hypothesis $(b)$. Suppose, towards a contradiction, that $g(0,1) = 0$. Then $g(y', r) = g(y',0)+ rg(0,1) = g(y',0)$ for all $y'\in Y$. As $g$ supports $\epigraph(f)$ at $\big(y, f(y)\big)$, we have that $g(y,0)$ is a maximum of $g^\imf(C\times\{0\})$.

So $g\circ (\id_Y,\underline{0})$, which is a continuous functional, supports $C$ at $y$. This is a contradiction by \ref{supportPointsNotInCore}.
\end{proof}

\begin{proposition} \label{existenceSubdifferential}
Let $\sSet{X,Y,\pair{\cdot,\cdot}}$ be a pairing of real vector spaces, $C\subseteq Y$ a convex subset, $f: C\to \R$ a convex function and $y\in \inh_\mathfrak{a}(C)$. If $f$ is $\sigma(X,Y)$-continuous at $y$, then $\subdiff{f}(y) \neq \emptyset$.
\end{proposition}
\begin{proof}
By \ref{convexContinuity}, there exists $U\in \neighbourhood_{\sigma(X,Y)}(y)$ such that $f$ is bounded above on $U$, say by $c\in \R$. We WLOG may take $U$ to be open. Then $U\oplus \interval[o]{c, +\infty}$ is an open subset of $Y\oplus \R$ (by \ref{directSumsOpenClosedSets}) that is a subset of $\epigraph(f)$. Thus, by \ref{epigraphProperties}, $\epigraph(f)$ is a convex subset of $V\oplus \R$ with non-empty interior.

Now $\big(y,f(y)\big) \in \epigraph(f)$ is not an interior point, so it is a proper support point of $\epigraph(f)$ by \ref{properSupportConvexSets}. Thus there exists a continuous linear functional $g: Y\oplus \R\to \R$ that supports $\epigraph(f)$ at $\big(y,f(y)\big)$. By \ref{subgradientEpigraphSupport} this implies the existence of a subgradient.
\end{proof}

\begin{proposition}
$\subdiff{f}(y)$ is weak-$*$-compact, convex subset of $X$
\end{proposition}
\begin{proof}
TODO p.265 Aliprantis / Border.
\end{proof}


\subsection{The one-sided directional derivative}
\begin{lemma} \label{oneSidedDirectionalDerivativeLemma}
Let $V$ be a vector space and $f: C\to \R$ a convex functional on a convex set. Let $x\in C$ and $v\in V$ and $0<\lambda <\mu$ such that $x+\lambda v\in C$ and $x+\mu v\in C$. Then
\[ \frac{f(x+\mu v) - f(x)}{\mu} \leq \frac{f(x+\lambda v)-f(x)}{\lambda}. \]
In particular, $\lim_{\lambda\downarrow 0}\frac{f(x+\lambda v)-f(x)}{\lambda}$ exists in $\overline{\R}$.
\end{lemma}
\begin{proof}
We have
\[ x + \mu v = \frac{\mu}{\lambda}(x+ \lambda v) + \Big(1 -\frac{\mu}{\lambda}\Big)x, \]
so by convexity,
\[ f(x+\mu v) \leq \frac{\mu}{\lambda}f(x+ \lambda v) + \Big(1 -\frac{\mu}{\lambda}\Big)f(x). \]
Dividing by $\mu$ and rearranging gives the result.
\end{proof}
\begin{definition}
Let $V$ be a vector space, $f: C\to \R$ a convex functional on a convex set and $x\in C$. The \udef{one-sided directional derivative} of $f$ is defined as
\[ \diff{^+_xf}: V \to \overline{\R}: v \mapsto \lim_{\lambda\downarrow 0} \frac{f(x+\lambda v)-f(x)}{\lambda}. \]
\end{definition}
It is a one-sided version of the Gateaux differential. If $\diff{^+_xf}$ is linear, then it is called the one-sided Gateaux derivative.

\begin{proposition}
Let $\sSet{X,Y,\pair{\cdot,\cdot}}$ be a pairing of real vector spaces, $f: C\subseteq Y\to \R$ a convex function on a convex set and $y\in C$. Then $x\in X$ is a subgradient of $f$ at $y$ \textup{if and only if} $\pair{x, \cdot} \leq \diff{^+_x f}$.
\end{proposition}
\begin{proof}
First assume $x$ is a subgradient. Setting $y' = y + \lambda v$, for some $\lambda > 0$ and $v\in Y$, we have $f(y+\lambda v) \geq f(y) + \pair{x, y+\lambda v - y}$, so
\[ \frac{f(y+\lambda v) - f(y)}{\lambda} \geq \lambda^{-1}\pair{x, \lambda v} = \pair{x,v}. \]
Taking the limit $\lambda\downarrow 0$ gives $\diff{^+_x f}(v) \geq \pair{x,v}$.

Take $y'\in C$. By \ref{oneSidedDirectionalDerivativeLemma}, $\diff{^+_x f}(y'-y) \geq \pair{x,y'-y}$ implies $\pair{x,y'-y} \leq \frac{f\big(y+ \lambda(y'-y)\big)-f(x)}{\lambda}$ for all $\lambda >0$. In particular setting $\lambda =1$ gives $f(y')\geq f(y) + \pair{x, y'-y}$.
\end{proof}

\begin{proposition}
Let $\sSet{X,Y,\pair{\cdot,\cdot}}$ be a pairing, $f: Y\to \R$ a convex functional and $y\in Y$. Then $f$ is differentiable at $y$ \textup{if and only if} $\subdiff{f}(y)$ is a singleton.
\end{proposition}
\begin{proof}
\url{https://mathoverflow.net/questions/221856/hahn-banach-theorem-with-convex-majorant}
\end{proof}

\section{Convex functions on finite-dimensional spaces}
\subsection{Convex functions on an interval}
\begin{proposition}
Let $a,b\in \R$ and $f: \interval{a,b}\to \R$ a function. Then the following are equivalent:
\begin{enumerate}
\item $f$ is convex;
\item for all $a \leq x<y<z \leq b$, we have
\[ f(y) \leq \frac{z-y}{z-x}f(x) + \frac{y-x}{z-x}f(z); \]
\item for all $a \leq x<y<z \leq b$, we have
\[ \frac{f(y)-f(x)}{y-x} \leq \frac{f(z)-f(x)}{z-x} \leq \frac{f(z)-f(y)}{z-y}. \]
\end{enumerate}
\end{proposition}
\begin{proof}
$(1) \Rightarrow (2)$ We have that $y$ is a convex combination of $x$ and $z$:
\[ y = \left(1 - \frac{y-x}{z-x}\right)x + \frac{y-x}{z-x}z =  \frac{z-y}{z-x}x + \frac{y-x}{z-x}z. \]

$(2) \Rightarrow (3)$ We have
\[ f(y) - f(x) \leq \frac{z-y}{z-x}f(x) + \frac{y-x}{z-x}f(z) - f(x) = \frac{y-x}{z-x}\big(f(z)-f(x)\big) \]
and the first equality follows. Similarly
\[ f(z) - f(y) \geq f(z) - \frac{z-y}{z-x}f(x) - \frac{y-x}{z-x}f(z) = \frac{z-y}{z-x}\big(f(z)-f(x)\big). \]

$(3) \Rightarrow (1)$ Pick $x<y$ and $0<\lambda< 1$. Then we can set $y = \lambda x + (1-\lambda)z$, so $\lambda = \frac{z-y}{z-x}$ and $1-\lambda = \frac{y-x}{z-x}$, so
\begin{align*}
f(\lambda x + (1-\lambda)z) &= f(y) \\
&\leq f(x) + \frac{y-x}{z-x}\big(f(z)-f(x)\big) \\
&= f(x) + (1-\lambda)\big(f(z) - f(x)\big) \\
&= \lambda f(x) + (1-\lambda)f(z).
\end{align*}
\end{proof}

\section{Extreme points of convex sets}
\begin{theorem}[Krein-Milman]
Aliprantis / Border p. 297
\end{theorem}

\chapter{Spectral theory and functional calculus}
\section{Invariant subspaces}
\begin{definition}
Let $L\in \Hom(V)$ be an endomorphism. A subspace $U$ of $V$ is \udef{invariant} under $L$ if $T|_U$ is an endomorphism on $U$. In other words, $u\in U$ implies $Tu\in U$.
\end{definition}
Clearly this definition only works for endomorphisms, not for linear maps in general. This is true for the rest of the theory about eigenvalues and eigenvectors.
\begin{example}
Let $L\in \Hom(V)$. The following are invariant under $L$:
\begin{itemize}
\item $\{0\}$;
\item $\ker L$;
\item $\im L$.
\end{itemize}
\end{example}

\section{The spectrum}
TODO: eigenvalue problem $Lx = \lambda x$

generalised eigenvalue problem $Lx = \lambda T x$

nonstandard eigenvalue problem $A(\gamma)x = 0$.

TODO: consistency $\lambda \id - L$, not $L-\lambda \id$.
TODO: everything is now in $\C$.

\begin{definition}
Let $L: \dom(L)\subset V \to V$ be an operator on a complex normed vector space $V$.

For $\lambda\in\C$ the \udef{resolvent} $R_L(\lambda): \im(\lambda \id_V - L)\to\dom(L)$ is the left inverse of $\lambda \id_V - L$, if this inverse exists (i.e.\ if $\lambda \id_V - L$ is injective).
\begin{itemize}
\item The \udef{resolvent set} $\res(L)$ is the set
\begin{align*}
\res(L) &\defeq \setbuilder{\lambda\in \C}{R_L(\lambda)\in\Bounded(V, \dom(L))} \\
&= \setbuilder{\lambda\in \C}{\text{$R_L(\lambda)$ exists, has domain $V$ and is bounded}} \\
&= \setbuilder{\lambda\in \C}{\text{$\im(\lambda\id_V - L) = V$, $R_L(\lambda)$ exists, and is bounded}}.
\end{align*}
\item The \udef{spectrum} of $L$ is the complement of the resolvent set: $\spec(L) \defeq \C\setminus\rho(L)$.
\item The \udef{spectral radius} $\spr(L)$ is $\sup_{\lambda\in\spec(L)} |\lambda|$.
\end{itemize}
\end{definition}

TODO: allow $R_L$ to be densely defined??

\begin{lemma}
Let $V$ be a complex normed vector space $V$, $L: V\not\to V$ an operator on $V$ and $\lambda\in\res(L)$. Then the resolvent $R_L(\lambda)$ is also a right inverse, in the sense that $(\lambda\id - L)\circ R_L = \id_V$.
\end{lemma}
\begin{proof}
By definition of $\lambda\in\res(L)$, $V = \im(\lambda \id - L)$.

Take $x\in V = \im(\lambda \id - L)$. Then there must exist $x'\in \dom(L)$ such that $\lambda x' - L(x') = x$. Now
\[ (\lambda\id - L)\circ R_L(x) = (\lambda\id - L)\circ R_L \circ (\lambda\id - L) (x') = (\lambda\id - L)(x') = x. \]
\end{proof}
TODO generalise?

\begin{lemma}
Let $T\in\Lin(V)$ be an operator and $\lambda\in\C$ such that $\lambda\id_V - T$ is injective. Then $\im(R_T(\lambda)) = \dom(T)$.
\end{lemma}
\begin{proof}
For all $x\in \dom(T)$ we have $x = R_T(\lambda)(\lambda\id_V - T)x$.
\end{proof}

\begin{lemma} \label{elementResolventSetNormedSpace}
Let $T$ be an operator on a normed vector space $V$. Then $\lambda \in \res(T)$ \textup{if and only if} $\lambda \id_V - T$ is surjective and bounded from below.
\end{lemma}
\begin{proof}
By \ref{boundedBelow}, $\lambda \id_V - T$ has a bounded inverse $(\lambda \id_V - T)^{-1}: \im(\lambda \id_V - T)\to V$ if and only if it is bounded below. In order for $\lambda$ to be in the resolvent set, we need $(\lambda \id_V - T)^{-1}$ to be defined everywhere, i.e. $\im(\lambda \id_V - T) = V$.
\end{proof}

\begin{lemma} \label{densityCoreLemma}
Let $A$ be a closed operator on a Banach space $X$, $D$ a core for $A$ and $\lambda\in\res(A)$. Then $(\lambda\id_X - A)D$ is dense in $X$.
\end{lemma}
\begin{proof}
Take any $x\in X$. Then $R_A(\lambda)x\in \dom(A)$ and we can find a sequence $\seq{x_n}\subseteq \dom(A)$ that converges in graph norm to $R_A(\lambda)x$. Then $Ax_n \to AR_A(\lambda)x$ by \ref{graphNormConvergenceLemma} and so
\[ (\lambda\id_X - A)D \supseteq \seq{(\lambda\id_X - A)x_n} \to (\lambda\id_X - A)R_A(\lambda)x = x. \]
\end{proof}

\subsection{The three-way classification of the spectrum}
\begin{definition}
Let $L: \dom(L)\subset V \to V$ be an operator on a complex vector space $V$.

\begin{itemize}
\item The \udef{point spectrum} or \udef{discrete spectrum} $\pspec(L)$ contains the values of $\lambda$ where $\lambda \id_V - L$ fails to be injective, so the resolvent fails to exist. These values are called the \udef{eigenvalues} of $L$.

We call
\begin{itemize}
\item $E_\lambda \defeq \ker(\lambda \id_V - L)$ the \udef{multiplicity space} or \udef{geometric eigenspace} of $\lambda$; and
\item $\dim\ker(\lambda \id_V - L)$ the \udef{(geometric) multiplicity} of $\lambda$.
\end{itemize}
\item The \udef{continuous spectrum} $\cspec(L)$ is the set of all values of $\lambda\in\spec(L)$ such that the resolvent $R_L(\lambda)$ exists and is densely defined.
\item The \udef{residual spectrum} $\rspec(L)$ is the set of all values of $\lambda\in\spec(L)$ such that the resolvent $R_L(\lambda)$ exists, but is not densely defined.

We call
\begin{itemize}
\item $\im(\lambda \id_V - L)^\perp$ the \udef{deficiency subspace} of $\lambda$; and 
\item $\dim(\im(\lambda \id_V - L)^\perp)$ the \udef{deficiency} of $\lambda$.
\end{itemize}
\end{itemize}
The sets $\pspec(T), \cspec(T)$ and $\rspec(T)$ are disjoint.
\end{definition}
In finite dimensions we know that
\[ \text{$\lambda \id_V - L$ is surjective} \quad\iff\quad \text{$\lambda \id_V - L$ is injective} \]
and all linear operator are bounded.
So in this case there can only ever be a point spectrum.

\begin{proposition} \label{spectrumNonClosedOperator}
If $T$ is an operator on a Banach space that is not closed, then $\spec(T) = \C$.
\end{proposition}
\begin{proof}
We can find a sequence $x_n \to x$ such that $Tx_n \to y$, but $Tx \neq y$. Then for all $\lambda\in\C$ we have $z_n = (\lambda\id - T)x_n \to \lambda x - y$. If $R_T(\lambda)$ was a bounded inverse of $(\lambda\id - T)$, then $R_T(\lambda)\circ(\lambda\id - T)x_n \to R_T(\lambda)(\lambda x - y)$. We need to show that $R_T(\lambda)(\lambda x - y) \neq x$. Indeed
\begin{align*}
R_T(\lambda)(\lambda x - y) &= R_T(\lambda)(\lambda x - Tx + Tx - y) \\
&= R_T(\lambda)(\lambda x - Tx) + R_T(\lambda)(Tx - y) \\
&= x + R_T(\lambda)(Tx - y),
\end{align*}
and $R_T(\lambda)(Tx - y) \neq 0$, because $Tx - y \neq 0$ and the kernel of $R_T(\lambda)$ is trivial because it is injective. 
\end{proof}

\begin{example}
Closed operators may also have empty resolvent set. \url{https://math.stackexchange.com/questions/3262168/closed-operator-with-trivial-resolvent-set}
\end{example}

So spectral theory is only interesting for closed operators. In this case the three-way classification exhausts the possibilities: (only on Banach spaces??)

\begin{proposition} \label{closedOperatorBanachSpaceSpectrumCriterion}
Let $X$ be a Banach space and $T$ a closed linear operator on $X$. Then $\lambda \in \spec(T)$ \textup{if and only if} $\lambda \id_X - T: \dom(T) \to V$ is not bijective.
\end{proposition}
\begin{proof}
If $\lambda \id_X - T$ is not bijective, then clearly $\lambda \in \spec(T)$.

Conversely, assume $\lambda \id_X - T$ is bijective. Then $(\lambda \id_X - T)^{-1}: X\to \dom(T)$ is closed by \ref{algebraClosedOperators} and has as domain a Banach space, so it is bounded by the closed graph theorem \ref{closedGraphTheorem}.
\end{proof}
\begin{corollary} \label{spectrumDecomposition}
Let $T$ a closed operator on a Banach space. Then
\[ \spec(T) = \pspec(T) \cup \cspec(T) \cup \rspec(T). \]
\end{corollary}


\begin{proposition}
Let $T:X\to X$ be an operator on a Banach space and $\lambda\in\cspec$, then $R_\lambda(T)$ is unbounded.
\end{proposition}
\begin{proof}
If $R_\lambda(T)$ is bounded, $\lambda \id_V - T$ then is bounded below by lemma \ref{boundedBelow} and has closed range by proposition \ref{boundedBelowClosedRange}. Then because $\im(\lambda \id_V - T)$ is dense, this means $T$ is surjective, which is a contradiction because then $\lambda\in\res(T)$.
\end{proof}

\subsection{Resolvents}

\begin{proposition}
Let $X$ be a Banach space and $S,T: X\not\to X$. Then
\begin{enumerate}
\item $R_T(\lambda) - R_T(\mu) = (\mu - \lambda)R_T(\lambda)R_T(\mu)$ for all $\lambda, \mu\in \res(T)$;
\item if $\dom(S)\subseteq \dom(T)$, then $R_x(\lambda)\big(x-y\big)R_y(\lambda) = R_x(\lambda) - R_y(\lambda)$ for all $\lambda\in \res(S)\cap \res(T)$.
\end{enumerate}
\end{proposition}
In other words, the first and second resolvent identities hold.
In particular $R_T$ is a pseudoresolvent for all $T:X\not\to X$.
\begin{proof}
The proofs are the same algebraic manipulations as in the bounded case, \ref{firstResolventIdentity} and \ref{secondResolventIdentity}, except care must be taken with the domains.

(1) We have
\begin{align*}
R_T(\lambda) - R_T(\mu) &= R_T(\lambda)(\mu - T)R_T(\mu) - R_T(\lambda)(\lambda - T)R_T(\mu) \\
&= \mu R_T(\lambda)R_T(\mu) - R_T(\lambda)TR_T(\mu) - \lambda R_T(\lambda)R_T(\mu) + R_T(\lambda)TR_T(\mu) \\
&= \mu R_T(\lambda)R_T(\mu) - \cancel{R_T(\lambda)TR_T(\mu)} - \lambda R_T(\lambda)R_T(\mu) + \cancel{R_T(\lambda)TR_T(\mu)} \\
&= (\mu - \lambda)R_T(\lambda)R_T(\mu).
\end{align*}

(2) We have $\dom(T-S) = \dom(S)$, so $R_T(\lambda)\big(T-S\big)R_S(\lambda)$ is well-defined and
\begin{align*}
R_T(\lambda)\big(T-S\big)R_S(\lambda) &= R_T(\lambda)\big(\lambda\vec{1}-S - (\lambda\vec{1} - T)\big)R_S(\lambda) \\
&= R_T(\lambda)(\lambda\vec{1}-S)R_S(\lambda) - R_T(\lambda)(\lambda\vec{1} - T)R_S(\lambda) \\
&= R_T(\lambda)\id_{X} - \id_{\dom(T)}R_S(\lambda) \\
&= R_T(\lambda) - R_S(\lambda).
\end{align*}
\end{proof}

\begin{lemma} \label{operatorResolventMultiplication}
Let $T$ be a linear operator on a Banach space $X$ and $\lambda\in\C$. Then
\[ TR_T(\lambda) = \lambda R_T(\lambda) - \id_X. \]
\end{lemma}
Note in particular that $TR_T(\lambda)$ is bounded and defined everywhere.
\begin{proof}
We have $\id_X = (\lambda \id_X - T)R_T(\lambda) = \lambda R_T(\lambda) - TR_T(\lambda)$.
\end{proof}

\begin{lemma}
Let $T$ be a linear operator and $\lambda,\mu\in\C$. Assume $\lambda\in \spec(T)$. Then $\mu\lambda\in \spec(\mu T)$ and
\[ R_T(\lambda) = \mu R_{\mu T}(\mu \lambda). \]
\end{lemma}
\begin{proof}
TODO
\end{proof}


\subsubsection{Pseudoresolvents}

\begin{lemma} \label{imageRangePseudoresolvents}
Let $\mathcal{R}:\Lambda \subseteq \C \to \Bounded(X)$ be a pseudoresolvent on a Banach space $X$ and $\lambda,\mu\in\Lambda$. Then
\begin{enumerate}
\item $\ker\mathcal{R}(\lambda) = \ker\mathcal{R}(\mu)$;
\item $\im\mathcal{R}(\lambda) = \im\mathcal{R}(\mu)$.
\end{enumerate}
In particular this means that $\mathcal{R}(\lambda)$ is injective \textup{if and only if} $\ker\mathcal{R}(\mu)$ is injective.
\end{lemma}
\begin{proof}
From
\[ \mathcal{R}(\lambda) = \mathcal{R}(\mu)\big(\id_X + (\mu-\lambda)\mathcal{R}(\lambda)\big) = \big(\id_X + (\mu-\lambda)\mathcal{R}(\lambda)\big)\mathcal{R}(\mu), \]
we see that $\im\mathcal{R}(\lambda) \subseteq \im\mathcal{R}(\mu)$ and $\ker\mathcal{R}(\lambda) \supseteq \ker\mathcal{R}(\mu)$. Swapping $\lambda$ and $\mu$ gives the result.
\end{proof}


\begin{proposition}
Let $\mathcal{R}:\Lambda \subseteq \C \to \Bounded(X)$ be a pseudoresolvent. Then $\mathcal{R} = R_T|_\Lambda$ for some operator $T$ \textup{if and only if} $\mathcal{R}(\lambda)$ is injective for some $\lambda\in\Lambda$.

In this case $\im(\mathcal{R}(\lambda)) = \dom(T)$ for all $\lambda\in \Lambda$ and the operator $T$ is unique.
\end{proposition}
\begin{proof}
$\boxed{\Rightarrow}$ Because in particular $\Lambda = \dom(\mathcal{R}) = \dom(R_T|_\Lambda)$, we need to have that $\Lambda \subseteq \res(T)$. The resolvent $R_T(\lambda): X\to \dom(T)$ is bijective for all $\lambda\in \res(T)\subseteq \Lambda$. It is in particular injective.

$\boxed{\Leftarrow}$ By \ref{imageRangePseudoresolvents}, $\mathcal{R}(\lambda)$ is injective for all $\lambda\in\Lambda$. By restricting the codomain of $\mathcal{R}(\lambda)$ to its image, $\mathcal{R}(\lambda)$ becomes invertible. We can define $T: \im(\mathcal{R}(\lambda)) \to X = \lambda\id - \mathcal{R}(\lambda)^{-1}$. Then
\[ \mathcal{R}(\lambda)(\lambda\id - T) = \mathcal{R}(\lambda)\mathcal{R}(\lambda)^{-1} = \id_{\im(\mathcal{R}(\lambda))} = \id_{\dom(T)}. \]
Thus $\mathcal{R}(\lambda)$ is the resolvent of $T$ at $\lambda$.
The definition of $T$ is the only one that makes $\mathcal{R}(\lambda)$ a resolvent of $T$ at $\lambda$, so $T$ is unique.
\end{proof}
\begin{corollary}
Let $\mathcal{R}:\Lambda \subseteq \C \to \Bounded(X)$ be a pseudoresolvent and assume that $\Lambda$ contains an unbounded sequence $\seq{\lambda_n}$. If either
\begin{enumerate}
\item $\lim_{n\to\infty}\lambda_n\mathcal{R}(\lambda_n)x = x$ for all $x\in X$; or
\item $\im\mathcal{R}(\lambda)$ is dense in $X$ for some $\lambda\in \Lambda$ and $\norm{\lambda_n \mathcal{R}(\lambda_n)} \leq M$ for some $M\geq 0$ and all $n\in\N$;
\end{enumerate}
then $\mathcal{R}$ is the resolvent map of a densely defined operator.
\end{corollary}
\begin{proof}
(1) If $x\in \ker\mathcal{R}(\lambda)$ for some $\lambda\in\Lambda$, then it is in the kernel for all $\lambda\in\Lambda$. Thus $\lim_{n\to\infty}\lambda_n\mathcal{R}(\lambda_n)x = 0 = x$, meaning that $\ker\mathcal{R}(\lambda) = \{0\}$ and $\mathcal{\lambda} = R_T(\lambda)$ for some operator $T$. Also
\[ X = \overline{\bigcup_{n\in\N}\im\mathcal{R}(\lambda_n)} = \overline{\im\mathcal{R}(\lambda)} = \overline{\dom(T)}, \]
meaning $T$ is densely defined.

(2) From the resolvent identity we have, for some $\lambda\in \Lambda$,
\[ \lambda_n\mathcal{R}(\lambda_n)\mathcal{R}(\lambda) - \mathcal{R}(\lambda) = \lambda\mathcal{R}(\lambda_n)\mathcal{R}(\lambda) - \mathcal{R}(\lambda_n) \]
and thus
\begin{align*}
\norm{(\lambda_n\mathcal{R}(\lambda_n) - \id)\mathcal{R}(\lambda)} &= \norm{\lambda\mathcal{R}(\lambda_n)\mathcal{R}(\lambda) - \mathcal{R}(\lambda_n)} \\
&\leq |\lambda|\,\norm{\mathcal{R}(\lambda_n)}\,\norm{\mathcal{R}(\lambda)} + \norm{\mathcal{R}(\lambda_n)} \to 0
\end{align*}
because $\norm{\mathcal{R}(\lambda_n)} \leq |\lambda_n^{-1}|\,M \to 0$. So for all $x\in\im\mathcal{R}(\lambda)$, we have $\lim_{n\to\infty}\lambda_n\mathcal{R}(\lambda_n)x = x$.

Now take $x\in X$. Because of density, we can find a sequence $\seq{x_n}$ in $\im\mathcal{R}(\lambda)$ that converges to $x$. By the continuity of the maps $\lambda_n\mathcal{R}(\lambda_n)$ and their uniform bound in conjunction with (TODO ref!!!), we get
\begin{align*}
\lim_{n\to\infty}\lambda_n\mathcal{R}(\lambda_n)x &= \lim_{n\to\infty}\lambda_n\mathcal{R}(\lambda_n)\lim_{k\to\infty}x_k \\
&= \lim_{n\to\infty}\lim_{k\to\infty}\lambda_n\mathcal{R}(\lambda_n)x_k \\
&= \lim_{k\to\infty}\lim_{n\to\infty}\lambda_n\mathcal{R}(\lambda_n)x_k \\
&= \lim_{k\to\infty}x_k = x.
\end{align*}
We conclude with point (1).
\end{proof}

\subsubsection{Properties of the spectrum}

\begin{proposition} \label{resolventNormDistanceToSpectrum}
For all $\lambda\in\res(T)$, we have $d(\lambda, \spec(T)) \geq \norm{R_T(\lambda)}^{-1}$.
\end{proposition}
\begin{proof}
For all $\mu\in \ball(\lambda, \norm{R_T(\lambda)}^{-1})$ we can define $R_T(\mu)$ by analytic continuation as in \ref{firstNeumannSeries}. By \ref{imageRangePseudoresolvents} we have that $R_T(\mu): X\to \dom(T)$ is bijective and bounded. We just need to show that it is a left inverse of $\mu\id_X - T$. We calculate
\begin{align*}
\mathcal{R}(\mu)(\mu\id_X - T) &= \big(\id_X + (\mu - \lambda)\mathcal{R}(\lambda)\big)^{-1}\mathcal{R}(\lambda)(\mu\id_X - T) \\
&= \big(\id_X + (\mu - \lambda)\mathcal{R}(\lambda)\big)^{-1}\mathcal{R}(\lambda)\big((\mu - \lambda)\id_X + (\lambda\id_X - T)\big) \\
&= \big(\id_X + (\mu - \lambda)\mathcal{R}(\lambda)\big)^{-1}\big((\mu - \lambda)\mathcal{R}(\lambda) + \id_X\big) \\
&= \id_X.
\end{align*}
\end{proof}
\begin{corollary}
The resolvent set $\res(T)$ is open. The spectrum $\spec(T)$ is closed.
\end{corollary}
This is stronger than \ref{spectrumCompact}, because $T$ is not assumed closed.


\begin{example}
Operator with empty spectrum. TODO \url{https://math.stackexchange.com/questions/1344287/example-operator-with-empty-spectrum}.
\end{example}

\begin{proposition}
Let $T$ be an injective operator with dense range. Then for all $\lambda\neq 0$
\[ R_{T^{-1}}(\lambda^{-1}) = -\lambda T R_{T}(\lambda) = \lambda -\lambda^2 R_T(\lambda). \]
\end{proposition}
\begin{proof}
This is a reformulation of the calculation
\[ \frac{1}{\lambda^{-1} - T^{-1}} = \frac{\lambda T}{\lambda T}\frac{1}{\lambda^{-1} - T^{-1}} = \frac{\lambda T}{T - \lambda} = \frac{\lambda T - \lambda^2 + \lambda^2}{T - \lambda} = \frac{\lambda\cancel{(T - \lambda)}}{\cancel{T - \lambda}} + \frac{\lambda^2}{T - \lambda} = \lambda - \lambda^2 R_T(\lambda). \]
TODO: make rigourous!!
\end{proof}
\begin{corollary}
Let $T$ be an injective operator with dense range. Then for all $\lambda\neq 0$
\begin{enumerate}
\item $\spec(T^{-1})\setminus\{0\} = (\spec(T)\setminus \{0\})^{-1}$;
\item $\pspec(T^{-1})\setminus\{0\} = (\pspec(T)\setminus \{0\})^{-1}$.
\end{enumerate}
\end{corollary}


\subsection{Parts of the spectrum}

\subsubsection{The point spectrum: eigenvalue and eigenvectors}
In this section we study invariant subspaces with dimension $1$, i.e.\ subspaces $U= \Span\{v\}$ such that
\[ Lv = \lambda v. \]
\begin{definition}
Suppose $L\in \Hom_{\mathbb{F}}(V)$.
\begin{itemize}
\item  A scalar $\lambda\in \mathbb{F}$ is called an \udef{eigenvalue} of $L$ if there exists a $v\in V$ such that $v\neq 0$ and $Lv = \lambda v$.
\item Such a vector $v$ is called an \udef{eigenvector}.
\item The set of all eigenvectors associated with an eigenvalue $\lambda$ is called the \udef{eigenspace} $E_\lambda(L)$. Because
\[ E_\lambda(L) = \ker(L-\lambda \id_V) \]
it is indeed a vector space.

The dimension of $E_\lambda(L)$ is the \udef{geometric multiplicity} of $\lambda$.
\end{itemize}
\end{definition}
If $L$ is a closed operator, then its eigenspaces are closed by \ref{closedOperatorKernelClosed}.

For a bounded operator $T$, we have $\pspec(T)\subset \cball(0, \norm{T})$ by \ref{spectrumCompact}. For the point spectrum a simpler argument also leads to $\pspec(T)\subset \cball(0, \norm{T})$: let $\lambda$ be an eigenvalue with eigenvector $x$. Then
\[ |\lambda|\;\norm{x} = \norm{\lambda x} = \norm{Tx} \leq \norm{T}\;\norm{x}. \]

\begin{proposition}
Let $L\in \Hom_\mathbb{F}(V)$ and $\lambda\in \mathbb{F}$, then
\[ \text{$\lambda$ is an eigenvalue of $L$} \qquad \iff \qquad \text{$\lambda$ is in the point spectrum $\pspec(L)$.} \]
\end{proposition}
\begin{proof}
The equation $Lv = \lambda v$ is equivalent to $(L-\lambda \id_V)v = 0$.
\end{proof}

\begin{proposition}
Let $L\in\Hom(V)$ be an operator on some vector space. Suppose $\lambda_1, \ldots, \lambda_m$ are distinct eigenvalues of $L$ and $v_1,\ldots, v_m$ are corresponding eigenvectors. Then $\{v_1,\ldots, v_m\}$ is linearly independent.
\end{proposition}
\begin{proof}
The proof goes by contradiction. Assume $\{v_1,\ldots, v_m\}$ is linearly dependent. Let $k$ be the smallest positive integer such that
\[ v_k \in \Span\{v_1,\ldots, v_{k-1}\}. \]
So there exists a nontrivial linear combination
\[ v_k = a_1v_1+\ldots +a_{k-1}v_{k-1}. \]
Applying $L$ to both sides gives
\[ \lambda_kv_k = a_1\lambda_kv_1+\ldots +a_{k-1}\lambda_kv_{k-1}. \]
Multipliying the previous combination by $\lambda_k$ and subtracting both equations gives
\[ 0= a_1(\lambda_k-\lambda_1)v_1 +\ldots + a_{k-1}(\lambda_k - \lambda_{k-1})v_{k-1}. \]
By assumption of linear independence of $\{v_1,\ldots, v_{k-1}\}$ this combination must be trivial, however none of the $(\lambda_k-\lambda_i)$ can be zero, so all the $a_i$ must be zero. This is a contradiction with the assumption of linear dependence.
\end{proof}
\begin{corollary}
For each operator on $V$, the set of distinct eigenvalues has at most cardinality $\dim V$.
\end{corollary}
\begin{corollary}
Let $L\in\Hom(V)$. Suppose $\lambda_1, \ldots, \lambda_m$ are distinct eigenvalues of $L$. Then
\[ E_{\lambda_1}(L) \oplus \ldots \oplus E_{\lambda_m}(L) \]
is a direct sum. Furthermore, the sum of geometric multiplicities is less than or equal to the dimension of $V$:
\[ \dim E_{\lambda_1}(L) + \ldots + \dim E_{\lambda_m}(L) \leq \dim V. \]
\end{corollary}

\subsubsection{Approximate spectrum and Weyl sequences}
\begin{definition}
The set of all $\lambda$ such that $T-\lambda \id_V$ is not bounded from below is called the \udef{approximate point spectrum} $\apspec$.

If $\lambda\in\apspec(T)$, then $\lambda$ is an \udef{approximate eigenvalue} of $T$.
\end{definition}

\begin{proposition} \label{approximateSpectrum}
Let $T$ be an operator. Then
\begin{enumerate}
\item $\apspec(T) \subset \spec(T)$;
\item if $T$ is closed, then $\pspec(T)\cup\cspec(T)\subset\apspec(T)$.
\end{enumerate}
\end{proposition}
\begin{proof}
(1) Assume $\lambda \notin \spec(T)$. Then $(T-\lambda \id_V)^{-1}$ is bounded, so its inverse $T-\lambda \id_V$ is bounded below by \ref{boundedBelow} and $\lambda\in \apspec(T)$.

(2) Assume $\lambda\notin \apspec(T)$, 
so $T-\lambda \id_V$ is bounded below. Then $T-\lambda \id_V$ is injective by \ref{boundedBelow} and $\lambda\notin\pspec(T)$. By proposition \ref{boundedBelowClosedRange} the range $\im(T-\lambda \id_V)$ is closed, so it cannot be a proper dense subset of $X$ and $\lambda\notin\cspec(T)$.
\end{proof}

\begin{proposition}[Weyl sequences] \label{WeylSequence}
Let $T$ be an operator on a normed vector space $V$. Then $\lambda \in \apspec(T)$ \textup{if and only if} there exists a sequence of unit vectors $(e_n)_{n\in\N}$ for which
\[ \lim_{n\to\infty}\norm{\lambda e_n - Te_n} = 0. \]
\end{proposition}
\begin{proof}
Assume there is such a sequence $(e_n)_{n\in\N}$. Then for all $\epsilon>0$, we can find a unit  vector $e_k$ such that $\norm{(\lambda \id_V - T)e_n} \leq \epsilon = \epsilon \norm{e_n}$. This is clearly not bounded below.

This other direction is just an inversion of this argument.
\end{proof}
A sequence as described in \ref{WeylSequence} is called a \udef{Weyl sequence} for $\lambda$. This gives meaning to the name ``approximate eigenvalue''.

\begin{corollary}
Let $T$ be an operator. Then $\sigma(T)\cap \overline{\res(T)} \subseteq \apspec(T)$.
\end{corollary}
\begin{proof}
Let $\lambda \in \sigma(T)\cap \overline{\res(T)}$. We show there is a Weyl sequence for $\lambda$.

We can find a sequence $\seq{\lambda_n}\subseteq \res(T)$ such that $\lambda_n \to \lambda$.
Now $d(\lambda_n, \spec(T)) \to 0$, so by \ref{resolventNormDistanceToSpectrum}, we can find a sequence of unit vectors $\seq{x_n}$ such that $\norm{R_T(\lambda_n)x_n} \to \infty$. Now we can rescale $\seq{x_n}$ such that $\norm{R_T(\lambda_n)x_n} = 1$.

Then $\norm{x_n}\to 0$, and hence
\begin{align*}
\norm{(\lambda\id - T)R_T(\lambda_n)x_n} &= \norm{\frac{\lambda\id - T}{\lambda_n\id - T}x_n} \\
&= \norm{\frac{(\lambda\id - T) + (\lambda_n\id - T) - (\lambda_n\id - T)}{\lambda_n\id - T}x_n} \\
&= \norm{\left(\id + \frac{(\lambda\id - T) - (\lambda_n\id - T)}{\lambda_n\id - T}\right)x_n} \\
&= \norm{\left(\id + \frac{\lambda\id - \lambda_n\id}{\lambda_n\id - T}\right)x_n} \\
&= \norm{x_n + (\lambda\id - \lambda_n\id)R_T(\lambda_n)x_n} \\
&\leq \norm{x_n} + |\lambda - \lambda_n|\;\norm{R_T(\lambda_n)x_n} \to 0.
\end{align*}
Thus $\seq{R_T(\lambda_n)x_n}$ is the kind of sequence we were looking for.
\end{proof}




\subsubsection{Compression spectrum}
\begin{definition}
The set of $\lambda$ for which $T-\lambda I$ does not have dense range is the \udef{compression spectrum} $\cpspec(T)$ of $T$.
\end{definition}
Then $\rspec(T) = \cpspec(T)\setminus\pspec(T)$.

\subsubsection{The essential spectrum}
TODO \url{https://en.wikipedia.org/wiki/Spectrum_(functional_analysis)#Classification_of_points_in_the_spectrum}


\subsection{The spectral radius}
\begin{definition}
The \udef{spectral radius} $\spr(T)$ of a operator $T$ is given by
\[ \spr(T) \defeq \sup_{\lambda\in\spec(T)}|\lambda|. \]
\end{definition}


\section{Spectral theory for types of operators}
\subsection{Compact operators}

\begin{proposition} \label{pointSpectrumCompactOperatorBanachSpace}
Let $K$ be a compact operator on a Banach space. Then
\[ \spec(K)\setminus\{0\} = \pspec(K)\setminus\{0\}. \]
\end{proposition}
\begin{proof}
For all $\lambda\neq 0$, we have that $\lambda\id - K$ is Fredholm with index zero (and thus bounded). Then by the Fredholm alternative \ref{FredholmAlternative} $\lambda\id - K$ is either bijective or neither injective nor surjective, meaning $\lambda$ is either in $\rho(T)$ or in $\pspec(T)$.
\end{proof}

\begin{proposition} \label{spectrumCompactOperator}
Let $K$ be a compact operator on a Banach space $X$. Then
\begin{enumerate}
\item for all $\lambda\in\spec(K)\setminus\{0\}$ there exists a least $m$ such that $\ker(\lambda\id- K)^m = \ker(\lambda\id- K)^{m+1}$. This space is finite dimensional and reducing for $K$;
\item for $\alpha > 0$ the number of eigenvalues $\lambda$ such that $|\lambda|\geq \alpha$ is finite;
\item $0$ is the only accumulation point; if $X$ is infinite dimensional, then $0\in\spec(K)$;
\item $\spec(K)$ is at most countably infinite;
\item every $\lambda \in \spec(K)\setminus \{0\}$ is a pole of the resolvent $R_K$.
\end{enumerate}
\end{proposition}
\begin{proof}
\url{https://en.wikipedia.org/wiki/Spectral_theory_of_compact_operators}
\end{proof}



\subsection{Multiplication operators}
\begin{definition}
Let $(\Omega, \mathcal{A}, \mu)$ be a measure space. A \udef{multiplication operator} is an operator of the form
\[ T: L^p(\Omega, \mu) \to L^p(\Omega, \mu): u(x) \mapsto a(x)u(x) \]
for some $a\in L^\infty(\Omega,\mu)$
\end{definition}

\begin{proposition}
Let $T: L^p(\Omega, \mu) \to L^p(\Omega, \mu): u \mapsto a\cdot u$ be a multiplication operator. Then
\[ \norm{T} = \norm{a}_{L^\infty}. \]
\end{proposition}
\begin{proof}
From the inequality $\norm{Tu}_{L^p}\leq \norm{a}_{L^\infty}\norm{u}_{L^p}$ we get $\norm{T} \leq \norm{a}_{L^\infty}$.

TODO
\end{proof}

\begin{lemma}
Let $T: L^2(\Omega, \mu) \to L^2(\Omega, \mu): u \mapsto a\cdot u$ be a multiplication operator with $a\in L^\infty(\Omega,\mu)$. Then $T^*$ is the multiplication operator
\[ T^*: L^2(\Omega, \mu) \to L^2(\Omega, \mu): u \mapsto \overline{a}\cdot u. \]
\end{lemma}
\begin{proof}
From 
\[ \inner{Tu,v} = \int_\Omega a\cdot u \cdot \overline{v}\diff{\mu} = \int_\Omega u \cdot \overline{\overline{a}\cdot v}\diff{\mu} \]
it follows that $T^*v = \overline{a}\cdot v$.
\end{proof}
\begin{corollary}
Then
\begin{enumerate}
\item $T$ is self-adjoint if $a$ is real-valued;
\item $T$ is skew-adjoint if $a$ is purely imaginary;
\item $T$ is unitary if $|a(x)| \equiv 1$.
\end{enumerate}
\end{corollary}

Let $E_\lambda$ be the level set
\[ E_\lambda = \setbuilder{x\in\Omega}{a(x) = \lambda} \]

\begin{proposition}
Let $T: L^2(\Omega, \mu) \to L^2(\Omega, \mu): u\mapsto a\cdot u$ be a multiplication operator with $a\in \cont(\Omega)$. Then
\begin{enumerate}
\item $\pspec(T) = \setbuilder{\lambda\in \im(a)}{\mu(E_\lambda)>0}$;
\item $\cspec(T) = \setbuilder{\lambda\in \overline{\im(a)}}{\mu(E_\lambda) = 0}$;
\item $\rspec(T) = \emptyset$;
\item $\rho(T) = \C\setminus \overline{\im(T)}$.
\end{enumerate}
\end{proposition}
\begin{proof}
TODO
\end{proof}

\subsection{Dissipative operators}
\begin{definition}
Let $T\in \Lin(V, W)$ be a linear operator between Banach spaces. Then $T$ is called \udef{dissipative} if $\lambda\id-T$ is bounded below by $\lambda$ for all $\lambda>0$:
\[ \norm{(\lambda\id-T)x} \geq \lambda\norm{x} \]
for all $x\in\dom(T)$.
\end{definition}

\begin{lemma} \label{dissipativeResolventBound}
Let $T\in \Lin(V, W)$ be an operator between Banach spaces. Then $T$ is dissipative \textup{if and only if} for all $\lambda>0$ the resolvent $R_T(\lambda): \im(T)\to V$ exists and is bounded by $\norm{R_T(\lambda)} \leq \lambda^{-1}$.
\end{lemma}
\begin{proof}
If $T$ is dissipative, then the result is given by \ref{boundedBelow}.

Assume $R_T(\lambda): \im(T)\to V$ exists. Then
\[ \lambda\norm{x} = \lambda\norm{R_T(\lambda)(\lambda\id-T)x} \leq \lambda \norm{R_T(\lambda)}\,\norm{(\lambda\id-T)x} \leq \lambda\lambda^{-1}\norm{(\lambda\id-T)x} = \norm{(\lambda\id-T)x}. \]
\end{proof}

Thus $\lambda>0$ is in $\res(T)$ if and only if $\lambda\id - T$ is surjective.


\begin{proposition} \label{spectrumDissipativeOperator}
Let $T\in \Lin(V, W)$ be a dissipative operator between Banach spaces. Then either $]0,+\infty[\,\perp \res(T)$ or $]0,+\infty[\,\subseteq \res(T)$.
\end{proposition}
\begin{proof}
By \ref{dissipativeResolventBound}, it is enough to show that if $\lambda\in\res(T)$ for some $\lambda >0$, then $\lambda\id - T$ is surjective for all $\lambda>0$.

Assume $\lambda\in\res(T)$ for some $\lambda >0$. Then \ref{dissipativeResolventBound} and \ref{firstNeumannSeries} combine the give $]0, 2\lambda[ \subseteq \res(T)$. We can repeat this to cover the whole of $]0,+\infty[$.
\end{proof}
\begin{corollary} \label{rangeDisjunctionDissipativeOperator}
Either
\begin{enumerate}
\item $\lambda\id-T$ is surjective for no $\lambda > 0$; or
\item $\lambda\id-T$ is surjective for all $\lambda > 0$.
\end{enumerate}
\end{corollary}

\begin{proposition} \label{closureDissipativeOperator}
Let $T\in \Lin(V, W)$ be a dissipative operator between Banach spaces. Then the following are equivalent:
\begin{enumerate}
\item $T$ is closed;
\item $\im(\lambda\id - T)$ is closed for some $\lambda > 0$;
\item $\im(\lambda\id - T)$ is closed for all $\lambda > 0$.
\end{enumerate}
\end{proposition}
\begin{proof}
For all $\lambda\in\R$, we have that $T$ is closed iff $\lambda\id - T$ is closed iff $(\lambda\id - T)^{-1}: \im(\lambda\id - T) \to V$ is closed by \ref{algebraClosedOperators}.

Now closedness of $\lambda\id - T$ implies $\im(\lambda\id - T)$ is closed by \ref{boundedBelowClosedRange}. Conversely, if $\im(\lambda\id - T)$ is closed, then $\lambda\id - T$ is closed by the closed graph theorem \ref{closedGraphTheorem}.
\end{proof}

\begin{proposition} \label{dissipativeOperatorClosable}
Let $T\in \Lin(V)$ be a dissipative operator on a Banach space $V$. If $\im(T)\subseteq \overline{\dom(T)}$, then
\begin{enumerate}
\item $T$ is closable;
\item its closure $\overline{T}$ is dissipative;
\item $\im(\lambda\id - \overline{T}) = \overline{\im(\lambda\id - T)}$ for all $\lambda >0$.
\end{enumerate}
\end{proposition}
In particular $\im(T)\subseteq \overline{\dom(T)}$ holds whenever $T$ is densely defined.
\begin{proof}
(1) We use \ref{closableCriterion}. Assume $\seq{x_n}\to 0$ and $\seq{Tx_n}\to v$. We need to show that $v=0$. Because $T$ is dissipative, we have
\[ \norm{\lambda(\lambda\id-T)x_n + (\lambda\id-T)w} = \norm{(\lambda\id-T)(\lambda x_n -w)} \geq \lambda\norm{\lambda x_n + w} \]
for all $w\in \in\dom(T)$ and all $\lambda>0$. Taking the limit $n\to \infty$ gives
\[ \norm{-\lambda v +(\lambda\id- T)w} \geq \lambda\norm{w}, \qquad\text{and hence}\qquad \norm{w - v - \frac{1}{\lambda}Tw} \geq w. \]
Taking the limit $\lambda \to \infty$ gives $\norm{w-v}\geq \norm{w}$. Now $y\in \overline{\im(T)} \subseteq \overline{\dom(T)}$. Thus we can find a sequence $\seq{w_n}\to y$ in $\dom(T)$. This sequence then satisfies $\norm{w_n-y} \geq \norm{w_n}$. Taking the limit gives $0\geq \norm{y}$, so $y = 0$.

(2) For all $x\in\dom(\overline{T})$ there exists a sequence $\seq{x_n}\to x$ in $\dom(T)$ such that $\seq{Tx_n} \to \overline{T}x$ by \ref{graphNormConvergenceLemma}. Now for all $n\in \N$,
\[ \norm{(\lambda\id-T)x_n} \geq \lambda\norm{x_n}. \]
Taking the limit $n\to\infty$ gives $\norm{(\lambda\id-\overline{T})x} \geq \lambda\norm{x}$, meaning $\overline{T}$ is dissipative.

(3) By \ref{domImClosureOperator}, $\im(\lambda\id - T)$ is dense in $\im(\lambda\id-\overline{T})$ and by \ref{closureDissipativeOperator}, $\im(\lambda\id-\overline{T})$ is closed.
\end{proof}

\begin{proposition}
Let $T\in\Lin(V,W)$ be an operator between Banach spaces. Then $T$ is dissipative \textup{if and only if} for all $x\in V$, there exists an $x'\in \mathfrak{d}(x)$ such that
\[ \Re\pair{x', Tx} \leq 0. \]
\end{proposition}
\begin{proof}
$\boxed{\Leftarrow}$ Take $x\in V$ and fix some $x'\in \mathfrak{d}(x)$ for which the inequality holds. By definition of the duality set, we have $\norm{x}^2 = x'(x) = \norm{x'}^2$. To verify dissipativity, we calculate
\begin{align*}
\norm{(\lambda\id-T)x}\,\norm{x'} &\geq |x'\big((\lambda\id-T)x\big)| \\
&\geq \Re x'\big((\lambda\id-T)x\big) = \Re x'(\lambda x) - \Re x'(Tx) \\
&\geq \lambda \Re x'(x) = \lambda \norm{x}^2.
\end{align*}
Noting $\norm{x'} = \norm{x}$ and dividing both sides by $\norm{x}$ yields dissipativity.

$\boxed{\Rightarrow}$ TODO
\end{proof}

\section{The spectral theorem}
\url{https://link.springer.com/content/pdf/10.1007%2F978-1-4614-7116-5.pdf}

\url{http://individual.utoronto.ca/jordanbell/notes/SVD.pdf}
\url{https://digitalcommons.mtu.edu/cgi/viewcontent.cgi?article=2133&context=etdr}

\url{https://web.ma.utexas.edu/mp_arc/c/09/09-32.pdf}


\section{Functional calculus}
\subsection{Holomorphic functional calculus}

\begin{theorem}[Holomorphic functional calculus] 
\label{holomorphicFunctionalCalculus} \label{holomorphicSpectralMapping}
Let $A$ be a Banach algebra and $x\in A$. Consider the function
\[ \Phi_x: \cont^\infty(\spec(x),\C) \to A: f\mapsto f(x)\defeq \oint_\Gamma f(z)R_x(z)\diff{z}. \]
Here $\Gamma$ is any simple Jordan curve that contains $\spec(x)$ such that $f$ is holomorphic in a region that contains $\Gamma$ and its interior. Then
\begin{enumerate}
\item $\Phi_x$ is well-defined: it does not depend on the particular curve $\Gamma$;
\item $\Phi_x$ is a homomorphism;
\item for any polynomial $p\in \C[X]$, we have $\Phi_x(p) = p(x)$; \\
in particular $\Phi_x(\id_\C) = x$ and $\Phi_x(\underline{1}) = \id_A$;
\item $\spec(\Phi_x(f)) = f[\spec(x)]$;
\item $\Phi_x$ is continuous if $\cont^\infty(\spec(x),\C)$ is equipped with continuous convergence (?).
\end{enumerate}
\end{theorem}
TODO: $\cont^\infty(\spec(x))$ should be the space of functions that are analytic in some neighbourhood of $\spec(x)$. Is it??
\begin{proof}
TODO
\end{proof}

TODO unbounded operators

\subsubsection{Riesz eigenprojections}
Holomorphic functional calculus applied to
\[ \chi_{S,\delta}: A\to \{0,1\}: x\mapsto \begin{cases}
1 & d(x,S) \leq \delta \\
0 & \text{otherwise}.
\end{cases} \]

TODO: spectral measure with only disconnected parts in $\sigma$-algebra??

TODO: $P_\Delta$ and $E_\Delta \defeq \im P_\Delta$.

\begin{lemma}
$\spec(T|_{E_\Delta}) = \spec(T)\cap\Delta$.
\end{lemma}

\begin{definition}
We call $\dim E_\lambda$ the \udef{algebraic multiplicity} of $\lambda$.
\end{definition}

\subsubsection{Frobenius covariants}
TODO $P_\lambda$ is a Frobenius covariant. \url{https://en.wikipedia.org/wiki/Frobenius_covariant}

TODO cfr. Lagrange polynomial??

\section{Jordan decomposition}
\subsection{Eigennilpotent}
\begin{definition}
Let $a$ be a finite element in a semisimple Banach algebra and $\lambda\in \spec(a)$. The \udef{eigennilpotent operator} of $a$ at $\lambda$ is defined as
\[ D_{\lambda} \defeq (a-\lambda)P_{\lambda}. \]
\end{definition}
This definition works because we can find a $\delta < d(\lambda, \spec(a)\setminus\{\lambda\})$.

\begin{lemma}
Let $a$ be a finite element in a semisimple Banach algebra and $\lambda\in \spec(a)$. The eigennilpotent operator $D_\lambda$ is nilpotent.
\end{lemma}
\begin{proof}
By spectral mapping \ref{holomorphicSpectralMapping}, $D_\lambda$ is quasinilpotent. Because $a$ is finite, it is nilpotent by \ref{nilpotentQuasinilpotent}.
\end{proof}



\subsection{Jordan vectors}
\begin{definition}
Let $V$ be a finite dimensional vector space and $T$ an operator on $V$. A \udef{Jordan vector} of $T$ belonging to the eigenvalue $\lambda$ is a vector $x\in V$ such that
\[ (\lambda\id_V - T)^kx = 0 \]
for some $k\in \N$. The least such $k$ is called the \udef{degree} of $x$ and is denoted $\deg_J(x)$.
\end{definition}
Eigenvectors are Jordan vectors of degree $1$.

\begin{proposition}
Let $V$ be a finite dimensional vector space, $T$ an operator on $V$ $\lambda\in\spec(T)$ and $x\in V$. Then $x$ is a Jordan vector of $T$ belonging to the eigenvalue $\lambda$ \textup{if and only if} $x\in E_\lambda$.
\end{proposition}
\begin{proof}
Let $x\in E_\lambda$. Then $x = P_\lambda x$ and thus
\[ (\lambda\id_V - T)^kx = (\lambda\id_V - T)^kP_\lambda x = \big((\lambda\id_V - T)P_\lambda\big)^k x = D_\lambda^k x, \]
which is zero for some $k$ because $D_\lambda$ is nilpotent.

Conversely, assume $x$ is a Jordan vector of $T$ belonging to the eigenvalue $\lambda$. We can write $x = x_1+x_2 \in E_{\lambda}\oplus E_{\C\setminus\{\lambda\}}$.
Then (because $E_\lambda$ is reducing for $T-\lambda\id_V$)
\[ 0 = (\lambda\id_V - T)^kx = (\lambda\id_V - T)^kx_1 + (\lambda\id_V - T)^kx_2 \in E_{\lambda}\oplus E_{\C\setminus\{\lambda\}} \]
Thus we have $(\lambda\id_V - T)^kx_1 = 0$ and $(\lambda\id_V - T)^kx_2 = 0$ separately.
Now $T-\lambda\id_V$ is invertible on $E_{\C\setminus\{\lambda\}}$, so $x_2 = 0$ (TODO ref). This means that $x = x_1 \in E_\lambda$.
\end{proof}

\begin{definition}
Let $m = \deg_N(D_\lambda)$. Then we have
\[ \{0\} \subsetneq \ker(\lambda\id_V - T) \subsetneq \ker(\lambda\id_V - T)^2 \subsetneq \ldots \subsetneq \ker(\lambda\id_V - T)^{m-1} \subsetneq \ker(\lambda\id_V - T)^m = V. \]
We define $E^k_\lambda \defeq \ker(\lambda\id_V - T)^k$. In particular
\begin{itemize}
\item $E^1_\lambda$ is the \udef{geometric eigenspace};
\item $E^{m-1}_\lambda$ is the \udef{algebraic eigenspace}.
\end{itemize}
\end{definition}

\begin{lemma}
Let $V$ be a finite dimensional vector space, $T$ an operator on $V$, $\lambda\in\spec(T)$ and $x\in E_\lambda$. Then
\begin{enumerate}
\item $1 \leq \dim\ker(\lambda\id_V - T) \leq \dim E_\lambda$;
\item $1 \leq \deg_J(x) \leq \dim_E\lambda$.
\end{enumerate}
\end{lemma}
The lemma says the geometric multiplicity is smaller than the algebraic multiplicity.
\begin{proof}
Every eigenvector is a Jordan vector, so $\ker(\lambda\id_V - T) \subseteq E_\lambda$.

For all $k\in\N$ smaller then the degree of $x$, $(\lambda\id_V - T)^kx$ is a Jordan vector and thus in $E_\lambda$. TODO all $(\lambda\id_V - T)^kx$ are linearly independent (like in \ref{nilpotentQuasinilpotent})
\end{proof}

\begin{definition}
Let $V$ be a finite dimensional vector space, $T$ an operator on $V$ and $\lambda\in\spec(T)$. The eigenvalue $\lambda$ is called
\begin{itemize}
    \item \udef{simple} if the algebraic multiplicity is $1$;
    \item \udef{semisimple} if every Jordan vector in $E_\lambda$ has degree $1$;
    \item \udef{prime} if the geometric multiplicity is $1$.
\end{itemize}
If all eigenvalues of $T$ are semisimple, then $T$ is called a \udef{diagonal operator}.
\end{definition}

\begin{lemma}
An operator $T$ is diagonal iff $T$ is of the form $\sum_j a_jP_j$, where $a_j\in \F$ and $P_j$ are projectors that commute pairwise.
\end{lemma}

\subsection{Characteristic polynomial and equation}
\begin{definition}
Let $V$ be a finite dimensional vector space and $T$ an operator on $V$. The \udef{characteristic polynomial} $p_T(x)$ of $T$ is the polynomial
\[ p_T(x) \defeq \det(x\id_V - T). \]
\end{definition}

\begin{proposition}
Let $V$ be a finite dimensional vector space, $T$ an operator on $V$ and $\spec(T) = \{\lambda_j\}_{j=1}^r$. Then
\[ p_T(x) = \prod_{j=1}^r(x - \lambda_j)^{\dim E_{\lambda_j}}. \]
\end{proposition}
\begin{proof}
TODO
\end{proof}
\begin{corollary}
A number $\lambda\in \C$ is an eigenvalue of $T$ \textup{if and only if} it is a root of $p_T(x)$.
\end{corollary}

\begin{definition}
The equation $p_T(x) = 0$ is the \udef{characteristic equation} of $T$.
\end{definition}

\subsection{Spectral representation}
\begin{proposition}
Let $V$ be a finite dimensional complex vector space and $T$ an operator on $V$. There exists a unique decomposition $T = S + D$ such that
\begin{itemize}
\item $S$ is diagonal;
\item $D$ is nilpotent;
\item $SD = DS$.
\end{itemize}
If $\spec(T) = \{\lambda_j\}_{j=1}^r$, this decomposition is given by
\[ T = \sum_{j=1}^r \lambda_r P_{\lambda_r} + \sum_{j=1}^r D_{\lambda_r}. \]
\end{proposition}

\subsection{Partial fraction decomposition of the resolvent}
For any operator $T$ on a vector space $V$ with eigenvalue $\lambda_0$, the resolvent $R_T(\lambda)$ has a pole at $\lambda_0$.

\begin{proposition}
Let $T$ be an operator on a finite dimensional vector space $V$ and $\lambda_0\in\spec(T)$. Then the Laurent expansion of $R_T(\lambda)$ around $\lambda_0$ is of the form
\[ R_T(\lambda) = \frac{P_0}{\lambda-\lambda_0} + \sum_{n=1}^{\deg_N(D_0)-1}\frac{D_0^{n}}{(\lambda - \lambda_0)^{n+1}} + \sum_{n=0}^\infty(-1)^n S_0^{n+1}(\lambda - \lambda_0)^n, \]
where $P_0\defeq P_{\lambda_0}, D_0\defeq D_{\lambda_0}$ and $S_0$ is some fixed operator.
\end{proposition}
\begin{proof}
TODO
\end{proof}

\begin{definition}
The holomorphic part of the Laurent expansion of $R_T(\lambda)$ at $\lambda_0$ is called the \udef{reduced resolvent} of $T$ w.r.t. $\lambda_0$:
\[ S_{T,\lambda_0}(\lambda) \defeq \sum_{n=0}^\infty(-1)^n S_0^{n+1}(\lambda - \lambda_0)^n = R_T(\lambda) - \left(\frac{P_0}{\lambda-\lambda_0} + \sum_{n=1}^{\deg_N(D_0)-1}\frac{D_0^{n}}{(\lambda - \lambda_0)^{n+1}}\right). \]
\end{definition}

\begin{proposition}
Let $T$ be an operator on a finite dimensional vector space $V$ and $\lambda_0\in\spec(T)$. Then
\[ R_{T|_{(\id_V-P_0)}}(\lambda) = S_{T,\lambda_0}|_{\id_V-P_0}(\lambda). \]
\end{proposition}

\begin{proposition}
Let $T$ be an operator on a finite dimensional vector space $V$ with $\spec(T) = \{\lambda_j\}_{j=1}^r$. The partial fraction decomposition of $R_T(\lambda)$ is given by
\[ R_T(\lambda) = \sum_{j=1}^r\left(\frac{P_{\lambda_j}}{\lambda - \lambda_j} +\sum_{n=1}^{\deg_N(D_{\lambda_j})-1}\frac{D_{\lambda_j}^n}{(\lambda - \lambda_j)^{n+1}}\right). \]
The partial fraction decomposition of $S_{T,\lambda_k}(\lambda)$ is given by
\[ S_{T,\lambda_k}(\lambda) = \sum_{\substack{j=1 \\ j\neq k}}^r\left(\frac{P_{\lambda_j}}{\lambda - \lambda_j} +\sum_{n=1}^{\deg_N(D_{\lambda_j})-1}\frac{D_{\lambda_j}^n}{(\lambda - \lambda_j)^{n+1}}\right). \]
\end{proposition}
\begin{proof}
The poles of $R_T(\lambda)$ are exactly the eigenvalues of $T$. There are finitely many of them, so we can use partial fraction decomposition, \ref{partialFractionDecomposition}. We just need to show that the holomorphic part is zero. For that we note that $\lim_{\lambda \to \infty} R_T(\lambda) = 0$ and all principal parts tend to $0$ at infinity as well. Thus the holomorphic part also tends to $0$, making it bounded. By Liouville's theorem, \ref{liouvilleTheoremAnalysis}, we get that it is identically zero.
\end{proof}
\begin{corollary}[Sylvester-Lagrange formula]
Let $f$ be a holomorphic function on an open set that contains $\spec(T)$. Then
\[ f(T) = \sum_{j=1}^r\left(f(\lambda_j)P_{\lambda_j} +\sum_{n=1}^{\deg_N(D_{\lambda_j})-1}\frac{f^{(n)}(\lambda_j)D_{\lambda_j}^n}{n!}\right). \] 
\end{corollary}
\begin{proof}
We have
\[ f(T) = \oint_\Gamma f(\lambda)R_T(\lambda)\diff{\lambda} = 2\pi i\sum_{j=1}^r \Res_{\lambda_j}f(\lambda)R_T(\lambda) \]
by the residue theorem (TODO ref for operators).
\end{proof}
\begin{corollary}[Cayley-Hamilton]
Let $p_T(x)$ be the characteristic polynomial of $T$. Then $p_T(T) = 0$.
\end{corollary}
\begin{proof}
Since $p_T(x) = \prod_{j=1}^r(x - \lambda_j)^{\dim E_{\lambda_j}}$ and $\dim E_{\lambda_j} \geq \deg_N(D_{\lambda_j})$, we see that $p_T(\lambda)R_T(\lambda)$ has no poles and is holomorphic, meaning that $oint_\Gamma f(\lambda)R_T(\lambda)\diff{\lambda} = 0$ by Cauchy's theorem (TODO ref for operators).
\end{proof}

\subsection{Normal operators}


\begin{proposition}
If $T$ is a normal operator, then $P_\lambda = P^*_\lambda$ and $D_\lambda = D^*_\lambda = 0$.
\end{proposition}
This means normal operators are diagonalisable.
\begin{proof}
TODO
\end{proof}
\begin{corollary}
Let $V$ be a finite dimensional complex vector space and $T$ a normal operator
on $V$ with $\spec(T) = \{\lambda_j\}_{j=1}^r$.
\begin{enumerate}
\item We have the spectral decompositions
\[ T = \sum_{j=1}^r \lambda_r P_{\lambda_r} \qquad\text{and}\qquad T^* = \sum_{j=1}^r \overline{\lambda_r} P_{\lambda_r}. \]
\item We have
\[ R_T(\lambda) = \sum_{j = 1}^r \frac{P_{\lambda_j}}{\lambda - \lambda_j} \qquad \text{and} \qquad S_{T,\lambda_k}(\lambda) = \sum_{\substack{j = 1 \\ j\neq k}}^r \frac{P_{\lambda_j}}{\lambda - \lambda_j} \]
\end{enumerate}
\end{corollary}

\subsection{Jordan decomposition}
TODO matrix representation + matrix representation of Lagrange-Sylvester. See BaumgÃ¤rtel