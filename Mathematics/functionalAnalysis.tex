\chapter{Vector space convergence}

TODO: \url{https://math.stackexchange.com/questions/2001771/existence-of-at-least-one-continuous-coordinate-functional}

\url{https://math.stackexchange.com/questions/60057/does-there-exist-a-linearly-independent-and-dense-subset}

\section{Vector space convergence}
\begin{definition}
Let $\sSet{\F,V,+}$ be a vector space and $\xi$ a convergence on $V$. Then $\sSet{\F,V,+, \xi}$ is a \udef{convergence vector space} (or CVS) if
\begin{itemize}
\item vector addition $+: V\times V \to V$ is continuous;
\item scalar multiplication $\cdot: \F\times V \to V$ is continuous.
\end{itemize}
\end{definition}

\begin{lemma}
If $\sSet{\F,V,+, \xi}$ is a convergence vector space, then $\sSet{V,+, 0, \xi}$ is a convergence group.
\end{lemma}
\begin{proof}
We just need to show that $v\mapsto -v$ is continuous, but this scalar multiplication and thus continuous by assumption.
\end{proof}

\begin{lemma} \label{continuityLemmaVectorConvergence}
If $\sSet{\F,V,+, \xi}$ is a convergence vector space, then
\begin{enumerate}
\item the function $V \to V: v \mapsto \lambda\cdot v$ is a homeomorphism for all $\lambda\in \F\setminus\{0\}$;
\item the function $\F \to \Span\{v\}: \lambda \mapsto \lambda\cdot v$ is continuous and invertible for all $v\in V\setminus\{0\}$. It is a homeomorphism \textup{if and only if} $\Span\{v\}$ is Hausdorff.
\end{enumerate}
\end{lemma}
TODO picture!
\begin{proof}
The functions $\lambda \mapsto (\lambda, v)$ and $v \mapsto (\lambda, v)$ are continuous by \ref{continuousEmbeddingProduct}. Composition with the continuous scalar product gives the result by continuity of composition (\ref{continuityComposition}).

They are both clearly invertible (for the second, note that the kernel is $\{0\}$). The inverse of the first is of the same form and thus immediately continuous.

If $u: \F \to \Span\{v\}: \lambda \mapsto \lambda\cdot v$ is a homeomorphism, then $\Span\{v\}$ is Hausdorff, because $\F$ is.

Now assume $\Span\{v\}$ Hausdorff. We need to show that $u^{-1}$ is continuous. It is enough to show continuity at $0$. We use \ref{pretopologicalContinuityVicinities}, so take $\Gamma \in \vicinity_\F(0)$ and we need to show that $\Gamma \in (u^{-1})^{\imf\imf}\big[\vicinity_{\Span\{v\}}(0)\big]$. WLOG we may take $\Gamma = \ball(0, \epsilon)$.

Now consider $\sphere(0,\epsilon)$, which is compact. Then $u^{\imf}\big(\sphere(0,\epsilon)\big) = \sphere(0,\epsilon)\cdot v$ is compact by \ref{compactConstructions} and thus closed by \ref{compactClosedSets} (as $\Span\{v\}$ we assumed Hausdorff). Now $0 \in \big(\sphere(0,\epsilon)\cdot v\big)^c$, so there exists a vicinity $U$ of $0$ disjoint from $\sphere(0,\epsilon)\cdot v$.

For each $F$ that converges to $0$ in $\Span\{v\}$, $\neighbourhood_\F(0)\cdot F$ also converges to $0$, so there exists $\delta_F>0$ and $C_F\in F$ such that $\ball(0, \delta_F)\cdot C_F \subseteq U$. If $\delta_F > 1$, then $C_F \subseteq \ball(0, \delta_F)\cdot C_F \subseteq \ball(0,\epsilon)\cdot v$, so $\ball(0,\epsilon)\cdot v\in F$.

Now assume $\delta_F \leq 1$. Then $\cball(0, \epsilon\cdot\delta_F^{-1})\setminus \ball(0,\epsilon)$ is compact, which, as before, means $\big(\cball(0, \epsilon\cdot\delta_F^{-1})\setminus \ball(0,\epsilon)\big)\cdot v$ is closed and we take a vicinity $U_F$ of $0$ disjoint from it. Now $C_F\cap U_F\in F$. We also claim that $C_F\cap U_F\subseteq \ball(0,\epsilon)\cdot v$: take $x\in C_F\cap U_F$. Then $x = \lambda v$ and $\delta_F |\lambda| \leq \epsilon$ (as $\ball(0, \delta_F)\cdot C_F \subseteq U$), which is equivalent to $|\lambda| \leq \epsilon\cdot\delta_F^{-1}$. Now because $x\in U_F$, this means $|\lambda| < \epsilon$ and thus $x\in \ball(0,\epsilon)\cdot v$.

As $\ball(0,\epsilon)\cdot v \in F$ for all $F$ that converge to $0$, we have $\ball(0,\epsilon)\cdot v\in \vicinity_{\Span\{v\}}$, so $\ball(0,\epsilon) = \Gamma \in (u^{-1})^{\imf\imf}\big[\vicinity_{\Span\{v\}}(0)\big]$, which is what we had to prove.
\end{proof}

Alternate proof in Beattie / Butzmann.

\begin{proposition} \label{vectorSpaceConvergenceConstruction}
Let $V$ be a vector space over a field $\F$. And $\mathcal{F} \subseteq \powerfilters(V)$ a family of filters. There exists a vector space convergence $\xi$ on $V$ such that $\mathcal{F} = \lim^{-1}_\xi(0)$ \textup{if and only if}
\begin{enumerate}
\item if $F \in \mathcal{F}$ and $G\supseteq F$, then $G\in \mathcal{F}$;
\item if $F,G \in \mathcal{F}$, then $F + G\in \mathcal{F}$;
\item if $F\in \mathcal{F}$, then $\neighbourhood_\F(0)\cdot F \in \mathcal{F}$;
\item if $v\in V$, then $\neighbourhood_\F(0)\cdot v \in \mathcal{F}$;
\item if $F\in \mathcal{F}$ and $\lambda\in \F$, then $\lambda\cdot F \in \mathcal{F}$.
\end{enumerate}
\end{proposition}
Note the similarity with \ref{groupConvergenceConstruction} for convergence groups. A group convergence is completely determined by $\lim^{-1}_\xi(0)$ due to the translation homeomorphisms \ref{shiftHomeomorphism}.
\begin{proof}
Assume first that $\mathcal{F} = \lim^{-1}_\xi(0)$ for some vector space convergence $\xi$.
\begin{enumerate}
\item This is just the monotonicity of the convergence.
\item If $F,G\to 0$, then $F\otimes G \to (0,0)$ by \ref{convergenceFiniteProductFilter}. By continuity of addition we have $F+G\to 0$.
\item The convergence on the scalar field is pretopological, so $\neighbourhood_\F(0)\to 0$. By \ref{convergenceFiniteProductFilter} $\neighbourhood_\F(0)\otimes F \to (0,0)$ and by continuity of the scalar multiplication $\neighbourhood_\F(0)\cdot F \to 0$.
\item By \ref{continuityLemmaVectorConvergence}.
\item By \ref{continuityLemmaVectorConvergence}.
\end{enumerate}

Now assume the five points hold. Define the convergence $\xi$ by $F\to v$ iff $F-v \in \mathcal{F}$. We need to show that this is a convergence and that it makes both the vector addition and scalar multiplication continuous.

Monotonicity is guaranteed by (1). To show the convergence is centered, note that $\mathcal{F} \neq \emptyset$ by (4), so long as $V\neq \emptyset$. Then for any $F\in \mathcal{F}$, $\big\{\{0\}\big\} = 0\cdot F \in \mathcal{F}$ by (5).

To show that the vector addition is continuous, take $F\to (v_1, v_2)$. Then $p_1^{\imf\imf}(F) = F_1\to v_1$ and $p_2^{\imf\imf}(F) = F_2 \to v_2$, i.e.\ $F_1-v_1 \in \mathcal{F}$ and $F_2-v_2 \in \mathcal{F}$. By (1), $(F_1-v_1) + (F_2-v_2) = (F_1+F_2) - (v_1 + v_2) \in \mathcal{F}$, so $F_1+F_2 \to v_1 + v_2$. Thus by \ref{filterFactorisationInequality}, $F_1+F_2 = +^{\imf\imf}[F_1\otimes F_2] \subseteq +^{\imf\imf}[F] \to v_1+v_2$ and the addition is continuous.

Let $G \to (\lambda, v)$. Then $G_1 = p_1^{\imf\imf}(G) \to \lambda$ and $G_2 = p_2^{\imf\imf}(G) \to v$, so $G_1 \supseteq \neighbourhood_\F(\lambda)$. We have
\begin{align*}
\cdot^{\imf\imf}[G] - \lambda\cdot v &\supseteq \cdot^{\imf\imf}[G_1\otimes G_2] - \lambda\cdot v = G_1\cdot G_2 - \lambda\cdot v \\
&\supseteq \neighbourhood_\F(\lambda) \cdot G_2 - \lambda\cdot v \\
&= (\neighbourhood_\F(0) + \lambda)\cdot((G_2 - v) + v) - \lambda\cdot v \\
&\supseteq \lambda\cdot (G_2 - v) + \neighbourhood_\F(0)\cdot(G_2-v) + \lambda\cdot v + \neighbourhood_\F(0)\cdot v - \lambda\cdot v \\
&= \lambda\cdot (G_2 - v) + \neighbourhood_\F(0)\cdot(G_2-v) + \neighbourhood_\F(0)\cdot v \in \mathcal{F}.
\end{align*}
So $\cdot^{\imf\imf}[G] \to \lambda\cdot v$, making the scalar multiplication continuous. Note the last inclusion is not an equality because we go from one instance of $G_2$ and $\neighbourhood_\F(0)$ to two!
\end{proof}
\begin{corollary} \label{vicinityFilterAtOrigin}
Let $\sSet{V, \xi}$ be a convergence vector space. Then
\begin{enumerate}
\item for all $A\in \vicinity_\xi(0)$ and $\lambda\in \F\setminus\{0\}$: $\lambda A\in \vicinity_\xi(0)$;
\item each $A \in \vicinity_\xi(0)$ is absorbent;
\item if $\xi$ is topological, then $\vicinity_\xi(0)$ has a balanced base;
\item if $\xi$ is topological, then $\vicinity_\xi(0)$ has a closed, balanced base.
\end{enumerate}
\end{corollary}
\begin{proof}
Now assume $\xi$ is a topological vector space convergence and $N = \neighbourhood_\xi(0)$.
\begin{enumerate}
\item Take arbitrary $\lambda\in\F\setminus\{0\}$. Then $v\mapsto \lambda v$ is a homeomorphism by \ref{continuityLemmaVectorConvergence}, so $\lambda A \in \vicinity_\xi(\lambda 0) = \vicinity_\xi(0)$, by \ref{homeomorphismPreservation}.
\item For absorbence, take $A\in \vicinity_\xi(0)$ and $v\in V$. As $\neighbourhood_\F(0)\cdot v \to 0$, we must have $A\in \upset\neighbourhood_\F(0)\cdot v$, so there exists $\Gamma \in \neighbourhood_\F(0)$ such that $\Gamma\cdot v \subseteq A$. Now we can find a $r>0$ such that $\ball(0,r)\subseteq \Gamma$, so for all $|c|\geq r^{-1}$ we have $v\in cA$.
\item By point (3) of of the proposition, $\neighbourhood_\F(0)\cdot \vicinity_\xi(0)$ converges to $0$ and thus $\vicinity_\xi(0) \subseteq \neighbourhood_\F(0)\cdot\vicinity_\xi(0)$. Take $A\in \vicinity_\xi(0)$. Then there exists a $\Gamma\in\neighbourhood_\F(0)$ and $B\in \vicinity_\xi(0)$ such that $\Gamma\cdot B \subseteq \vicinity_\xi(0)$. We can find some ball $\ball(0,\epsilon) \subseteq \Gamma$, so $\ball(0,1)\cdot \epsilon B\subseteq \epsilon B \subseteq A$. Thus $\epsilon B$ is balanced and a neighbourhood by point(1). So every $A\in \vicinity_\xi(0)$ contains a balanced set in $\vicinity_\xi(0)$.
\item Take arbitrary $A\in \vicinity_\xi(0)$. By regularity, \ref{topologicalGroupsRegular}, $A$ contains a closed vicinity $B$. By (3), $B$ contains a balanced set $C$. Now consider $\closure_\xi(C)$, which is closed and a a subset of $B$ (as $\closure(C)\subseteq \closure(B) = B$). It is now enough to note that the closure of a balanced set is balanced: if $x$ is the limit of a filter $F$ in $B$, then $r\cdot x$ is the limit of $r\cdot F$ for all $|r|\leq 1$. Now $r\cdot F$ is a filter in $B$ by balance.
\end{enumerate}
\end{proof}

\begin{proposition} \label{vectorSumInherenceAdherence}
Let $\sSet{V,\xi}$ be a vector space convergence and $A,B\subseteq V$. Then
\begin{enumerate}
\item $\adh(A)+\adh(B) \subseteq \adh(A+B)$;
\item $\inh(A)+\inh(B) \subseteq A+\inh(B) \subseteq \inh(A+B)$;
\item $\interior(A)+\interior(B) \subseteq A+\interior(B) \subseteq \interior(A+B)$.
\end{enumerate}
\end{proposition}
TODO: same for closure?
\begin{proof}
(1) We use \ref{productAdherence} and \ref{adherenceInherenceContinuity} to compute
\[ \adh(A)+\adh(B) = +^\imf[\adh(A)\times\adh(B)] = +^\imf[\adh(A\times B)] \subseteq \adh(+^\imf[A\times B]) = \adh(A+B). \]

(2) The inclusion $\inh(A)+\inh(B) \subseteq A+\inh(B)$ is immediate. Now for all $v\in V$ we have $v+\inh(B) = \inh(v+B)$, so
\[ A+\inh(B) = \bigcup_{v\in A}v+\inh(B) = \bigcup_{v\in A}\inh(v+B) \subseteq \inh\left(\bigcup_{v\in A} v+B\right) = \inh(A+B), \]
where we have used the monotonicity of $\inh$ and \ref{orderPreservingFunctionLatticeOperations}.

(3) Similar to (2).
\end{proof}
Notice that the argument used for (2) and (3) does not work for the adherence because $\adh(A)+\adh(B) \nsubseteq A+\adh(B)$ in general.

\begin{lemma}
Let $V$ be a convergence vector space over a field $K$ and $F\subseteq K$ a subfield. Then the $F$-vector space $V_F$ with the same convergence structure is also a convergence vector space.
\end{lemma}
\begin{proof}
It is enough that the restriction of the scalar multiplication to $F$ remains continuous. Alternatively, we can use \ref{vectorSpaceConvergenceConstruction} and note that passing to the field $F$ simply represents a weakening of condition $(5)$.
\end{proof}


\subsection{Initial and final vector space convergences}
\subsubsection{Initial vector space convergence}
\begin{proposition} \label{initialVectorSpaceConvergence}
Let $V$ be a vector space, $\{V_i\}_{i\in I}$ a set of convergence vector spaces and $\{L_i: V \to V_i\}_{i\in I}$ a set of linear maps. Then the initial convergence on $V$ w.r.t. $\{L_i: V \to V_i\}_{i\in I}$ makes $V$ a convergence vector space.
\end{proposition}
\begin{proof}
Continuity of vector addition follows from \ref{initialConvergenceGroup}.

We verify continuity of scalar multiplication $m: \F\times V \to V: (\lambda, v) \mapsto \lambda v$. Using \ref{characteristicPropertyInitialFinalConvergence}, we need to verify that $L_i\circ m$ is continuous for all $i\in I$. Because the $L_i$ are linear, we have
\[ L_i(\lambda v) = \lambda L_i(v) \]
for all $\lambda \in \F, v \in V$. This means that $L_i\circ m = m_i \circ (\id_{V_i}, L_i)$, where $m_i$ is scalar multiplication in $V_i$. Now $(\id_{\F}, L_i)$ is continuous by \ref{continuityFunctionTuple}, so $L_i \circ m$ is continuous.
\end{proof}
\begin{corollary}
Let $\{V_i\}_{i\in I}$ be a set of convergence vector spaces. Then the direct product $\prod_{i\in I} V_i$ with the product convergence is a convergence vector space.
\end{corollary}


\subsubsection{Quotient spaces}
\begin{proposition}
Let $\sSet{V, \xi}$ be a convergence vector space, $W$ a vector space and $q: \sSet{V, \xi} \to W$ a surjective linear function. Then the quotient convergence on $W$ w.r.t. $q$ is a vector space convergence.
\end{proposition}
\begin{proof}
Continuity of vector addition follows from
\ref{quotientConvergenceGroup}.

We verify continuity of scalar multiplication $m: \F\times W \to W: (\lambda, w) \mapsto \lambda w$. Take $F\overset{\F}{\longrightarrow}\lambda$ and $G \overset{W}{\longrightarrow} w$. Then, by \ref{initialFinalConvergence}, there exist $w'\in q^{\preimf}\{w\}$ and $G' \overset{\xi}{\longrightarrow} w'$ such that $q^{\imf\imf}[G'] \subseteq G$. Then
\[ F\cdot G \supseteq F\cdot q^{\imf\imf}[G'] = q^{\imf\imf}[F\cdot G'] \to q(\lambda \cdot w') = \lambda q(w') = \lambda w, \]
which shows that $m$ is continuous.
\end{proof}
\begin{corollary}
Let $\sSet{V,\xi}$ be a convergence vector space and $U\subseteq V$ a subspace. Then $G/U$ is a convergence vector space.
\end{corollary}
\begin{proof}
The function $[\cdot]_U: V\to V/U$ is linear by (TODO ref universal algebra aspects of vector spaces) and \ref{quotientAlgebra}. It is clearly surjective.
\end{proof}
\begin{corollary}
Let $\sSet{V, \xi}$ and $\sSet{W, \zeta}$ be CVSs. Let $f: V\to W$ be a continuous linear function and $U\subseteq G$ a subspace such that $N\subseteq \ker f$. Then there exists a unique continuous linear function $f': A/N \to B$ such that
\[ \begin{tikzcd}
A \arrow[r, "{[\cdot]_N}"] \arrow[dr, swap, "f"] & A/N \arrow[d, dashed, "{f'}"] \\
& B
\end{tikzcd} \qquad\text{commutes.} \]
Further, $f'$ is injective \textup{if and only if} $N = \ker f$.
\end{corollary}
\begin{proof}
The linear function $f'$ is the one from \ref{factorTheorem}. It is continuous by \ref{characteristicPropertyInitialFinalConvergence}.
\end{proof}

\subsubsection{Direct sum}
\begin{definition}
Let $\{\sSet{V_i, \xi_i}\}_{i\in I}$ be a set of convergence vector spaces. Then the \udef{direct sum convergence} is the final \emph{vector space} convergence on $\bigoplus_{i\in I}V_i$ w.r.t. the set $\{e_j: V_j \to \bigoplus_{i\in I}V_i\}$ of natural injections.
\end{definition}
The direct sum convergence is the final vector space convergence. It is equal to the final convergence if and only if the direct sum is trivial (see \ref{algebraicConvergenceStrength}).

\begin{proposition}
Let $\{\sSet{V_i, \xi_i}\}_{i\in I}$ be a set of convergence vector spaces. Then the direct sum convergence is the final convergence on $\bigoplus_{i\in I}V_i$ w.r.t. the set of natural injections $\setbuilder{e_J: \prod_{j\in J} V_j \to \bigoplus_{i\in I}V_i}{\text{$J\subseteq I$ finite}}$.
\end{proposition}
\begin{proof}

\end{proof}
\begin{corollary}
If $I$ is finite, then $\bigoplus_{i\in I}V_i = \prod_{i\in I}V_i$.
\end{corollary}

\begin{proposition}
Let $\{\sSet{V_i, \xi_i}\}_{i\in I}$ be a set of convergence vector spaces. The inclusion map
\[ \bigoplus_{i\in I}V_i \hookrightarrow \prod_{i\in I}V_i \]
is a continuous map into a dense subspace.
\end{proposition}

\subsubsection{Inductive systems}
TODO


\subsection{Continuity}
\subsubsection{Finite dimensional spaces}
\begin{proposition}
Let $\sSet{V,\xi}$ and $\sSet{W,\zeta}$ be convergence vector spaces and $f: V\to W$ a linear map. If $V$ is finite-dimensional and Hausdroff, then $f$ is continuous.
\end{proposition}
\begin{proof}
We prove this by induction on the dimension $n$ of $V$. For the base step $n=1$, we take some non-zero vector $v\in V$ such that $V = \Span\{v\}$. The for all $x\in V$, we have $x= \lambda v$ and thus
\[ f(x) = f(\lambda v) = \lambda f(v). \]
So we have that $f$ is given by
\[ \begin{tikzcd}
V = \Span\{v\} \arrow[rr, "\lambda\cdot v\mapsto \lambda"] && \F \arrow[rr, "\lambda\mapsto \lambda \cdot f(v)"] && \Span\{f(v)\} \arrow[r, hook] & W
\end{tikzcd} \]
which are all continuous functions (in particular by \ref{continuityLemmaVectorConvergence}, using Hausdroffness of $V$).

For the induction step, assume all linear functions $f: V\to W$, where $V$ is Hausdorff and has dimension $\dim(V)< n$ are continuous.

Pick some basis $\{v_1, \ldots, v_n\}$ of $V$.

TODO!
\end{proof}
\begin{corollary}
Every bijective linear map between finite-dimensional Hausdorff convergence vector spaces is a homeomorphism.
\end{corollary}
\begin{corollary}
Every finite-dimensional vector space has a unique convergence that makes it a Hausdorff CVS.
\end{corollary}
\begin{proof}
Unicity is immediate. For existence, every $n$-dimensional vector space is linearly isomorphic to $\F^n$ by \ref{isomorphicDimension} and the Euclidean norm on $\F^n$ gives it a Hausdroff vector convergence. 
\end{proof}

\subsubsection{Hamel coordinate functions}
\begin{lemma} \label{finiteNonZeroHamelCoordinateFunctions}
Let $V$ be a vector space and $\seq{e_i}_{i\in I}$ a Hamel basis of $V$. Let $\seq{\varphi_i}_{i\in I}$ be the associated coordinate functions. Then for all $v\in V$, at most finitely many $\varphi_i(v)$ are non-zero.
\end{lemma}
\begin{proof}
By definition of a Hamel basis, we have $v = \sum_{i\in I}\lambda_i e_i = \sum_{i\in I}\varphi_i(v) e_i$ and the sum must be finite.
\end{proof}
TODO: compare existence dual basis.

\begin{proposition}
Let $\sSet{V,\norm{\cdot}}$ be a Banach space and $\seq{e_i}_{i\in I}$ a Hamel basis of $V$. Let $\seq{\varphi_i}_{i\in I}$ be the associated coordinate functions. At most finitely many $\varphi_i$ are continuous.
\end{proposition}
\begin{proof}
Suppose there existed a countable sequence $\seq{e_i}_{i\in I}$ of basis elements, each with a continuous coordinate function $\varphi_n$. Consider the vector $v = \sum_{n=0}^\infty 2^{-n}e_i/\norm{e_i}$. Then, by continuity, each $\varphi_n(v)$ is non-zero. This is impossible by \ref{finiteNonZeroHamelCoordinateFunctions}.
\end{proof}



\subsection{Topological vector spaces}
\begin{definition}
A \udef{topological vector space} (or TVS) is a convergence vector space that is topological.
\end{definition}
As with convergence groups, any pretopological vector space convergence is topological, see \ref{pretopologicalGroupConvergence}.

\subsubsection{Neighbourhoods and base}
\begin{proposition} \label{TVSconstruction}
Let $V$ be a vector space and $N\in\powerfilters(V)$. Then $N = \neighbourhood_\xi(0)$ for some topological convergence on $V$ \textup{if and only if}
\begin{enumerate}
\item for all $A\in N$ and $\lambda\in \F\setminus\{0\}$: $\lambda A\in N$;
\item each $A \in N$ is absorbent;
\item $N$ has a balanced base;
\item for all $A\in N$, there exists some $B\in N$ such that $B+B\subseteq A$.
\end{enumerate}
\end{proposition}
\begin{proof}
We adapt \ref{vectorSpaceConvergenceConstruction} to the present situation.

First assume $N$ has a balanced and absorbent base. We check the five conditions for $\mathcal{F} = \pfilter{N}$.

\begin{enumerate}
\item Immediate because $\mathcal{F} = \pfilter{N}$.
\item Take $F,G\in \pfilter{N}$. We need to show that $\upset (F + G) \supseteq N$, which means that for all $A \in N$ there exist $B\in F$ and $C\in G$ such that $B+C\subseteq A$. We can take $B = C$ equal to the $B$ of point (2).
\item Take $F\in \pfilter{N}$. We need to show that $\upset(\neighbourhood_\F(0)\cdot F) \supseteq N$, which means that for all $A\in N$ there exists a $\Gamma\in \neighbourhood_\F(0)$ and $B\in F$ such that $\Gamma \cdot B\subseteq A$. We can take $B = \balancedCore(A) \in N \subseteq F$ and $\Gamma = B(0,1)$.
\item Take $v\in V$. We need to show that all $A\in N$ contain $\Gamma\cdot v$ for some $\Gamma \in \neighbourhood_\F(0)$. Because $A$ is absorbent, there exists an $r>0$ such that $v\in cA$ for all $|c|\geq r$. Conversely $c^{-1}v \in A$ for all $|c^{-1}| \leq r^{-1}$. So $\ball(0,r^{-1})\cdot v \subseteq A$ and $B(0,r^{-1}) \in \neighbourhood_\F(0)$.
\item Take $F\in \pfilter{N}$ and $\lambda\in \F$. We need to show that for all $A\in N$ there exists a $B\in F$ such that $\lambda\cdot B\subseteq A$. We can take $B = \lambda^{-1}A \in N\subseteq F$.
\end{enumerate}

Now assume $\xi$ is a topological vector space convergence and $N = \neighbourhood_\xi(0)$. The first 3 points follow from \ref{vicinityFilterAtOrigin}. The fourth from \ref{vicinityFactorisation}.
\end{proof}
\begin{corollary} \label{TVSbase}
Let $V$ be a vector space and $\mathcal{B}\subseteq\powerset(V)$. If $\mathcal{B}$ is such that
\begin{enumerate}
\item all $A\in \mathcal{B}$ are balanced and absorbent;
\item for each $A\in\mathcal{B}$, there exists some $B\in \mathcal{B}$ such that $B+B\subseteq A$;
\end{enumerate}
then $\mathfrak{F}(\mathcal{B}) = \neighbourhood_\xi(0)$ for some topological convergence on $V$.
\end{corollary}
\begin{proof}
We verify the 4 points of the proposition:
\begin{enumerate}
\item From point (2) of the hypothesis, we can prove by induction that for all $A\in\mathcal{B}$ and $n\in \N$, there exists $B\in \mathcal{B}$ such that $2^nB \subseteq A$.

Now take arbitrary $A\in\mathfrak{F}(\mathcal{B})$ and $\lambda\in\F\setminus\{0\}$. Then there exists a finite set $\{B_i\}_{i=0}^k\subseteq \mathcal{B}$ such that $B_0\cap \ldots \cap B_k \subseteq A$. Pick $n\in\N$ such that $2^{-n}\leq |\lambda|$ (and thus $|\lambda^{-1}2^{-n}| \leq 1$). Then we can find a finite set $\{C_i\}_{i=0}^k\subseteq \mathcal{B}$ such that $C_i \subseteq 2^{-n}B_i$. As each $B_i$ is absorbent, we have
\[ C_i \subseteq 2^{-n}B_i = \lambda (\lambda^{-1}2^{-n}) \subseteq \lambda B_i. \]
Thus $(C_0\cap \ldots \cap C_k) \subseteq \lambda (C_0\cap \ldots \cap C_k) \subseteq \lambda A$.
\item By \ref{absorbingSetProperties}, finite intersections of absorbent sets are absorbent. Thus each element of $\mathfrak{F}(\mathcal{B})$ contains an absorbent set and, by \ref{absorbingSetProperties}, is also absorbent.
\item Each element of $\mathfrak{F}(\mathcal{B})$ contains a finite intersection of balanced sets, which is also balanced by \ref{balancedLemma}.
\item Take arbitrary $A\in\mathfrak{F}(\mathcal{B})$. Then there exists a finite set $\{B_i\}_{i=0}^k\subseteq \mathcal{B}$ such that $B_0\cap \ldots \cap B_k \subseteq A$. By assumption, we can find a finite set $\{C_i\}_{i=0}^k\subseteq \mathcal{B}$ such that $C_i + C_i \subseteq B_i$. Then, using \ref{orderPreservingFunctionLatticeOperations}, we have
\[ \Big(\cap_{i\leq k}C_i\Big) + \Big(\cap_{j\leq k}C_j\Big) \subseteq \bigcap_{i,j\leq k} C_i + C_j \subseteq \bigcap_{i\leq k}C_i + C_i \subseteq \bigcap_{i\leq k} B_i \subseteq A. \]
\end{enumerate}
\end{proof}


\subsubsection{Locally convex topological convergence}

\begin{lemma} \label{locallyConvexNeighbourhoodsLemma}
Let $\sSet{V,\xi}$ be a TVS. Then the following are equivalent:
\begin{enumerate}
\item $\xi$ is locally convex;
\item $\neighbourhood_\xi(0)$ is based in the convex sets;
\item $\neighbourhood_\xi(0)$ is based in the absolutely convex sets.
\end{enumerate}
\end{lemma}
\begin{proof}
$(1) \Leftrightarrow (2)$ One direction is immediate, for the other it is enough to note that if $U$ is convex, then so is the translated set $x+U$ for all $x\in V$.

$(2) \Leftrightarrow (3)$ One direction is immediate, the other follows because the balanced core of a convex set is convex by \ref{balancedCoreConvexSet}.
\end{proof}

\begin{proposition}
Let $V$ be a vector space and $N\in\powerfilters(V)$. Then $N = \neighbourhood_\xi(0)$ for some locally convex topological convergence on $V$ \textup{if and only if}
\begin{enumerate}
\item for all $A\in N$ and $\lambda\in \F$: $\lambda A\in N$;
\item each $A \in N$ is absorbent;
\item $N$ has an absolutely convex base.
\end{enumerate}
\end{proposition}
\begin{proof}
This almost completely follows from \ref{TVSconstruction} and \ref{locallyConvexNeighbourhoodsLemma}. We just need to show that for all $A\in N$, there exists some $B\in N$ such that $B+B\subseteq A$. We may take $B = \frac{1}{2}A'$, where $A'$ is a convex subset of $A$, because for all $v,w\in A'$ we have $\frac{1}{2}v + \frac{1}{2}w \in A'$ by convexity.
\end{proof}


\section{Properties of subsets}
\begin{proposition} \label{inherenceAdherenceBalanced}
Let $\sSet{V,\xi}$ be a vector space convergence and $A\subseteq V$. Then
\begin{enumerate}
\item if $A$ is balanced, then $\adh(A)$ is balanced;
\item if $A$ is balanced and $0\in\inh(A)$, then $\inh(A)$ is balanced;
\item if $A$ is open and contains the origin, then $\balanced(A)$ is open.
\end{enumerate}
\end{proposition}
\begin{proof}
(1) We use \ref{productAdherence} and \ref{adherenceInherenceContinuity} to compute
\begin{align*}
\cball(0,1)\cdot \adh_\xi(A) &= \cdot^\imf[\adh_\F(\cball(0,1))\times \adh_\xi(A)] = \cdot^\imf[\adh_{\F\otimes \xi}(\cball(0,1)\times A)] \\
&\subseteq \adh_{\xi}\big(\cdot^\imf[\cball(0,1)\times A]\big) = \adh_{\xi}(\cball(0,1)\cdot A) = \adh_\xi(A).
\end{align*}

(2) Take $0<r<1$. Then multiplying by $r$ is a homeomorphism and thus $r\cdot\inh(A) = \inh(r\cdot A) \subseteq \inh(A)$. Now take $r=0$. If $0\in\inh(A)$, then
\[ r\cdot\inh(A) = \{0\} \subseteq \inh(A). \]

(3) For all $r\neq 0$, $r\cdot A$ is open. Thus
\[ \balanced(A) = \bigcup_{|r|\leq 1}r\cdot A = \{0\}\cup \bigcup_{0< r\leq 1}r\cdot A = \bigcup_{0< r\leq 1}r\cdot A \]
is a union of open sets and thus open by \ref{completeClosureTopology}.
\end{proof}
\begin{proof}[Alternative proof of (1)]
Take $|\lambda|\leq 1$ and $v\in \adh_\xi(A)$, then we need to show that $\lambda v \in \adh_\xi(A)$. We have $A\in \vicinity_\xi(v)^{\mesh}$ and $A\subseteq \lambda^{-1}A$. So for all $B\in \vicinity_\xi(v)$:
\[ A\mesh B \quad\implies\quad \lambda^{-1}A\mesh B \quad\implies\quad A\mesh \lambda B. \]
Thus $A\in \vicinity_\xi(\lambda v)^{\mesh}$, which is what we needed to show by \ref{principalAdherenceInherence}.
\end{proof}

\begin{proposition} \label{inherenceAdherenceConvex}
Let $\sSet{V,\xi}$ be a vector space convergence and $A\subseteq V$. Then
\begin{enumerate}
\item if $A$ is convex, then $\adh(A)$, $\inh(A)$ and $\interior(A)$ is convex;
\item if $A$ is open, then $\convex(A)$ is open.
\end{enumerate}
\end{proposition}
TODO same for closure?
\begin{proof}
(1) For all $0<r<1$, we have
\[ r\adh(A) + (1-r)\adh(A) = \adh(rA) + \adh\big((1-r)A\big) \subseteq \adh\big(rA + (1-rA)\big) \subseteq \adh(A) \]
by \ref{vectorSumInherenceAdherence}. 

The argument for $\inh(A)$ and $\interior(A)$ is similar.

(2) We have
\[ \interior(\convex(A)) = \interior\left(\bigcup_{|r|\leq 1} rA + (1-r)A\right) \supseteq \bigcup_{|r|\leq 1} r\interior(A) + (1-r)\interior(A) = \bigcup_{|r|\leq 1} rA + (1-r)A = \convex(A). \]
TODO ref.
\end{proof}

\begin{proposition}
Let $\sSet{V,\xi}$ be a vector space convergence and $A\subseteq V$ a subspace. Then $\adh(A)$ is a subspace.
\end{proposition}
\begin{proof}
Clearly $\adh_\xi(A)$ is not empty. It is then enough to note that $\adh_\xi(A)+\adh_\xi(A)\subseteq \adh_\xi(A)$, by \ref{vectorSumInherenceAdherence}, and $\F\cdot \adh_\xi(A) \subseteq \adh_\xi(A)$, for which we use \ref{productAdherence} and \ref{adherenceInherenceContinuity} to compute
\begin{align*}
\F\cdot \adh_\xi(A) &= \cdot^\imf[\adh_\F(\F)\times \adh_\xi(A)] = \cdot^\imf[\adh_{\F\otimes \xi}(\F\times A)] \\
&\subseteq \adh_{\xi}\big(\cdot^\imf[\F\times A]\big) = \adh_{\xi}(\F\cdot A) = \adh_\xi(A).
\end{align*}
\end{proof}
\begin{corollary} \label{hyperplaneClosedDense}
A hyperplane in a convergence vector space is either closed or dense.
\end{corollary}
\begin{proof}
Let $H$ be a hyperplane in a vector space $V$. Then $H \subseteq \adh(H)$ and $\adh(H)$ is a subspace. Because $H$ is a coatom, we have either $\adh(H) = H$ or $\adh(H) = V$. In the first case $H$ is closed, in the second dense.
\end{proof}
\begin{corollary}
Let $\sSet{V,\xi}$ be a complete Hausdorff CVS. Then any finite dimensional subspace $U$ of $V$ is closed.
\end{corollary}
\begin{proof}
Consider $\adh(U)$. This is a vector space by the proposition. If $\adh(U)$ has the same dimension as $U$, then $\adh(U) = U$ by \ref{vectorSpaceEquality} (as $U \subseteq \adh(U)$). In this case $U$ is closed.

Now assume $\adh(U)$ has a strictly larger dimension than $U$. Then pick a basis $\beta$ of $U$ and enlarge it to a basis $\beta'$ of $\adh(U)$, which is possible by \ref{extensionReductionBasisFiniteDimensions}. Take $w\in \beta'\setminus \beta$.

As $w\in\adh(U)$, there exists $F\to w$ such that $U\in F$
\end{proof}

\subsection{Bounded subsets}
\begin{definition}
Let $\sSet{V,\xi}$ be a convergence vector space. A subset $A\subseteq V$ is called \udef{bounded} if it is absorbed by all vicinities of the origin (i.e.\ by all elements of $\vicinity_{\xi}(0)$).
\end{definition}
Clearly subsets of bounded sets are bounded.

\begin{lemma} \label{boundedBaseCriterion}
Let $\sSet{V,\xi}$ be a convergence vector space and $A\subseteq V$ a subset. If $A$ is absorbed by all sets in a base of $\vicinity_{\xi}(0)$, then it is bounded.
\end{lemma}

\begin{lemma} \label{topologicalBoundedness}
Let $\sSet{V,\xi}$ be a topological vector space and $A\subseteq V$ a subset. Then $A$ is bounded \textup{if and only if}
\[ \forall U\in \neighbourhood_{\xi}(0): \exists r > 0: \forall c \geq r: \; A \subseteq cU. \]
\end{lemma}
This lemma says that in the topological case we do not need to check all $|c| \geq r$, only the positive ones.
\begin{proof}
The direction $\Rightarrow$ is immediate. For the converse, pick a balanced base of $\neighbourhood_{\xi}(0)$. Then the result follows immediately from the observation that $cV = |c|V$ (\ref{balancedLemma}) for all balanced sets.
\end{proof}

\begin{lemma} \label{boundedSetLemma}
Let $\sSet{V,\xi}$ be a convergence vector space and $A,B\subseteq V$ bounded subsets. Then
\begin{enumerate}
\item $\lambda A$ is bounded for all $\lambda\in\F$;
\item $A+B$ is bounded;
\item $A\cup B$ is bounded.
\end{enumerate}
\end{lemma}

\begin{lemma} \label{boundedSetsTVS}
Let $\sSet{V,\xi}$ be a topological vector space and $A\subseteq V$ a bounded subset. Then
\begin{enumerate}
\item $\closure_\xi(A)$ is bounded;
\item $\balanced(A)$ is bounded;
\item $\disked(A)$ is bounded if $\xi$ is locally convex.
\end{enumerate}
\end{lemma}
\begin{proof}
(1,2) By \ref{vicinityFilterAtOrigin}, we may take a closed and balanced base of $\vicinity_{\xi}(0)$. 
By \ref{boundedBaseCriterion} it is enough to show absorption by these basis elements. This is immediate, because for all closed and bounded $U$, we have $A\subseteq cU$ iff $\closure_\xi(A) \subseteq cU$ iff $\disked(A) \subseteq cU$.

(3) Similar, now taking convex balanced base, \ref{locallyConvexNeighbourhoodsLemma}.
\end{proof}

\begin{proposition} \label{continuousMappingBoundedSets}
Let $\sSet{V,\xi}, \sSet{W,\zeta}$ be vector convergence spaces, $f:V\to W$ a function and $A\subseteq V$ a bounded subset. Then
\begin{enumerate}
\item if $f$ is linear and continuous, then $f^\imf(A)$ is bounded;
\item if $\zeta$ is topological and $f$ is positively homogeneous and continuous at $0$, then $f^\imf(A)$ is bounded.
\end{enumerate} 
\end{proposition}
\begin{proof}
(1) We have $\vicinity_\zeta(0) \subseteq f^{\imf\imf}\big(\vicinity_\xi(0)\big)$ by \ref{continuityVicinityFilter}.
Take arbitrary $U\in \vicinity_\zeta(0)$. Then there exists $V\in \vicinity_\xi(0)$ such that $f^\imf(V) \subseteq U$. By boundedness of $A$, there exists $r>0$ such that $A \subseteq cV$ for all $|c|\geq r$. Then $f^\imf(A)\subseteq f^\imf(cV) = cf^\imf(V) \subseteq cU$ for all $|c|\geq r$. Thus $f^\imf(A)$ is bounded.

(2) Again we have b$\vicinity_\zeta(0) \subseteq f^{\imf\imf}\big(\vicinity_\xi(0)\big)$ by \ref{continuityVicinityFilter} (using $f(0) = 0$ from \ref{homogeneousFunctionLemma}). Take arbitrary $U\in \vicinity_\zeta(0)$. Then there exists $V\in \vicinity_\xi(0)$ such that $f^\imf(V) \subseteq U$. By boundedness of $A$, there exists $r>0$ such that $A \subseteq cV$ for all $c\geq r$. Then $f^\imf(A)\subseteq f^\imf(cV) = cf^\imf(V) \subseteq cU$ for all $c\geq r$. Thus $f^\imf(A)$ is bounded by \ref{topologicalBoundedness}.
\end{proof}

\begin{proposition} \label{boundedSetsInitialTopology}
Let $V$ be a vector space, $\{f_i:V\to \sSet{Y_i,\zeta_i}\}_{i\in I}$ a set of linear functions to topological vector spaces and $A\subseteq V$ a subset. Then $A$ is bounded \textup{if and only if} $f_{i}^{\imf}(A)$ is bounded for all $i\in I$.
\end{proposition}
\begin{proof}
The direction $\Rightarrow$ is given by \ref{continuousMappingBoundedSets}.

For the converse, note that $\neighbourhood_V(0)$ has a base consisting of sets of the form $f^{\preimf}_i(U)$, with $U\in \neighbourhood_{\zeta_i}(0)$, by \ref{pretopologicalInitialConvergence}.
As $f_{i}^{\imf}(A)$ is bounded, there exists $r>0$ such that $f_{i}^{\imf}(A) \subseteq cU$ for all $|c|\geq r$. Then $A \subseteq f_i^{\preimf}\big(f_i^\imf(A)\big) \subseteq f_i^\preimf(cU) = cf_i^\preimf(U)$ for all $|c|\geq r$.
\end{proof}

\begin{proposition} \label{boundedOnVicinityImpliesContinuous}
Let $\sSet{V,\xi}$ vector convergence space and $\sSet{W,\zeta}$ a topological vector convergence space and $f: V\to W$ a positively homogeneous function.
\begin{enumerate}
\item if there exists $U\in \vicinity_\xi(0)$ such that $f^\imf(U)$ is bounded, then $f$ is continuous at the origin;
\item if $f$ is linear, then this implies the continuity of $f$ everywhere.
\end{enumerate}
\end{proposition}
\begin{proof}
(1) By \ref{pretopologicalContinuityVicinities}, it is enough to verify $\neighbourhood_\zeta(0) \subseteq f^{\imf\imf}\big(\vicinity_\xi(0)\big)$. Take $A\in \neighbourhood_\zeta(0)$. Then $f^\imf(U)\subseteq rA$ for some $r>0$ by boundedness. So $f^\imf(r^{-1}U) \subseteq A$. As $r^{-1}U\in \vicinity_\xi(0)$ by \ref{vicinityFilterAtOrigin}, we have $A \in f^{\imf\imf}\big(\vicinity_\xi(0)\big)$.

(2) The continuity of $f$ is equivalent to the continuity of $f$ at $0$, by \ref{shiftHomeomorphism}.
\end{proof}
\begin{corollary} \label{continuityToNormedSpace}
Let $\sSet{V, \xi}$ be a convergence vector space, $\sSet{W, \norm{\cdot}}$ a normed space and $f: V\to W$ a positively homogeneous function. Then
\begin{enumerate}
\item $f$ is continuous at $0$ \textup{if and only if} $f$ is bounded on some $U\in \vicinity_\xi(0)$;
\item if $f$ is linear, then this is equivalent to the continuity of $f$ everywhere.
\end{enumerate}
\end{corollary}
\begin{proof}
(1) The direction $\Leftarrow$ is given by the proposition.

For the converse, assume $f$ continuous at $0$, then $\ball\big(0,1\big)\in \neighbourhood_W(0) = \neighbourhood_W\big(f(0)\big) \subseteq f^{\imf\imf}[\vicinity_\xi(0)]$ by \ref{continuityVicinityFilter}. So there exists $U\in \vicinity_\xi(0)$ such that $f^{\imf}[U] \subseteq \ball(0,1)$, which means that $f$ is bounded by $1$ on $U$.

(2) The continuity of $f$ is equivalent to the continuity of $f$ at $0$, by \ref{shiftHomeomorphism}.
\end{proof}


\begin{lemma} \label{boundedSetVicinityBase}
Let $\sSet{V,\xi}$ be a convergence vector space. If $U\in \vicinity_\xi(0)$ is bounded, then $\{\epsilon U\}_{\epsilon>0}$ forms a base of $\vicinity_\xi(0)$.
\end{lemma}
\begin{proof}
Note that $\{\epsilon U\}_{\epsilon>0} \subseteq \vicinity_\xi(0)$ by \ref{vicinityFilterAtOrigin}.

Conversely, take $U'\in \vicinity_\xi(0)$, then we can find $r>0$ such that $U\subseteq rU'$ and thus $r^{-1}U\subseteq U'$.
\end{proof}

\begin{proposition}
Let $\sSet{V,\xi}$ be a topological vector space and $U\in\neighbourhood_\xi(0)$.
\begin{enumerate}
\item if $U$ is bounded, then $\xi$ is the initial topology w.r.t. some absolutely homogeneous function $f: V\to \R$;
\item if $U$ is bounded and convex, then $\xi$ is the initial topology w.r.t. some seminorm $f$.
\item if $U$ is bounded and convex and $\xi$ is Hausdorff, then $\xi$ is normable.
\end{enumerate}
\end{proposition}
TODO: (1) implies pseudometrisable? Narici/Beckenstein.
\begin{proof}
(1) Suppose $U$ bounded. Then $\balanced(U)$ is bounded by \ref{boundedSetsTVS}, so we may take $U$ balanced WLOG. Then $\{\epsilon U\}_{\epsilon >0}$ forms a base of $\neighbourhood_\xi(0)$ by \ref{boundedSetVicinityBase}. Consider the gauge $p_U$, which is absolutely continuous by \ref{gaugeProperties}. By \ref{gaugeClassificationLemma}, each $\epsilon U$ is contained in a preimage of $p_U$, so the initial topology w.r.t. $p_U$ is stronger than $\xi$. We just need to show that $p_U$ is continuous, which immediately follows from \ref{boundedOnVicinityImpliesContinuous} and \ref{gaugeClassificationLemma}.If $p_U(v) = 0$ for some 

(2) In this case $p_U$ is a seminorm by \ref{gaugeProperties}.

(3) TODO.
\end{proof}


\section{Algebraic convergence}
\begin{definition}
Let $V$ be a vector space over a field $\F$. The \udef{algebraic convergence} on $V$ is the final convergence on $V$ w.r.t $\setbuilder{\F \to V: \lambda\mapsto \lambda \cdot v}{v\in V}$.

We denote this convergence $\mathfrak{a}$ and thus write $F \overset{\mathfrak{a}}{\longrightarrow} x$ and $x\in \lim_\mathfrak{a} F$.
\end{definition}

\begin{lemma} \label{algebraicConvergence}
Let $V$ be a vector space over a field $\F$ and $F\in \powerfilters(V)$. Then the algebraic convergence is defined by
\[ F \overset{\mathfrak{a}}{\longrightarrow} x \iff \begin{cases}
\exists v\in V: \;F \supseteq \neighbourhood_\F(0)\cdot v & (x = 0) \\
F \supseteq \neighbourhood_\F(1)\cdot x & (x \neq 0).
\end{cases}  \]
\end{lemma}
\begin{proof}
This is an application of \ref{initialFinalConvergence}, which states that $F \overset{\mathfrak{a}}{\longrightarrow} x$ iff there exists some $v\in V$ and $\lambda\in \F$ such that $x = \lambda v$ and $\neighbourhood_\F(\lambda)\cdot v \subseteq F$.

If $x\neq 0$, then $\lambda \neq 0$, so
\[ \neighbourhood_\F(\lambda)\cdot v = \neighbourhood_\F(\lambda)\cdot \lambda^{-1}x = \neighbourhood_\F(\lambda\lambda^{-1})\cdot x = \neighbourhood_\F(1)\cdot x. \]
If $x = 0$, then either $\lambda = 0$ or $v = 0$. In the latter case, we have
\[ \neighbourhood_\F(\lambda)\cdot v = \neighbourhood_\F(\lambda)\cdot 0 = \pfilter{0} = \neighbourhood_\F(0)\cdot 0 = \neighbourhood_\F(0)\cdot v. \]
\end{proof}

\begin{lemma} \label{algebraicConvergenceStrength}
Let $\sSet{V,\xi}$ be a convergence vector space. Then
\begin{enumerate}
\item $\mathfrak{a} \subseteq \xi$;
\item $\mathfrak{a}$ is a vector convergence \textup{if and only if} $V$ is 1D.
\end{enumerate}
\end{lemma}
\begin{proof}
(1) Immediate as $\xi$ must make all functions in $\setbuilder{\F \to V: \lambda\mapsto \lambda \cdot v}{v\in V}$ continuous.

(2) First assume $V$ is 1D, so $V = \Span\{v\}$. Then any filter in $\powerfilters(V)$ is of the form $F\cdot v$ for some $F\in \powerfilters(\F)$. Now take two convergent filters, $F\cdot v\to \lambda v$ and $G\cdot \mu v$. Then by \ref{algebraicConvergence}, we have that $F \overset{\F}{\longrightarrow} \lambda$ and $G \overset{\F}{\longrightarrow} \mu$, so
\[ F\cdot v + G\cdot v = (F+G)\cdot v \to (\lambda +\mu)v = \lambda v + \mu v. \]
by continuity of $(\lambda\mapsto \lambda \cdot v)$. This means that the vector addition is continuous and $\mathfrak{a}$ is a vector space convergence.

Now assume $V$ is not 1D. So we can find linearly independent $v,w$. Consider the sequence $\seq{v + \frac{1}{n}w}_{n\in\N}$, which converges to $v$ in any convergence vector space. But $\ball_\F(1,1)\cdot v$ is not an element of the tail filter (as no element of the sequence is of the form $\lambda v$), so $\neighbourhood_\F(1)\cdot v \nsubseteq \TailsFilter\seq{v + \frac{1}{n}w}$ and the sequence does not converge in the algebraic convergence by \ref{algebraicConvergence}.
\end{proof}

\begin{lemma} \label{constructionsInAlgebraicConvergence}
Let $V$ be a vector space over a field $\F$, $v\in V$ and $A\subseteq V$ a subset. Then
\begin{enumerate}
\item $\begin{aligned}[t]
\vicinity_\mathfrak{a}(0) &= \bigcap_{v\in V} \upset \neighbourhood_\F(0)\cdot v \\
&= \setbuilder{B\in \powerset(V)}{\forall v\in V: \exists \Gamma_v\in \neighbourhood_\F(0):\; \Gamma_v\cdot v\subseteq B} \\
&= \setbuilder{\bigcup_{v\in V} \Gamma_v\cdot v}{\forall v\in V:\; \Gamma_v \in \neighbourhood_\F(0)};
\end{aligned}$
\item $\inh_\mathfrak{a}(A) = \setbuilder{x\in V}{\forall v\in V:\exists \Gamma_v \in \neighbourhood_\F(0):\; x + \Gamma_v\cdot v \subseteq A}$;
\item $\adh_\mathfrak{a}(A) = \setbuilder{x\in V}{\exists v\in V: \forall \Gamma\in\neighbourhood_\F(0):\; (x+\Gamma\cdot v)\mesh A}$.
\end{enumerate}
\end{lemma}
\begin{proof}
(1) The first equality follows straight from \ref{algebraicConvergence}.

(2) We have $\inh_\mathfrak{a}(A) = \setbuilder{x}{A\in \vicinity_\mathfrak{a}(x)} = \setbuilder{x}{A-x\in \vicinity_\mathfrak{a}(0)}$. From (1) we get 
\begin{align*}
\inh_\mathfrak{a}(A) &= \setbuilder{x}{\forall v\in V: \exists \Gamma_v\in \neighbourhood_\F(0): \Gamma_v\cdot v \subseteq A-x} \\
&= \setbuilder{x}{\forall v\in V: \exists \Gamma_v\in \neighbourhood_\F(0): x + \Gamma_v\cdot v \subseteq A}.
\end{align*}

(3) We calculate
\begin{align*}
\adh_\mathfrak{a}(A) &= \big(\inh_\mathfrak{a}(A^c)\big)^c \\
&= \setbuilder{x\in V}{\exists v\in V:\forall \Gamma \in \neighbourhood_\F(0):\; \neg(x + \Gamma\cdot v \subseteq A^c)} \\
&= \setbuilder{x\in V}{\exists v\in V:\forall \Gamma \in \neighbourhood_\F(0):\; (x + \Gamma\cdot v) \mesh A}.
\end{align*}
\end{proof}

\begin{lemma}
Let $V$ be a vector space. Then every subspace $U\subseteq V$ is algebraically closed.
\end{lemma}
\begin{proof}
We need to show that $\adh_\mathfrak{a}(U)\subseteq U$. Take $x\in \adh_\mathfrak{a}(U)$. Then take a $v\in V$ such that $\forall \Gamma\in\neighbourhood_\F(0):\; (x+\Gamma\cdot v)\mesh U$.

Pick some $\Gamma\in\neighbourhood_\F(0)$. Then $x+\lambda v\in U$ for some $\lambda\in \Gamma$. Then take $\ball(0,|\lambda|/2)\in \neighbourhood_\F(0)$, so $x+\mu v\in U$ for some $\mu\in \ball(0,|\lambda|/2)$. In particular $\lambda \neq \mu$. If either $\lambda =0$ or $\mu = 0$, then $x\in U$ and we are done. Suppose $\lambda\neq 0 \neq \mu$. Then
\[ \lambda^{-1}(x+\lambda v) - \mu^{-1}(x+\mu v) = (\lambda^{-1} - \mu^{-1})x \in U. \]
So $x\in U$.
\end{proof}

\subsection{The algebraic interior or core}
\begin{definition}
Let $V$ be a vector space and $A\subseteq V$ a subset. Then algebraic inherence $\inh_\mathfrak{a}(A)$ is also called the \udef{algebraic interior} or \udef{core} of $A$.
\end{definition}

\begin{proposition} \label{coreProperties}
Let $V$ be a vector space and $A \subseteq V$ a subset. Then
\begin{enumerate}
\item $A$ is absorbing \textup{if and only if} $0\in \inh_\mathfrak{a}(A)$;
\item if $A$ is convex, then $\inh_\mathfrak{a}(A)$ is convex and open.
\end{enumerate}
\end{proposition}
\begin{proof}
(1) We have that
\begin{align*}
\text{$A$ is absorbing} &\iff \forall v\in V: \exists \epsilon >0: \; \ball(0,\epsilon)\cdot v\subseteq A \\
&\iff \forall v\in V: \exists \Gamma \in \neighbourhood_\F(0): \; \Gamma\cdot v\subseteq A \\
&\iff 0\in \inh_\mathfrak{a}(A).
\end{align*}

(2) We first show convexity: take $x,y \in \inh_\mathfrak{a}(A)$. Then there exist relevant $v,w,\Gamma_v,\Gamma_w$ such that $x+ \Gamma_v\cdot v \subseteq A$ and $y+ \Gamma_w\cdot w \subseteq A$. By \ref{convexCriteria} we have $\lambda \big(x+ \Gamma_v\cdot v\big) + (1-\lambda)\big(y+ \Gamma_w\cdot w\big)\subseteq A$ for all $0\leq \lambda \leq 1$, so
\[ \lambda x+(1-\lambda)y + (\Gamma_v\cap\Gamma_w)\big(\lambda v+(1-\lambda)w\big) \subseteq \lambda x+(1-\lambda)y + \Gamma_v\cdot \lambda v+\Gamma_w\cdot (1-\lambda)w \subseteq A. \]

To show $\inh_\mathfrak{a}(A)$ is open, we use \ref{openClosedCriteria}. Take $x\in \inh_\mathfrak{a}(A)$. Then for all $v\in V$ we can find a $\Gamma_v\in\neighbourhood_\F(0)$ such that $x+\Gamma_v\cdot v \subseteq A$. This means $x+\bigcup_{v\in V}\Gamma_v\cdot v \subseteq A$. Because the convergence on $\F$ is topological, we may take the $\Gamma_v$ open. To conclude with \ref{openClosedCriteria} it is enough to show that $x+\bigcup_{v\in V}\Gamma_v\cdot v \subseteq \inh_\mathfrak{a}(A)$.

Pick some $y = x+ c_w w \in x+ \bigcup_{v\in V}\Gamma_v\cdot v \subseteq A$, meaning $c_w\in\Gamma_w$. We can find an $0<\epsilon_w<|c_w|$ such that $c_w + \ball(0,\epsilon_w) \subseteq \Gamma_w$ by \ref{openClosedCriteria}. Then for all $1-\frac{\epsilon_w}{|c_w|}<\delta<1$ we have $|c_w - \delta c_w| = (1-\delta)|c_w| < \frac{\epsilon_w}{|c_w|}|c_w| = \epsilon_w$ and so $x+ \delta c_w w \in A$.

Now pick an arbitrary $u\in V$. We have $x+\Gamma_u\cdot u \subseteq A$. By convexity we have
\[ \delta^{-1}(x+ \delta c_w w) + (1-\delta^{-1})\big(x+\Gamma_u\cdot u\big) = x + c_w w + (1-\delta^{-1})\Gamma_u\cdot u \subseteq A. \]
This means that for all $v\in V$ we have $y + (1-\delta^{-1})\Gamma_v\cdot v \subseteq A$ and thus $y\in \inh_\mathfrak{a}(A)$.
\end{proof}

\begin{proposition} \label{algebraicallyOpen}
Let $V$ be a vector space and $A \subseteq V$ an algebraically open subset. Then
\begin{enumerate}
\item $A+U$ is algebraically open for any subspace $U\subseteq V$;
\end{enumerate}
\end{proposition}
\begin{proof}
TODO
\end{proof}




\section{Functionals}
\begin{definition}
Let $V$ be a vector space over a field $\mathbb{F}$.
\begin{enumerate}
\item A \udef{functional} on $V$ is a map $V\to \F$;
\item A \udef{linear functional} on $V$ is a linear map from $V$ to $\mathbb{F}$;
\item A \udef{real functional} on $V$ is a map $V\to \R$.
\end{enumerate}
\end{definition}

\begin{lemma} \label{continuityDominatedFunctional}
Let $V$ be a TVS and $f:V\to \F$ a continuous functional. If $g:V\to \F$ is a functional such that $|g(v)|\leq |f(v)|$ for all $v\in V$, then $g$ is continuous.
\end{lemma}
\begin{proof}
We use \ref{pretopologicalContinuityVicinities} to show continuity. To that end take $K\in \neighbourhood_\F(0)$. Then there exists $\epsilon >0$ such that $\ball(0,\epsilon)\subseteq K$ and so
\[ g^{\preimf}(K) \supseteq g^\preimf[\ball(0,\epsilon)] \supseteq f^\preimf[\ball(0,\epsilon)] \in \neighbourhood_V(0). \]
\end{proof}

\subsection{Linear functionals}
\begin{lemma} \label{kernelHyperplane}
Let $V$ be a vector space and $U\subseteq V$ a subspace. Then $U$ is a hyperplane \textup{if and only if} it is the kernel of a linear functional.
\end{lemma}

\begin{lemma} \label{functionalBoundedNeighbourhood}
Let $f: V\to \F$ be a linear functional and $x\notin \ker(f)$. Let $A\subseteq V$ be a balanced set. Then $(x+A)\perp \ker(f)$ \textup{if and only if} $A \subseteq f^{\preimf}(\ball(0,|f(x)|))$.
\end{lemma}
\begin{proof}
Suppose $A \subseteq f^{\preimf}(\ball(0,|f(x)|))$. Then for all $a\in A$: $f(x+a) = f(x) + f(a) \neq 0$.

Conversely, suppose $A \not\subseteq f^{\preimf}(\ball(0,|f(x)|))$, i.e.\ there exists $a\in A$ such that $|f(a)| \geq |f(x)|$. Then $v= -\frac{f(x)}{f(a)}a\in A$, because $A$ is balanced and so $f(x+ v) = f(x)-\frac{f(x)}{f(a)}f(a) = 0$ and so $(x+A) \mesh \ker(f)$.
\end{proof}

\begin{proposition} \label{linearFunctionalOpen}
Let $V$ be a convergence vector space and $f:V\to \F$ a non-zero linear functional. Then $f$ is an open map.
\end{proposition}
\begin{proof}
It is enough to show $f$ is open when $V$ is equipped with the algebraic convergence.

Let $A$ be an algebraically open map. We use \ref{openClosedCriteria} to show $f^\imf[A]$ is also open. Because $f$ is non-zero, there exists a $v\in V$ such that $f(v) \neq 0$. Take some $y\in f^\imf[A]$. Then there exists an $x\in A$ such that $f(x) = y$. Because $A$ is open, $x\in \inh_\mathfrak{x}(A)$ and there exists $x+ \Gamma_v\in \neighbourhood_\F(0)$ such that $x+\Gamma_v\cdot v \subseteq A$ by \ref{constructionsInAlgebraicConvergence}.

Now $f^\imf[x+ \Gamma_v\in \neighbourhood_\F(0)] = y+\Gamma_v \cdot f(v) \subseteq f^\imf[A]$ and $y+\Gamma_v \cdot f(v)$ is a vicinity of $y$, so we are done.
\end{proof}

\begin{lemma} \label{complexRangeExtensionRealFunctional}
Let $V$ be a complex vector space and $g: V_\R\to \R$ a linear functional. Then there exists a unique linear functional $f: V\to \C$ such that $g = \Re(f)$.
\end{lemma}
\begin{proof}
We can write $f = g + ih$ for some function $h: V\to \R$. Then for all $x\in V$
\[ g(ix)+ih(ix) = f(ix) = if(x) = ig(x) - h(x). \]
Comparing real parts gives $h(x) = - g(ix)$. So $f$ must be given by $f(x) = g(x) - ig(ix)$. Clearly $f$ is real-linear. We just need to verify that this makes $f$ complex-linear. Indeed, take $\lambda = a +ib \in \C = \R+i\R$ arbitrarily. Then for all $v\in V$
\begin{align*}
f(\lambda v) &= f\big((a+ib)v\big) \\
&= af(v) + bf(iv) \\
&= af(v) + b\big(g(iv) - ig(i^2v)\big) \\
&= af(v) + b\big(g(iv) + ig(v)\big) \\
&= af(v) + ib\big(-ig(iv) + g(v)\big) \\
&= af(v) + ibf(v) = (a+ib)f(v) = \lambda f(v).
\end{align*}
\end{proof}

\begin{lemma} \label{linearDependenceLinearFunctionals}
Let $V$ be a vector space and $f_0,\ldots, f_n, f$ linear functionals in $(V\to \F)$. Then the following are equivalent:
\begin{enumerate}
\item $f$ is a linear combination of $f_0,\ldots, f_n$;
\item there exists a $C>0$ such that $f(v) \leq C \max_{0\leq i\leq n}|f_i(v)|$;
\item $\ker(f) \supseteq \bigcap_{0\leq i \leq n}\ker(f_i)$;
\end{enumerate}
\end{lemma}
\begin{proof}
The implications $(1) \Rightarrow (2) \Rightarrow (3)$ are clear.

Now assume $(3)$ holds. Consider the function
\[ \begin{pmatrix}
f_0 \\ \vdots \\ f_n
\end{pmatrix}: V\to \F^{n+1}: v\mapsto \begin{pmatrix}
f_0(v) \\ \vdots \\ f_n(v)
\end{pmatrix}. \]
Due to the assumption, we can find a linear function $F: \F^{n+1}\to \F$ such that $f = F\circ \begin{pmatrix}
f_0 \\ \vdots \\ f_n
\end{pmatrix}$.

This function $F$ can be represented as a matrix by \ref{ellIsomorphism}. Thus $f$ is a linear combination of $f_0,\ldots, f_n$.
\end{proof}
\begin{corollary}
Let $V$ be a vector space and $f_0,\ldots, f_n$ linearly independent linear functionals in $(V\to \F)$. Then there exist $v_0, \ldots, v_n$ such that $f_i(v_j) = \delta_{i,j}$.
\end{corollary}
\begin{proof}
The proof is by induction. The case $n=1$ is clear: if there was no such $a_1$, then $f_1$ would be zero and thus not linearly independent.

Suppose the statement holds for $n-1$ and take $f_0,\ldots, f_n$ linearly independent linear functionals with corresponding $v_0,\ldots, v_{n-1}$. By point (3) of the proposition we can find $v_n \in \bigcap_{0\leq i \leq n}\ker(f_i)\setminus \ker(f_n)$, which after rescaling can be taken to be such that $f_n(v_n) = 1$. By construction $f_i(v_n) = 0$ for $i<n$.

Now replace $v_i$ with $v_i-f_n(v_i)v_n$ and rescale.
\end{proof}

\subsection{The dual space}
\begin{definition}
Let $\sSet{V,\xi}$ be a convergence vector space over a field $\mathbb{F}$.

The \udef{dual} of $V$ is the vector space of all continuous linear functionals on $V$.

The dual is denoted $\sSet{V,\xi}^{*}$ (or just $V^*$ is the convergence is clear from the context).
\end{definition}

\begin{proposition} \label{continuityLinearFunctionals}
Let $\sSet{V, \xi}$ be a CVS and $f:V\to \F$ a linear functional on $V$. Then the following are equivalent:
\begin{enumerate}
\item $f\in V^{*}$, i.e.\ $f$ is continuous;
\item there exists a vicinity $U\in \vicinity_\xi(0)$ such that $f$ is bounded on $U$;
\item $\ker(f)$ is closed;
\item $\ker(f)$ is not dense.
\end{enumerate}
\end{proposition}
\begin{proof}
$(1) \Leftrightarrow (2)$ By \ref{continuityToNormedSpace}.

$(1) \Rightarrow (3)$ Because $\ker(f) = f^{\preimf}(\{0\})$ and $\{0\}$ is closed in $\F$, $\ker(f)$ is closed by \ref{preimageOpenClosed}.

$(3) \Rightarrow (1)$ TODO

$(3) \Leftrightarrow (4)$ By \ref{kernelHyperplane} $\ker(f)$ is a hyperplane and by \ref{hyperplaneClosedDense} this hyperplane is either closed or dense.
\end{proof}

Now assume $\ker(f)$ closed. If $\ker(f) = V$, then $f$ is constant and thus continuous by \ref{continuityConstructions}. If $\ker(f) \neq V$, we can find some some $x\in \ker(f)^c$, which is open. Thus $\ker(f)^c - x$ is a neighbourhood of the origin, meaning we can take a balanced subset $A$ by \ref{vicinityFilterAtOrigin}. Now $(x+A)\perp \ker(f)$ by construction, so $f$ is bounded on $A$ by \ref{functionalBoundedNeighbourhood}.


\begin{lemma} Let $X$ be a normed space and
let $x\in X$ $\omega\in \tdual{X}$ be a bounded linear functional. Then
\begin{align*}
\norm{\omega} &= \sup\setbuilder{|\omega(v)|}{\norm{v}=1 } \\
&= \sup\setbuilder{\frac{|\omega(v)|}{\norm{v}}}{v\neq 0} \\
&= \inf\setbuilder{c>0} {|\omega(v)|\leq c\norm{v}\forall v\in X}
\end{align*}
and
\begin{align*}
\norm{x} &= \sup\setbuilder{|\varphi(x)|}{ \norm{\varphi}=1} \qquad\qquad\quad\\ %TODO: fragile spacing!
&= \sup\setbuilder{\frac{|\varphi(x)|}{\norm{\varphi}}}{\varphi\neq 0}.
\end{align*}
\end{lemma}
TODO move??
\begin{proof}
We prove the third equality. Let $\alpha$ be the infimum. Let $\epsilon>0$, then by the definition $|\omega[(\norm{x}+\epsilon)^{-1}x]|\leq \norm{\omega}$. Hence $|\omega(x)|\leq \norm{\omega}(\norm{x}+\epsilon)$. Letting $\epsilon\to 0$ gives $|\omega(x)|\leq \norm{\omega}\norm{x}$ for all $x$. So $\alpha\leq \norm{\omega}$. On the other hand, $|\omega(x)|\leq c$ for all $x$ with $\norm{x}=1$. Hence $\norm{\omega}\leq \alpha$.
\end{proof}

\subsubsection{The algebraic dual}
\begin{definition}
Let $V$ be a vector space. The \udef{algebraic dual} of $V$ is the dual of $\sSet{V,\mathfrak{a}}$, where $\mathfrak{a}$ is the algebraic convergence.

If no convergence on $V$ has been mentioned, then $V^*$ means the algebraic dual.
\end{definition}

\begin{proposition} \label{algebraicDual}
Let $V$ be a vector space. Then the algebraic dual of $V$ is the set of all linear functionals: $V^* = \Lin(V,\F)$.

Thus $V^* \supseteq \sSet{V,\xi}^*$ for all vector space convergences $\xi$ on $V$.
\end{proposition}
\begin{proof}
We need to show that all linear functionals are continuous when $V$ is equipped with the algebraic convergence. Assume $F\overset{\mathfrak{a}}{\longrightarrow} x$. Then there exists a $v\in V$ such that $\neighbourhood_\F(0)\cdot v+x \subseteq F$ and so $\neighbourhood_\F(0)\cdot f(v)+f(x) \subseteq f^\imf[F]$, meaning $f^\imf[F] \overset{\F}{\longrightarrow} f(x)$. Thus $f$ is continuous.
\end{proof}


\begin{proposition} \label{dualBasisDimension}
Let $V$ be a vector space. Then $\dim V^* \geq \dim V$ and
\[ \dim V^* = \dim V \iff \text{$V$ is finite-dimensional}. \]
If $V$ is finite-dimensional with a basis $v_1, \ldots, v_n$, then the \udef{dual basis} $\varphi_1, \ldots, \varphi_n$ is the set of linear functionals on $V$ such that
\[ \varphi_j(v_k) = \begin{cases}
1 & (k=j), \\ 0 & (k\neq j)
\end{cases}. \]
This dual basis is indeed a basis of $V^*$.
\end{proposition}
\begin{proof}
We first assume $V$ is finite-dimensional and prove the dual basis is a basis, which proves $\dim V^* = \dim V$. We then assume $V$ is infinite-dimensional and prove $\dim V^* \neq \dim V$.\footnote{Reference: \url{https://mathoverflow.net/questions/13322/slick-proof-a-vector-space-has-the-same-dimension-as-its-dual-if-and-only-if-i}}
\begin{enumerate}
\item Assume $V$ is finite-dimensional. To show the dual basis spans $V^*$, take a linear functional $\varphi$. Now define $a_i = \varphi(v_i)$. It is clear that $\varphi = \sum_{i=1}^n a_i\varphi_i$. To show linear independence, take a combination
\[ b_1\varphi_1 + \ldots +b_n\varphi_n =0. \]
Filling in all basis vectors $v_i$ in turn, gives $b_i=0$ for all $i$.
\item Assume $V$ is infinite-dimensional. At first let us assume $\dim_{\mathbb{F}}V \geq |\mathbb{F}|$. Then we can apply lemma \ref{vsCardinality} to obtain $\dim_{\mathbb{F}}V = |V|$. Let $\beta$ be a basis for $V$. The elements of $V^*$ correspond bijectively to functions from $\beta$ to $\mathbb{F}$. Thus
\[ |V^*| = |\mathbb{F}^\beta| = |\mathbb{F}|^{|\beta|} > |\beta| = |V|. \]
Now we relax the condition $\dim_{\mathbb{F}}V \geq |\mathbb{F}|$. We first note that every field contains a subfield that is at most denumerable. Take such a field $K\subset \mathbb{F}$. We introduce the new vector space $W = \Span_K(\beta)$. Every functional from $W$ to $K$ extends to a functional from $V$ to $\mathbb{F}$. Hence
\[ \dim_\mathbb{F} V = \dim_K W < \dim_K W^* \leq \dim_{\mathbb{F}} V^* \]
using $\dim_{K}W \geq |K| \geq \aleph_0$.
\end{enumerate}
\end{proof}
\begin{corollary}
Let $V$ be a finite-dimensional vector space. Then the algebraic convergence is the unique Hausdorff vector space convergence on $V$.
\end{corollary}
\begin{proof}
Consider a basis $v_1, \ldots, v_n$ of $V$ with dual basis $\varphi_1, \ldots, \varphi_n$. Let $\xi$ be some vector space convergence. By definition we have $\mathfrak{a} \subseteq \xi$. Now take $F \overset{\xi}{\longrightarrow} v$. We have $F = v_1\cdot \varphi_1^{\imf\imf}[F] + \ldots + v_n\cdot \varphi_n^{\imf\imf}[F]$. Now each $\varphi_1^{\imf\imf}[F]$ converges in both $\mathfrak{a}$ and $\xi$ by \ref{algebraicDual} and the proposition, so by continuity of addition and scalar multiplication, $F$ also converges in $\mathfrak{a}$. 
\end{proof}
\begin{corollary}
Let $\sSet{V,\xi}$ be a convergence vector space. If $V$ is finite-dimensional, then $\sSet{V,\xi}^* = \sSet{V,\mathfrak{a}}^*$.
\end{corollary}
\begin{proof}
We have $\sSet{V,\xi}^* \subseteq \sSet{V,\mathfrak{a}}^*$ by \ref{algebraicDual}. Because $V$ is finite-dimensional, we obtain equality equality of space from equality of dimension by \ref{vectorSpaceEquality}.
\end{proof}

\subsubsection{The bidual space}
TODO!
\begin{definition}
Let $V$ be a convergence vector space. The \udef{bidual space} is the dual of the dual $\abidual{V} = \adual{(\adual{V})}$.
\end{definition}
TODO continuous convergence!!

\begin{definition}
Let $V$ be a vector space over $\mathbb{F}$ and $v\in V$. The \udef{evaluation map} $\evalMap: V\to \abidual{V}: v\mapsto \evalMap_v$ is given by
\[ \evalMap_v: \adual{V} \to \mathbb{F}: l\mapsto l(v). \]
\end{definition}

\begin{lemma}
Let $V$ be a vector space. The evaluation map $\evalMap: V\to \abidual{V}: v\mapsto \evalMap_v$ is linear:
\[ \forall v,w\in V, a\in\mathbb{F}: \quad \evalMap_{av + w} = a\evalMap_v + \evalMap_w. \]
\end{lemma}
\begin{lemma}
Let $V$ be vector space over $\mathbb{F}$. The evaluation map is injective.
\end{lemma}
\begin{proof}
Assume $\evalMap_v = \evalMap_w$ for some $v,w\in V$. Then
\[ 0 = \evalMap_v - \evalMap_w  = \evalMap_{v-w}. \]
So $\forall l\in \adual{V}: \evalMap_{v-w}(l) = l(v-w) = 0$. Now define the sublinear functional by
\[ p(x) = \begin{cases}
\alpha & x = \alpha(v-w) \\
0 & \text{else}.
\end{cases} \]
Then the functional $f$ defined on $\Span\{v-w\}$ by $f(\alpha(v-w)) = \alpha$ is bounded by $p$ and can be extended to a functional on all $V$ by the Hahn-Banach theorem \ref{sublinearHahnBanach} if $v-w\neq 0$. Then $f(v-w) \neq 0$, which contradicts our assumptions. Thus $v=w$.
\end{proof}

\begin{proposition}
The mapping $\evalMap: V\to \abidual{V}: v\mapsto \evalMap_v$ is an isomorphism \textup{if and only if} $V$ is finite-dimensional.
\end{proposition}
\begin{proof}
Assume $V$ finite dimensional. As the evaluation map is injective, it is an isomorphism by \ref{invertibleFiniteDim}.
The other direction is a dimensional argument by proposition \ref{dualBasisDimension}.
\end{proof}


Just like for algebraic duality, we can define a topological bidual space (or second dual space) $\tbidual{V}$.

\begin{proposition}
Let $V$ be a normed space. 
For each $v\in V$
\[ \evalMap_v: \tdual{V} \to \mathbb{F}: \omega \mapsto \omega(v) \]
is bounded and thus an element of $\tbidual{V}$.

The evaluation map $\evalMap: V \to \tbidual{V}$ is
\begin{enumerate}
\item isometric (and thus injective): $\norm{\evalMap_v} = \norm{v}$;
\item bounded with norm $\norm{\evalMap} = 1$.
\end{enumerate}
\end{proposition}
\begin{proof}
Let $v\in V$. Then
\[ \norm{\evalMap_v} = \sup\setbuilder{\norm{\evalMap_v(\omega)}}{\norm{\omega}=1} = \sup\setbuilder{\norm{\omega(v)}}{\norm{\omega}=1} \leq \sup\setbuilder{\norm{v}\;\norm{\omega}}{\norm{\omega}=1} = \norm{v}. \]

(1) Setting $\omega = \inner{v/\norm{v}, \cdot}$, we get
\[ \norm{\evalMap_v} \leq |\evalMap_v(\omega)| = |\inner{v/\norm{v}, v}| = \norm{v}. \]
Together with the calculation above, this gives $\norm{\evalMap_v} = \norm{v}$.

(2) $\norm{\evalMap} = \sup\setbuilder{\norm{\evalMap_v}}{\norm{v}=1} = \sup\setbuilder{\norm{v}}{\norm{v}=1} = 1$.
\end{proof}

\begin{lemma}
Let $V$ be normed space over $\mathbb{F}$ and $v\in V$. For each $v\in V$
\[ \evalMap_v: \tdual{V} \to \mathbb{F}: \omega \mapsto \omega(v) \]
is bounded with norm $\norm{v}$ and thus $\evalMap\in \tbidual{V}$ with $\norm{\evalMap} = 1$.
\end{lemma}


\subsubsection{Reflexive spaces}
\begin{definition}
A normed space $V$ is \udef{reflexive} if the evaluation map $\evalMap:V\to \tbidual{V}$ is surjective:
\[ \im\evalMap = \tbidual{V}. \]
\end{definition}
If $V$ is reflexive, then $\tbidual{V}$ is isometrically isomorphic to $V$. The converse is not necessarily true.

\begin{lemma}
Every finite-dimensional space is reflexive.
\end{lemma}

\begin{proposition}
A separable normed space $X$ with a non-separable dual space $\tdual{X}$ cannot be reflexive. 
\end{proposition}
\begin{proof}
TODO
\end{proof}
Thus $l^1$ is not reflexive.

\begin{proposition}
If the dual space $\tdual{X}$ of a  normed space $X$ is separable, then $X$ itself is separable. 
\end{proposition}
\begin{proof}
TODO
\end{proof}

\subsubsection{Transposition}
\begin{definition}
Let $f:V\to W \in \Hom_{\mathbb{F}}(V,W)$. The \udef{dual map}\footnote{The dual map $f^t$ is often denoted $f^*$ or $f'$. We avoid this because it clashes with the notation of the Hilbert adjoint.} or \udef{transpose} $f^t$ is the linear map
\[ f^t:W^* \to V^*: l\mapsto f^t(l) = l\circ f. \]
\end{definition}
\begin{lemma}
Let $f\in \Hom(U,V)$ and $g\in \Hom(V,W)$.
\begin{itemize}
\item $(g\circ f)^t = f^t\circ g^t$;
\item $\id^t_V = \id_{\adual{V}}$;
\item $f$ is an isomorphism \textup{if and only if} $f^t$ is an isomorphism;
\item $(f^t)^{-1} = (f^{-1})^t$ 
\end{itemize}
\end{lemma}
TODO: merge
\begin{lemma}
Let $S,T\in\Hom(V,W)$ and $\alpha\in\mathbb{F}$. Then
\begin{enumerate}
\item $(S+T)^t = S^t+T^t$;
\item $(\alpha T)^t = \alpha T^t$
\item if $T$ is invertible, then $T^t$ is invertible and
\[ (T^t)^{-1} = (T^{-1})^t. \]
\end{enumerate}
\end{lemma}

\begin{proposition}
Let $U\subset V$ be a subspace and $T\in \Hom(V,W)$, where $V,W$ are \emph{finite-dimensional}.
\begin{enumerate}
\item $\dim\ker T^t = \dim \ker T + \dim W - \dim V$;
\item $\dim\im T^t = \dim \im T$;
\item $\im T^t = (\ker T)^0$
\item $T$ is injective \textup{if and only if} $T^t$ is surjective.
\end{enumerate}
\end{proposition}
\begin{proof}
\mbox{}
\begin{enumerate}
\item Using $\dim \adual{V} = \dim V$, we have
\begin{align*}
\dim \ker T^t &= \dim(\im T)^0 = \dim W-\dim \im T \\
&= \dim W - (\dim V - \dim \ker T) = \dim \ker T + \dim W - \dim V
\end{align*}
where the equalities come from proposition \ref{annihilatorSpace} and the dimension theorem for linear maps, theorem \ref{dimensionLinearMaps}.
\item Still using these results, we can calculate
\begin{align*}
\dim \im T^t &= \dim \adual{W} - \dim \ker T^t = \dim \adual{W} - \dim (\im T)^0 \\
&= \dim \adual{(\im T)} = \dim \im T.
\end{align*}
\item Take $\varphi = T^t(\psi) \in \im T^t$ where $\psi \in \adual{W}$. If $v\in \ker T$, then
\[ \varphi(v) = \left(T^t(\psi)\right)v = (\psi\circ T)(v) = \psi(Tv) = \psi(0) = 0. \]
Hence $\varphi \in (\ker T)^0$ and $\im T^t\subset (\ker T)^0$. We prove the equality by showing the dimensions are the same. Indeed:
\[ \dim \im T^t = \dim \im T = \dim V - \dim \ker T = \dim(\ker T)^0. \]
\item $T\in\Hom(V,W)$ is injective iff $\ker T = \{0\}$ iff $(\ker T)^0 = \adual{V}$ iff $\im T^t = \adual{V}$ iff $T^t$ is surjective.
\end{enumerate}
\end{proof}

\begin{proposition}
Let $\sSet{V,\xi}$ and $\sSet{W, \zeta}$ be CVSs and $T: V\to W$ a linear map. Then $T^t$ has a restriction to $T^t: W^* \to V^*$ \textup{if and only if} $T$ is continuous.
\end{proposition}
\begin{proof}
TODO! Only for locally convex??
\end{proof}

\begin{proposition} \label{transpDual}
Let $f\in\Hom(V,W)$ and $\mathcal{V}, \mathcal{W}$ bases of $V,W$. The
\[ (f^*)^{\mathcal{V}^*}_{\mathcal{W}^*} = ((f)^{\mathcal{W}}_{\mathcal{V}})^\transp. \] 
\end{proposition}

\begin{definition}
Let $T\in\Bounded(V,W)$. The dual map $T^t: \tdual{W}\to \tdual{V}$ is called the \udef{adjoint} or the \udef{transpose} of $T$.
\end{definition}
The notation $T^t$ is consistent for maps on both the algebraic and topological duals: if $T$ is bounded, $T^t:\adual{W}\to \adual{V}$ restricts to $T^t|_{\tdual{W}} = T^t:\tdual{W}\to \tdual{V}$.

\begin{proposition}
Let $T\in\Bounded(V,W)$. Then the transpose $T^t$ is a bounded operator in $\Bounded(W,V)$ with $\norm{T^t} = \norm{T}$.
\end{proposition}
\begin{proof}
The operator $T^t$ is linear since $\forall f_1,f_2\in \tdual{W}, \forall a\in\mathbb{F}, \forall x\in V:$
\[ (T^t(af_1 + f_2))(x) = (af_1 + f_2)(Tx) = af_1(Tx) + f_2(Tx) = a(T^tf_1)(x) + (T^tf_2)(x). \]
For the equality of norms, we prove two inequalities. First $\forall x\in V, f\in \tdual{W}$
\[ |f(Tx)|\leq \norm{f}\norm{Tx}\leq \norm{f}\norm{x}\norm{T} \implies \frac{|f(Tx)|}{\norm{x}} \leq \norm{f}\norm{T}. \]
taking the supremum over $x\in V$, we get $\norm{T^tf} = \norm{f\circ T}\leq \norm{f}\norm{T}$ and taking the supremum over $f\in \tdual{W}$ gives $\norm{T^t}\leq \norm{T}$. This shows that $T^t$ is bounded.

For the other inequality, we use corollary \ref{existenceBoundedFunctionalOfSameNorm} to the Hahn-Banach theorem: for every $x\in V$, there exists a bounded functional $\omega_x$ such that $\norm{\omega_x}=1$ and $\omega_x(x) = \norm{x}$. Then we can calculate:
\begin{align*}
\norm{Tx} = \omega_{Tx}(Tx) = (T^t\omega_{Tx})(x) \leq \norm{T^t\omega_{Tx}}\norm{x} \leq \norm{T^t}\norm{\omega_{Tx}}\norm{x} = \norm{T^t}\norm{x}
\end{align*}
So $\norm{T}\leq\norm{T^t}$. Combining gives $\norm{T^t}=\norm{T}$.
\end{proof}
\begin{corollary}
The map $T\mapsto T^t$ is an isometric isomorphism in $(\Bounded(X,Y)\to \Bounded(\tdual{Y}, \tdual{X}))$.
\end{corollary}

\begin{lemma}
Let $S,T\in\Bounded(V,W)$ and $\alpha\in\mathbb{F}$. Then
\begin{enumerate}
\item $(S+T)^t = S^t+T^t$;
\item $(\alpha T)^t = \alpha T^t$
\item if $T$ is invertible, then $T^t$ is invertible and
\[ (T^t)^{-1} = (T^{-1})^t. \]
\end{enumerate}
Let $T\in\Bounded(U,V)$ and $S\in\Bounded(V,W)$. Then
\begin{enumerate}
\setcounter{enumi}{3}
\item $(ST)^t = T^tS^t$
\end{enumerate}
\end{lemma}


\subsection{Annihilator subspace}
\begin{definition}
Let $U\subset V$ be a subspace. The \udef{annihilator} of $U$, denoted $U^0$, is the set of functionals that are identically zero on $U$:
\[ U^0 = \left\{ \varphi\in V^*\;|\; \forall u\in U:\varphi(u) = 0 \right\}. \]
\end{definition}
\begin{proposition} \label{annihilatorSpace}
Let $U\subset V$ be a subspace and $T\in \Hom(V,W)$.
\begin{enumerate}
\item $U^0$ is a subspace of $\adual{V}$;
\item $\dim \adual{U} + \dim U^0 = \dim \adual{V}$;
\item $\ker T^t = (\im T)^0$
\item $T$ is surjective \textup{if and only if} $T^t$ is injective.
\end{enumerate}
\end{proposition}
\begin{proof}
\mbox{}
\begin{enumerate}
\item Elementary application of subspace criterion, proposition \ref{subspaceCriterion}.
\item Consider the inclusion $\iota: U\hookrightarrow V$. Then the dimension theorem \ref{dimensionLinearMaps} applied to $\iota'$ gives
\[ \dim \im \iota' + \dim \ker\iota' = \dim V^*. \]
Now $\dim \ker\iota'$ are $\varphi\in V^*$ such that $\varphi \circ \iota = 0$. These are exactly the elements of the annihilator. Any functional on $U$ can be extended to a functional on $V$, so $\iota'$ is surjective and $\dim \im \iota' = \dim U^*$.
\item There are two inclusions. First assume $\varphi \in \ker T'$, so $\forall v\in V$
\[ 0 = (\varphi\circ T)(v) = \varphi(Tv). \]
Thus $\varphi\in(\im T)^0$. The other inclusion uses the same equality.
\item $T\in\Hom(V,W)$ is surjective iff $\im T = W$ iff $(\im T)^0 = \{0\}$ iff $\ker T' = \{0\}$ iff $T'$ is injective.
\end{enumerate}
\end{proof}



\subsection{Real functionals}
\begin{definition}
Let $V$ be a real or complex vector space. Let $f: V\to \R$ be a real functional. We say
\begin{itemize}
\item $f$ is \udef{subadditive} or satisfies the \udef{triangle inequality} if $\forall x,y\in V: f(x+y) \leq f(x) + f(y)$;
\item $f$ is \udef{quasi-subadditive} if $\exists K>0: \forall x,y\in V: f(x+y) \leq K\big(f(x) + f(y)\big)$;
\item $f$ is \udef{point-separating} if $\forall x\in V: f(x) = 0 \implies x = 0$;
\item $f$ is \udef{convex} if $\forall x,y\in V, \lambda\in[0,1]: f(\lambda x + (1-\lambda)y) \leq \lambda f(x) + (1-\lambda)f(y)$.
\end{itemize}
We call $f$
\begin{itemize}
\item \udef{sublinear} if it is subadditive and positively homogeneous;
\item a \udef{seminorm} if it is subadditive and absolutely homogeneous;
\item a \udef{quasi-seminorm} if it is quasi-subadditive and absolutely homogeneous;
\item a \udef{norm} is a point-separating seminorm;
\item a \udef{quasi-norm} is a point-separating quasi-seminorm.
\end{itemize}
\end{definition}

TODO general valued fields.

\begin{lemma}
Let $V$ be a real or complex vector space and $f: V\to \R$ be a real functional. Then
\begin{enumerate}
\item absolute homogeneity $\implies$ positive homogeneity;
\item subadditivity $\implies$ quasi-subadditivity;
\item subadditivity+positive homogeneity $\implies$ convexity $\implies$ subadditivity.
\end{enumerate}
\end{lemma}
Thus norms and seminorms are sublinear.

\begin{lemma} \label{seminormPositivity}
Let $f:V\to \R$ be a quasi-seminorm. Then $\im(f)\subseteq \R^+$.
\end{lemma}
Thus (quasi)-seminorms are often considered as function in $V\to \R^+$.
\begin{proof}
For all $v\in V$ we have $0 = f(v-v) \leq K\big(f(v)+f(-v)\big) = 2Kf(v)$, so $f(v) \geq 0$.
\end{proof}

\begin{proposition}[Reverse triangle inequality] \label{reverseTriangleInequality}
Let $V$ be a vector space and $\norm{\cdot}: V\to \R$ a function that satisfies the triangle inequality and has $\norm{-v} = \norm{v}$ for all $v\in V$. Then $\forall v,w\in V$:
\begin{enumerate}
\item $|\norm{v}-\norm{w}|\leq \norm{v-w}$;
\item $|\norm{v}-\norm{w}|\leq \norm{v+w}$.
\end{enumerate}
In particular this holds if $\norm{\cdot}$ is a norm or seminorm.
\end{proposition}
\begin{proof}
We calculate $\norm{v} = \norm{v-w+w} \leq \norm{v-w} + \norm{w}$, so $\norm{v}-\norm{w}\leq \norm{v-w}$. By swapping $v\leftrightarrow w$ we also get $-\norm{v}+\norm{w}\leq \norm{w-v} = \norm{v-w}$ and thus the first inequality is established.

For the second inequality, set $w\to -w$ and use $\norm{-w} = \norm{w}$.
\end{proof}

\subsubsection{Extended real functionals}
\begin{definition}
Let $V$ be a real or complex vector space. An \udef{extended real functional} is a function $V \to \overline{\R}$.
\end{definition}

\begin{lemma} \label{realPartExtendedRealFunctional}
Let $V$ be a real or complex vector space and $f: V\to \overline{\R}$ an extended real functional. If $f$ is a quasi-seminorm and there exists $v\in V$ such that $f(v)\in\R$, then $f^{\preimf}(\R)$ is a subspace of $V$. 
\end{lemma}
\begin{proof}
We verify the subspace criteria (\ref{subspaceCriterion}). 

By assumption, $f^{\preimf}(\R)$ is not empty.

Take $v,w\in f^{\preimf}(\R)$. As $\im(f) \subseteq \overline{\R}^+$ by \ref{seminormPositivity}, we have $0\leq f(v+w)$. Also $f(v+w)\leq K\big(f(v)+f(w)\big)\in \R$. Thus $f(v+w)\in\R$.

Take $\lambda\in\F$. Then $f(\lambda v) = |\lambda|f(v)\in \R$.
\end{proof}

\subsubsection{Epigraphs}
\begin{definition}
Let $V$ be a vector space and $f: V\to \R$ a real functional on $V$. Then \udef{epigraph} of $f$ is defined as
\[ \epigraph(f) \defeq \setbuilder{(v,r)\in V\times \R}{f(v)\leq r}. \]
\end{definition}

\begin{lemma} \label{epigraphLemma}
Let $V$ be a vector space and $f: V\to \R$ a real functional on $V$. Then for all $v\in V$:
\[ f(v) = \inf\setbuilder{r}{(v,r)\in \epigraph(f)}. \]
\end{lemma}

\begin{proposition}
Let $V$ be a real vector space and $f: V\to \R$ a functional. Then
\begin{enumerate}
\item $f$ is convex \textup{if and only if} $\epigraph(f)$ is a convex subset of $V\oplus \R$;
\item $f$ is positively homogeneous \textup{if and only if} $\epigraph(f)$ is a cone in $V\oplus \R$.
\end{enumerate}
\end{proposition}
\begin{proof}
(1) First assume $f$ convex and pick $(v, s), (w,t)\in \epigraph(f)$ and $\lambda\in [0,1]$. Then we need to show that $(\lambda v + (1-\lambda)w, \lambda s + (1-\lambda)t) \in \epigraph(f)$. This is equivalent to saying $f(\lambda v + (1-\lambda)w) \leq \lambda s + (1-\lambda)t$. Indeed we have $f(\lambda v + (1-\lambda)w) \leq \lambda f(v) + (1-\lambda)f(w) \leq \lambda s + (1-\lambda)t$ by the convexity of $f$.

Conversely, assume $\epigraph(f)$ convex. Then $(v, f(v)), (w,f(w))\in \epigraph(f)$, $(\lambda v + (1-\lambda)w, \lambda f(v) + (1-\lambda)f(w)) \in \epigraph(f)$ for all $\lambda\in [0,1]$. This implies $f(\lambda v + (1-\lambda)w) \leq \lambda f(v) + (1-\lambda)f(w)$.

(2) First assume $f$ is positively homogeneous, take $(v,s)\in \epigraph(f)$ and $r>0$. Then we need to show that $r(v,s) = (rv,rs)\in \epigraph(f)$. This follows because of the implications $f(v)\leq s \implies rf(v) \leq rs \implies f(rv) \leq rs$.

Conversely, assume that $\epigraph(f)$ is a cone. Then $\lambda\cdot \epigraph(f) = \epigraph(f)$ for all $\lambda>0$ by \ref{coneEqualityLemma}. We then calculate using \ref{epigraphLemma}:
\begin{align*}
f(\lambda v) &= \inf\setbuilder{r}{(\lambda v,r)\in \epigraph(f)} \\
&= \inf\setbuilder{r}{(\lambda v,r)\in \lambda\cdot\epigraph(f)} \\
&= \inf\setbuilder{r}{\lambda(v,\lambda^{-1}r)\in \lambda\cdot\epigraph(f)} \\
&= \inf\setbuilder{r}{(v,\lambda^{-1}r)\in \epigraph(f)} \\
&= \inf\setbuilder{\lambda r}{(v,r)\in \epigraph(f)} = \lambda f(v).
\end{align*} 
\end{proof}
\begin{corollary}
A functional on a real vector space is sublinear \textup{if and only if} its epigraph is a convex cone.
\end{corollary}

\subsubsection{Convex functionals}

\begin{proposition}
Let $p: V\to\R$ be convex functional. Then
\[ P: V\to\R: x\mapsto \inf_{t>0} t^{-1}p(tx) \]
is sublinear and $P(x)\leq p(x)$.

Also, if $f:V\to \R$ is a linear functional, then $f\leq p \iff f\leq P$.
\end{proposition}
\begin{proof}
For sublinearity: let $x,y\in V$, then for all $s,t>0$
\[ P(x+y) \leq \frac{s+t}{st}p\left(\frac{st}{s+t}(x+y)\right) = \frac{s+t}{st}p\left(\frac{s}{s+t}(tx)+\frac{t}{s+t}(sy)\right) \leq t^{-1}p(tx) + s^{-1}p(sy). \]
This implies that $P(x+y)\leq P(x)+P(y)$.

For positive homogeneity: let $x\in V,\lambda\geq 0$
\[ P(\lambda x) = \inf_{t>0} t^{-1}p(t\lambda x) = \inf_{t\lambda>0} \lambda (t\lambda)^{-1}p(t\lambda x) = \inf_{t>0} \lambda (t)^{-1}p(tx) = \lambda P(x). \]

Finally we prove that $f\leq p \implies f\leq P$ for linear functionals $f$. For all $t>0$ we have $f(tx) \leq p(tx)$, which implies $f(x) = t^{-1}f(tx) \leq t^{-1}p(tx) \leq P(x)$. So $f\leq P$.
\end{proof}

\subsubsection{Sublinear functionals}

\begin{lemma}
Let $V$ be a \emph{real} vector space and $f: V \to \R$ a sublinear functional. Then $f': V\to \R: x\mapsto \max\{f(x), f(-x)\}$ is a seminorm.
\end{lemma}
We call the seminorm $f'$ the \udef{associated seminorm} of the sublinear functional.
\begin{proof}
Take arbitrary $x,y\in V$ and $a\in \R$

For subadditivity, we have
\begin{align*}
f'(x+y) &= \max\{f(x+y), f(-x-y)\} \\
&\leq \max\{f(x)+f(y), f(-x)+ f(-y)\} \\
&\leq \max\{f(x)+f(y), f(-x)+ f(-y), f(x) + f(-y), f(-x) + f(y)\} \\
&= \max\{f(x), f(-x)\} + \max\{f(y), f(-y)\} \\
&= f'(x) + f'(y).
\end{align*}

For absolute homogeneity, we have,
\begin{align*}
f'(ax) &= \begin{cases}
f'(|a|x) & (a \geq 0) \\ f'(-|a|x) & (a < 0)
\end{cases} \\
&= \begin{cases}
\max\{f(|a|x), f(-|a|x)\} & (a \geq 0) \\ \max\{f(-|a|x), f(|a|x)\} & (a < 0)
\end{cases} \\
&= \max\{|a|f(x), |a|f(-x)\} = |a|f'(x).
\end{align*}
\end{proof}

\begin{lemma} \label{superSubtractiveContinuityEverywhere}
Let $\sSet{V, \xi}$ be a convergence vector space and $f: V\to \R$ a function such $f(0) = 0$ and $|f(v) - f(w)| \leq \max\{|f(v-w)|, |f(w-v)|\}$ for all $v,w\in V$.

Then continuity of $f$ at $0$ implies continuity everywhere.
\end{lemma}
\begin{proof}
Take arbitrary $F\overset{\xi}{\longrightarrow} u$. Then $F-u \to 0$, so $|f^{\imf\imf}(F-u)|\to 0$ by continuity at $0$. Similarly $|f^{\imf\imf}(u-F)|\to 0$. Then, by assymption, $|f^{\imf\imf}(F) - f(u)| \leq \max\{|f^{\imf\imf}(F-u)|, |f^{\imf\imf}(u-F)|\} \to 0$, so $|f^{\imf\imf}(F) - f(u)| \to 0$, by TODO ref squeeze theorem. We conclude that $f^{\imf\imf}(F)\to f(u)$.
\end{proof}

\begin{proposition} \label{sublinearContinuity}
Let $\sSet{V,\xi}$ be a convergence vector space and $f: V\to \R$ a sublinear functional. Then the following are equivalent:
\begin{enumerate}
\item $f$ is continuous;
\item $f$ is continuous at $0$;
\item $f$ is bounded on some $U\in\vicinity_\xi(0)$.
\end{enumerate}
\end{proposition}
\begin{proof}
The implication $(1) \Rightarrow (2)$ is immediate. 

The implication $(2) \Rightarrow (1)$ follows from \ref{superSubtractiveContinuityEverywhere}: 
for arbitrary $v,w\in V$, we have $f(v) = f(v-w+w) \leq f(v-w) + f(w)$, so $f(v) - f(w) \leq f(v-w)$. Similarly $f(w) - f(v) \leq f(w-v)$, so
\begin{align*}
|f(v) - f(w)| &= \max\{f(v) - f(w), f(w) - f(v)\} \\
&\leq \max\{f(v-w), f(w-v)\} \\
&\leq \max\{|f(v-w)|, |f(w-v)|\}.
\end{align*}

The equivalence $(2) \Leftrightarrow (3)$ is given by \ref{continuityToNormedSpace}.
\end{proof}
\begin{corollary} \label{continuityAbsFunctional}
Let $\sSet{V,\xi}$ be a convergence vector space and $f: V\to \R$ a \emph{linear} functional. Then $|f|$ is continuous \textup{if and only if} $f$ is continuous.
\end{corollary}
\begin{proof}
The functional $|f|$ is sublinear and bounded on the same sets as $f$. We can then compare the proposition to \ref{continuityToNormedSpace}.
\end{proof}

\subsubsection{Gauges}
\begin{definition}
Let $V$ be a vector space and $A\subseteq V$ an absorbent subset. The function
\[ p_A: V\to \overline{\R^+}: v\mapsto \inf\setbuilder{\lambda\in \R^{\geq 0}}{v\in \lambda A} \]
is called the \udef{gauge} or \udef{Minkowski functional} of $A$.
\end{definition}

\begin{lemma}
Let $V$ be a vector space and $A,B\subseteq V$. Then
\begin{enumerate}
\item if $A$ absorbs $B$, then $p_A^\imf(B)$ is bounded;
\item if $A$ is balanced and $p_A^\imf(B)$ is bounded, then $A$ absorbs $B$.
\end{enumerate}
\end{lemma}
\begin{proof}
(1) Assume $A$ absorbs $B$. Then there exists $r >0$ such that $B\subseteq cA$ for all $|c|\geq r$. In particular $v\in rA$, so $p_A(v) \leq r$, for all $v\in B$. Thus $p_A^\imf(B)$ is bounded by $r$.

(2) Assume $p_A^\imf(B)$ is bounded. Then we can find an upper bound $s>0$. Take $|c|\geq s$ arbitrarily. We need to show that $B\subseteq cA$.

For all $v\in B$, we can find some $\lambda \leq s$ such that $v\in\lambda A = c\left(\frac{\lambda}{c}\right)A \subseteq cA$. The last inclusion follows because $A$ is balanced and $\left|\frac{\lambda}{c}\right|\leq 1$ (as $\lambda \leq s \leq |c|$).
\end{proof}
\begin{corollary} \label{gaugeWellDefined}
Let $V$ be a vector space and $A\subseteq V$. Then
\begin{enumerate}
\item if $A$ is absorbent, then $p_A(v)$ is finite for all $v\in V$;
\item if $A$ is balanced and $p_A(v)$ is finite for all $v\in V$, then $A$ is absorbent.
\end{enumerate}
\end{corollary}

\begin{lemma} \label{gaugeScaling}
Let $V$ be a vector space and $A\subseteq V$ an absorbent subset. For all $v\in V$ and $t\geq 0$:
\[ p_A(tv) = p_{t^{-1}A}(v) = t p_A(v). \]
Thus $p_A$ is positively homogeneous.
\end{lemma}
\begin{proof}
We calculate
\begin{align*}
p_A(tv) &= \inf\setbuilder{\lambda\in \R^{\geq 0}}{tv\in \lambda A} \\
&= \inf\setbuilder{\lambda\in \R^{\geq 0}}{v\in t^{-1}\lambda A} = p_{t^{-1}A}(v) \\
&= \inf\setbuilder{t\lambda\in \R^{\geq 0}}{v\in \lambda A} \\
&= t\inf\setbuilder{\lambda\in \R^{\geq 0}}{v\in \lambda A} = tf(v).
\end{align*}
\end{proof}

\begin{lemma} \label{semibalancedClosureGauge}
Let $V$ be a vector space and $A\subseteq V$ an absorbent subset. Then $p_A = p_{\semibalanced(A)}$.
\end{lemma}
\begin{proof}
We calculate
\begin{align*}
\setbuilder{\lambda\in\R^{\geq 0}}{v\in \lambda \semibalanced(A)} &= \setbuilder{\lambda\in\R^{\geq 0}}{v\in \lambda\cdot\interval{0,1}\cdot A} \\
&= \setbuilder{\lambda\in\R^{\geq 0}}{\exists k\in \interval{0,1}:\; v\in \lambda k\cdot A} \\
&= \setbuilder{\lambda\in\R^{\geq 0}}{\exists \lambda'\leq \lambda:\; v\in \lambda' \cdot A} \\
&= \upset \setbuilder{\lambda'\in\R^{\geq 0}}{v\in \lambda' \cdot A}.
\end{align*}
Thus the infima of both $\setbuilder{\lambda\in\R^{\geq 0}}{v\in \lambda \semibalanced(A)}$ and $\setbuilder{\lambda'\in\R^{\geq 0}}{v\in \lambda' \cdot A}$ are the same.
\end{proof}

\begin{lemma} \label{gaugeLemma}
Let $V$ be a vector space, $A\subseteq V$ an absorbent subset and $\lambda\in \R^{> 0}$. Then
\begin{enumerate}
\item if $A$ is semibalanced, then $p_A(v) < \lambda \implies \lambda^{-1}v\in A$;
\item $\lambda^{-1}v\in A \implies p_A(v) \leq \lambda$;
\item $p_A^{\preimf}[\ball(0,1)] \;\subseteq\; \semibalanced(A) \;\subseteq\; p_A^{\preimf}[\cball(0,1)]$;
\item $\frac{v}{p_A(v)+\epsilon} \in \semibalanced(A)$ for all $v\in V$ and $\epsilon >0$.
\end{enumerate}
\end{lemma}
\begin{proof}
(1) If $p_A(v) < \lambda$, then there exists $\lambda' \leq \lambda$ such that $v\in \lambda' A$. As we can write $\lambda' = k\lambda$ for some $k\in\interval{0,1}$, we have
\[ v\in \lambda k A \subseteq \lambda \cdot \interval{0,1}\cdot A = \lambda A, \]
where we have used that $A = \semibalanced(A) = \interval{0,1}\cdot A$. Thus $\lambda^{-1}v \in A$.

(2) Assume $\lambda^{-1}v \in A$. Then $v\in \lambda A$, so we immediately have $p_A \leq \lambda$.

(3) This follows from (1), the fact that $p_A(v) < p_A(v) + \epsilon$ and the fact that $p_A = p_{\semibalanced(A)}$, \ref{semibalancedClosureGauge}.
\end{proof}

\begin{lemma} \label{gaugeClassificationLemma}
Let $V$ be a vector space, $f: V\to \R^{\geq 0}$ a positively homogeneous function and $A \subseteq V$ a semibalanced subset.
Then the following are equivalent:
\begin{enumerate}
\item $f = p_A$;
\item $f^{\preimf}[\ball(0,1)] \subseteq A \subseteq f^{\preimf}[\cball(0,1)]$.
\end{enumerate}
\end{lemma}
\begin{proof}
$(1) \Rightarrow (2)$ We calculate, using \ref{gaugeLemma},
\begin{align*}
x\in p_{A}^\preimf[\ball(0,1)] \iff& p_{A}(x) < 1 \\
\implies& x\in A \\
\implies& p_{A}(x) \leq 1 \\
\iff& x\in p_{A}^\preimf[\cball(0,1)].
\end{align*}
Reformulating in terms of sets gives the result.

$(2) \Rightarrow (1)$ We calculate, for arbitrary $v\in V$,
\[ \begin{aligned}
p_A(v) &= \inf\setbuilder{\lambda\in \R^{\geq 0}}{v\in \lambda A} \\
&\leq \inf\setbuilder{\lambda\in \R^{\geq 0}}{v\in \lambda f^{\preimf}[\ball(0,1)]} \\
&= \inf\setbuilder{\lambda\in \R^{\geq 0}}{v\in f^{\preimf}[\ball(0,\lambda)]} \\
&= \inf\setbuilder{\lambda\in \R^{\geq 0}}{f(v) < \lambda} = f(v)
\end{aligned} \quad\text{and}\quad \begin{aligned}
p_A(v) &= \inf\setbuilder{\lambda\in \R^{\geq 0}}{v\in \lambda A} \\
&\geq \inf\setbuilder{\lambda\in \R^{\geq 0}}{v\in \lambda f^{\preimf}[\cball(0,1)]} \\
&= \inf\setbuilder{\lambda\in \R^{\geq 0}}{v\in f^{\preimf}[\cball(0,\lambda)]} \\
&= \inf\setbuilder{\lambda\in \R^{\geq 0}}{f(v) \leq \lambda} = f(v).
\end{aligned} \]
We conclude that $f(v) = p_A(v)$.
\end{proof}

\begin{proposition} \label{gaugeClassification}
Let $V$ be a vector space and $f: V\to \R^{\geq 0}$ a function.
Then the following are equivalent:
\begin{enumerate}
\item $f$ is positively homogenous;
\item $f = p_A$ for some semibalanced, absorbent subset $A$.
\end{enumerate}
\end{proposition}
\begin{proof}
Assume $f$ positively homogeneous. Then we can set $A = f^{\preimf}[\ball(0,1)]$ in \ref{gaugeClassificationLemma} because $f^{\preimf}[\ball(0,1)]$ is semibalanced. Indeed
\[ \interval{0,1}\cdot f^{\preimf}[\ball(0,1)] = f^{\preimf}[\interval{0,1}\cdot\ball(0,1)] = f^{\preimf}[\ball(0,1)]. \]

The converse is given by \ref{gaugeScaling}.
\end{proof}

\begin{lemma} \label{gaugeZeroLemma}
Let $V$ be a vector space, $A\subseteq V$ an absorbent subset and $a\in A$. If there exists a subspace $U\subseteq A$ such that $a\in U$, then $p_A(a) = 0$.
\end{lemma}
\begin{proof}
For all $\epsilon > 0$, $\epsilon^{-1}a\in A$, so $a\in \epsilon A$.
\end{proof}

\begin{proposition} \label{gaugeProperties}
Let $V$ be a vector space and $A\subseteq V$ an absorbent subset. Then
\begin{enumerate}
\item $p_A$ is absolutely homogenous if $A$ is balanced;
\item $p_A$ is sublinear if $A$ is convex;
\item $p_A$ is point-separating if $A$ is balanced and contains only the trivial subspace.
\end{enumerate}
\end{proposition}
\begin{proof}
(1) By \ref{balancedLemma} we have $\mu A = |\mu| A$ and thus
\begin{align*}
p_A(\mu\cdot v) &= \inf\setbuilder{\lambda\in \R^{\geq 0}}{\mu\cdot v\in \lambda A} = \inf\setbuilder{\lambda\in \R^{\geq 0}}{v\in \frac{\lambda}{\mu} A} \\
&= \inf\setbuilder{\lambda\in \R^{\geq 0}}{v\in \frac{\lambda}{|\mu|} A} = \inf\setbuilder{|\mu|\lambda\in \R^{\geq 0}}{v\in \lambda A} = |\mu|\cdot p_A(v).
\end{align*}

(2) We just need to show subadditivity. Positive homogeneity is automatic by \ref{gaugeScaling}. Take $v,w\in V$. Now take arbitrary $\epsilon > 0$, so $(p_A(v)+\epsilon)^{-1}v \in A$ and $(p_A(w)+\epsilon)^{-1}w \in A$ by \ref{gaugeLemma} (as $A$ is semibalanced by \ref{convexAbsorbentImpliesSemibalanced}). By convexity of $A$, we have
\[ \frac{v+w}{p_A(v)+p_A(w)+2\epsilon} = \frac{p_A(v)+\epsilon}{p_A(v)+p_A(w)+2\epsilon}(p_A(v)+\epsilon)^{-1}v + \frac{p_A(w)+\epsilon}{p_A(v)+p_A(w)+2\epsilon}(p_A(w)+\epsilon)^{-1}w \in A. \]
By \ref{gaugeLemma} this means $p_A(v)+p_A(w)+2\epsilon \geq p_A(v+w)$ and because $\epsilon$ was arbitrary, we conclude that $p_A(v+w) \leq p_A(v)+p_A(w)$.

(3) Assume $A$ contains only the trivial subspace. Then for all $v\in V$ there exists some $\lambda\in \F$ such that $\lambda\cdot v\notin A$. Now for all $|c|\geq |\lambda|$, $c\cdot v\notin A$ because $A$ is balanced. Then $p_A(2\lambda\cdot v) \neq 0$ and because $p_A$ is absolutely homogeneous we have $p_A(v) = (2\lambda)^{-1}p_A(2\lambda\cdot v) \neq 0$.
\end{proof}
\begin{corollary}
The gauge of an absolutely convex and absorbent subset is a seminorm. If the subset contains only the trivial subspace, then the gauge is a norm.
\end{corollary}

\begin{proposition} \label{continuityConvexGauge}
Let $\sSet{V, \xi}$ be a convergence vector space and $A\subseteq V$ a convex, absorbent subset. Then $p_A: \sSet{V,\xi} \to \F$ is continuous \textup{if and only if} $A\in\vicinity_\xi(0)$.
\end{proposition}
\begin{proof}
First assume $A\in\vicinity_\xi(0)$. By \ref{gaugeProperties}, we have that $p_A$ is sublinear. By \ref{gaugeClassificationLemma}, we have that $A \subseteq p_A^\preimf[\cball(0,1)]$ and thus that $p_A$ is bounded on $A$. Then $p_A$ is continuous by \ref{sublinearContinuity}.

Now assume $p_A$ continuous. Then $\ball(0,1) \in \neighbourhood_\F(0) = \neighbourhood_\F(p_A(0))$, so $p_A^\preimf[\ball(0,1)] \in \vicinity_\xi(0)$ by \ref{continuityVicinityFilter}. By \ref{gaugeClassificationLemma} (using the fact that $A$ is semibalanced, \ref{convexSemibalanced}), $p_A^\preimf[\ball(0,1)] \subseteq A$, so $A\in\vicinity_\xi(0)$.
\end{proof}
\begin{corollary} \label{gaugeContinuousAlgebraicConvergence}
Let $V$ be a vector space. Then $p_A: \sSet{V,\mathfrak{a}} \to \F$ is continuous for any convex, absorbent subset $A \subseteq V$.
\end{corollary}
\begin{proof}
By \ref{coreProperties}, we have $0\in\inh_\mathfrak{a}(A)$. Then $A\in \vicinity_\mathfrak{a}(0)$ by \ref{principalAdherenceInherence}.
\end{proof}

\begin{lemma} \label{absoluteFunctionalGauge}
Let $\sSet{V, \xi}$ be a convergence vector space and $f: V\to \F$ a linear functional. Then $f$ is continuous \textup{if and only if} $|f| = p_K$ for some $K\in\vicinity_\xi(0)$.
\end{lemma}
\begin{proof}
We have that $|f|$ is positively homogeneous. Set $K \defeq |f|^{\preimf}[\ball(0,1)] = |f|^{\preimf}(\interval[o]{0,1})$. Then $|f| = p_{K}$, by \ref{gaugeClassificationLemma}. 

First assume $f$ is continuous. Then $p_K^\preimf\big[\ball(0,1)\big] = K$ is in $\vicinity_\xi(0)$ by \ref{continuityVicinityFilter}.

Now assume $K\in\vicinity_\xi(0)$. As $K \subseteq p_K^\preimf\big[\cball(0,1)\big]$ (\ref{gaugeClassificationLemma}), we have that $|f|$ is bounded on $K$. It is also sublinear and thus continuous by \ref{sublinearContinuity}.
\end{proof}


\begin{proposition} \label{gaugeInherenceAdherence}
Let $V$ be a vector space and $A\subseteq V$ an absorbent semibalanced subset. Then
\begin{enumerate}
\item $\inh_\mathfrak{a}(A) \subseteq p_A^{\preimf}[\ball(0,1)]$;
\item $p_A^{\preimf}[\cball(0,1)] \subseteq \adh_\mathfrak{a}(A)$.
\end{enumerate}
The inclusions are equalities if $A$ is convex.
\end{proposition}
\begin{proof}
(1) Take $x\in \inh_\mathfrak{a}(A)$. Then by \ref{constructionsInAlgebraicConvergence}, there exists $\Gamma\in\neighbourhood_\F(0)$ such that $v+\Gamma\cdot v = (1 + \Gamma)\cdot v \subseteq A$. There exists $\lambda \in 1 + \Gamma$ that is real and strictly less than $1$. Thus $p_A(x) <1$, meaning $x\in p^\preimf_A\big(\ball(0,1)\big)$.

(Convex) For the other inclusion we use that $p_A$ is continuous by \ref{gaugeContinuousAlgebraicConvergence}. By \ref{adherenceInherenceContinuity} and \ref{gaugeClassificationLemma} we have
\[ p_A^{\preimf}[\ball(0,1)] = p_A^{\preimf}\Big[\interior_\F\big(\ball(0,1)\big)] \subseteq \inh_\mathfrak{a}\big(p_A^{\preimf}[\ball(0,1)]\big) \subseteq \inh_\mathfrak{a}(A). \]

(2) Take $x\in p^\preimf_A\big(\cball(0,1)\big)$, which means that $p_A(x) \leq 1$, so $p_A(x) < 1+\epsilon$ for all $\epsilon > 0$. By \ref{gaugeLemma}, $(1+\epsilon)^{-1}x = x - \epsilon(1+\epsilon)^{-1}x \in A$. Because $\frac{\epsilon}{1+\epsilon} < \epsilon$, we have $x - \epsilon(1+\epsilon)^{-1}x \in x + \ball(0,\epsilon)\cdot x$ and so $x + \ball(0,\epsilon)\cdot x \mesh A$.

Now for all $\Gamma\in\neighbourhood_\F(0)$, we have $\ball(0,\epsilon) \subseteq \Gamma$ for some $\epsilon >0$. Thus $x+ \Gamma\cdot x \mesh A$ and $x\in\adh_\mathfrak{a}(A)$ by \ref{constructionsInAlgebraicConvergence}.

(Convex) For the other inclusion we again use that $p_A$ is continuous by \ref{gaugeContinuousAlgebraicConvergence}. From \ref{gaugeClassificationLemma} we have $A \subseteq p^\preimf_A\big(\cball(0,1)\big)$. Thus, by \ref{adherenceInherenceContinuity},
\[ \adh_\mathfrak{a}(A) \subseteq \adh_\mathfrak{a}\Big(p^\preimf_A\big(\cball(0,1)\big)\Big) \subseteq p_A^\preimf\big(\overline{\cball(0,1)}\big) = p^\preimf_A\big(\cball(0,1)\big). \]
\end{proof}

\begin{example}
TODO square with corner missing.
\end{example}



\begin{proposition} \label{gaugeConstructions}
Let $V$ be a vector space and $A,B\subseteq V$ semibalanced subsets. Then
\begin{enumerate}
\item the gauge of $A\cap B$ is $\max\{p_A, p_B\}$;
\item if $A\subseteq B$, then $p_B \leq p_A$;
\item if $p_B \leq p_A$ and $A$ is convex, then $\adh_\mathfrak{a}(A) \subseteq \adh_\mathfrak{a}(B)$.
\end{enumerate}
\end{proposition}
\begin{proof}
(1) Clearly $p_A \leq p_{A\cap B}$:
\begin{align*}
p_A(v) &= \inf\setbuilder{\lambda\in\R^{\geq 0}}{v\in \lambda A} \\
&\leq \setbuilder{\lambda\in\R^{\geq 0}}{v\in \lambda (A\cap B)} \\
&= p_{A\cap B}(v).
\end{align*}
Similarly $p_B \leq p_{A\cap B}$. Thus $\max\{p_A, p_B\} \leq p_{A\cap B}$.

For the other inequality we use \ref{gaugeLemma}: take $v\in V$ and arbitrary $\epsilon > 0$. Then $\max\{p_A(v)+\epsilon, p_B(v)+\epsilon\} > p_A(v)$, so $\max\{p_A(v)+\epsilon, p_B(v)+\epsilon\}^{-1}v\in A$. Similarly $\max\{p_A(v)+\epsilon, p_B(v)+\epsilon\}^{-1}v\in B$. Thus $\max\{p_A(v)+\epsilon, p_B(v)+\epsilon\}^{-1}v \in A\cap B$ and finally $p_{A\cap B}(v) \leq \max\{p_A(v)+\epsilon, p_B(v)+\epsilon\}$. Taking the limit $\epsilon \to 0$, we have $p_{A\cap B} \leq \max\{p_A, p_B\}$.

(2) First assume $A\subseteq B$. Then $\frac{v}{p_A(v)+\epsilon}\in A$ by \ref{gaugeLemma}, for all $\epsilon >0$. Then $\frac{v}{p_A(v)+\epsilon}\in B$, so $p_B(v) \leq p_A(v)+\epsilon$ (again by \ref{gaugeLemma}). Taking the limit $\epsilon\to 0$ yields the result.

(3) Assume $p_B \leq p_A$ and take $v\in \adh_\mathfrak{a}(A)$. Then $p_B(v) \leq p_A(v) \leq 1$ by \ref{gaugeInherenceAdherence}, which also gives $v\in\adh_\mathfrak{a}(B)$.
\end{proof}

\subsubsection{Seminorms}
\begin{lemma}
The kernel of a seminorm is a vector space.
\end{lemma}
Note this does not follow from \ref{kernelSubspace} because seminorms are not linear.
\begin{proof}
Let $p:V\to \R$ be a seminorm. We verify the subspace criterion \ref{subspaceCriterion}. First $0\in\ker(p)$ because $p(0) = p(0\cdot 0) = |0|p(0) = 0$.

Now take $v,w\in \ker(p)$ and $\lambda\in \F$. Then $0\leq p(v+\lambda w) \leq p(v)+|\lambda|p(w) = 0$, so $v+\lambda w\in\ker(p)$.
\end{proof}

\begin{proposition} \label{initialSeminormConvergence}
Let $V$ be a vector space and $S$ a set of seminorms on $V$. Let $\xi$ be the initial convergence on $V$ w.r.t. $S$. Then
\begin{enumerate}
\item $\xi$ is a topological vector space convergence;
\item $\begin{aligned}[t]
\neighbourhood_\xi(0) &= \mathfrak{F}\setbuilder{p^\preimf[\ball(0,\epsilon)]}{p\in S, \epsilon > 0} \\
&= \mathfrak{F}\setbuilder{p^\preimf[\cball(0,\epsilon)]}{p\in S, \epsilon > 0}
\end{aligned}$
\item $f\in \sSet{V, \xi}^*$ \textup{if and only if}
\begin{itemize}
\item $f\in \sSet{V,\mathfrak{a}}^*$;
\item there exists a finite subset $A\subseteq S$ and $C>0$ such that $|f(v)| \leq C\max_{g\in A} g(v)$ for all $v\in V$.
\end{itemize}
\end{enumerate}
\end{proposition}
\begin{proof}
(1, 2) That $\xi$ is topological follows from \ref{pretopologicalInitialConvergence}, which also gives point (2).

To show $\xi$ is a vector space convergence, we verify the conditions in \ref{TVSconstruction}:
\begin{enumerate}
\item Take $\lambda\in \F$ and $U\in \neighbourhood_\xi(0)$. Then there exist $p\in S$ and $\epsilon > 0$ such that $p^\preimf[\ball(0,\epsilon)] \subseteq U$. Then
\[ \lambda U \subseteq \lambda p^\preimf[\ball(0,\epsilon)] = p^\preimf[|\lambda|\ball(0,\epsilon)] = p^\preimf[\ball(0,|\lambda|\cdot \epsilon)], \]
so $\lambda U\in \neighbourhood_\xi(0)$.
\item Take $U\in \neighbourhood_\xi(0)$, so there exist $p\in S$ and $\epsilon > 0$ such that $p^\preimf[\ball(0,\epsilon)] \subseteq U$. Then
\[ p^\preimf[\ball(0,\epsilon/2)] + p^\preimf[\ball(0,\epsilon/2)] \subseteq p^\preimf[\ball(0,\epsilon)] \subseteq U. \]
\item By \ref{coreProperties}.
\item We claim $p^\preimf[\ball(0,\epsilon)]$ is balanced for all $p\in S$ and $\epsilon > 0$. Indeed for all $|r|\leq 1$
\[ rp^\preimf[\ball(0,\epsilon)] = p^\preimf[|r|\cdot \ball(0,\epsilon)] = p^\preimf[\ball(0,|r|\cdot \epsilon)] \subseteq p^\preimf[\ball(0,\epsilon)]. \]
\end{enumerate}

(3) We have by \ref{continuityLinearFunctionals}
\[ f\in \sSet{V, \xi}^* \iff \exists D>0: \exists U\in \neighbourhood_\xi(0):\; f^\imf[U] \subseteq \cball(0,D). \]
Now $U\in \neighbourhood_\xi(0)$ iff there exists a finite $A = \{p_n^\preimf[\ball(0,\epsilon_n)]\}_{n=0}^N \subseteq \setbuilder{p^\preimf[\ball(0,\epsilon)]}{p\in S, \epsilon > 0}$ such that $\bigcap A\subseteq U$. So WLOG we may take $U$ of this form.
Now 
\begin{align*}
f^\imf\Big[\bigcap A\Big] \subseteq \cball(0,D) &\iff \forall v\in V: \; \Big(\forall n\leq N: p_n(v)\leq \epsilon_n \Big) \implies |f(v)|\leq D \\
&\iff \forall v\in V: \; \max_{n\leq N}\epsilon_n^{-1}p_n(v)\leq 1 \implies |f(v)|\leq D \\
&\iff \forall v\in V: \; \max_{n\leq N}\epsilon_n^{-1}p_n\left(\frac{\max_{n\leq N}\epsilon_n^{-1}p_n(v)}{\max_{n\leq N}\epsilon_n^{-1}p_n(v)} v\right)\leq 1 \implies |f(v)|\leq D \\
&\iff \forall v\in V: \; \left(\max_{n\leq N}\epsilon_n^{-1}p_n(v)\right)^{-1}\max_{n\leq N}\epsilon_n^{-1}p_n(v)\leq 1 \implies \left(\max_{n\leq N}\epsilon_n^{-1}p_n(v)\right)^{-1}|f(v)|\leq D \\
&\iff \forall v\in V: \; 1\leq 1 \implies |f(v)|\leq D\max_{n\leq N}\epsilon_n^{-1}p_n(v) \\
&\iff \forall v\in V: \; |f(v)|\leq D\max_{n\leq N}\epsilon_n^{-1}p_n(v).
\end{align*}
WLOG we may take all $\epsilon_n = \epsilon = \min_{n\leq N}\epsilon_n$. We may then take $C = D/\epsilon$.
\end{proof}
Note that for (1) we cannot use \ref{initialVectorSpaceConvergence}, as the elements of $S$ are not linear.

\begin{proposition} \label{locallyConvexSeminormTopology}
Let $V$ be a vector space. A topological convergence on $V$ is locally convex \textup{if and only if} it is the initial convergence w.r.t. some set $S$ of seminorms on $V$.
\end{proposition}
\begin{proof}
If $V$ has the initial convergence w.r.t. $S$, then $V$ is locally convex by \ref{initialSeminormConvergence} because $p^\preimf[\ball(0,\epsilon)]$ is convex for all $p\in S$.

Now let $V$ be a locally convex TVS, then there exists an absolutely convex base $\mathcal{B}$ of $\neighbourhood(0)$ by \ref{vicinityFilterAtOrigin}. Then $S = \setbuilder{p_B}{B\in \mathcal{B}}$ is a set of continuous seminorms, by \ref{gaugeProperties} and \ref{continuityConvexGauge}.

In order to show that the convergence on $V$ is initial w.r.t. $S$, we verify the form of $\neighbourhood(0)$ given in \ref{initialSeminormConvergence}.

We may take $\mathcal{B}$ to consist of algebraically open convex sets by replacing it with $\inh_\mathfrak{a}^\imf[\mathcal{B}]$, which contains open convex sets by \ref{coreProperties}. Then
\begin{align*}
\neighbourhood(0) &= \mathfrak{F}(\mathcal{B}) \\
&= \mathfrak{F}\setbuilder{p_B^\preimf[\ball(0,1)]}{B\in \mathcal{B}} \\
&= \mathfrak{F}\setbuilder{\epsilon^{-1} p_B^\preimf[\ball(0,1)]}{B\in \mathcal{B}} \\
&= \mathfrak{F}\setbuilder{p_B^\preimf[\ball(0,\epsilon)]}{B\in \mathcal{B}, \epsilon > 0} \\
&= \mathfrak{F}\setbuilder{p^\preimf(\ball(0,\epsilon))}{p\in S, \epsilon > 0},
\end{align*}
where we have used \ref{gaugeInherenceAdherence} and the fact that the convergence is a vector space convergence, so $\epsilon B \in \upset\mathcal{B}$.
\end{proof}

\begin{proposition}
Let $V$ be a vector space. The functions
\begin{align*}
\powerset\setbuilder{A\subseteq V}{\text{$A$ is convex}} &\to \setbuilder{p: V\to \R}{\text{$p$ is a seminorm}}: &&\mathcal{B}\mapsto \setbuilder{p_K}{K\in \mathcal{B}} \\
\setbuilder{p: V\to \R}{\text{$p$ is a seminorm}} &\to \powerset\setbuilder{A\subseteq V}{\text{$A$ is convex}}: &&S\mapsto \setbuilder{p^\preimf[U]}{p\in S, U\in \neighbourhood_\R(0)}
\end{align*}
form an antitone Galois connection, where we order the seminorms pointwise.
\end{proposition}
\begin{proof}
TODO + previous as corollary
\end{proof}

Note: metrisable is not equivalent to normable!






\subsection{Hahn-Banach extension theorems}
\begin{theorem}[Hahn-Banach majorised by convex functionals] \label{convexHahnBanach}
Let $V$ be a real vector space, $U\subset V$ a subspace and $p$ a convex functional on $V$. Let $f:U\to\R$ be a linear functional that is bounded by $p$:
\[ \forall u\in U: \quad f(u) \leq p(u). \]
Then $f$ has an extension $\tilde{f}: V\to \R$ such that $\tilde{f}$ is a linear functional on $V$ bounded by $p$:
\[ \forall v\in V: \tilde{f}(v) \leq p(v) \qquad \text{and} \qquad \forall u\in U: \tilde{f}(u) = f(u). \]
\end{theorem}
\begin{proof}
As a first step, we want to extend $f$ to a functional $g$ on a space that is one dimension larger than $U$. This means $g$ is of the form
\[ g: U\oplus\Span\{v_1\}\to\R: v + \alpha v_1 \mapsto f(v) + \alpha c \]
for some $v_1\in V\setminus U$.

If we want $g$ to be majorised by $p$, then we need to find a $c$ such that
\[ \forall v\in U: \forall \alpha\in\R: \; g(\alpha v_1 + v) = \alpha c + f(v) \leq p(\alpha v_1 + v) \]
this means that we need
\[ \forall v\in U: \forall \alpha\in\R:\; \frac{-p(v - |\alpha|v_1) + f(v)}{|\alpha|} \leq c \leq \frac{p(v + |\alpha|v_1) - f(v)}{|\alpha|} \]
and we can find such a $c$ if and only if
\[ \forall v\in U: \forall \alpha\in\R:\; -p(v - |\alpha|v_1) + f(v) \leq p(v + |\alpha|v_1) - f(v), \]
which is equivalent to $2f(v) \leq p(v+|\alpha|v_1)+p(v-|\alpha|v_1)$. This follows from
\begin{align*}
f(v) \leq p(v) &= p(\tfrac{1}{2}(v+|\alpha|v_1) + \tfrac{1}{2}(v-|\alpha|v_1)) \\
&\leq \tfrac{1}{2}p(v+|\alpha|v_1) + \tfrac{1}{2}p(v-|\alpha|v_1).
\end{align*}
So we can extend the domain of $f$ by one dimension such that it is still majorised by $p$.

We can iterate the construction to extend $f$ by multiple dimensions. Each extension can be viewed as a subset of $V\times \R$, by identifying it with its graph.
Consider the family of all such subsets that determine a majorised extension of $f$ (not just those obtained by iteration of the previous construction!). This is a family of finite character. We apply the Teichmller-Tukey lemma, \ref{ZornEquivalents}, to obtain a maximal element.

This maximal element has domain $V$, because if it did not, it could be extended and was not a maximal element.
\end{proof}
Clearly if $V$ has a well-ordered Hamel basis, we do not need choice as we can just take successive $v$s in the basis and find $c$s constructively.
\begin{corollary}[Hahn-Banach majorised by sublinear functionals] \label{sublinearHahnBanach}
Any majorant $p$ that is sublinear is also convex and can be used in the Hahn-Banach theorem.
\end{corollary}
\begin{corollary}[Hahn-Banach majorised by seminorms] \label{seminormHahnBanach}
Let $(\mathbb{F},V,+)$ be a real or complex vector space, $U\subset V$ a subspace and $p$ a seminorm on $V$. Let $f:U\to\mathbb{F}$ be a linear functional that is bounded by $p$:
\[ \forall u\in U: \quad |f(u)| \leq p(u). \]
Then $f$ has an extension $\tilde{f}: V\to \R$ such that $\tilde{f}$ is a linear functional on $V$ bounded by $p$:
\[ \forall v\in V: |\tilde{f}(v)| \leq p(v) \qquad \text{and} \qquad \forall u\in U: \tilde{f}(u) = f(u). \]
\end{corollary}
\begin{proof}
First assume $V$ is a \emph{real} vector space. Because every seminorm is a sublinear function, we can use \ref{sublinearHahnBanach} to find an extension $\tilde{f}$. We then just need to check it satisfies $\forall v\in V: |\tilde{f}(v)| \leq p(v)$.
From \ref{sublinearHahnBanach} we know $\forall v\in V: \tilde{f}(v) \leq p(v)$.
To prove $-\tilde{f}(v) \leq p(v)$, we calculate
\[ -\tilde{f}(v) = \tilde{f}(-v) \leq p(-v) = |-1|p(v) = p(v). \]

If $V$ is a \emph{complex} vector space, consider the realification $V_\R$ and apply the preceding proof to obtain a linear functional $g: V_\R \to \R$ that extends $f$ and is majorised by $p$. Then by \ref{complexRangeExtensionRealFunctional} we can find a complex-linear functional $\tilde{f}:V \to \C$ such that $\Re(\tilde{f}) = g$.

We just need to show that $f$ is bounded by $p$. Take arbitrary $v\in V$ and write $\tilde{f}(v) = |\tilde{f}(v)|e^{i\theta}$ then
\[ |\tilde{f}(v)| = \Re|\tilde{f}(v)| = \Re\Big(e^{-i\theta}\tilde{f}(v)\Big) = \Re\Big(\tilde{f}(e^{-i\theta}v)\Big) = g(e^{-i\theta}v) \leq p(e^{-i\theta}v) = |e^{-i\theta}|p(v) = p(v). \]
\end{proof}
\begin{corollary} \label{}
Let $V$ be a locally convex convergence vector space, $U\subseteq V$ a subspace and $f:U\to \F$ a continuous functional. Then $f$ has a continuous extension to $V$.
\end{corollary}
\begin{proof}
We have that $|f| = p_K$ for some $K\in \vicinity_U(0)$ by \ref{absoluteFunctionalGauge}. 
By continuity of the inclusion map, we can find an $M \in \vicinity_V(0)$ such that $M\cap U = K$. Then $|f|\leq p_M$ and $f$ can be extended by the Hahn-Banach extension theorem to a functional $f'$ defined in the whole of $V$. Then $f'$ is bounded on $M$ and thus continuous by \ref{boundedOnVicinityImpliesContinuous}.
\end{proof}
\begin{corollary}
Let $X$ be a normed space and $Z\subset X$ a subspace. Any bounded linear functional in $\tdual{Z}$ can be extended to a bounded linear functional in $\tdual{X}$ with the same norm.
\end{corollary}
\begin{proof}
Let $f:Z\to \mathbb{F}$ be such a functional. Extend $f$ by the previous theorem, \ref{seminormHahnBanach}, using $p(x) = \norm{f}_Z\norm{x}$.
\end{proof}
\begin{corollary} \label{existenceBoundedFunctionalOfSameNorm}
Let $X$ be a normed space and $x_0\neq 0$ an element of $X$. Then there exists a bounded linear functional $\omega_{x_0}$ such that
\[ \norm{\omega_{x_0}} = 1 \qquad \text{and} \qquad \omega_{x_0}(x_0)=\norm{x_0}. \]
\end{corollary}
\begin{proof}
Extend the functional $f: \Span\{x_0\}\to \mathbb{F}$ defined by
\[ f(x) = f(ax_0) = a\norm{x_0}. \]
\end{proof}
\begin{corollary}
Let $X$ be a normed space. Then $\forall x\in X:$
\[ \norm{x} = \sup_{\substack{f\in X' \\ f\neq 0}}\frac{|f(x)|}{\norm{f}}. \]
\end{corollary}
\begin{proof}
We calculate
\[ \norm{x} \geq \sup_{\substack{f\in X' \\ f\neq 0}}\frac{|f(x)|}{\norm{f}} \geq \frac{|\omega_{x}(x)|}{\norm{\omega_{x}}} = \frac{\norm{x}}{1} = \norm{x} \]
where the first inequality follows from $|f(x)|\leq \norm{f}\norm{x}$ for all $f\in X', x\in X$.
\end{proof}

\subsubsection{Hahn-Banach separation}

\begin{lemma} \label{gaugeSeparationLemma}
Let $V$ be a real vector space, $A$ an absorbent, semibalanced set and $x_0 \notin A$. Consider the functional $f_{x_0}: \Span\{x_0\}\to \F: tx_0 \mapsto t$. Then $f_{x_0}(x)\leq p_A(x)$ for all $x\in \Span\{x_0\}$.
\end{lemma}
\begin{proof}
Let $x = tx_0$. If $t\leq 0$, then the inequality is immediate. Suppose $t>0$. Because $p_A(x_0) \geq 1$ (by the converse of \ref{gaugeLemma}), we have
\[ f_{x_0}(x) = f_{x_0}(tx_0) = t \leq tp_A(x_0) = p_A(tx_0) = p_A(x)  \]
using positive homogeneity (\ref{gaugeScaling}).
\end{proof}

\begin{theorem}[Mazur] \label{MazurTheorem}
Let $V$ be a real or complex convergence vector space and $A$ an open and convex set. If $U$ is a subspace such that $A\perp U$, then there exists a closed hyperplane $H \supseteq U$ such that $A\perp H$.
\end{theorem}
\begin{proof}
First suppose $V$ is a \emph{real} vector space. Because $A$ is open, it is algebraically open. Take $a\in A$. Then $0\in a-A = \inh_{\mathfrak{a}}(a-A)$, so $a-A$ is absorbing by \ref{coreProperties}. It is also semibalanced (by \ref{convexAbsorbentImpliesSemibalanced} as it is convex by \ref{translationScalingConvexSet}).

Then we have
\[ U\perp A \iff 0\notin U-A \iff a \notin a-A+U. \]
Consider the functional $f_{a}$ of \ref{gaugeSeparationLemma}, which is majorised by the gauge $p_{a-A+U}$, which is sublinear by \ref{gaugeProperties}. Then $f_a$ can be extended as an $\R$-linear function to all $V$ by the Hahn-Banach extension theorem \ref{sublinearHahnBanach}.

We note that $U\subseteq \ker(f_a)$, because $p_{a-A+U}(u) = 0$ by \ref{gaugeZeroLemma}.

In order to conclude with \ref{functionalBoundedNeighbourhood}, we need to show that $A-a \subseteq f_a^{\preimf}(\ball(0,|f_a(a)|)) = f_a^{\preimf}(\ball(0,1))$.
Indeed $A-a \subseteq U+A-a = \inh_\mathfrak{a}(U+A-a) \subseteq p_{U+A-a}^\preimf[\ball(0,1)] \subseteq f_{a}^\preimf[\ball(0,1)]$ by \ref{algebraicallyOpen} and \ref{gaugeInherenceAdherence} ($U+A-a$ is semibalanced because $A-a$ is).

Note that $\ker(f_a)^c$ contains the open set $A$ and thus $\ker(f_a)$ is not dense by \ref{openDensityLemma}. By \ref{hyperplaneClosedDense} this means that $\ker(f_a)$ is closed.

Now suppose $V$ is a \emph{complex} vector space. We can consider the realification $V_\R$ with the same convergence, which is a real convergence vector space by TODO \ref{}. So we can use the preceding proof to find a real hyperplane $K$ in $V$. Then \ref{realComplexHyperplane} gives that $H = K\cap iK$ is a complex hyperplane in $V$. Now $H$ and $A$ must be disjoint because $K$ and $A$ are disjoint and $H \subseteq K$.

Also $H$ is closed because $K$ and $iK$ are closed (the first by the preceding proof, the second because multiplication by $i$ is a homeomorphism \ref{continuityLemmaVectorConvergence}) and the intersection of two closed sets is closed.
\end{proof}
\begin{corollary} \label{functionalZeroOnClosedSubSpace}
Let $V$ be a locally convex vector space and $M$ a closed subspace. There exists a non-zero bounded linear functional $f$ on $V$ such that $M\subseteq \ker(f)$.
\end{corollary}
\begin{proof}
The set $M^c$ is open and by local convexity it contains a convex set $C$. We may take $C$ open by replacing it with its interior, which is convex by \ref{inherenceAdherenceConvex}. Now $C\perp M$ and we can apply the theorem. Now $\ker(f)$ is closed, so $f$ is bounded by \ref{continuityLinearFunctionals}.
\end{proof}

\begin{theorem}[Hahn-Banach separation theorem] \label{HahnBanachSeparation}
Let $V$ be a convergence vector space. Suppose $A,B$ are disjoint, non-empty, convex sets and that $A$ is open. Then there exists a continuous linear functional $f:V\to \F$ such that $f^\imf[A]$ and $f^\imf[B]$ are disjoint.
\end{theorem}
\begin{proof}
The set $A-B = \bigcup_{b\in B}A-b$ is convex and a union of open sets and thus open by \ref{completeClosureTopology}.
The set $A-B$ and the vector space $\{0\}$ are disjoint, so by \ref{MazurTheorem} we can find a closed hyperplane that is disjoint with $A-B$.

By \ref{kernelHyperplane} and \ref{continuityLinearFunctionals} this is the kernel of a continuous linear functional $f$.
\end{proof}
\begin{corollary}
Let $V$ be a real or complex convergence vector space and $A,B$ as in the proposition. Then there exists a continuous linear functional $f:V\to \F$ and $t\in \R$ such that
\[ \Re f(a) < t \leq \Re f(b) \]
for all $a\in A$ and $b\in B$.
\end{corollary}
This means $A$ and $B$ are separated by a closed affine hyperplane $\ker(f)+v$, where $v \in f^\preimf[\{t\}]$.

We can reverse the inequalities by replacing $f$ by $-f$.
\begin{proof}
Apply the proposition to the realification $V_\R$. This gives us an $\R$-linear functional $g: V\to \R$ such that $g^\imf[A]$ and $g^\imf[B]$ are disjoint convex sets. Additionally $g^{\imf}[A]$ is open in $\R$ by \ref{linearFunctionalOpen}.

Because $g^\imf[A]$ and $g^\imf[B]$ are convex, we either have $g^\imf[A]\leq g^\imf[B]$ or $g^\imf[A]\geq g^\imf[B]$. In the second case we simply replace $g$ by $-g$ to obtain the first case. We may take $t= \sup g^\imf[A]$. This is not in $g^\imf[A]$ because it is open.

If $V$ is a real vector space we take $f=g$ are done. If $V$ is complex, we can find a suitable $f$ by \ref{complexRangeExtensionRealFunctional}.
\end{proof}
\begin{corollary} \label{locallyConvexHahnBanachSeparationClosedSet}
Let $\sSet{V, \xi}$ be a locally convex vector convergence space. Let $B$ be a closed convex set and $v\notin B$, then there exists a continuous linear functional $f:V\to \F$ such that $f(v) \notin \overline{f^\imf[B]}$.
\end{corollary}
\begin{proof}
As $B^c$ is open, it is a neighbourhood of $v$ and we can find an convex neighbourhood $U$ of $v$ in $B^c$. Now replace $U$ by its interior. This is open and still convex by \ref{inherenceAdherenceConvex}, so we can apply the theorem.

Then $f^\imf[U]$ is open by \ref{linearFunctionalOpen} and thus in $\neighbourhood_\F\big(f(v)\big)$. It is however disjoint from $f^\imf[B]$, which means that $f(v) \notin \overline{f^\imf[B]}$.
\end{proof}
\begin{corollary}
Let $V$ be a locally convex TVS. Suppose $A,B$ are disjoint, non-empty, convex sets and that $A$ is compact, $B$ is closed. Then there exists a continuous linear functional $f:V\to \F$ and $s,t\in \R$ such that
\[ \Re f(a) < t < s < \Re f(b) \]
for all $a\in A$ and $b\in B$.
\end{corollary}
\begin{proof}
TODO
\end{proof}
\begin{corollary} \label{locallyConvexDualPair}
Let $V$ be a Hausdorff locally convex convergence vector space and $v\in V$. If $f(v) = 0$ for all $f\in V^*$, then $v = 0$.
\end{corollary}
\begin{proof}
We prove the contrapositive. Assume $v\neq 0$. By \ref{FrechetCharacterisation}, we have that $\{0\}$ is closed, so $\{0\}^c$ is a neighbourhood of $v$. By local convexity, $\{0\}^c$ contains a convex vicinity of $x$. We may take this vicinity to be open by taking the interior (which is still convex by \ref{inherenceAdherenceConvex}). Let this open vicinity be $A$ and set $B = \{0\}$. By Hahn-Banach separation, there exists $f\in \dual{V}$ such that $f^\imf[A]$ and $f^\imf[B] = \{0\}$ are disjoint. Thus $f(v) \neq 0$.
\end{proof}

\subsubsection{Banach limits}
\begin{proposition}
There exists a linear map $L:l^\infty(\N) \to \C$ satisfying
\begin{enumerate}
\item $\displaystyle L(x) = \lim_{n\to \infty}x_n$ if the limit exists;
\item $L((x_{n+1})_{n\in\N}) = L((x_n)_{n\in\N})$;
\item if $\forall n\in\N:x_n\geq 0$, then $L(x) \geq 0$;
\item $\norm{L} = 1$.
\end{enumerate}
Such a linear map is called a \udef{Banach limit}.
\end{proposition}
\begin{proof}
TODO, after Cesro means.
\end{proof}

\subsection{Continuous functionals}

TODO???
\begin{proposition}
Let $V$ and $W$ be TVSs and $f: V\to W$ a linear function.
\begin{enumerate}
\item If $f$ is continuous and $W$ is Hausdorff, then $\ker(f)$ is closed.
\item If $f$ has closed kernel and finite-dimensional image, then $f$ is continuous.
\end{enumerate}
\end{proposition}
\begin{proof}
(1) Because $W$ is Hausdorff, it is also $T_1$ and thus $\{0\}$ is closed by \ref{FrechetCharacterisation}. Then $\ker(f) = f^{\preimf}(\{0\})$ is closed by \ref{continuity}.

(2) 
\end{proof}
??



\section{General duality theory}
\subsection{Paired spaces}
\begin{definition}
A \udef{pairing} is a triple $\sSet{V,W, \pair{\cdot,\cdot}}$ where $V,W$ are vector spaces over $\mathbb{F}$ and $\pair{\cdot,\cdot}: V\times W\to \mathbb{F}$ is a bilinear form. Often we will write the pairing as just $\sSet{V,W}$.

We say $W$
\begin{itemize}
\item \udef{distinguishes} points of $V$; or
\item is \udef{separating} on $V$; or
\item \udef{separates} $V$
\end{itemize}
if 
\[ \forall v\in V\setminus\{0\}: \exists w\in W: \pair{v,w} \neq 0. \]

A \udef{dual system}, \udef{dual pair} or \udef{duality} over a field $\mathbb{F}$ is a pairing $\sSet{V,W,\pair{\cdot,\cdot}}$ such that $V$ distinguishes points of $W$ and $W$ distinguishes points of $V$.
\end{definition}
We have that $W$ is separating on $V$ \textup{if and only if}

\begin{lemma} \label{dualSystemInjective}
Let $\sSet{V,W, \pair{\cdot,\cdot}}$ be a pairing. Then $W$ separates $V$ \textup{if and only if} $v\mapsto \pair{v, \cdot}$ is injective.
\end{lemma}
\begin{proof}
Suppose $W$ separates $V$ and take arbitrary $v,v'\in V$ such that $\pair{v, \cdot} = \pair{v', \cdot}$. Then $\pair{v-v',\cdot} = \underline{0}$, which by assumption means $v-v' = 0$, or $v= v'$.

Now suppose $v\mapsto \pair{v, \cdot}$ is injective and take arbitrary $v\in V\setminus\{0\}$. If $\pair{v,w} = 0$ for all $w\in W$, then $\pair{v,\cdot} = \pair{0,\cdot}$ and thus $v=0$ by injectivity. This was disallowed by assumption.
\end{proof}

\begin{example}
\begin{itemize}
\item Let $\sSet{V, \xi}$ be a convergence vector space. Then $\sSet{\dual{V}, V, \evalMap(\cdot,\cdot)}$ is a pairing.
\item Let $\sSet{V,\xi}$ be a Hausdorff locally convex convergence vector space. Then $\sSet{\dual{V}, V, \evalMap(\cdot,\cdot)}$ is a dual pair by \ref{locallyConvexDualPair}.
\end{itemize}
\end{example}

\begin{lemma}
Let $\sSet{V,W,\pair{\cdot,\cdot}}$ be a dual pair. Then $\sSet{W,V,\pair{\cdot,\cdot}^d}$ is also a dual pair.
\end{lemma}

\subsection{The weak topology}
\begin{definition}
Let $(X,Y,\pair{\cdot,\cdot})$ be paired vector spaces. 
The initial convergence on $Y$ w.r.t. the set of linear functionals $\setbuilder{\pair{x,\cdot}}{x\in X}$ is called the \udef{weak topology} $\sigma(X,Y)$ on $Y$ for the pair $\sSet{X,Y}$\footnote{What we denote $\sigma(X,Y)$ is usually denoted $\sigma(Y,X)$.}.
\end{definition}

\begin{lemma} \label{weakTopologyLCTVS}
Let $\sSet{X,Y,\pair{\cdot,\cdot}}$ be a pairing. The weak topology $\sigma(X,Y)$ on $Y$ 
\begin{enumerate}
\item is the same as the initial convergence w.r.t. the set of seminorms $\setbuilder{\abspair{x,\cdot}}{x\in X}$;
\item is a locally convex vector space topology;
\item has the neighbourhood filter
\begin{align*}
\neighbourhood_{\sigma(X,Y)}(0) &= \mathfrak{F}\setbuilder{y\in Y}{\exists x\in X: \abspair{x,y} \leq 1} \\
&= \mathfrak{F}(_\pol{X}).
\end{align*}
\end{enumerate}
\end{lemma}
\begin{proof}
(1, 2) Let $\sigma_1$ be the initial convergence w.r.t. $\setbuilder{\pair{x,\cdot}}{x\in X}$ and $\sigma_2$ the initial convergence w.r.t. $\setbuilder{\abspair{x,\cdot}}{x\in X}$.

By \ref{continuityAbsFunctional}, all functionals of the form $\abspair{x,\cdot}: \sSet{V,\sigma_1} \to \R$, for some $x\in X$, are continuous. Thus $\sigma_1 \subseteq \sigma_2$.

By \ref{locallyConvexSeminormTopology}, $\sigma_2$ is a locally convex vector space topology. Thus all functionals of the form $\pair{x,\cdot}: \sSet{V,\sigma_2} \to \R$, for some $x\in X$, are continuous. This means that $\sigma_2 \subseteq \sigma_1$.

(3) The form of the neighbourhood filter also follows from \ref{locallyConvexSeminormTopology}. It is enough to show that $\setbuilder{\abspair{x,\cdot}^{\preimf}(\,[0,\epsilon]\,)}{x\in X, \epsilon > 0} = \setbuilder{y\in Y}{\exists x\in X: \abspair{x,y} \leq 1}$. Then
\begin{align*}
y \in \setbuilder{\abspair{x,\cdot}^{\preimf}(\,[0,\epsilon]\,)}{x\in X, \epsilon > 0} &\iff \exists x\in X: \exists \epsilon > 0: \; \abspair{x,y} \leq \epsilon \\
&\iff \exists x\in X: \exists \epsilon > 0: \; \epsilon^{-1}\abspair{x,y} \leq 1 \\
&\iff \exists x\in X: \exists \epsilon > 0: \; \abspair{\epsilon^{-1}x,y} \leq 1 \\
&\iff \exists x\in X: \; \abspair{x,y} \leq 1 \\
&\iff y\in \setbuilder{y\in Y}{\exists x\in X: \abspair{x,y} \leq 1}.
\end{align*}
\end{proof}

\begin{lemma}
Let $(X,Y,\pair{\cdot,\cdot})$ be a pairing and $x\in X$. Then $\abspair{x,\cdot} = p_{^\pol\{x\}}$.
\end{lemma}

\begin{proposition} \label{functionalContinuityWeakTopology}
Let $\sSet{X,Y,\pair{\cdot,\cdot}}$ be a pairing and $f: Y\to \F$ a linear functional. Then
\[ \dual{(Y,\sigma(X,Y))} = \setbuilder{\pair{x,\cdot}}{x\in X}. \]
\end{proposition}
\begin{proof}
This inclusion $\supseteq$ is immediate by the definition of initial topology.

Now take $f\in \dual{(Y,\sigma(X,Y))}$. By point (3) of \ref{initialSeminormConvergence} there exists a finite set $\{x_1, \ldots, x_n\}$ such that $|f(v)| \leq C\max_{i}\abspair{x_i, \cdot}$ for all $v\in V$. By \ref{linearDependenceLinearFunctionals}, this means that $f$ is some linear combination of the $\pair{x_i,\cdot}$, say $\sum_{i=0}^n \alpha_i \pair{x_i, \cdot}$. So
\[ f = \sum_{i=0}^n \alpha_i \pair{x_i, \cdot} = \pair{\sum_{i=0}^n \alpha_i x_i, \cdot}. \]
\end{proof}
\begin{corollary} \label{dualSystemBijection}
Let $\sSet{X,Y,\pair{\cdot,\cdot}}$ be a pairing such that $Y$ separates $X$. Then $X\to Y^*: x\mapsto \pair{x,\cdot}$ is a bijection.
\end{corollary}
In particular this holds if $\sSet{X,Y,\pair{\cdot,\cdot}}$ is a dual system.
\begin{proof}
Injectivity is given by \ref{dualSystemInjective}. Surjectivity by the proposition.
\end{proof}
\begin{corollary}
Let $V$ be a convergence vector space. Then $V^* = \sSet{V, \sigma(V^*, V)}^*$.

The weak topology is the weakest convergence $\tau$ such that $V^* = \sSet{V, \tau}^*$.
\end{corollary}
Thus for any convergence vector space $\sSet{V,\xi}$, the space $\sSet{V, \sigma(V^*, V)}$ is a locally convex TVS with the same continuous functionals.

\subsubsection{Weak continuity}
\begin{definition}
Let $T: \sSet{V,\xi} \to \sSet{W,\zeta}$ be a linear operator between convergence vector spaces. Then $T$ is called \udef{weakly continuous} if
\[ T: \sSet{V, \sigma(V^*,V)} \to \sSet{W, \sigma(W^*,W)} \]
is continuous.
\end{definition}

\begin{lemma}
If $T: V\to W$ is continuous, then it is weakly continuous.
\end{lemma}
\begin{proof}
By the characteristic property of the initial convergence \ref{characteristicPropertyInitialFinalConvergence}, the weak continuity of $T$ is equivalent to the continuity of $f\circ T$ for all $f\in W^*$. This holds because the composition of continuous functions is continuous, \ref{continuityComposition}.
\end{proof}


\subsubsection{The pair $(V^*, V)$}
\begin{definition}
Let $V$ be a vector space and $V^*$ the continuous dual under some convergence. Any convergence on $V$ such that the continuous dual is still $V^*$ is called a \udef{convergence of the dual pair}.
\end{definition}
Any property that only depends on continuous linear functionals is the same for any convergence of the dual pair.

The weak topology is the weakest convergence of the dual pair.

\begin{proposition}
Let $V$ be a vector space and $A\subseteq V$ a convex subset. Let $\xi$ be a locally convex vector space convergence on $V$. Then $\closure_\xi(A) = \closure_{\sigma(V^*, V)}(A)$.
\end{proposition}
In other words the closure of convex sets is the same for all locally convex convergences of the dual pair.
\begin{proof}
From \ref{principalInherenceAdherenceProperties}, we have $\closure_\xi(A) \subseteq \closure_{\sigma(V^*, V)}(A)$.

Now assume $x\notin \closure_\xi(A)$. Then, by \ref{locallyConvexHahnBanachSeparationClosedSet}, we can find a continuous functional $f\in V^*$ such that $f(x) \notin \overline{f^{\imf}\big(\closure_\xi(A)\big)}$. So not every neighbourhood of $f(x)$ meshes with $f^{\imf}\big(\closure_\xi(A)\big)$; take some neighbourhood $U$ that is disjoint from it. By continuity and \ref{continuityVicinityFilter}, we have that $f^{\preimf}(U)$ is a $\sigma(V^*, V)$-neighbourhood of $x$ that must be disjoint from $\closure_\xi(A)$ (we have used that $\sigma(V^*, V)$ is topological, \ref{weakTopologyLCTVS}). This implies that $A$ is also disjoint from $f^{\preimf}(U)$.

Thus $x\notin \closure_{\sigma(V^*, V)}(A)$ by \ref{interiorClosureMembership}.
\end{proof}


\subsubsection{Weak-$*$ topology}
\begin{definition}
Let $(X,Y,\pair{\cdot,\cdot})$ be paired vector spaces. The \udef{weak-$*$ topology} $\sigma^*(X,Y)$ on $X$ for this pairing is the weak topology $\sigma(Y,X)$ for the pairing $(Y,X,\pair{\cdot,\cdot}^d)$.
\end{definition}

\begin{proposition} \label{weak*continuousFunctional}
Let $X$ be a Banach space and let $X'$ have the weak-$*$ topology. Then a linear functional $\theta: X'\to \C$ is continuous \textup{if and only if}
\[ \exists x\in X: \forall \omega\in X': \quad \theta(\omega) = \omega(x). \]
\end{proposition}
\begin{proof}
TODO 9.2 in lecture notes.
\end{proof}

\subsection{Polars}
\subsubsection{Polar sets}
\begin{definition}
Let $\sSet{X,Y,\pair{\cdot,\cdot}}$ be a pairing and $B\subseteq Y$ a subset. The \udef{polar} of $B$ is the polar w.r.t. the relation $\pol$ on $(Y,X)$ defined by
\[ y\pol x \qquad\iff\qquad \abspair{x, y} \leq 1. \]
Conventionally, we also use $\pol$ to denote $\pol^\transp$. Thus the \udef{bipolar} $B^{\pol\pol}$ of $B$ is $B^{\pol\pol^\transp}$.
\end{definition}

\begin{lemma} \label{polarLemma}
Let $\sSet{X,Y,\pair{\cdot,\cdot}}$ be a pairing and $B\subseteq Y$ a subset. Then
\begin{align*}
B^{\pol} &= \setbuilder{x\in X}{\sup_{y\in B}\abspair{x,y} \leq 1} \\
&= \bigcap_{y\in B}\setbuilder{x\in X}{\abspair{x,y}\leq 1}.
\end{align*}
and for the gauge of $B^\pol$, we have $p_{B^\pol}(x) = \sup_{y\in B}\abspair{x,y}$.
\end{lemma}
\begin{proof}
The expression for the polar is straightforward. For the gauge we calculate
\begin{align*}
p_{B^\pol}(x) &= \inf \setbuilder{\lambda\in\overline{\R^+}}{x\in \lambda B^\pol} \\
&= \inf \setbuilder{\lambda\in\overline{\R^+}}{\lambda^{-1}x\in B^\pol} \\
&= \inf \setbuilder{\lambda\in\overline{\R^+}}{\sup_{y\in B}\abspair{\lambda^{-1}x,y}\leq 1} \\
&= \inf \setbuilder{\lambda\in\overline{\R^+}}{\sup_{y\in B}\abspair{x,y}\leq \lambda} \\
&= \sup_{y\in B}\abspair{x,y}.
\end{align*}
\end{proof}

\begin{lemma} \label{polarPropertiesLemma}
Let $\sSet{X,Y,\pair{\cdot,\cdot}}$ be a pairing and $B\subseteq Y$ a subset. Then
\begin{enumerate}
\item for all $\lambda \neq 0$: $(\lambda B)^{\pol} = \lambda^{-1}B^{\pol}$;
\item $B^{\pol}$ is absolutely convex;
\item $B^{\pol}$ is $\sigma^*(X,Y)$-closed.
\end{enumerate}
\end{lemma}
\begin{proof}
(1) We calculate
\begin{align*}
x\in (\lambda B)^{\pol} &\iff \forall y\in B:\; \abspair{x,\lambda y} \leq 1 \\
&\iff \forall y\in B:\; \abspair{\lambda x,y} \leq 1 \\
&\iff \lambda x\in B^\pol \\
&\iff x\in \lambda^{-1}B^\pol.
\end{align*}

(2) We use \ref{absolutelyConvexCriteria}, so we take $x,y\in B^\pol$ and $|r|\leq 1$. We need to show that $rx + (1-r)y\in B^\pol$. Indeed, for arbitrary $z\in B$ we have
\begin{align*}
\abspair{rx + (1-r)y, z} &= |r\pair{x,z} + (1-r)\pair{y,z}| \\
&\leq |r|\;\abspair{x,z} + |1-r|\;\abspair{y,z} \\
&\leq |r| + |1-r| \\
&\leq 1,
\end{align*}
where the last inequality follows from $1 = |1 - r + r| \leq |1-r| + |r|$. Since $z\in B$ was chosen arbitrarily, we have $rx + (1-r)y\in B^\pol$.

(3) We have, using \ref{polarOfUnion},
\begin{align*}
B^\pol &= \left(\bigcup_{y\in B}\{y\}\right)^\pol \\
&= \bigcap_{y\in B} \{y\}^\pol \\
&= \bigcap_{y\in B}\setbuilder{x\in X}{\abspair{x,y}\leq 1} \\
&= \bigcap{y\in B}\abspair{\cdot, y}^{\preimf}[\cball(0,1)],
\end{align*}
which is an intersection of closed sets (as each $\abspair{\cdot, y}$ is continuous in the $\sigma(X,Y)$ topology) and thus closed.
\end{proof}

\begin{proposition}[Bipolar theorem] \label{bipolarTheorem}
Let $\sSet{X,Y,\pair{\cdot,\cdot}}$ be a pairing and $B\subseteq Y$ a subset. Then
\[ B^{\pol\pol} = \overline{\disked(B)}^{\sigma(X,Y)}. \]
\end{proposition}
\begin{proof}
We have $B\subseteq B^{\pol\pol}$ by \ref{reflexiveGaloisCorollary}. Then $\disked(B) \subseteq B^{\pol\pol}$ because $B^{\pol\pol}$ is absolutely convex by \ref{polarPropertiesLemma}. Similarly $\overline{\disked(B)}^{\sigma(X,Y)} \subseteq B^{\pol\pol}$, because $B^{\pol\pol}$ is $\sigma(X,Y)$-closed.

The other inclusion is proved by contradiction. Assume, to this end, that $y_0\in B^{\pol\pol} \setminus \overline{\disked(B)}^{\sigma(X,Y)}$. Then we can apply Hahn-Banach separation \ref{locallyConvexHahnBanachSeparationClosedSet} to obtain a continuous functional $f$ such that $f^\imf\left[\overline{\disked(B)}\right]$ is disjoint from some open neighbourhood $U$ of $f(y_0)$.

Now $\overline{\disked(B)}$ is absolutely convex by \ref{inherenceAdherenceBalanced} and \ref{inherenceAdherenceConvex}, so $f^\imf\left[\overline{\disked(B)}\right]$ is also absolutely convex by linearity. Then, because $|U|$ is open, there exists $t\in |U|$ such that $|f(b)| < t < |f(y_0)|$ for all $b\in \overline{\disked(B)}$. Thus $\sup_{b\in \overline{\disked(B)}}|f(b)| < |f(y_0)|$. By rescaling $f$ we can take $\sup_{b\in \overline{\disked(B)}}|f(b)| \leq 1 < |f(y_0)|$.

By \ref{functionalContinuityWeakTopology}, we can find some $x\in X$ such that $f = \pair{x,\cdot}$. Then $\sup_{b\in \overline{\disked(B)}}\abspair{x, b} \leq 1$ implies $x\in \overline{\disked(B)}^\pol \subseteq B^\pol$. Finally $1 < \abspair{x, y_0}$ implies $y_0\notin B^{\pol\pol}$. This is a contradiction.
\end{proof}

\subsubsection{Weak-$*$-compactness}
\begin{theorem}[(Banach/Bourbaki)-Alaoglu]
Let $(X,Y,\pair{\cdot,\cdot})$ be paired vector spaces and $A\subseteq Y$ a neighbourhood of the origin in the weak topology. Then $A^\pol$ is $\sigma^*(X,Y)$-compact.
\end{theorem}
\begin{proof}

\end{proof}

\subsubsection{Orthogonal complements}
\begin{definition}
Let $\sSet{X,Y,\pair{\cdot,\cdot}}$ be a pairing and $B\subseteq Y$ a subset. The \udef{orthogonal complement} of $B$ is the polar w.r.t. the relation $\perp$ on $(Y,X)$ defined by
\[ y\perp x \qquad\iff\qquad \pair{x, y} = 0. \]
\end{definition}

\begin{proposition} \label{perpAsPolar}
Let $\sSet{X,Y,\pair{\cdot,\cdot}}$ be a pairing and $B\subseteq Y$ a subset. Then $B^\perp = \Span(B)^\pol$.
\end{proposition}
\begin{proof}
We show both inclusions. First assume $x\in B^\perp$. We need to show that $\abspair{x,y} \leq 1$ for all $y\in \Span(B)$. Indeed we can write $y = \sum_{j=1}^n c_jy_j$ for some $c_j\in\F$ and $y_j\in B$. Then
\[ \abspair{x,y} = \abspair{x, \sum_{j=1}^n c_jy_j} \leq \sum_{j=1}^n |c_j|\;\abspair{x, y_j} = 0 \leq 1, \]
as $y_j\perp x$.

Now assume $x\in \Span(B)^\pol$. If $\abspair{x,y} = 0$ for all $y\in B$, then $x\in B^\perp$ and we are done. Now assume, towards a contradiction, that this is not the case. Then there exists $y\in B$ such that $\abspair{x,y} = \epsilon \neq 1$. Then $\abspair{x,2\epsilon^{-1}y} = 2$, but $2\epsilon^{-1}y\in\Span(B)$, so $\abspair{x,2\epsilon^{-1}y} \leq 1$. This is a contradiction.
\end{proof}
\begin{corollary} \label{corollaryPerpAsPolar}
Let $\sSet{X,Y,\pair{\cdot,\cdot}}$ be a pairing and $B\subseteq Y$ a subset. Then
\begin{enumerate}
\item $B^\perp$ is a subspace;
\item $B^\perp = \Span(B)^\perp = \Span(B^\perp)$;
\item $\{0\}^\perp = X$;
\item $Y$ separates $X$ \textup{if and only if} $Y^\perp = \{0\}$;
\item $B^\perp$ is $\sigma^*(X,Y)$-closed.
\item $B^{\perp\perp} = \overline{\Span(B)}^{\sigma(X,Y)}$;
\item if $\Span(B)$ is $\sigma(X,Y)$-dense in $Y$ and $Y$ separates $X$, then $B^\perp = \{0\}$.
\end{enumerate}
\end{corollary}
\begin{proof}
(1) As $\Span(B)^\pol$ is convex by \ref{polarPropertiesLemma}, we just need to show it is closed under multiplication by $2$, \ref{convexSubspace}. Now $2\cdot \Span(B)^\pol = (2^{-1}\cdot\Span(B))^\pol = \Span(B)^\pol$ by \ref{polarPropertiesLemma}.

(2) We have $B^\perp = \Span(B)^\pol = \Span\big(\Span(B)\big)^\pol = \Span(B)^\perp$. The second equality follows straight from (1).

(3) For all $y\in Y$ we have $y\perp 0$.

(4) We have $0\in Y$, as for all $y\in Y$ we have $y\perp 0$. For all $x\in X\setminus\{0\}$, the following are equivalent: $x\notin Y^\perp$ and $\exists y\in Y: \pair{x,y}\neq 0$. Thus $Y$ being separating on $X$ is equivalent to $\forall x\in X\setminus \{0\}: x\notin Y^\perp$, which is equivalent to $Y^\perp \subseteq \{0\}$.

(5) By \ref{polarPropertiesLemma}.

(6) We have 
\[ B^{\perp\perp} = \Span(B^\perp)^\pol = \big(B^\perp\big)^\pol = \Span(B)^{\pol\pol} = \overline{\disked(\Span(B))}^{\sigma(X,Y)} = \overline{\Span(B)}^{\sigma(X,Y)}, \]
using the bipolar theorem \ref{bipolarTheorem}.

(7) In this case we have $B^\perp = B^{\perp\perp\perp} = \left(\overline{\Span(B)}^{\sigma(X,Y)}\right)^\perp = Y^\perp = \{0\}$.
\end{proof}


\begin{proposition}
Let $\sSet{X,Y,\pair{\cdot,\cdot}}$ be a pairing and $W_1,W_2$ subspaces of $Y$. Then
\[ (W_1+W_2)^\perp = W_1^\perp \cap W_2^\perp. \]
\end{proposition}
\begin{proof}
For a vector $v\in X$,
\begin{align*}
v\in (W_1+W_2)^\perp = (W_1 \cup W_2)^\perp &\implies \forall x\in W_1\cup W_2: \inner{v,x} = 0 \\
&\implies v\in W_1^\perp \cap W_2^\perp
\end{align*}
and
\begin{align*}
v\in W_1^\perp \cap W_2^\perp &\implies \forall x\in W_1, y\in W_2: \inner{v,x} = 0 = \inner{v,y} \\
&\implies \forall x\in W_1, y\in W_2:\inner{v, x+y} = 0 \implies v\in (W_1+W_2)^\perp.
\end{align*}
\end{proof}
TODO: dual result for closed subspaces.



\subsubsection{Annihilator subspaces}
\begin{lemma}
Let $\sSet{X,Y,\pair{\cdot,\cdot}}$ be a pairing and $V\subseteq Y$ a subspace. Then
\[ V^{\pol} = \setbuilder{x\in X}{\forall y\in V:\;\pair{x,y} = 0}. \]
\end{lemma}

\subsubsection{Polar topologies}

\begin{lemma} \label{weaklyBoundedLemma}
Let $\sSet{X,Y,\pair{\cdot,\cdot}}$ be a pairing and $A\subseteq Y$ a subset. The following are equivalent:
\begin{enumerate}
\item $A$ is weakly bounded;
\item $\sup_{y\in A}\abspair{x, y}$ is finite for all $x\in X$;
\item $A^\pol$ is an absorbent subset of $X$.
\end{enumerate}
\end{lemma}
\begin{proof}
$(1) \Leftrightarrow (2)$ Immediate from \ref{boundedSetsInitialTopology} and \ref{weakTopologyLCTVS}, noting that
\[ \sup_{y\in A}\abspair{x, y} = \sup\Big(\abspair{x,-}^{\imf}(A)\Big). \]

$(2) \Leftrightarrow (3)$ By \ref{polarLemma}, point (2) is equivalent to the finiteness of $p_{A^\pol}(x)$ for all $x\in X$. By \ref{gaugeWellDefined} (and the fact that $A^\pol$ is balanced, \ref{polarPropertiesLemma}) we have that this is equivalent to the absorbence of $A^\pol$.
\end{proof}

\begin{proposition}
Let $\sSet{X,Y,\pair{\cdot,\cdot}}$ be a pairing and $\mathcal{A}\subseteq\powerset(Y)$ a set of weakly bounded sets. Then the filter
\[ N = \mathfrak{F}\setbuilder{\lambda A^\pol}{\lambda\in \F, A\in \mathcal{A}} \]
is the neighbourhood filter of $0$ in a locally convex topology on $X$.
\end{proposition}
\begin{proof}
We use \ref{TVSbase} to verify that this filter is the neighbourhood filter of a topological vector space. Indeed, the sets $\lambda A^\pol$ are absorbent by \ref{boundedSetLemma} and \ref{weaklyBoundedLemma}. They are balanced by \ref{polarPropertiesLemma}. Finaly by convexity (\ref{polarPropertiesLemma}), we have $\frac{1}{2}\lambda A^\pol + \frac{1}{2} \lambda A^\pol \subseteq \lambda A^\pol$.

As noted, the basis sets are convex, so the topology is locally convex.
\end{proof}

\begin{definition}
Let $\sSet{X,Y,\pair{\cdot,\cdot}}$ be a pairing and $\mathcal{A}\subseteq\powerset(Y)$ a set of weakly bounded sets. The topology $\xi$ on $X$ with neighbourhood filter
\[ \neighbourhood_\xi(0) \defeq \mathfrak{F}\setbuilder{\lambda A^\pol}{\lambda\in \F, A\in \mathcal{A}} \]
is called the \udef{polar topology} determined by $\mathcal{A}$.
\end{definition}

\begin{proposition}
Let $\sSet{X,Y,\pair{\cdot,\cdot}}$ be a dual system and  $\mathcal{A}\subseteq\powerset(Y)$ a set of weakly bounded sets. Then the polar topology determined by $\mathcal{A}$ is Hausdorff \textup{if and only if} $\Span\Big(\bigcup \mathcal{A}\Big)$ is $\sigma(X,Y)$-dense in $Y$.
\end{proposition}
\begin{proof}

\end{proof}

\subsection{Adjoints}
\begin{definition}
Let $\sSet{X,Y,\pair{\cdot,\cdot}}$ and $\sSet{X',Y',\pair{\cdot,\cdot}'}$ be two pairings and $T: Y\to Y'$ a linear function. An \udef{adjoint} or \udef{transpose} is a linear operator $S: X'\to X$ such that
\[ \pair{x, Ty}' = \pair{Sx, y} \qquad \forall x\in X', \; y\in Y. \]
\end{definition}

\begin{proposition}
Let $\sSet{X,Y,\pair{\cdot,\cdot}}$ and $\sSet{X',Y',\pair{\cdot,\cdot}'}$ be two pairings, $T: Y\to Y'$ a linear function. Then $T$ has an adjoint $S: X'\to X$ \textup{if and only if} it is weakly continuous, i.e.\ continuous as a function
\[ T: \sSet{Y, \sigma(X,Y)} \to \sSet{Y', \sigma(X',Y')}. \]
The adjoint is unique if $Y$ separates $X$.
\end{proposition}
\begin{proof}
The weak continuity of $T$ is, by the characteristic property of the initial convergence \ref{characteristicPropertyInitialFinalConvergence}, equivalent to the continuity of
\[ \pair{x', \cdot}' \circ T = \pair{x', T(\cdot)}' : \sSet{Y, \sigma(X,Y)} \to \F \]
for all $x'\in X'$. In other words, $\pair{x', T(\cdot)}' \in \dual{\sSet{Y, \sigma(X,Y)}}$ for all $x'\in X'$. By \ref{functionalContinuityWeakTopology}, this is equivalent to the existence of some $x\in X$ such that $\pair{x', T(\cdot)}' = \pair{x,\cdot}$. We set $S(x') = x$.

Thus the weak continuity of $T$ is equivalent to the existence of some adjoint function $S$, without the requirement that it be linear. We now just need to show that $S$ can always be taken to be linear.

Indeed, pick some Hamel basis $\mathcal{X}$ of $X'$ and define $S'$ by setting $S'|_{\mathcal{X}} = S|_{\mathcal{X}}$ and extending linearly to the whole of $X'$. It is clear that $S'$ is an adjoint: set $x' = \sum_{x\in\mathcal{X}}\lambda_x x$ (with only finitely many $\lambda_x$ non-zero) and calculate
\begin{multline*}
\pair{x', T(\cdot)}' = \pair{\sum_{x\in\mathcal{X}}\lambda_x x, T(\cdot)}' = \sum_{x\in\mathcal{X}}\lambda_x \pair{x, T(\cdot)} = \sum_{x\in\mathcal{X}}\lambda_x \pair{S(x), \cdot} = \\ \sum_{x\in\mathcal{X}}\lambda_x \pair{S'(x), \cdot} = \pair{S'\left(\sum_{x\in\mathcal{X}}\lambda_x x\right), \cdot} = \pair{S'(x'), \cdot}.
\end{multline*}

Finally we note that the choice of $S(x')$ is unique if $Y$ separates $X$ by \ref{dualSystemBijection}.
\end{proof}
\begin{corollary}
The adjoint of a weakly continuous operator is weak-$*$ continuous.
\end{corollary}
\begin{proof}
Suppose $S$ is an adjoint of $T$. By symmetry of the definition, $T$ is an adjoint of $S$ when considering the dual pairings. Thus $S$ is weak-$*$ continuous by the proposition.
\end{proof}

\begin{lemma}
Let $\sSet{X,Y,\pair{\cdot,\cdot}}$, $\sSet{X',Y',\pair{\cdot,\cdot}'}$ be pairings and $T: Y\to Y'$ a weakly continuous linear function with adjoint $S: X'\to X$. Then for all subsets $A\subseteq Y$, we have
\[ \big(T^{\imf}(A)\big)^\pol = S^{\preimf}(A^\pol). \]
\end{lemma}
\begin{proof}
We calculate, using \ref{polarLemma},
\begin{align*}
S^{\preimf}(A^\pol) &= S^{\preimf}\Big(\bigcap_{y\in A}\setbuilder{x\in X}{\abspair{x,y}\leq 1}\Big) \\
&= \bigcap_{y\in A}S^{\preimf}\Big(\setbuilder{x\in X}{\abspair{x,y}\leq 1}\Big) \\
&= \bigcap_{y\in A}\Big(\setbuilder{x'\in X'}{\abspair{S(x'),y}\leq 1}\Big) \\
&= \bigcap_{y\in A}\Big(\setbuilder{x'\in X'}{\abspair{x',T(y)}\leq 1}\Big) \\
&= \bigcap_{y'\in T^{\imf}(A)}\Big(\setbuilder{x'\in X'}{\abspair{x',y'}\leq 1}\Big) \\
&= \big(T^{\imf}(A)\big)^\pol.
\end{align*}
\end{proof}

\subsection{Adjoints TODO}
\begin{definition}
Let $\sSet{X,Y,\pair{\cdot,\cdot}}$ and $\sSet{X',Y',\pair{\cdot,\cdot}'}$ be two pairings and $T: Y\not\to Y'$ a linear operator. An \udef{adjoint} or \udef{transpose} is a linear operator $S: X'\not\to X$ such that
\[ \pair{x, Ty}' = \pair{Sx, y} \qquad \forall x\dom(S), \; y\in\dom(T). \]
\end{definition}

\begin{lemma}
Let $\sSet{X,Y,\pair{\cdot,\cdot}}$ and $\sSet{X',Y',\pair{\cdot,\cdot}'}$ be two pairings and $T: Y\not\to Y'$ a linear operator.

Let $S_1, S_2: X'\not\to X$ be adjoints of $T$ then for all $x\in \dom(S_1)\cap\dom(S_2)$ we have $S_1(x) - S_2(x) \in \dom(T)^\perp$.

Conversely, let $S$ be an adjoint of $T$ and $x\in\dom(S)$. Then for all $v\in \dom(T)^\perp$ there exists an adjoint $S'$ such that $S'(x) = S(x) + v$.
\end{lemma}
\begin{proof}
For all $u\in \dom(T)$ we have
\[ \pair{S_1(x) - S_2(x), u} = \pair{S_1(x), u} - \pair{S_2(x), u} = \pair{x, Tu}' - \pair{x, Tu}' = 0. \]
So $(S_1(x) - S_2(x)) \in \dom(T)^\perp$.

For the converse, pick some $x\in X$ and set $S' = S + \pair{x,\cdot}v$. This is an adjoint: for all $a\in \dom(T), b\in \dom(S') = \dom(S)$ we have
\[  \inner{S'b,a} = \inner{Sb, a} + \pair{x,b}\pair{v,a} = \inner{Sb, a} = \inner{b,Ta}'. \]
\end{proof}
\begin{corollary}
Let $\sSet{X,Y,\pair{\cdot,\cdot}}$ and $\sSet{X',Y',\pair{\cdot,\cdot}'}$ be two pairings, $T: Y\not\to Y'$ a linear operator and $S_1, S_2$ two adjoints of $T$.

If $Y$ separates $X$ and $T$ is $\sigma(X,Y)$-densely defined, then for all $x\in \dom(S_1)\cap\dom(S_2)$ we have $S_1(x) = S_2(x)$.
\end{corollary}
\begin{proof}
We have, by \ref{corollaryPerpAsPolar}, $\dom(T)^\perp = \{0\}$. So $S_1(x) - S_2(x) = 0$.
\end{proof}
\begin{corollary}
Let $\sSet{X,Y,\pair{\cdot,\cdot}}$ and $\sSet{X',Y',\pair{\cdot,\cdot}'}$ be two pairings, such that $Y$ separates $X$.

Let $T: Y\not\to Y'$ be a linear operator. Then
\[ \bigcup\setbuilder{\graph(S)}{\text{$S\in (X'\not\to X)$ is an adjoint of $T$}} \]
is the graph of an operator \textup{if and only if} $T$ is $\sigma(X,Y)$-densely defined.
\end{corollary}

\begin{definition}
Let $\sSet{X,Y,\pair{\cdot,\cdot}}$ and $\sSet{X',Y',\pair{\cdot,\cdot}'}$ be two pairings. Let $T: Y\not\to Y'$ be a linear operator.

We define the adjoint $T^*$ as the \emph{relation} on $(X',X)$ with graph
\[ \graph(T^*) \defeq \bigcup\setbuilder{\graph(S)}{\text{$S\in (X'\not\to X)$ is an adjoint of $T$}}. \]
\end{definition}

\begin{lemma}
Let $\sSet{X,Y,\pair{\cdot,\cdot}}$ and $\sSet{X',Y',\pair{\cdot,\cdot}'}$ be two pairings, such that $Y$ separates $X$. Let $T: Y\not\to Y'$ be a linear operator with $\sigma(X,Y)$-dense domain.

If $S$ is an adjoint of $T$ that is defined everywhere, then $T^* = S$.
\end{lemma}

\begin{lemma} \label{pairAdjointRelationLemma}
Let $\sSet{X,Y,\pair{\cdot,\cdot}}$ and $\sSet{X',Y',\pair{\cdot,\cdot}'}$ be two pairings. Let $T: Y\not\to Y'$ be a linear operator and $(x,y)\in X'\times X$.

Then $(x, y)\in T^*$ \textup{if and only if}
\[ \forall z\in\dom(T): \; \pair{x, T(z)} = \pair{y, z}. \]
\end{lemma}
\begin{proof}
$\boxed{\Rightarrow}$ If $(x, y)\in T^*$, then there exists an adjoint $S: X'\not\to X$ such that $S(x) = y$. For all $z\in \dom(T)$ we have $\pair{x, T(z)}' = \pair{S(x), z} = \pair{y, z}$.

$\boxed{\Leftarrow}$ The function defined by $S(x) = y$ and extended to $\Span\{x\}$ by linearity is an adjoint.
\end{proof}

\begin{proposition} \label{pairAdjointDomain}
Let $\sSet{X,Y,\pair{\cdot,\cdot}}$ and $\sSet{X',Y',\pair{\cdot,\cdot}'}$ be two pairings. Let $T: Y\not\to Y'$ be a linear operator. Then
\[ \dom(T^*) = \setbuilder{x\in X'}{\text{$\dom(T)\to \F: u\mapsto \pair{x, Tu}$ is a $\sigma(X,Y)$-continuous functional}}. \]
\end{proposition}
\begin{proof}
$\boxed{\subseteq}$ If $\omega_x: u\mapsto \inner{x, Tu}$ is $\sigma(X,Y)$-continuous, then it can be extended to a continuous functional on all of $Y$ by 


------ TODO: rework from here!! ------

its domain can be extended by continuity to $\overline{\dom(T)}$, which is a Hilbert space. This extended functional has a Riesz vector $x^*$ such that $\omega_x = u\mapsto \inner{x^*, u}$. The linear operator with domain $\Span\{x\}$ that maps $x$ to $x^*$ is then an adjoint.

$\boxed{\supseteq}$ If $x\in\dom(T^*)$, then, using the Cauchy-Schwarz inequality,
\[ |\inner{x,Tu}| = |\inner{T^*x,u}| \leq \norm{T^*x}\;\norm{u}, \]
so the functional $u\mapsto \inner{x, Tu}$ is bounded.
\end{proof}
\begin{corollary}
The domain $\dom(T^*)$ is a vector space and in particular contains $0$.
\end{corollary}

\begin{proposition} \label{HilbertAdjointGaloisConnection}
Let $H, K$ be Hilbert spaces. Take $T\in (H\not\to K)$ and $S\in (K\not\to H)$. Then
\[ S \subseteq T^* \iff T\subseteq S^*. \]
Thus $(*,*)$ is an antitone Galois connection between $\sSet{(H\not\to K), \subseteq}$ and $\sSet{(K\not\to H), \subseteq}$.
\end{proposition}
\begin{proof}
We have $S \subseteq T^*$ iff $S$ is an adjoint of $T$ iff $T$ is an adjoint of $S$ (by \ref{adjointRequirementSymmetric}) iff $T\subseteq S^*$.
\end{proof}
\begin{corollary} \label{HilbertAdjointAntitone}
Let $S,T: H\not\to K$ be operators between Hilbert spaces such that $S\subseteq T$. Then $T^* \subseteq S^*$.
\end{corollary}
\subsubsection{Properties of the adjoint relation}

\begin{proposition}
Let $T$ be an operator between Hilbert spaces and $\lambda\in\C$. If $\lambda \neq 0$, then
\[ \begin{pmatrix}
\id & 0 \\ 0 & \overline{\lambda}\id
\end{pmatrix} \graph(T^*) = (\lambda T)^*. \]
\end{proposition}
Note that if $T^*$ is a function (i.e.\ if $T$ is densely defined), then $\begin{pmatrix}
\id & 0 \\ 0 & \overline{\lambda}\id
\end{pmatrix} \graph(T^*) = \overline{\lambda}T^*$. We write the former in the proposition, because we have not made this assumption.

If $\lambda = 0$ and $T: H\not\to K$, then
\[ \begin{pmatrix}
\id & 0 \\ 0 & 0
\end{pmatrix} \graph(T^*) = \big(0: \dom(T^*)\to H\big) \subseteq \big(0: K\to H\big) = (0 T)^*, \]
where the last equality is given by \ref{adjointBoundedEverywhereDefined}.
\begin{proof}
For the inclusion $\subseteq$, take $f$ to be an adjoint of $T$. It is enough to show that $\overline{\lambda}f$ is an adjoint of $\lambda T$. This follows from
\[ \inner{\overline{\lambda}f(w), v} = \lambda\inner{f(w), v} = \lambda\inner{w,Tv} = \inner{w,\lambda Tv} \qquad \forall w\in \dom(f), v\in \dom(T). \]

For the other inclusion, let $f$ be an adjoint of $\lambda T$. It is enough to show that $\overline{\lambda^{-1}}f$ is an adjoint of $T$, because then $f = \overline{\lambda}\cdot\overline{\lambda^{-1}}f \subseteq \begin{pmatrix}
\id & 0 \\ 0 & \overline{\lambda}\id
\end{pmatrix} \graph(T^*)$. Indeed
\[ \inner{\overline{\lambda^{-1}}f(w), v} = \lambda^{-1}\inner{f(w),v} = \inner{w,\lambda^{-1}\lambda Tv} = \inner{w,Tv} \quad \forall w\in \dom(f), v\in \dom(T). \]
\end{proof}

\begin{proposition} \label{adjointGraph}
Let $T: H\not\to K$ be an operator between Hilbert spaces. Then
\begin{align*}
\graph(T^*) &= \left( \begin{pmatrix}
0 & -\id \\ \id & 0
\end{pmatrix}\graph(T) \right)^\perp 
=  \begin{pmatrix}
0 & -\id \\ \id & 0
\end{pmatrix}\graph(T)^\perp.
\end{align*}
If $T$ is densely defined, then $T^*$ is a closed operator.
\end{proposition}
\begin{proof}
We have
\[ \graph(T^*) = \bigcup\setbuilder{\graph(S)}{\text{$S\in (K\not\to H)$ is an adjoint of $T$}}. \]
Take an adjoint $S$ and $(w, Sw)$ in $\graph(S)$. Then for all $v\in\dom(T)$:
\[ 0 = \inner{w, Tv}_K - \inner{Sw, v}_H = \inner{w, Tv}_K + \inner{Sw, -v}_H = \inner{(w, Sw), (Tv,-v)}_{K\oplus H}. \]
So $(Tv,-v) = \begin{pmatrix}
0 & -\id \\ \id & 0
\end{pmatrix} (v,Tv) \in \graph(S)^\perp $.

The final equality follows from \ref{perpUnderIsometry}, using the fact that $\begin{pmatrix}
0 & -\id \\ \id & 0
\end{pmatrix}$ is a surjective isometry.

If $T$ is densely defined, then $T^*$ is a function by \ref{maximalAdjointIsOperator}. It is closed by \ref{orthogonalComplementClosed}.
\end{proof}
\begin{corollary} \label{adjointDenselyDefinedClosable}
Let $T: H\not\to K$ be a densely defined operator between Hilbert spaces.
Then
\begin{enumerate}
\item $\graph(T^{**}) = \overline{\graph(T)}$;
\item $T^*$ is densely defined \textup{if and only if} $T$ is closable;
\item If $T$ is closable, then $\overline{T} = T^{**}$.
\end{enumerate}
\end{corollary}
\begin{proof}
From the proposition we have
\begin{align*}
\graph(T^{**}) &=  \begin{pmatrix}
0 & -\id \\ \id & 0
\end{pmatrix}\graph(T^*)^\perp 
=  \begin{pmatrix}
0 & -\id \\ \id & 0
\end{pmatrix}\left(\begin{pmatrix}
0 & -\id \\ \id & 0
\end{pmatrix}\graph(T)^\perp\right)^\perp \\
&= \begin{pmatrix}
0 & -\id \\ \id & 0
\end{pmatrix}^2\graph(T)^{\perp\perp} = -\graph(T)^{\perp\perp}
= \overline{\graph(T)}.
\end{align*}
The right-hand side is the graph of an operator iff $T$ is closable and the left-hand side is the graph of an operator iff $T^*$ is densely defined, by \ref{maximalAdjointIsOperator}.

For a closable operator, the closure is defined by $\overline{\graph(T)} = \graph(\overline{T})$.
\end{proof}

\begin{proposition} \label{adjointBoundedEverywhereDefined}
Let $T: H\to K$ be a densely defined operator between Hilbert spaces. Then $\dom(T^*) = K$ \textup{if and only if} $T$ is bounded.
\end{proposition}
\begin{proof}
The direction $\Leftarrow$ is given by \ref{adjointDomain}.

For the other direction, note that $T^*$ is closed by \ref{adjointGraph}. Then $T^*$ is bounded by the closed graph theorem \ref{closedGraphTheorem}. We use the direction $\Leftarrow$ to see that $\dom(T^{**}) = H$. Similarly, $T^{**}$ is closed by \ref{adjointGraph} and bounded by the closed graph theorem \ref{closedGraphTheorem}. Thus $T\subseteq \overline{T} = T^{**}$ is bounded.
\end{proof}

An important application of this proposition is the Hellinger-Toeplitz theorem \ref{HellingerToeplitz}.

\begin{proposition} \label{adjointAlgebraicProperties}
Let $T,S$ be compatible operators between Hilbert spaces. Then
\begin{enumerate}
\item $S^* + T^* \subseteq (S+T)^*$;
\item $S^*T^* \subseteq (TS)^*$.
\end{enumerate}
\end{proposition}
\begin{proof}
(1) Let $f$ be an adjoint of $S$ and $g$ an adjoint of $T$. It is enough to see that $f+g$ is an adjoint of $S+T$. Indeed $\forall w\in \dom(f + g), v\in \dom(S+T)$
\[ \inner{(f + g)(w), v} = \inner{f(w),v} + \inner{g(w), Tv} = \inner{w,Sv} + \inner{w,Tv} = \inner{w,(S+T)v}. \]

(2) Let $f$ be an adjoint of $T$ and $g$ an adjoint of $S$. It is enough to see that $gf$ is an adjoint of $TS$. Indeed
\[ \inner{g\circ f(w), v} = \inner{f(w), Sv} = \inner{w,TSv} \qquad \forall w\in \dom(g\circ f), v\in \dom(TS). \]
\end{proof}


There exist various conditions that make the inclusions in \ref{adjointAlgebraicProperties} equalities.
\begin{proposition} \label{equalityAlgebraicPropertiesAdjoint}
Let $T,S$ be compatible operators between Hilbert spaces.
\begin{enumerate}
\item if $T$ is densely defined, $\dom(S) \subseteq \dom(T)$ and $\dom\big((S+T)^*\big) \subseteq \dom(T^*)$, then $S^* + T^* = (S+T)^*$;
\item if $T$ is densely defined, $\im(S)\subseteq \dom(T)$ and $\dom\big((TS)^*)\subseteq \dom(T^*)$, then $S^*T^* = (TS)^*$;
\item if $S$ is densely defined and $\im(S)$ has finite codimension, then $S^*T^* = (TS)^*$.
\end{enumerate}
\end{proposition}
\begin{proof}
(1) By \ref{adjointAlgebraicProperties}, we have
\[ (S+T)^* - T^* \subseteq (S+T-T)^* = S^*, \]
where the last equality is due to $\dom(S) \subseteq \dom(T)$. Now take $x,y$ such that $x\in \dom\big((S+T)^*\big)$. Then $T^*(x)$ exists and we have the implications
\begin{align*}
x(S+T)^*y \iff& x\big((S+T)^* - T^* + T^*\big)y \\
\iff& \exists z: \; x\big((S+T)^* - T^*\big)z \land (z+T^*(x) = y) \\
\implies& \exists z: \; x(S^*)z \land (z+T^*(x) = y) \\
\iff& x(S^* + T^*)y.
\end{align*}
Thus $(S+T)^* \subseteq S^* + T^*$.

(2) We need to prove $(TS)^* \subseteq S^*T^*$. Assume $(x,y)\in (TS)^*$. By \ref{adjointRelationLemma}, we have
\[ \forall z\in \dom(TS):\; \inner{x, TS(z)} = \inner{y, z}. \]
Because $\im(S)\subseteq \dom(T)$, we have $\dom(TS) = \dom(S)$. Also, by assumption, $x\in \dom(T^*)$. So we have
\[ \forall z\in \dom(S):\; \inner{x, TS(z)} = \inner{T^*(x), S(z)} = \inner{y, z}, \]
which means that $\big(T^*(x), y\big)\in S^*$, so $(x,y)\in S^*T^*$.

(3)
\end{proof}
\begin{corollary}
If $T$ is bounded and everywhere defined, then
\[ S^* + T^* = (S+T)^* \qquad\text{and}\qquad S^*T^* = (TS)^*. \]
\end{corollary}


\begin{lemma} \label{HilbertAdjointLemma}
Let $S,T\in\Bounded(H,K)$ and $\lambda \in \mathbb{F}$.
\begin{enumerate}
\item $(T^*)^* = T$;
\item $(S+T)^* = S^* + T^*$;
\item $(\lambda T)^* = \bar{\lambda}T^*$;
\item $\id_V^* = \id_V$.
\end{enumerate}
Let $T\in\Bounded(H_1,H_2), S\in\Bounded(H_2,H_3)$
\begin{enumerate}
\setcounter{enumi}{4}
\item $(ST)^* = T^*S^*$.
\end{enumerate}
\end{lemma}

\begin{note}
Useful exercise: The identities of \ref{HilbertAdjointLemma} can also be proven by elementary manipulations. For example, to prove (1), we take arbitrary $v\in H$ and $w\in K$, Then
\[ \inner{w,Tv} = \inner{T^*w,v} = \overline{\inner{v,T^*w}} = \overline{\inner{(T^*)^*v,w}} = \inner{w, (T^*)^*v}. \]
By lemma \ref{elementaryOrthogonality} we have $Tv = (T^*)^*v$ for all $v\in V$. 
\end{note}

\subsubsection{Adjoints of densely defined operators}
The adjoint of an operator is a function if and only the operator is densely defined.

\begin{proposition} \label{adjointRangeCriterion}
Let $S: K\not\to H$ and $T: H\not\to K$ be linear operators between Hilbert spaces. If
\[ \im(S\cap T^*) = H \qquad\text{and}\qquad \im(T\cap S^*) = K, \]
then $S$ and $T$ are densely defined with $S^* = T$ and $T^* = S$.
\end{proposition}
\begin{proof}
Notice that $S\cap T^*$ and $T\cap S^*$ are linear operators that are adjoints of each other.

We claim that they are densely defined: take $x\in \dom(S\cap T^*)^\perp$. Then there exists some $y\in H$ such that $x = (T\cap S^*)y$ because of surjectivity. Now for all $z\in \dom(S\cap T^*)$
\[ 0 = \inner{z,x} = \inner{z, (T\cap S^*)y} = \inner{(S\cap T^*)z, y}, \]
so $\inner{z',y} = 0$ for all $z'\in H$, by surjectivity. This means, by \ref{elementaryOrthogonality}, that $y=0$ and thus also $x = (T\cap S^*)y = 0$. We conclude that $\dom(S\cap T^*)^\perp = \{0\}$, meaning $(S\cap T^*)$ is densely defined. The argument for $(T\cap S^*)$ is similar.

It follows that $S$ and $T$ must be densely defined. We have, by \ref{kernelImageAdjoint},
\[ \ker(S) = \im(S^*)^\perp \subseteq \im(T\cap S^*)^\perp = \{0\}. \]
Similarly $\ker(T) = \ker(S^*) = \ker(T^*) = \{0\}$.

So we have $\ker(S) = \ker(T^*)$, $\im(S)\subseteq \im(S\cap T^*)$ and $\im(T^*)\subseteq \im(S\cap T^*)$. The equality $S = T^*$ follows from \ref{partialFunctionSubset}. The equality $T = S^*$ is similar.
\end{proof}


\begin{proposition} \label{kernelImageAdjoint}
Let $T: H\not\to K$ be an operator between Hilbert spaces. Then
\[ \forall v\in K: \; (v,0)\in T^* \iff v\in \im(T)^\perp. \]
If $T^*$ is densely defined, this reduces to
\begin{enumerate}
\item $\ker(T^*) = \im(T)^\perp$;
\item $\ker(T) \subseteq \im(T^*)^\perp$;
\item if $T$ is closed, then $\ker(T) = \im(T^*)^\perp$
\end{enumerate}
\end{proposition}
\begin{proof}
(1) Because $\dom(T)$ is dense in $H$, we have $\dom(T)^\perp = \{0\}$ by \ref{orthogonalComplementDenseSpace}. Take $v\in K$. We have the equivalences
\begin{align*}
v\in \im(T)^\perp &\iff \forall x \in\dom(T): \inner{v, T(x)} = 0 \\
&\iff \forall x \in\dom(T): \inner{v, T(x)} = \inner{v, 0} \\
&\iff (v,0)\in T^*,
\end{align*}
using \ref{adjointRelationLemma}.

Point (1) is a direct translation in the case that $T^*$ is a function.

For point (2) note that $T\subseteq T^{**}$ (by \ref{adjointDenselyDefinedClosable}) implies that $(v,0)\in T \implies (v,0)\in T^{**}$.

For point (3): in this case $\ker(T) = \ker(T^{**}) = \im(T^*)^\perp$.
\end{proof}
\begin{corollary}[Closed range theorem for Hilbert spaces]
Let $T$ be a closed, densely defined operator between Hilbert spaces. Then the following are equivalent:
\begin{enumerate}
\item $\im(T)$ is closed;
\item $\im(T^*)$ is closed;
\item $\im(T) = \ker(T^*)^\perp$;
\item $\im(T^*) = \ker(T)^\perp$.
\end{enumerate}
\end{corollary}
\begin{proof}
By the proposition and \ref{orthogonalComplementClosed}, we have $\overline{\im(T)} = \ker(T^*)^\perp$. This shows $(1) \Leftrightarrow (3)$ and $(2) \Leftrightarrow (4)$.

TODO equivalence $(1)\Leftrightarrow (2)$.
\end{proof}
TODO ref closed range theorem for Banach spaces. This is, e.g., the case when $T$ is bounded below, see \ref{boundedBelowClosedRange}.

\begin{proposition}
Let $T: H\not\to K$ be a densely defined operator between Hilbert spaces. Then
\begin{enumerate}
\item $\im(T)$ is dense in $K$ \textup{if and only if} $T^*$ is injective;
\item if $T$ and $T^*$ are injective, then $(T^*)^{-1} = (T^{-1})^*$;
\item if $T$ is closable and $\overline{T}$ is injective, then $\overline{T}^{\,-1} = \overline{T^{-1}}$.
\end{enumerate}
\end{proposition}
\begin{proof}
(1) This is immediate from \ref{kernelImageAdjoint} and \ref{injectivityKernelTriviality}:
\[ \text{$\im(T)$ is dense} \quad\iff\quad \{0\} = \im(T)^\perp = \ker(T^*). \]

(2) We have $\graph(T^{-1}) = \begin{pmatrix}
0 & \id \\ \id & 0
\end{pmatrix}\graph(T)$. Also note that $\begin{pmatrix}
0 & \id \\ \id & 0
\end{pmatrix}$ and $\begin{pmatrix}
0 & -\id \\ \id & 0
\end{pmatrix}$ commute. Then we compute using \ref{adjointGraph}:
\begin{align*}
\graph((T^*)^{-1}) &= \begin{pmatrix}
0 & \id \\ \id & 0
\end{pmatrix}\begin{pmatrix}
0 & -\id \\ \id & 0
\end{pmatrix}\graph(T)^\perp \\
&= \begin{pmatrix}
0 & -\id \\ \id & 0
\end{pmatrix}\begin{pmatrix}
0 & \id \\ \id & 0
\end{pmatrix}\graph(T)^\perp \\
&= \begin{pmatrix}
0 & -\id \\ \id & 0
\end{pmatrix}\left(\begin{pmatrix}
0 & \id \\ \id & 0
\end{pmatrix}\graph(T)\right)^\perp = \graph((T^{-1})^*).
\end{align*}
The penultimate equality follows from \ref{perpUnderIsometry}, using the fact that $\begin{pmatrix}
0 & \id \\ \id & 0
\end{pmatrix}$ is a surjective isometry.
\end{proof}

\subsubsection{Adjoints of bounded operators}
\begin{proposition}
Let $T: H\to K$ be a densely defined operator between Hilbert spaces. Then
\begin{enumerate}
\item if $T\in\Bounded(H,K)$, then $T^*\in\Bounded(K,H)$;
\item if $T^*\in\Bounded(K,H)$, then $T$ is bounded. If $T$ is closed, then $T$ is defined everywhere.
\end{enumerate}
Assume $T\in\Bounded(H,K)$. Then
\begin{enumerate} \setcounter{enumi}{2}
\item $\norm{T} = \norm{T^*}$;
\item $T^* = C_H^{-1}T^tC_K$, where $C_K$ is the Riesz isometry from \ref{RieszIsometry}.
\end{enumerate}
\end{proposition}
\begin{proof}
(1) Assume $T\in\Bounded(H,K)$. Then $u\mapsto \inner{x,Tu}$ is a bounded functional for all $x\in K$, so $\dom(T^*) = K$ by \ref{adjointDomain}. Also $T^*$ is closed by \ref{adjointGraph}, so it is bounded by the closed graph theorem \ref{closedGraphTheorem}.

(2) Assume $T^*\in\Bounded(K,H)$. By the previous argument $T \subseteq \overline{T} = T^{**}\in\Bounded(H,K)$.

(3) The function $(x,u)\mapsto \inner{x,Tu}$ is a bounded sesquilinear form. By proposition \ref{sesquilinearRepresentation}, $T^*$ must be the unique $S$ from the proposition, which has norm $\norm{T}$.

(4) Finally we note that $C_H^{-1}T^tC_K$ is an adjoint with domain $K$ and conclude by \ref{everywhereDefinedAdjointLemma}.
\end{proof}

\begin{lemma}
The adjoint defines a map $*:\Bounded(H,K)\to \Bounded(K,H)$ that is anti-linear and continuous in the weak and uniform operator topologies. It is continuous in the strong operator topology \textup{if and only if} finite dimensional.
\end{lemma}
\begin{proof}
By the proposition the adjoint map is anti-linear. It is also bounded with norm $1$. Then by corollary \ref{boundedAntiLinearMaps} it must be bounded.

TODO
\end{proof}

\begin{proposition}
Let $H,K$ be Hilbert spaces and $T:H\to K$ a bijective bounded linear operator with bounded inverse. Then $(T^*)^{-1}$ exists and
\[ (T^*)^{-1} = (T^{-1})^*. \]
\end{proposition}
\begin{proof}
We prove $(T^{-1})^*$ is both a left- and a right-inverse of $T^*$: $\forall x\in H, y\in K$
\begin{align*}
\inner{T^*(T^{-1})^*x,y} &= \inner{x,T^{-1}Ty} = \inner{x,y} \\
\inner{x,(T^{-1})^*T^*y} &= \inner{TT^{-1}x,y} = \inner{x,y}
\end{align*}
So, by lemma \ref{elementaryOrthogonality}, $T^*(T^{-1})^* = \id_H$ and $(T^{-1})^*T^* = \id_K$.
\end{proof}

\begin{proposition} \label{normOfSquare}
Let $T\in \Bounded(H,K)$ with $H,K$ Hilbert spaces. Then
\[ \norm{T^*T}= \norm{T}^2 = \norm{TT^*}. \]
\end{proposition}
\begin{proof}
For $\norm{T^*T}= \norm{T}^2$ first observe that
\[ \norm{T^*T} \leq \norm{T^*}\cdot\norm{T} = \norm{T}^2. \]
Conversely, $\forall x\in H$:
\[ \norm{T(x)}^2 = \inner{Tx,Tx} = \inner{T^*Tx,x} \leq \norm{T^*Tx}\cdot \norm{x} \leq \norm{T^*T}\cdot\norm{x}^2. \]
The other equality follows by applying the first to $T^*$ and using $\norm{T^*}=\norm{T}$.
\end{proof}


\subsection{Mackey topology}

\begin{theorem}[Mackey-Arens]
\end{theorem}

\subsection{Duality sets for normed spaces}
\begin{definition}
Consider a dual system $\sSet{V, W, \pair{\cdot,\cdot}}$ where $V,W$ are normed spaces. For all $v\in V$ we have the \udef{duality set} of $v$
\[ \mathfrak{d}(v) \defeq \setbuilder{w\in W}{\norm{v}^2 = \pair{v,w} = \norm{w}^2}. \]
Similarly the duality set of $w\in W$ is
\[ \mathfrak{d}(w) \defeq \setbuilder{v\in V}{\norm{v}^2 = \pair{v,w} = \norm{w}^2}. \]
\end{definition}

\begin{proposition}
Consider the dual pair $\sSet{V^*, V}$ for some normed space $V$. Then for all $v\in V$, $\mathfrak{d}(v)$ is not empty.
\end{proposition}
\begin{proof}
We have $\norm{v}\cdot \omega_v\in \mathfrak{d}(v)$, where $\omega_v$ is defined in Corollary \ref{existenceBoundedFunctionalOfSameNorm} of the Hahn-Banach extension theorem.
\end{proof}

\section{Operators on topological vector spaces}

\subsection{Continuous operators}
\subsubsection{Closed graph theorem}

\begin{theorem}[Closed graph theorem] \label{closedGraphTheorem}
Let $f:X\to Y$ be a map from a topological space $X$ into a Hausdorff space $Y$.
\begin{enumerate}
\item if $f$ is continuous, then $f$ has closed graph;
\item if $X$ is compact, then the converse also holds.
\end{enumerate}
\end{theorem}
\begin{proof}
TODO
\end{proof}
TODO: for Banach spaces $X$ complete enough!!!!!!


\subsection{Compact operators}
\begin{definition}
A linear operator $T:X\to Y$ between TVSs is \udef{compact} if it maps a neighbourhood of the origin to a precompact set, i.e.\ 
\[ \exists U \in \neighbourhood(0): \;  \text{$\overline{T[U]}$ is compact.} \]
The set of compact linear operators in $(X\to Y)$ is denoted $\Compact(X,Y)$.
\end{definition}
TODO: doesn't the neighbourhood need to be bounded in some way?????

\begin{proposition}
Let $X$ be a normed space and $Y$ a TVS and $T:X\to Y$ a linear operator. Then the following are equivalent:
\begin{enumerate}
\item $T$ is a compact operator;
\item there exists a neighbourhood $U \subset X$ of the origin and a compact set $V\subset Y$ such that $T[U] \subset V$;
\item the image of the unit ball of $X$, $T[B(\vec{0},1)]$, is precompact in $Y$;
\item the image of any bounded set in $X$ is precompact in $Y$.
\end{enumerate}
If $Y$ is a normed space, these are also equivalent to
\begin{enumerate} \setcounter{enumi}{4}
\item for any bounded sequence $(x_{n})_{n\in \mathbb{N}}$ in $X$, the sequence $(Tx_{n})_{n\in \mathbb{N} }$ contains a converging subsequence.
\end{enumerate}
\end{proposition}
\begin{proof}
TODO
\end{proof}


\begin{lemma}
Let $X,Y$ be TVSs.
\begin{enumerate}
\item Then $\Compact(X, Y)$ is a vector space.
\item If $X,Y$ are normed spaces, then $\Compact(X, Y)$ is a subspace of $\Bounded(X, Y)$.
\end{enumerate}
\end{lemma}
\begin{proof}
(1) Let $K,K':X\to Y$ be compact operators. Then, by \ref{closureGroupOperation} (TODO opposite inclusion!),
\[ \overline{K[B(0, 1)]+K'[B(0, 1)]} \subseteq \overline{K[B(0, 1)]}+\overline{K'[B(0, 1)]}, \qquad \overline{K[\lambda B(0, 1)]} = \lambda\overline{K[B(0, 1)]}. \]

(2) Let $K\in\Compact(X, Y)$. Then the image of the unit ball is precompact, meaning it is bounded. So $K$ is bounded by \ref{existenceOperatorNorm}.
\end{proof}

\begin{lemma}
Let $T:V\to W$ be a bounded operator. If $W$ has the Heine-Borel property, then $T$ is compact.
\end{lemma}
\begin{proof}
The set $T[B(\vec{0},1)]$ is bounded because $T$ is. By the Heine-Borel (TODO ref) property of $W$, $\overline{B(\vec{0},1)}$ is compact.
\end{proof}
\begin{corollary}
Bounded operators with as image a finite dimensional normed space are compact.
\end{corollary}
\begin{corollary}
The identity on a normed space $X$ is compact \textup{if and only if} $X$ is finite-dimensional.
\end{corollary}
\begin{proof}
TODO ref. 
\end{proof}

\begin{proposition}
Compact operators map weakly convergent sequences to strongly convergent sequences. TODO! + remove from Hilbert section.
\end{proposition}
\begin{corollary} \label{limitCompactImageOrthonormalSequence}
Let $V$ be an inner product space and $\seq{e_n}$ a sequence of orthonormal vectors in $V$. If $K$ is a compact operator, then $\lim_{n\to\infty}Ke_n = 0$.
\end{corollary}
\begin{proof}
Any sequence of orthonormal vectors $\seq{e_n}$ converges weakly to $0$. Because $K$ is compact, $\seq{Ke_n}$ converges strongly to zero. TODO ref.
\end{proof}
\begin{corollary}
If $V$ is infinite-dimensional and $K$ is invertible, then its inverse is unbounded.
\end{corollary}
\begin{proof}
Due to $\lim_{n\to\infty}Ke_n = 0$ the operator $K$ cannot be bounded below, so $K^{-1}$ is not bounded by \ref{boundedBelow}.
\end{proof}

\section{Continuity}
\url{https://en.wikipedia.org/wiki/Bilinear_map#Continuity_and_separate_continuity}













\input{functionalAnalysis/banachSpaces}









\chapter{Spectral theory and functional calculus}
\section{Invariant subspaces}
\begin{definition}
Let $L\in \Hom(V)$ be an endomorphism. A subspace $U$ of $V$ is \udef{invariant} under $L$ if $T|_U$ is an endomorphism on $U$. In other words, $u\in U$ implies $Tu\in U$.
\end{definition}
Clearly this definition only works for endomorphisms, not for linear maps in general. This is true for the rest of the theory about eigenvalues and eigenvectors.
\begin{example}
Let $L\in \Hom(V)$. The following are invariant under $L$:
\begin{itemize}
\item $\{0\}$;
\item $\ker L$;
\item $\im L$.
\end{itemize}
\end{example}

\section{The spectrum}
TODO: eigenvalue problem $Lx = \lambda x$

generalised eigenvalue problem $Lx = \lambda T x$

nonstandard eigenvalue problem $A(\gamma)x = 0$.

TODO: consistency $\lambda \id - L$, not $L-\lambda \id$.
TODO: everything is now in $\C$.

\begin{definition}
Let $L: \dom(L)\subset V \to V$ be an operator on a complex normed vector space $V$.

For $\lambda\in\C$ the \udef{resolvent} $R_L(\lambda): \im(\lambda \id_V - L)\to\dom(L)$ is the left inverse of $\lambda \id_V - L$, if this inverse exists (i.e.\ if $\lambda \id_V - L$ is injective).
\begin{itemize}
\item The \udef{resolvent set} $\res(L)$ is the set
\begin{align*}
\res(L) &\defeq \setbuilder{\lambda\in \C}{R_L(\lambda)\in\Bounded(V, \dom(L))} \\
&= \setbuilder{\lambda\in \C}{\text{$R_L(\lambda)$ exists, has domain $V$ and is bounded}}.
\end{align*}
\item The \udef{spectrum} of $L$ is the complement of the resolvent set: $\spec(L) \defeq \C\setminus\rho(L)$.
\item The \udef{spectral radius} $\spr(L)$ is $\sup_{\lambda\in\spec(L)} |\lambda|$.
\end{itemize}
\end{definition}

\begin{lemma}
Let $T\in\Lin(V)$ be an operator and $\lambda\in\C$ such that $\lambda\id_V - T$ is injective. Then $\im(R_T(\lambda)) = \dom(T)$.
\end{lemma}
\begin{proof}
For all $x\in \dom(T)$ we have $x = R_T(\lambda)(\lambda\id_V - T)x$.
\end{proof}

\begin{lemma} \label{elementResolventSetNormedSpace}
Let $T$ be an operator on a normed vector space $V$. Then $\lambda \in \res(T)$ \textup{if and only if} $\lambda \id_V - T$ is surjective and bounded from below.
\end{lemma}
\begin{proof}
By \ref{boundedBelow}, $\lambda \id_V - T$ has a bounded inverse $(\lambda \id_V - T)^{-1}: \im(\lambda \id_V - T)\to V$ if and only if it is bounded below. In order for $\lambda$ to be in the resolvent set, we need $(\lambda \id_V - T)^{-1}$ to be defined everywhere, i.e. $\im(\lambda \id_V - T) = V$.
\end{proof}

\begin{lemma} \label{densityCoreLemma}
Let $A$ be a closed operator on a Banach space $X$, $D$ a core for $A$ and $\lambda\in\res(A)$. Then $(\lambda\id_X - A)D$ is dense in $X$.
\end{lemma}
\begin{proof}
Take any $x\in X$. Then $R_A(\lambda)x\in \dom(A)$ and we can find a sequence $\seq{x_n}\subseteq \dom(A)$ that converges in graph norm to $R_A(\lambda)x$. Then $Ax_n \to AR_A(\lambda)x$ by \ref{graphNormConvergenceLemma} and so
\[ (\lambda\id_X - A)D \supseteq \seq{(\lambda\id_X - A)x_n} \to (\lambda\id_X - A)R_A(\lambda)x = x. \]
\end{proof}

\subsection{The three-way classification of the spectrum}
\begin{definition}
Let $L: \dom(L)\subset V \to V$ be an operator on a complex vector space $V$.

\begin{itemize}
\item The \udef{point spectrum} or \udef{discrete spectrum} $\pspec(L)$ contains the values of $\lambda$ where $\lambda \id_V - L$ fails to be injective, so the resolvent fails to exist. These values are called the \udef{eigenvalues} of $L$.

We call
\begin{itemize}
\item $\ker(\lambda \id_V - L)$ the \udef{multiplicity space} or \udef{geometric eigenspace} of $\lambda$; and
\item $\dim\ker(\lambda \id_V - L)$ the \udef{(geometric) multiplicity} of $\lambda$.
\end{itemize}
\item The \udef{continuous spectrum} $\cspec(L)$ is the set of all values of $\lambda\in\spec(L)$ such that the resolvent $R_L(\lambda)$ exists and is densely defined.
\item The \udef{residual spectrum} $\rspec(L)$ is the set of all values of $\lambda\in\spec(L)$ such that the resolvent $R_L(\lambda)$ exists, but is not densely defined.

We call
\begin{itemize}
\item $\im(\lambda \id_V - L)^\perp$ the \udef{deficiency subspace} of $\lambda$; and 
\item $\dim(\im(\lambda \id_V - L)^\perp)$ the \udef{deficiency} of $\lambda$.
\end{itemize}
\end{itemize}
The sets $\pspec(T), \cspec(T)$ and $\rspec(T)$ are disjoint.
\end{definition}
In finite dimensions we know that
\[ \text{$\lambda \id_V - L$ is surjective} \quad\iff\quad \text{$\lambda \id_V - L$ is injective} \]
and all linear operator are bounded.
So in this case there can only ever be a point spectrum.

\begin{proposition} \label{spectrumNonClosedOperator}
If $T$ is an operator on a Banach space that is not closed, then $\spec(T) = \C$.
\end{proposition}
\begin{proof}
We can find a sequence $x_n \to x$ such that $Tx_n \to y$, but $Tx \neq y$. Then for all $\lambda\in\C$ we have $z_n = (\lambda\id - T)x_n \to \lambda x - y$. If $R_T(\lambda)$ was a bounded inverse of $(\lambda\id - T)$, then $R_T(\lambda)\circ(\lambda\id - T)x_n \to R_T(\lambda)(\lambda x - y)$. We need to show that $R_T(\lambda)(\lambda x - y) \neq x$. Indeed
\begin{align*}
R_T(\lambda)(\lambda x - y) &= R_T(\lambda)(\lambda x - Tx + Tx - y) \\
&= R_T(\lambda)(\lambda x - Tx) + R_T(\lambda)(Tx - y) \\
&= x + R_T(\lambda)(Tx - y),
\end{align*}
and $R_T(\lambda)(Tx - y) \neq 0$, because $Tx - y \neq 0$ and the kernel of $R_T(\lambda)$ is trivial because it is injective. 
\end{proof}

\begin{example}
Closed operators may also have empty resolvent set. \url{https://math.stackexchange.com/questions/3262168/closed-operator-with-trivial-resolvent-set}
\end{example}

So spectral theory is only interesting for closed operators. In this case the three-way classification exhausts the possibilities: (only on Banach spaces??)

\begin{proposition} \label{closedOperatorBanachSpaceSpectrumCriterion}
Let $X$ be a Banach space and $T$ a closed linear operator on $X$. Then $\lambda \in \spec(T)$ \textup{if and only if} $\lambda \id_X - T: \dom(T) \to V$ is not bijective.
\end{proposition}
\begin{proof}
If $\lambda \id_X - T$ is not bijective, then clearly $\lambda \in \spec(T)$.

Conversely, assume $\lambda \id_X - T$ is bijective. Then $(\lambda \id_X - T)^{-1}: X\to \dom(T)$ is closed by \ref{algebraClosedOperators} and has as domain a Banach space, so it is bounded by the closed graph theorem \ref{closedGraphTheorem}.
\end{proof}
\begin{corollary}
Let $T$ a closed operator on a Banach space. Then
\[ \spec(T) = \pspec(T) \cup \cspec(T) \cup \rspec(T). \]
\end{corollary}


\begin{proposition}
Let $T:X\to X$ be an operator on a Banach space and $\lambda\in\cspec$, then $R_\lambda(T)$ is unbounded.
\end{proposition}
\begin{proof}
If $R_\lambda(T)$ is bounded, $\lambda \id_V - T$ then is bounded below by lemma \ref{boundedBelow} and has closed range by proposition \ref{boundedBelowClosedRange}. Then because $\im(\lambda \id_V - T)$ is dense, this means $T$ is surjective, which is a contradiction because then $\lambda\in\res(T)$.
\end{proof}

\subsection{Resolvents}

\begin{lemma}
Let $T$ be a linear operator on a Banach space $X$ and $\lambda\in\C$. Then
\[ TR_T(\lambda) = \lambda R_T(\lambda) - \id_X. \]
\end{lemma}
\begin{proof}
We have $\id_X = (\lambda \id_X - T)R_T(\lambda) = \lambda R_T(\lambda) - TR_T(\lambda)$.
\end{proof}

\begin{lemma}
Let $T$ be a linear operator and $\lambda,\mu\in\C$. Assume $\lambda\in \spec(T)$. Then $\mu\lambda\in \spec(\mu T)$ and
\[ R_T(\lambda) = \mu R_{\mu T}(\mu \lambda). \]
\end{lemma}
\begin{proof}
TODO
\end{proof}


\subsubsection{Pseudoresolvents}

\begin{lemma} \label{imageRangePseudoresolvents}
Let $\mathcal{R}:\Lambda \subseteq \C \to \Bounded(X)$ be a pseudoresolvent on a Banach space $X$ and $\lambda,\mu\in\Lambda$. Then
\begin{enumerate}
\item $\ker\mathcal{R}(\lambda) = \ker\mathcal{R}(\mu)$;
\item $\im\mathcal{R}(\lambda) = \im\mathcal{R}(\mu)$.
\end{enumerate}
In particular this means that $\mathcal{R}(\lambda)$ is injective \textup{if and only if} $\ker\mathcal{R}(\mu)$ is injective.
\end{lemma}
\begin{proof}
From
\[ \mathcal{R}(\lambda) = \mathcal{R}(\mu)\big(\id_X + (\mu-\lambda)\mathcal{R}(\lambda)\big) = \big(\id_X + (\mu-\lambda)\mathcal{R}(\lambda)\big)\mathcal{R}(\mu), \]
we see that $\im\mathcal{R}(\lambda) \subseteq \im\mathcal{R}(\mu)$ and $\ker\mathcal{R}(\lambda) \supseteq \ker\mathcal{R}(\mu)$. Swapping $\lambda$ and $\mu$ gives the result.
\end{proof}


\begin{proposition}
Let $\mathcal{R}:\Lambda \subseteq \C \to \Bounded(X)$ be a pseudoresolvent. Then $\mathcal{R} = R_T|_\Lambda$ for some operator $T$ \textup{if and only if} $\mathcal{R}(\lambda)$ is injective for some $\lambda\in\Lambda$.

In this case $\im(\mathcal{R}(\lambda)) = \dom(T)$ for all $\lambda\in \Lambda$ and the operator $T$ is unique.
\end{proposition}
\begin{proof}
$\boxed{\Rightarrow}$ Because in particular $\Lambda = \dom(\mathcal{R}) = \dom(R_T|_\Lambda)$, we need to have that $\Lambda \subseteq \res(T)$. The resolvent $R_T(\lambda): X\to \dom(T)$ is bijective for all $\lambda\in \res(T)\subseteq \Lambda$. It is in particular injective.

$\boxed{\Leftarrow}$ By \ref{imageRangePseudoresolvents}, $\mathcal{R}(\lambda)$ is injective for all $\lambda\in\Lambda$. By restricting the codomain of $\mathcal{R}(\lambda)$ to its image, $\mathcal{R}(\lambda)$ becomes invertible. We can define $T: \im(\mathcal{R}(\lambda)) \to X = \lambda\id - \mathcal{R}(\lambda)^{-1}$. Then
\[ \mathcal{R}(\lambda)(\lambda\id - T) = \mathcal{R}(\lambda)\mathcal{R}(\lambda)^{-1} = \id_{\im(\mathcal{R}(\lambda))} = \id_{\dom(T)}. \]
Thus $\mathcal{R}(\lambda)$ is the resolvent of $T$ at $\lambda$.
The definition of $T$ is the only one that makes $\mathcal{R}(\lambda)$ a resolvent of $T$ at $\lambda$, so $T$ is unique.
\end{proof}
\begin{corollary}
Let $\mathcal{R}:\Lambda \subseteq \C \to \Bounded(X)$ be a pseudoresolvent and assume that $\Lambda$ contains an unbounded sequence $\seq{\lambda_n}$. If either
\begin{enumerate}
\item $\lim_{n\to\infty}\lambda_n\mathcal{R}(\lambda_n)x = x$ for all $x\in X$; or
\item $\im\mathcal{R}(\lambda)$ is dense in $X$ for some $\lambda\in \Lambda$ and $\norm{\lambda_n \mathcal{R}(\lambda_n)} \leq M$ for some $M\geq 0$ and all $n\in\N$;
\end{enumerate}
then $\mathcal{R}$ is the resolvent map of a densely defined operator.
\end{corollary}
\begin{proof}
(1) If $x\in \ker\mathcal{R}(\lambda)$ for some $\lambda\in\Lambda$, then it is in the kernel for all $\lambda\in\Lambda$. Thus $\lim_{n\to\infty}\lambda_n\mathcal{R}(\lambda_n)x = 0 = x$, meaning that $\ker\mathcal{R}(\lambda) = \{0\}$ and $\mathcal{\lambda} = R_T(\lambda)$ for some operator $T$. Also
\[ X = \overline{\bigcup_{n\in\N}\im\mathcal{R}(\lambda_n)} = \overline{\im\mathcal{R}(\lambda)} = \overline{\dom(T)}, \]
meaning $T$ is densely defined.

(2) From the resolvent identity we have, for some $\lambda\in \Lambda$,
\[ \lambda_n\mathcal{R}(\lambda_n)\mathcal{R}(\lambda) - \mathcal{R}(\lambda) = \lambda\mathcal{R}(\lambda_n)\mathcal{R}(\lambda) - \mathcal{R}(\lambda_n) \]
and thus
\begin{align*}
\norm{(\lambda_n\mathcal{R}(\lambda_n) - \id)\mathcal{R}(\lambda)} &= \norm{\lambda\mathcal{R}(\lambda_n)\mathcal{R}(\lambda) - \mathcal{R}(\lambda_n)} \\
&\leq |\lambda|\,\norm{\mathcal{R}(\lambda_n)}\,\norm{\mathcal{R}(\lambda)} + \norm{\mathcal{R}(\lambda_n)} \to 0
\end{align*}
because $\norm{\mathcal{R}(\lambda_n)} \leq |\lambda_n^{-1}|\,M \to 0$. So for all $x\in\im\mathcal{R}(\lambda)$, we have $\lim_{n\to\infty}\lambda_n\mathcal{R}(\lambda_n)x = x$.

Now take $x\in X$. Because of density, we can find a sequence $\seq{x_n}$ in $\im\mathcal{R}(\lambda)$ that converges to $x$. By the continuity of the maps $\lambda_n\mathcal{R}(\lambda_n)$ and their uniform bound in conjunction with (TODO ref!!!), we get
\begin{align*}
\lim_{n\to\infty}\lambda_n\mathcal{R}(\lambda_n)x &= \lim_{n\to\infty}\lambda_n\mathcal{R}(\lambda_n)\lim_{k\to\infty}x_k \\
&= \lim_{n\to\infty}\lim_{k\to\infty}\lambda_n\mathcal{R}(\lambda_n)x_k \\
&= \lim_{k\to\infty}\lim_{n\to\infty}\lambda_n\mathcal{R}(\lambda_n)x_k \\
&= \lim_{k\to\infty}x_k = x.
\end{align*}
We conclude with point (1).
\end{proof}

\subsubsection{Properties of the spectrum}

\begin{proposition} \label{resolventNormDistanceToSpectrum}
For all $\lambda\in\res(T)$, we have $d(\lambda, \spec(T)) \geq \norm{R_T(\lambda)}^{-1}$.
\end{proposition}
\begin{proof}
For all $\mu\in \ball(\lambda, \norm{R_T(\lambda)}^{-1})$ we can define $R_T(\mu)$ by analytic continuation as in \ref{firstNeumannSeries}. By \ref{imageRangePseudoresolvents} we have that $R_T(\mu): X\to \dom(T)$ is bijective and bounded. We just need to show that it is a left inverse of $\mu\id_X - T$. We calculate
\begin{align*}
\mathcal{R}(\mu)(\mu\id_X - T) &= \big(\id_X + (\mu - \lambda)\mathcal{R}(\lambda)\big)^{-1}\mathcal{R}(\lambda)(\mu\id_X - T) \\
&= \big(\id_X + (\mu - \lambda)\mathcal{R}(\lambda)\big)^{-1}\mathcal{R}(\lambda)\big((\mu - \lambda)\id_X + (\lambda\id_X - T)\big) \\
&= \big(\id_X + (\mu - \lambda)\mathcal{R}(\lambda)\big)^{-1}\big((\mu - \lambda)\mathcal{R}(\lambda) + \id_X\big) \\
&= \id_X.
\end{align*}
\end{proof}
\begin{corollary}
The resolvent set $\res(T)$ is open. The spectrum $\spec(T)$ is closed.
\end{corollary}
This is stronger than \ref{spectrumCompact}, because $T$ is not assumed closed.


\begin{example}
Operator with empty spectrum. TODO \url{https://math.stackexchange.com/questions/1344287/example-operator-with-empty-spectrum}.
\end{example}

\begin{proposition}
Let $T$ be an injective operator with dense range. Then for all $\lambda\neq 0$
\[ R_{T^{-1}}(\lambda^{-1}) = -\lambda T R_{T}(\lambda) = \lambda -\lambda^2 R_T(\lambda). \]
\end{proposition}
\begin{proof}
This is a reformulation of the calculation
\[ \frac{1}{\lambda^{-1} - T^{-1}} = \frac{\lambda T}{\lambda T}\frac{1}{\lambda^{-1} - T^{-1}} = \frac{\lambda T}{T - \lambda} = \frac{\lambda T - \lambda^2 + \lambda^2}{T - \lambda} = \frac{\lambda\cancel{(T - \lambda)}}{\cancel{T - \lambda}} + \frac{\lambda^2}{T - \lambda} = \lambda - \lambda^2 R_T(\lambda). \]
TODO: make rigourous!!
\end{proof}
\begin{corollary}
Let $T$ be an injective operator with dense range. Then for all $\lambda\neq 0$
\begin{enumerate}
\item $\spec(T^{-1})\setminus\{0\} = (\spec(T)\setminus \{0\})^{-1}$;
\item $\pspec(T^{-1})\setminus\{0\} = (\pspec(T)\setminus \{0\})^{-1}$.
\end{enumerate}
\end{corollary}


\subsection{Parts of the spectrum}

\subsubsection{The point spectrum: eigenvalue and eigenvectors}
In this section we study invariant subspaces with dimension $1$, i.e.\ subspaces $U= \Span\{v\}$ such that
\[ Lv = \lambda v. \]
\begin{definition}
Suppose $L\in \Hom_{\mathbb{F}}(V)$.
\begin{itemize}
\item  A scalar $\lambda\in \mathbb{F}$ is called an \udef{eigenvalue} of $L$ if there exists a $v\in V$ such that $v\neq 0$ and $Lv = \lambda v$.
\item Such a vector $v$ is called an \udef{eigenvector}.
\item The set of all eigenvectors associated with an eigenvalue $\lambda$ is called the \udef{eigenspace} $E_\lambda(L)$. Because
\[ E_\lambda(L) = \ker(L-\lambda \id_V) \]
it is indeed a vector space.

The dimension of $E_\lambda(L)$ is the \udef{geometric multiplicity} of $\lambda$.
\end{itemize}
\end{definition}
If $L$ is a closed operator, then its eigenspaces are closed by \ref{closedOperatorKernelClosed}.

For a bounded operator $T$, we have $\pspec(T)\subset \cball(0, \norm{T})$ by \ref{spectrumCompact}. For the point spectrum a simpler argument also leads to $\pspec(T)\subset \cball(0, \norm{T})$: let $\lambda$ be an eigenvalue with eigenvector $x$. Then
\[ |\lambda|\;\norm{x} = \norm{\lambda x} = \norm{Tx} \leq \norm{T}\;\norm{x}. \]

\begin{proposition}
Let $L\in \Hom_\mathbb{F}(V)$ and $\lambda\in \mathbb{F}$, then
\[ \text{$\lambda$ is an eigenvalue of $L$} \qquad \iff \qquad \text{$\lambda$ is in the point spectrum $\pspec(L)$.} \]
\end{proposition}
\begin{proof}
The equation $Lv = \lambda v$ is equivalent to $(L-\lambda \id_V)v = 0$.
\end{proof}

\begin{proposition}
Let $L\in\Hom(V)$ be an operator on some vector space. Suppose $\lambda_1, \ldots, \lambda_m$ are distinct eigenvalues of $L$ and $v_1,\ldots, v_m$ are corresponding eigenvectors. Then $\{v_1,\ldots, v_m\}$ is linearly independent.
\end{proposition}
\begin{proof}
The proof goes by contradiction. Assume $\{v_1,\ldots, v_m\}$ is linearly dependent. Let $k$ be the smallest positive integer such that
\[ v_k \in \Span\{v_1,\ldots, v_{k-1}\}. \]
So there exists a nontrivial linear combination
\[ v_k = a_1v_1+\ldots +a_{k-1}v_{k-1}. \]
Applying $L$ to both sides gives
\[ \lambda_kv_k = a_1\lambda_kv_1+\ldots +a_{k-1}\lambda_kv_{k-1}. \]
Multipliying the previous combination by $\lambda_k$ and subtracting both equations gives
\[ 0= a_1(\lambda_k-\lambda_1)v_1 +\ldots + a_{k-1}(\lambda_k - \lambda_{k-1})v_{k-1}. \]
By assumption of linear independence of $\{v_1,\ldots, v_{k-1}\}$ this combination must be trivial, however none of the $(\lambda_k-\lambda_i)$ can be zero, so all the $a_i$ must be zero. This is a contradiction with the assumption of linear dependence.
\end{proof}
\begin{corollary}
For each operator on $V$, the set of distinct eigenvalues has at most cardinality $\dim V$.
\end{corollary}
\begin{corollary}
Let $L\in\Hom(V)$. Suppose $\lambda_1, \ldots, \lambda_m$ are distinct eigenvalues of $L$. Then
\[ E_{\lambda_1}(L) \oplus \ldots \oplus E_{\lambda_m}(L) \]
is a direct sum. Furthermore, the sum of geometric multiplicities is less than or equal to the dimension of $V$:
\[ \dim E_{\lambda_1}(L) + \ldots + \dim E_{\lambda_m}(L) \leq \dim V. \]
\end{corollary}

\subsubsection{Approximate spectrum and Weyl sequences}
\begin{definition}
The set of all $\lambda$ such that $T-\lambda \id_V$ is not bounded from below is called the \udef{approximate point spectrum} $\apspec$.

If $\lambda\in\apspec(T)$, then $\lambda$ is an \udef{approximate eigenvalue} of $T$.
\end{definition}

\begin{proposition} \label{approximateSpectrum}
Let $T$ be an operator. Then
\begin{enumerate}
\item $\apspec(T) \subset \spec(T)$;
\item if $T$ is closed, then $\pspec(T)\cup\cspec(T)\subset\apspec(T)$.
\end{enumerate}
\end{proposition}
\begin{proof}
(1) Assume $\lambda \notin \spec(T)$. Then $(T-\lambda \id_V)^{-1}$ is bounded, so its inverse $T-\lambda \id_V$ is bounded below by \ref{boundedBelow} and $\lambda\in \apspec(T)$.

(2) Assume $\lambda\notin \apspec(T)$, 
so $T-\lambda \id_V$ is bounded below. Then $T-\lambda \id_V$ is injective by \ref{boundedBelow} and $\lambda\notin\pspec(T)$. By proposition \ref{boundedBelowClosedRange} the range $\im(T-\lambda \id_V)$ is closed, so it cannot be a proper dense subset of $X$ and $\lambda\notin\cspec(T)$.
\end{proof}

\begin{proposition}[Weyl sequences] \label{WeylSequence}
Let $T$ be an operator on a normed vector space $V$. Then $\lambda \in \apspec(T)$ \textup{if and only if} there exists a sequence of unit vectors $(e_n)_{n\in\N}$ for which
\[ \lim_{n\to\infty}\norm{\lambda e_n - Te_n} = 0. \]
\end{proposition}
\begin{proof}
Assume there is such a sequence $(e_n)_{n\in\N}$. Then for all $\epsilon>0$, we can find a unit  vector $e_k$ such that $\norm{(\lambda \id_V - T)e_n} \leq \epsilon = \epsilon \norm{e_n}$. This is clearly not bounded below.

This other direction is just an inversion of this argument.
\end{proof}
A sequence as described in \ref{WeylSequence} is called a \udef{Weyl sequence} for $\lambda$. This gives meaning to the name ``approximate eigenvalue''.

\begin{corollary}
Let $T$ be an operator. Then $\sigma(T)\cap \overline{\res(T)} \subseteq \apspec(T)$.
\end{corollary}
\begin{proof}
Let $\lambda \in \sigma(T)\cap \overline{\res(T)}$. We show there is a Weyl sequence for $\lambda$.

We can find a sequence $\seq{\lambda_n}\subseteq \res(T)$ such that $\lambda_n \to \lambda$.
Now $d(\lambda_n, \spec(T)) \to 0$, so by \ref{resolventNormDistanceToSpectrum}, we can find a sequence of unit vectors $\seq{x_n}$ such that $\norm{R_T(\lambda_n)x_n} \to \infty$. Now we can rescale $\seq{x_n}$ such that $\norm{R_T(\lambda_n)x_n} = 1$.

Then $\norm{x_n}\to 0$, and hence
\begin{align*}
\norm{(\lambda\id - T)R_T(\lambda_n)x_n} &= \norm{\frac{\lambda\id - T}{\lambda_n\id - T}x_n} \\
&= \norm{\frac{(\lambda\id - T) + (\lambda_n\id - T) - (\lambda_n\id - T)}{\lambda_n\id - T}x_n} \\
&= \norm{\left(\id + \frac{(\lambda\id - T) - (\lambda_n\id - T)}{\lambda_n\id - T}\right)x_n} \\
&= \norm{\left(\id + \frac{\lambda\id - \lambda_n\id}{\lambda_n\id - T}\right)x_n} \\
&= \norm{x_n + (\lambda\id - \lambda_n\id)R_T(\lambda_n)x_n} \\
&\leq \norm{x_n} + |\lambda - \lambda_n|\;\norm{R_T(\lambda_n)x_n} \to 0.
\end{align*}
Thus $\seq{R_T(\lambda_n)x_n}$ is the kind of sequence we were looking for.
\end{proof}




\subsubsection{Compression spectrum}
\begin{definition}
The set of $\lambda$ for which $T-\lambda I$ does not have dense range is the \udef{compression spectrum} $\cpspec(T)$ of $T$.
\end{definition}
Then $\rspec(T) = \cpspec(T)\setminus\pspec(T)$.

\subsubsection{The essential spectrum}
TODO \url{https://en.wikipedia.org/wiki/Spectrum_(functional_analysis)#Classification_of_points_in_the_spectrum}


\subsection{The spectral radius}
\begin{definition}
The \udef{spectral radius} $\spr(T)$ of a operator $T$ is given by
\[ \spr(T) \defeq \sup_{\lambda\in\spec(T)}|\lambda|. \]
\end{definition}


\section{Spectral theory for types of operators}
\subsection{Compact operators}

\begin{proposition}
Let $K$ be a compact operator on a Banach space. Then
\[ \spec(K)\setminus\{0\} = \pspec(K)\setminus\{0\}. \]
\end{proposition}
\begin{proof}
For all $\lambda\neq 0$, we have that $\lambda\id - K$ is Fredholm with index zero (and thus bounded). Then by the Fredholm alternative \ref{FredholmAlternative} $\lambda\id - K$ is either bijective or neither injective nor surjective, meaning $\lambda$ is either in $\rho(T)$ or in $\pspec(T)$. 
\end{proof}

\begin{proposition} \label{spectrumCompactOperator}
Let $K$ be a compact operator on a Banach space $X$. Then
\begin{enumerate}
\item for all $\lambda\in\spec(K)\setminus\{0\}$ there exists a least $m$ such that $\ker(\lambda\id- K)^m = \ker(\lambda\id- K)^{m+1}$. This space is finite dimensional and reducing for $K$;
\item for $\alpha > 0$ the number of eigenvalues $\lambda$ such that $|\lambda|\geq \alpha$ is finite;
\item $0$ is the only accumulation point; if $X$ is infinite dimensional, then $0\in\spec(K)$;
\item $\spec(K)$ is at most countably infinite;
\item every $\lambda \in \spec(K)\setminus \{0\}$ is a pole of the resolvent $R_K$.
\end{enumerate}
\end{proposition}
\begin{proof}
\url{https://en.wikipedia.org/wiki/Spectral_theory_of_compact_operators}
\end{proof}



\subsection{Multiplication operators}
\begin{definition}
Let $(\Omega, \mathcal{A}, \mu)$ be a measure space. A \udef{multiplication operator} is an operator of the form
\[ T: L^p(\Omega, \mu) \to L^p(\Omega, \mu): u(x) \mapsto a(x)u(x) \]
for some $a\in L^\infty(\Omega,\mu)$
\end{definition}

\begin{proposition}
Let $T: L^p(\Omega, \mu) \to L^p(\Omega, \mu): u \mapsto a\cdot u$ be a multiplication operator. Then
\[ \norm{T} = \norm{a}_{L^\infty}. \]
\end{proposition}
\begin{proof}
From the inequality $\norm{Tu}_{L^p}\leq \norm{a}_{L^\infty}\norm{u}_{L^p}$ we get $\norm{T} \leq \norm{a}_{L^\infty}$.

TODO
\end{proof}

\begin{lemma}
Let $T: L^2(\Omega, \mu) \to L^2(\Omega, \mu): u \mapsto a\cdot u$ be a multiplication operator with $a\in L^\infty(\Omega,\mu)$. Then $T^*$ is the multiplication operator
\[ T^*: L^2(\Omega, \mu) \to L^2(\Omega, \mu): u \mapsto \overline{a}\cdot u. \]
\end{lemma}
\begin{proof}
From 
\[ \inner{Tu,v} = \int_\Omega a\cdot u \cdot \overline{v}\diff{\mu} = \int_\Omega u \cdot \overline{\overline{a}\cdot v}\diff{\mu} \]
it follows that $T^*v = \overline{a}\cdot v$.
\end{proof}
\begin{corollary}
Then
\begin{enumerate}
\item $T$ is self-adjoint if $a$ is real-valued;
\item $T$ is skew-adjoint if $a$ is purely imaginary;
\item $T$ is unitary if $|a(x)| \equiv 1$.
\end{enumerate}
\end{corollary}

Let $E_\lambda$ be the level set
\[ E_\lambda = \setbuilder{x\in\Omega}{a(x) = \lambda} \]

\begin{proposition}
Let $T: L^2(\Omega, \mu) \to L^2(\Omega, \mu): u\mapsto a\cdot u$ be a multiplication operator with $a\in \cont(\Omega)$. Then
\begin{enumerate}
\item $\pspec(T) = \setbuilder{\lambda\in \im(a)}{\mu(E_\lambda)>0}$;
\item $\cspec(T) = \setbuilder{\lambda\in \overline{\im(a)}}{\mu(E_\lambda) = 0}$;
\item $\rspec(T) = \emptyset$;
\item $\rho(T) = \C\setminus \overline{\im(T)}$.
\end{enumerate}
\end{proposition}
\begin{proof}
TODO
\end{proof}

\subsection{Dissipative operators}
\begin{definition}
Let $T\in \Lin(V, W)$ be a linear operator between Banach spaces. Then $T$ is called \udef{dissipative} if $\lambda\id-T$ is bounded below by $\lambda$ for all $\lambda>0$:
\[ \norm{(\lambda\id-T)x} \geq \lambda\norm{x} \]
for all $x\in\dom(T)$.
\end{definition}

\begin{lemma} \label{dissipativeResolventBound}
Let $T\in \Lin(V, W)$ be an operator between Banach spaces. Then $T$ is dissipative \textup{if and only if} for all $\lambda>0$ the resolvent $R_T(\lambda): \im(T)\to V$ exists and is bounded by $\norm{R_T(\lambda)} \leq \lambda^{-1}$.
\end{lemma}
\begin{proof}
If $T$ is dissipative, then the result is given by \ref{boundedBelow}.

Assume $R_T(\lambda): \im(T)\to V$ exists. Then
\[ \lambda\norm{x} = \lambda\norm{R_T(\lambda)(\lambda\id-T)x} \leq \lambda \norm{R_T(\lambda)}\,\norm{(\lambda\id-T)x} \leq \lambda\lambda^{-1}\norm{(\lambda\id-T)x} = \norm{(\lambda\id-T)x}. \]
\end{proof}

Thus $\lambda>0$ is in $\res(T)$ if and only if $\lambda\id - T$ is surjective.


\begin{proposition} \label{spectrumDissipativeOperator}
Let $T\in \Lin(V, W)$ be a dissipative operator between Banach spaces. Then either $]0,+\infty[\,\perp \res(T)$ or $]0,+\infty[\,\subseteq \res(T)$.
\end{proposition}
\begin{proof}
By \ref{dissipativeResolventBound}, it is enough to show that if $\lambda\in\res(T)$ for some $\lambda >0$, then $\lambda\id - T$ is surjective for all $\lambda>0$.

Assume $\lambda\in\res(T)$ for some $\lambda >0$. Then \ref{dissipativeResolventBound} and \ref{firstNeumannSeries} combine the give $]0, 2\lambda[ \subseteq \res(T)$. We can repeat this to cover the whole of $]0,+\infty[$.
\end{proof}
\begin{corollary} \label{rangeDisjunctionDissipativeOperator}
Either
\begin{enumerate}
\item $\lambda\id-T$ is surjective for no $\lambda > 0$; or
\item $\lambda\id-T$ is surjective for all $\lambda > 0$.
\end{enumerate}
\end{corollary}

\begin{proposition} \label{closureDissipativeOperator}
Let $T\in \Lin(V, W)$ be a dissipative operator between Banach spaces. Then the following are equivalent:
\begin{enumerate}
\item $T$ is closed;
\item $\im(\lambda\id - T)$ is closed for some $\lambda > 0$;
\item $\im(\lambda\id - T)$ is closed for all $\lambda > 0$.
\end{enumerate}
\end{proposition}
\begin{proof}
For all $\lambda\in\R$, we have that $T$ is closed iff $\lambda\id - T$ is closed iff $(\lambda\id - T)^{-1}: \im(\lambda\id - T) \to V$ is closed by \ref{algebraClosedOperators}.

Now closedness of $\lambda\id - T$ implies $\im(\lambda\id - T)$ is closed by \ref{boundedBelowClosedRange}. Conversely, if $\im(\lambda\id - T)$ is closed, then $\lambda\id - T$ is closed by the closed graph theorem \ref{closedGraphTheorem}.
\end{proof}

\begin{proposition} \label{dissipativeOperatorClosable}
Let $T\in \Lin(V)$ be a dissipative operator on a Banach space $V$. If $\im(T)\subseteq \overline{\dom(T)}$, then
\begin{enumerate}
\item $T$ is closable;
\item its closure $\overline{T}$ is dissipative;
\item $\im(\lambda\id - \overline{T}) = \overline{\im(\lambda\id - T)}$ for all $\lambda >0$.
\end{enumerate}
\end{proposition}
In particular $\im(T)\subseteq \overline{\dom(T)}$ holds whenever $T$ is densely defined.
\begin{proof}
(1) We use \ref{closableCriterion}. Assume $\seq{x_n}\to 0$ and $\seq{Tx_n}\to v$. We need to show that $v=0$. Because $T$ is dissipative, we have
\[ \norm{\lambda(\lambda\id-T)x_n + (\lambda\id-T)w} = \norm{(\lambda\id-T)(\lambda x_n -w)} \geq \lambda\norm{\lambda x_n + w} \]
for all $w\in \in\dom(T)$ and all $\lambda>0$. Taking the limit $n\to \infty$ gives
\[ \norm{-\lambda v +(\lambda\id- T)w} \geq \lambda\norm{w}, \qquad\text{and hence}\qquad \norm{w - v - \frac{1}{\lambda}Tw} \geq w. \]
Taking the limit $\lambda \to \infty$ gives $\norm{w-v}\geq \norm{w}$. Now $y\in \overline{\im(T)} \subseteq \overline{\dom(T)}$. Thus we can find a sequence $\seq{w_n}\to y$ in $\dom(T)$. This sequence then satisfies $\norm{w_n-y} \geq \norm{w_n}$. Taking the limit gives $0\geq \norm{y}$, so $y = 0$.

(2) For all $x\in\dom(\overline{T})$ there exists a sequence $\seq{x_n}\to x$ in $\dom(T)$ such that $\seq{Tx_n} \to \overline{T}x$ by \ref{graphNormConvergenceLemma}. Now for all $n\in \N$,
\[ \norm{(\lambda\id-T)x_n} \geq \lambda\norm{x_n}. \]
Taking the limit $n\to\infty$ gives $\norm{(\lambda\id-\overline{T})x} \geq \lambda\norm{x}$, meaning $\overline{T}$ is dissipative.

(3) By \ref{domImClosureOperator}, $\im(\lambda\id - T)$ is dense in $\im(\lambda\id-\overline{T})$ and by \ref{closureDissipativeOperator}, $\im(\lambda\id-\overline{T})$ is closed.
\end{proof}

\begin{proposition}
Let $T\in\Lin(V,W)$ be an operator between Banach spaces. Then $T$ is dissipative \textup{if and only if} for all $x\in V$, there exists an $x'\in \mathfrak{d}(x)$ such that
\[ \Re\pair{x', Tx} \leq 0. \]
\end{proposition}
\begin{proof}
$\boxed{\Leftarrow}$ Take $x\in V$ and fix some $x'\in \mathfrak{d}(x)$ for which the inequality holds. By definition of the duality set, we have $\norm{x}^2 = x'(x) = \norm{x'}^2$. To verify dissipativity, we calculate
\begin{align*}
\norm{(\lambda\id-T)x}\,\norm{x'} &\geq |x'\big((\lambda\id-T)x\big)| \\
&\geq \Re x'\big((\lambda\id-T)x\big) = \Re x'(\lambda x) - \Re x'(Tx) \\
&\geq \lambda \Re x'(x) = \lambda \norm{x}^2.
\end{align*}
Noting $\norm{x'} = \norm{x}$ and dividing both sides by $\norm{x}$ yields dissipativity.

$\boxed{\Rightarrow}$ TODO
\end{proof}

\section{The spectral theorem}
\url{https://link.springer.com/content/pdf/10.1007%2F978-1-4614-7116-5.pdf}

\url{http://individual.utoronto.ca/jordanbell/notes/SVD.pdf}
\url{https://digitalcommons.mtu.edu/cgi/viewcontent.cgi?article=2133&context=etdr}

\url{https://web.ma.utexas.edu/mp_arc/c/09/09-32.pdf}


\section{Functional calculus}
\subsection{Holomorphic functional calculus}

\begin{theorem}[Holomorphic functional calculus] 
\label{holomorphicFunctionalCalculus} \label{holomorphicSpectralMapping}
Let $A$ be a Banach algebra and $x\in A$. Consider the function
\[ \Phi_x: \cont^\infty(\spec(x),\C) \to A: f\mapsto f(x)\defeq \oint_\Gamma f(z)R_x(z)\diff{z}. \]
Here $\Gamma$ is any simple Jordan curve that contains $\spec(x)$ such that $f$ is holomorphic in a region that contains $\Gamma$ and its interior. Then
\begin{enumerate}
\item $\Phi_x$ is well-defined: it does not depend on the particular curve $\Gamma$;
\item $\Phi_x$ is a homomorphism;
\item for any polynomial $p\in \C[X]$, we have $\Phi_x(p) = p(x)$; \\
in particular $\Phi_x(\id_\C) = x$ and $\Phi_x(\underline{1}) = \id_A$;
\item $\spec(\Phi_x(f)) = f[\spec(x)]$;
\item $\Phi_x$ is continuous if $\cont^\infty(\spec(x),\C)$ is equipped with continuous convergence (?).
\end{enumerate}
\end{theorem}
TODO: $\cont^\infty(\spec(x))$ should be the space of functions that are analytic in some neighbourhood of $\spec(x)$. Is it??
\begin{proof}
TODO
\end{proof}

TODO unbounded operators

\subsubsection{Riesz eigenprojections}
Holomorphic functional calculus applied to
\[ \chi_{S,\delta}: A\to \{0,1\}: x\mapsto \begin{cases}
1 & d(x,S) \leq \delta \\
0 & \text{otherwise}.
\end{cases} \]

TODO: spectral measure with only disconnected parts in $\sigma$-algebra??

TODO: $P_\Delta$ and $E_\Delta \defeq \im P_\Delta$.

\begin{lemma}
$\spec(T|_{E_\Delta}) = \spec(T)\cap\Delta$.
\end{lemma}

\begin{definition}
We call $\dim E_\lambda$ the \udef{algebraic multiplicity} of $\lambda$.
\end{definition}

\subsubsection{Frobenius covariants}
TODO $P_\lambda$ is a Frobenius covariant. \url{https://en.wikipedia.org/wiki/Frobenius_covariant}

TODO cfr. Lagrange polynomial??

\section{Jordan decomposition}
\subsection{Eigennilpotent}
\begin{definition}
Let $a$ be a finite element in a semisimple Banach algebra and $\lambda\in \spec(a)$. The \udef{eigennilpotent operator} of $a$ at $\lambda$ is defined as
\[ D_{\lambda} \defeq (a-\lambda)P_{\lambda}. \]
\end{definition}
This definition works because we can find a $\delta < d(\lambda, \spec(a)\setminus\{\lambda\})$.

\begin{lemma}
Let $a$ be a finite element in a semisimple Banach algebra and $\lambda\in \spec(a)$. The eigennilpotent operator $D_\lambda$ is nilpotent.
\end{lemma}
\begin{proof}
By spectral mapping \ref{holomorphicSpectralMapping}, $D_\lambda$ is quasinilpotent. Because $a$ is finite, it is nilpotent by \ref{nilpotentQuasinilpotent}.
\end{proof}



\subsection{Jordan vectors}
\begin{definition}
Let $V$ be a finite dimensional vector space and $T$ an operator on $V$. A \udef{Jordan vector} of $T$ belonging to the eigenvalue $\lambda$ is a vector $x\in V$ such that
\[ (\lambda\id_V - T)^kx = 0 \]
for some $k\in \N$. The least such $k$ is called the \udef{degree} of $x$ and is denoted $\deg_J(x)$.
\end{definition}
Eigenvectors are Jordan vectors of degree $1$.

\begin{proposition}
Let $V$ be a finite dimensional vector space, $T$ an operator on $V$ $\lambda\in\spec(T)$ and $x\in V$. Then $x$ is a Jordan vector of $T$ belonging to the eigenvalue $\lambda$ \textup{if and only if} $x\in E_\lambda$.
\end{proposition}
\begin{proof}
Let $x\in E_\lambda$. Then $x = P_\lambda x$ and thus
\[ (\lambda\id_V - T)^kx = (\lambda\id_V - T)^kP_\lambda x = \big((\lambda\id_V - T)P_\lambda\big)^k x = D_\lambda^k x, \]
which is zero for some $k$ because $D_\lambda$ is nilpotent.

Conversely, assume $x$ is a Jordan vector of $T$ belonging to the eigenvalue $\lambda$. We can write $x = x_1+x_2 \in E_{\lambda}\oplus E_{\C\setminus\{\lambda\}}$.
Then (because $E_\lambda$ is reducing for $T-\lambda\id_V$)
\[ 0 = (\lambda\id_V - T)^kx = (\lambda\id_V - T)^kx_1 + (\lambda\id_V - T)^kx_2 \in E_{\lambda}\oplus E_{\C\setminus\{\lambda\}} \]
Thus we have $(\lambda\id_V - T)^kx_1 = 0$ and $(\lambda\id_V - T)^kx_2 = 0$ separately.
Now $T-\lambda\id_V$ is invertible on $E_{\C\setminus\{\lambda\}}$, so $x_2 = 0$ (TODO ref). This means that $x = x_1 \in E_\lambda$.
\end{proof}

\begin{definition}
Let $m = \deg_N(D_\lambda)$. Then we have
\[ \{0\} \subsetneq \ker(\lambda\id_V - T) \subsetneq \ker(\lambda\id_V - T)^2 \subsetneq \ldots \subsetneq \ker(\lambda\id_V - T)^{m-1} \subsetneq \ker(\lambda\id_V - T)^m = V. \]
We define $E^k_\lambda \defeq \ker(\lambda\id_V - T)^k$. In particular
\begin{itemize}
\item $E^1_\lambda$ is the \udef{geometric eigenspace};
\item $E^{m-1}_\lambda$ is the \udef{algebraic eigenspace}.
\end{itemize}
\end{definition}

\begin{lemma}
Let $V$ be a finite dimensional vector space, $T$ an operator on $V$, $\lambda\in\spec(T)$ and $x\in E_\lambda$. Then
\begin{enumerate}
\item $1 \leq \dim\ker(\lambda\id_V - T) \leq \dim E_\lambda$;
\item $1 \leq \deg_J(x) \leq \dim_E\lambda$.
\end{enumerate}
\end{lemma}
The lemma says the geometric multiplicity is smaller than the algebraic multiplicity.
\begin{proof}
Every eigenvector is a Jordan vector, so $\ker(\lambda\id_V - T) \subseteq E_\lambda$.

For all $k\in\N$ smaller then the degree of $x$, $(\lambda\id_V - T)^kx$ is a Jordan vector and thus in $E_\lambda$. TODO all $(\lambda\id_V - T)^kx$ are linearly independent (like in \ref{nilpotentQuasinilpotent})
\end{proof}

\begin{definition}
Let $V$ be a finite dimensional vector space, $T$ an operator on $V$ and $\lambda\in\spec(T)$. The eigenvalue $\lambda$ is called
\begin{itemize}
    \item \udef{simple} if the algebraic multiplicity is $1$;
    \item \udef{semisimple} if every Jordan vector in $E_\lambda$ has degree $1$;
    \item \udef{prime} if the geometric multiplicity is $1$.
\end{itemize}
If all eigenvalues of $T$ are semisimple, then $T$ is called a \udef{diagonal operator}.
\end{definition}

\begin{lemma}
An operator $T$ is diagonal iff $T$ is of the form $\sum_j a_jP_j$, where $a_j\in \F$ and $P_j$ are projectors that commute pairwise.
\end{lemma}

\subsection{Characteristic polynomial and equation}
\begin{definition}
Let $V$ be a finite dimensional vector space and $T$ an operator on $V$. The \udef{characteristic polynomial} $p_T(x)$ of $T$ is the polynomial
\[ p_T(x) \defeq \det(x\id_V - T). \]
\end{definition}

\begin{proposition}
Let $V$ be a finite dimensional vector space, $T$ an operator on $V$ and $\spec(T) = \{\lambda_j\}_{j=1}^r$. Then
\[ p_T(x) = \prod_{j=1}^r(x - \lambda_j)^{\dim E_{\lambda_j}}. \]
\end{proposition}
\begin{proof}
TODO
\end{proof}
\begin{corollary}
A number $\lambda\in \C$ is an eigenvalue of $T$ \textup{if and only if} it is a root of $p_T(x)$.
\end{corollary}

\begin{definition}
The equation $p_T(x) = 0$ is the \udef{characteristic equation} of $T$.
\end{definition}

\subsection{Spectral representation}
\begin{proposition}
Let $V$ be a finite dimensional complex vector space and $T$ an operator on $V$. There exists a unique decomposition $T = S + D$ such that
\begin{itemize}
\item $S$ is diagonal;
\item $D$ is nilpotent;
\item $SD = DS$.
\end{itemize}
If $\spec(T) = \{\lambda_j\}_{j=1}^r$, this decomposition is given by
\[ T = \sum_{j=1}^r \lambda_r P_{\lambda_r} + \sum_{j=1}^r D_{\lambda_r}. \]
\end{proposition}

\subsection{Partial fraction decomposition of the resolvent}
For any operator $T$ on a vector space $V$ with eigenvalue $\lambda_0$, the resolvent $R_T(\lambda)$ has a pole at $\lambda_0$.

\begin{proposition}
Let $T$ be an operator on a finite dimensional vector space $V$ and $\lambda_0\in\spec(T)$. Then the Laurent expansion of $R_T(\lambda)$ around $\lambda_0$ is of the form
\[ R_T(\lambda) = \frac{P_0}{\lambda-\lambda_0} + \sum_{n=1}^{\deg_N(D_0)-1}\frac{D_0^{n}}{(\lambda - \lambda_0)^{n+1}} + \sum_{n=0}^\infty(-1)^n S_0^{n+1}(\lambda - \lambda_0)^n, \]
where $P_0\defeq P_{\lambda_0}, D_0\defeq D_{\lambda_0}$ and $S_0$ is some fixed operator.
\end{proposition}
\begin{proof}
TODO
\end{proof}

\begin{definition}
The holomorphic part of the Laurent expansion of $R_T(\lambda)$ at $\lambda_0$ is called the \udef{reduced resolvent} of $T$ w.r.t. $\lambda_0$:
\[ S_{T,\lambda_0}(\lambda) \defeq \sum_{n=0}^\infty(-1)^n S_0^{n+1}(\lambda - \lambda_0)^n = R_T(\lambda) - \left(\frac{P_0}{\lambda-\lambda_0} + \sum_{n=1}^{\deg_N(D_0)-1}\frac{D_0^{n}}{(\lambda - \lambda_0)^{n+1}}\right). \]
\end{definition}

\begin{proposition}
Let $T$ be an operator on a finite dimensional vector space $V$ and $\lambda_0\in\spec(T)$. Then
\[ R_{T|_{(\id_V-P_0)}}(\lambda) = S_{T,\lambda_0}|_{\id_V-P_0}(\lambda). \]
\end{proposition}

\begin{proposition}
Let $T$ be an operator on a finite dimensional vector space $V$ with $\spec(T) = \{\lambda_j\}_{j=1}^r$. The partial fraction decomposition of $R_T(\lambda)$ is given by
\[ R_T(\lambda) = \sum_{j=1}^r\left(\frac{P_{\lambda_j}}{\lambda - \lambda_j} +\sum_{n=1}^{\deg_N(D_{\lambda_j})-1}\frac{D_{\lambda_j}^n}{(\lambda - \lambda_j)^{n+1}}\right). \]
The partial fraction decomposition of $S_{T,\lambda_k}(\lambda)$ is given by
\[ S_{T,\lambda_k}(\lambda) = \sum_{\substack{j=1 \\ j\neq k}}^r\left(\frac{P_{\lambda_j}}{\lambda - \lambda_j} +\sum_{n=1}^{\deg_N(D_{\lambda_j})-1}\frac{D_{\lambda_j}^n}{(\lambda - \lambda_j)^{n+1}}\right). \]
\end{proposition}
\begin{proof}
The poles of $R_T(\lambda)$ are exactly the eigenvalues of $T$. There are finitely many of them, so we can use partial fraction decomposition, \ref{partialFractionDecomposition}. We just need to show that the holomorphic part is zero. For that we note that $\lim_{\lambda \to \infty} R_T(\lambda) = 0$ and all principal parts tend to $0$ at infinity as well. Thus the holomorphic part also tends to $0$, making it bounded. By Liouville's theorem, \ref{liouvilleTheoremAnalysis}, we get that it is identically zero.
\end{proof}
\begin{corollary}[Sylvester-Lagrange formula]
Let $f$ be a holomorphic function on an open set that contains $\spec(T)$. Then
\[ f(T) = \sum_{j=1}^r\left(f(\lambda_j)P_{\lambda_j} +\sum_{n=1}^{\deg_N(D_{\lambda_j})-1}\frac{f^{(n)}(\lambda_j)D_{\lambda_j}^n}{n!}\right). \] 
\end{corollary}
\begin{proof}
We have
\[ f(T) = \oint_\Gamma f(\lambda)R_T(\lambda)\diff{\lambda} = 2\pi i\sum_{j=1}^r \Res_{\lambda_j}f(\lambda)R_T(\lambda) \]
by the residue theorem (TODO ref for operators).
\end{proof}
\begin{corollary}[Cayley-Hamilton]
Let $p_T(x)$ be the characteristic polynomial of $T$. Then $p_T(T) = 0$.
\end{corollary}
\begin{proof}
Since $p_T(x) = \prod_{j=1}^r(x - \lambda_j)^{\dim E_{\lambda_j}}$ and $\dim E_{\lambda_j} \geq \deg_N(D_{\lambda_j})$, we see that $p_T(\lambda)R_T(\lambda)$ has no poles and is holomorphic, meaning that $oint_\Gamma f(\lambda)R_T(\lambda)\diff{\lambda} = 0$ by Cauchy's theorem (TODO ref for operators).
\end{proof}

\subsection{Normal operators}


\begin{proposition}
If $T$ is a normal operator, then $P_\lambda = P^*_\lambda$ and $D_\lambda = D^*_\lambda = 0$.
\end{proposition}
This means normal operators are diagonalisable.
\begin{proof}
TODO
\end{proof}
\begin{corollary}
Let $V$ be a finite dimensional complex vector space and $T$ a normal operator
on $V$ with $\spec(T) = \{\lambda_j\}_{j=1}^r$.
\begin{enumerate}
\item We have the spectral decompositions
\[ T = \sum_{j=1}^r \lambda_r P_{\lambda_r} \qquad\text{and}\qquad T^* = \sum_{j=1}^r \overline{\lambda_r} P_{\lambda_r}. \]
\item We have
\[ R_T(\lambda) = \sum_{j = 1}^r \frac{P_{\lambda_j}}{\lambda - \lambda_j} \qquad \text{and} \qquad S_{T,\lambda_k}(\lambda) = \sum_{\substack{j = 1 \\ j\neq k}}^r \frac{P_{\lambda_j}}{\lambda - \lambda_j} \]
\end{enumerate}
\end{corollary}

\subsection{Jordan decomposition}
TODO matrix representation + matrix representation of Lagrange-Sylvester. See Baumgrtel



